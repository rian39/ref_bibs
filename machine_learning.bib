


% Better BibLaTeX: generated
@inproceedings{Anjos_2012,
  pages = {1449–1452},
  shorttitle = {{Bob}},
  title = {{Bob: a free signal processing and machine learning toolbox for researchers}},
  url = {http://dl.acm.org/citation.cfm?id=2396517},
  options = {useprefix},
  booktitle = {{Proceedings of the 20th ACM international conference on Multimedia}},
  publisher = {{ACM}},
  author = {Anjos, André and El-Shafey, Laurent and Wallace, Roy and Günther, Manuel and McCool, Christopher and Marcel, Sébastien},
  urldate = {2014-05-05},
  date = {2012},
  year = {2012},
  file = {[PDF] from andreanjos.org:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/N4X56PTK/Anjos et al. - 2012 - Bob a free signal processing and machine learning.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/9T6WNQ62/citation.html:text/html}
}

% Better BibLaTeX: generated
@article{Pedregosa_2011,
  pages = {2825–2830},
  shorttitle = {{Scikit-learn}},
  title = {{Scikit-learn: Machine learning in Python}},
  url = {http://dl.acm.org/citation.cfm?id=2078195},
  volume = {{12}},
  options = {useprefix},
  journaltitle = {{The Journal of Machine Learning Research}},
  author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent},
  urldate = {2014-05-05},
  date = {2011},
  year = {2011},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/S2ZXCK4I/citation.html:text/html}
}

% Better BibLaTeX: generated
@online{Rotella_2012,
  abstract = {Recently, on a CNBC Squawk Box segment, “The Pulse of Silicon Valley,” host Joe Kernan posed the question, “What is the next really big thing?” to Ann Winblad, the legendary investor and senior partner at Hummer-Winblad. Her response: “Data is the new oil.” Winblad talked about predictive analytics as the new \[...\]},
  title = {{Is Data The New Oil?}},
  url = {http://www.forbes.com/sites/perryrotella/2012/04/02/is-data-the-new-oil/},
  options = {useprefix},
  titleaddon = {{Forbes}},
  author = {Rotella, Perry},
  urldate = {2014-05-06},
  date = {2012-02-02},
  year = {2012},
  keywords = {Building the Organization of Tomorrow,CEO Network,Leaders,leadership,Life In The New Workplace,Strategies Solutions,Strategies \& Solutions},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/EAUCA6WK/is-data-the-new-oil.html:text/html}
}

% Better BibLaTeX: generated
@article{Curtin_2013,
  pages = {801–805},
  shorttitle = {{MLPACK}},
  title = {{MLPACK: A scalable C++ machine learning library}},
  url = {http://dl.acm.org/citation.cfm?id=2502606},
  volume = {{14}},
  options = {useprefix},
  number = {1},
  journaltitle = {{The Journal of Machine Learning Research}},
  author = {Curtin, Ryan R. and Cline, James R. and Slagle, Neil P. and March, William B. and Ram, Parikshit and Mehta, Nishant A. and Gray, Alexander G.},
  urldate = {2014-05-05},
  date = {2013},
  year = {2013},
  file = {[PDF] from mlpack.org:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/6FQATCN9/Curtin et al. - 2013 - MLPACK A scalable C++ machine learning library.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/KDQ46ART/citation.html:text/html}
}

% Better BibLaTeX: generated
@article{Wu_2008,
  pages = {1–37},
  title = {{Top 10 algorithms in data mining}},
  volume = {{14}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Knowledge and Information Systems}},
  author = {Wu, X. and Kumar, V. and Ross Quinlan, J. and Ghosh, J. and Yang, Q. and Motoda, H. and McLachlan, G. J and Ng, A. and Liu, B. and Yu, P. S and {others}},
  date = {2008},
  year = {2008}
}

% Better BibLaTeX: generated
@video{StanfordUniversity_2008,
  abstract = {Lecture by Professor Andrew Ng for Machine Learning (CS 229) in the Stanford Computer Science department.  Professor Ng lectures on linear regression, gradient descent, and normal equations and discusses how they relate to machine learning. 

This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include supervised learning, unsupervised learning, learning theory, reinforcement learning and adaptive control.   Recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing are also discussed.

Complete Playlist for the Course:
http://www.youtube.com/view\_play\_list?p=A89DCFA6ADACE599

CCS 229 Course Website:
http://www.stanford.edu/class/cs229/

Stanford University:
http://www.stanford.edu/

Stanford University Channel on YouTube:
http://www.youtube.com/stanford},
  title = {{Lecture 2 | Machine Learning (Stanford)}},
  url = {http://www.youtube.com/watch?v=5u4G23\_OohI\&feature=youtube\_gdata\_player},
  options = {useprefix},
  editora = {{StanfordUniversity}},
  editoratype = {collaborator},
  urldate = {2013-02-11},
  date = {2008-07-23},
  year = {2008}
}

% Better BibLaTeX: generated
@article{_2010,
  shorttitle = {{The Grill}},
  title = {{The Grill: Tom Mitchell}},
  url = {http://www.computerworld.com/s/article/346917/The\_Grill\_Tom\_Mitchell},
  options = {useprefix},
  journaltitle = {{Computerworld}},
  urldate = {2012-03-09},
  date = {2010-02-22},
  year = {2010},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/NKP5QXI2/The_Grill_Tom_Mitchell.html:text/html}
}

% Better BibLaTeX: generated
@online{_,
  title = {{The Company for Apache Lucene Solr Open Source Search | Lucid Imagination}},
  url = {http://www.lucidimagination.com/},
  options = {useprefix},
  urldate = {2012-03-15}
}

% Better BibLaTeX: generated
@book{Clarke_2010,
  isbn = {0262026511},
  pagetotal = {632},
  shorttitle = {{Information Retrieval}},
  title = {{Information Retrieval: Implementing and Evaluating Search Engines}},
  options = {useprefix},
  publisher = {{The MIT Press}},
  author = {Clarke, Charles L. A. and Buettcher, Stefan and Cormack, Gordon V.},
  date = {2010-07-23},
  year = {2010}
}

% Better BibLaTeX: generated
@book{Manning_2008,
  edition = {{1}},
  isbn = {0521865719},
  pagetotal = {496},
  title = {{Introduction to Information Retrieval}},
  options = {useprefix},
  publisher = {{Cambridge University Press}},
  author = {Manning, Christopher D. and Raghavan, Prabhakar and Schütze, Hinrich},
  date = {2008-07-07},
  year = {2008}
}

% Better BibLaTeX: generated
@article{Breiman_2001,
  pages = {5–32},
  title = {{Random forests}},
  volume = {{45}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Machine learning}},
  author = {Breiman, L.},
  date = {2001},
  year = {2001}
}

% Better BibLaTeX: generated
@article{Ensmenger_2012,
  abstract = {Since the mid 1960s, researchers in computer science have famously referred to chess as the ‘drosophila’ of artificial intelligence (AI). What they seem to mean by this is that chess, like the common fruit fly, is an accessible, familiar, and relatively simple experimental technology that nonetheless can be used productively to produce valid knowledge about other, more complex systems. But for historians of science and technology, the analogy between chess and drosophila assumes a larger significance. As Robert Kohler has ably described, the decision to adopt drosophila as the organism of choice for genetics research had far-reaching implications for the development of 20th century biology. In a similar manner, the decision to focus on chess as the measure of both human and computer intelligence had important and unintended consequences for AI research. This paper explores the emergence of chess as an experimental technology, its significance in the developing research practices of the AI community, and the unique ways in which the decision to focus on chess shaped the program of AI research in the decade of the 1970s. More broadly, it attempts to open up the virtual black box of computer software – and of computer games in particular – to the scrutiny of historical and sociological analysis.},
  doi = {10.1177/0306312711424596},
  issn = {0306-3127, 1460-3659},
  pages = {5-30},
  shorttitle = {{Is chess the drosophila of artificial intelligence?}},
  title = {{Is Chess the Drosophila of Artificial Intelligence? A Social History of an Algorithm}},
  url = {http://sss.sagepub.com.ezproxy.lancs.ac.uk/content/42/1/5},
  volume = {{42}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Social Studies of Science}},
  shortjournal = {{Social Studies of Science}},
  author = {Ensmenger, Nathan},
  urldate = {2012-05-28},
  date = {2012-02-01},
  year = {2012},
  langid = {english},
  keywords = {artificial intelligence,computing,drosophila,experimental technology},
  file = {Is chess the drosophila of artificial intelligence? A social history of an algorithm:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/V3KGKEKN/5.html:text/html;Is chess the drosophila of artificial intelligence? A social history of an algorithm:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/SXFNK8TD/5.html:text/html}
}

% Better BibLaTeX: generated
@video{Bacon_2012,
  abstract = {Vimeo is the home for high-quality videos and the people who love them.},
  title = {{Hilary Mason - Machine Learning for Hackers}},
  url = {http://vimeo.com/43547079},
  options = {useprefix},
  author = {{Bacon}},
  urldate = {2012-07-06},
  date = {2012-06-06},
  year = {2012},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/XXH9QQJS/43547079.html:text/html}
}

% Better BibLaTeX: generated
@book{Koren_2009,
  abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest-neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels. Modern consumers are inundated with choices. Electronic retailers and content providers offer a huge selection of products, with unprecedented opportunities to meet a variety of special needs and tastes. Matching consumers with the most appropriate products is key to enhancing user satisfaction and loyalty. Therefore, more retailers have become interested in recommender systems, which analyze patterns of user interest in products to provide personalized recommendations that suit a user’s taste. Because good personalized recommendations can add another dimension to the user experience, e-commerce leaders like Amazon.com and Netflix have made recommender systems a salient part of their websites. Such systems are particularly useful for entertainment products such as movies, music, and TV shows. Many customers will view the same movie, and each customer is likely to view numerous different movies. Customers have proven willing to indicate their level of satisfaction with particular movies, so a huge volume of data is available about which movies appeal to which customers. Companies can analyze this data to recommend movies to particular customers. Recommender system strategies Broadly speaking, recommender systems are based on one of two strategies. The content filtering approach creates a profile for each user or product to characterize its nature. For example, a movie profile could include attributes regarding its genre, the participating actors, its box office popularity, and so forth. User profiles might include demographic information or answers provided on a suitable questionnaire. The profiles allow programs to associate users with matching products. Of course, content-based strategies require gathering external information that might not be available or easy to collect. A known successful realization of content filtering is the Music Genome Project, which is used for the Internet radio service Pandora.com. A trained music analyst scores},
  title = {{Matrix Factorization Techniques for Recommender Systems}},
  options = {useprefix},
  author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
  date = {2009},
  year = {2009},
  file = {Citeseer - Full Text PDF:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/KSM4IF25/Koren et al. - 2009 - Matrix Factorization Techniques for Recommender Sy.pdf:application/pdf;Citeseer - Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/RHNCXHWT/summary.html:text/html}
}

% Better BibLaTeX: generated, soft conflict
@online{_a,
  title = {{dataists » A Taxonomy of Data Science}},
  url = {http://www.dataists.com/2010/09/a-taxonomy-of-data-science/},
  options = {useprefix},
  urldate = {2012-07-06},
  file = {dataists » A Taxonomy of Data Science:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/6VAB8TUH/a-taxonomy-of-data-science.html:text/html}
}

% Better BibLaTeX: generated
@article{Wagstaff_2012,
  abstract = {Much of current machine learning (ML) research has lost its connection to problems of import to the larger world of science and society. From this perspective, there exist glaring limitations in the data sets we investigate, the metrics we employ for evaluation, and the degree to which results are communicated back to their originating domains. What changes are needed to how we conduct research to increase the impact that ML has? We present six Impact Challenges to explicitly focus the field?s energy and attention, and we discuss existing obstacles that must be addressed. We aim to inspire ongoing discussion and focus on ML that matters.},
  title = {{Machine Learning that Matters}},
  url = {http://arxiv.org/abs/1206.4656},
  options = {useprefix},
  journaltitle = {{arXiv:1206.4656}},
  author = {Wagstaff, Kiri},
  urldate = {2012-07-16},
  date = {2012-06-18},
  year = {2012},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Learning,Statistics - Machine Learning},
  file = {1206.4656 PDF:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/UZRQSNZ9/Wagstaff - 2012 - Machine Learning that Matters.pdf:application/pdf;arXiv.org Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/XGPZ3HCN/1206.html:text/html}
}

% Better BibLaTeX: generated
@article{Langley_2011,
  pages = {275–279},
  title = {{The changing science of machine learning}},
  url = {http://www.springerlink.com/index/J067H855N8223338.pdf},
  volume = {{82}},
  options = {useprefix},
  number = {3},
  journaltitle = {{Machine Learning}},
  author = {Langley, P.},
  urldate = {2012-06-21},
  date = {2011},
  year = {2011}
}

% Better BibLaTeX: generated
@article{Carstens_2011,
  title = {{Sentiment Analysis}},
  url = {http://www.doc.ic.ac.uk/teaching/distinguished-projects/2011/l.carstens.pdf},
  options = {useprefix},
  author = {Carstens, L. and Intelligence, S. A},
  urldate = {2012-06-21},
  date = {2011},
  year = {2011}
}

% Better BibLaTeX: generated, soft conflict
@article{Wagstaff_2012a,
  title = {{Machine Learning that Matters}},
  url = {http://ml.jpl.nasa.gov/papers/wagstaff/wagstaff-MLmatters-icml12.pdf},
  options = {useprefix},
  author = {Wagstaff, K. L},
  urldate = {2012-06-21},
  date = {2012},
  year = {2012}
}

% Better BibLaTeX: generated
@book{Conway_2012,
  edition = {{1}},
  isbn = {1449303714},
  pagetotal = {324},
  title = {{Machine Learning for Hackers}},
  options = {useprefix},
  publisher = {{O'Reilly Media}},
  author = {Conway, Drew and White, John Myles},
  date = {2012},
  year = {2012}
}

% Better BibLaTeX: generated
@book{Vapnik_1999,
  edition = {{2nd ed. 2000}},
  isbn = {0387987800},
  pagetotal = {314},
  title = {{The Nature of Statistical Learning Theory}},
  options = {useprefix},
  publisher = {{Springer}},
  author = {Vapnik, Vladimir},
  date = {1999-12-01},
  year = {1999}
}

% Better BibLaTeX: generated
@inproceedings{Ma_2009,
  pages = {681–688},
  shorttitle = {{Identifying suspicious URLs}},
  title = {{Identifying suspicious URLs: an application of large-scale online learning}},
  url = {http://dl.acm.org/citation.cfm?id=1553462},
  options = {useprefix},
  booktitle = {{Proceedings of the 26th Annual International Conference on Machine Learning}},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2009},
  year = {2009},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/BS4JEB3N/citation.html:text/html}
}

% Better BibLaTeX: generated, soft conflict
@inproceedings{Ma_2009a,
  pages = {1245–1254},
  shorttitle = {{Beyond blacklists}},
  title = {{Beyond blacklists: learning to detect malicious web sites from suspicious URLs}},
  url = {http://dl.acm.org/citation.cfm?id=1557153},
  options = {useprefix},
  booktitle = {{Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining}},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2009},
  year = {2009},
  file = {[PDF] from sinica.edu.tw:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/V3934UNU/Ma et al. - 2009 - Beyond blacklists learning to detect malicious we.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/3GI8RQQN/citation.html:text/html}
}

% Better BibLaTeX: generated
@article{Ma_2011,
  pages = {30},
  title = {{Learning to detect malicious URLs}},
  url = {http://dl.acm.org/citation.cfm?id=1961202},
  volume = {{2}},
  options = {useprefix},
  number = {3},
  journaltitle = {{ACM Transactions on Intelligent Systems and Technology (TIST)}},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2011},
  year = {2011},
  file = {[PDF] from berkeley.edu:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/BJ2GZCKP/Ma et al. - 2011 - Learning to detect malicious URLs.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/VS6CUR7Z/citation.html:text/html}
}

% Better BibLaTeX: generated
@article{Le_2011,
  abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8\% accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70\% relative im- provement over the previous state-of-the-art.},
  title = {{Building high-level features using large scale unsupervised learning}},
  url = {http://arxiv.org/abs/1112.6209},
  options = {useprefix},
  journaltitle = {{arXiv:1112.6209}},
  author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
  urldate = {2013-04-21},
  date = {2011-12-28},
  year = {2011},
  keywords = {Computer Science - Learning},
  file = {1112.6209 PDF:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/QUF2DCRS/Le et al. - 2011 - Building high-level features using large scale uns.pdf:application/pdf;arXiv.org Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/TU8JVCMI/1112.html:text/html}
}

% Better BibLaTeX: generated
@mvbook{Bishop_2006,
  title = {{Pattern recognition and machine learning}},
  url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
  volume = {{1}},
  options = {useprefix},
  publisher = {{springer New York}},
  author = {Bishop, Christopher M. and Nasrabadi, Nasser M.},
  urldate = {2013-07-12},
  date = {2006},
  year = {2006},
  file = {[PDF] from wisc.edu:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/DWIDSVQD/Bishop and Nasrabadi - 2006 - Pattern recognition and machine learning.pdf:application/pdf}
}

% Better BibLaTeX: generated
@book{Murphy_2012,
  abstract = {"This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online"--Back cover.},
  isbn = {9780262018029  0262018020},
  location = {{Cambridge, MA}},
  shorttitle = {{Machine learning}},
  title = {{Machine learning: a probabilistic perspective}},
  options = {useprefix},
  publisher = {{MIT Press}},
  author = {Murphy, Kevin P},
  date = {2012},
  year = {2012},
  langid = {english}
}

% Better BibLaTeX: generated
@article{BBC_2012,
  abstract = {A Google research team has trained a network of 1,000 computers wired up like the human brain to recognise cats.},
  title = {{Google 'brain' machine spots cats}},
  url = {http://www.bbc.co.uk/news/technology-18595351},
  options = {useprefix},
  journaltitle = {{BBC News}},
  author = {{BBC}},
  urldate = {2013-06-06},
  date = {2012-06-26},
  year = {2012},
  file = {BBC News Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/GX9SSXDE/technology-18595351.html:text/html}
}

% Better BibLaTeX: generated, soft conflict
@article{Breiman_2001a,
  pages = {199–231},
  shorttitle = {{Statistical modeling}},
  title = {{Statistical modeling: The two cultures (with comments and a rejoinder by the author)}},
  url = {http://projecteuclid.org/euclid.ss/1009213726},
  volume = {{16}},
  options = {useprefix},
  number = {3},
  journaltitle = {{Statistical Science}},
  author = {Breiman, Leo},
  urldate = {2013-06-10},
  date = {2001},
  year = {2001},
  file = {[PDF] from recognition.su:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/U23JA82S/Breiman - 2001 - Statistical modeling The two cultures (with comme.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/XNW8S5Q5/DPubS.html:text/html}
}

% Better BibLaTeX: generated, soft conflict
@video{StanfordUniversity_2008a,
  abstract = {Lecture by Professor Andrew Ng for Machine Learning (CS 229) in the Stanford Computer Science department.  Professor Ng provides an overview of the course in this introductory meeting. 

This course provides a broad introduction to machine learning and statistical pattern recognition. Topics include supervised learning, unsupervised learning, learning theory, reinforcement learning and adaptive control.   Recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing are also discussed.

Complete Playlist for the Course:
http://www.youtube.com/view\_play\_list?p=A89DCFA6ADACE599

CS 229 Course Website:
http://www.stanford.edu/class/cs229/

Stanford University:
http://www.stanford.edu/

Stanford University Channel on YouTube:
http://www.youtube.com/stanford},
  title = {{Lecture 1 | Machine Learning (Stanford)}},
  url = {http://www.youtube.com/watch?v=UzxYlbK2c7E\&feature=youtube\_gdata\_player},
  options = {useprefix},
  editora = {{StanfordUniversity}},
  editoratype = {collaborator},
  urldate = {2013-06-10},
  date = {2008-07-23},
  year = {2008}
}

% Better BibLaTeX: generated
@article{Wacquant_2010,
  pages = {69},
  title = {{Participant Observation/Observant Participation}},
  url = {http://books.google.co.uk/books?hl=en\&lr=\&id=pLSAay\_xwjEC\&oi=fnd\&pg=PA69\&dq=wacquant+observant+\&ots=LUgGkfHYRD\&sig=WwrRprm32d0QB4H8LScW8zlINHc},
  options = {useprefix},
  journaltitle = {{Sociology: Introductory Readings}},
  author = {Wacquant, Loïc},
  urldate = {2013-06-11},
  date = {2010},
  year = {2010},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/JJ9N4N2X/books.html:text/html}
}

% Better BibLaTeX: generated
@book{Barber_2011,
  abstract = {"Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online"-- "Vast amounts of data present amajor challenge to all thoseworking in computer science, and its many related fields, who need to process and extract value from such data. Machine learning technology is already used to help with this task in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis and robot locomotion. As its usage becomes more widespread, no student should be without the skills taught in this book. Designed for final-year undergraduate and graduate students, this gentle introduction is ideally suited to readers without a solid background in linear algebra and calculus. It covers everything from basic reasoning to advanced techniques in machine learning, and rucially enables students to construct their own models for real-world problems by teaching them what lies behind the methods. Numerous examples and exercises are included in the text. Comprehensive resources for students and instructors are available online"--},
  isbn = {9780521518147 0521518148},
  location = {{Cambridge; New York}},
  title = {{Bayesian reasoning and machine learning}},
  options = {useprefix},
  publisher = {{Cambridge University Press}},
  author = {Barber, David},
  date = {2011},
  year = {2011},
  langid = {english}
}

% Better BibLaTeX: generated
@book{Wacquant_2004,
  location = {{Oxford}},
  title = {{Body and Soul. Notebooks of an apprentice boxer}},
  options = {useprefix},
  publisher = {{Oxford University Press}},
  author = {Wacquant, Loic},
  date = {2004},
  year = {2004}
}

% Better BibLaTeX: generated
@article{Olazaran_1996,
  abstract = {In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the `perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the `research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate.},
  doi = {10.1177/030631296026003005},
  issn = {0306-3127, 1460-3659},
  pages = {611-659},
  title = {{A Sociological Study of the Official History of the Perceptrons Controversy}},
  url = {http://sss.sagepub.com/content/26/3/611},
  volume = {{26}},
  options = {useprefix},
  number = {3},
  journaltitle = {{Social Studies of Science}},
  shortjournal = {{Social Studies of Science}},
  author = {Olazaran, Mikel},
  urldate = {2013-06-17},
  date = {1996-01-08},
  year = {1996},
  langid = {english},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/U5C4XRIM/611.html:text/html}
}

% Better BibLaTeX: generated
@online{Ng_,
  abstract = {Video Lecture:  in Machine Learning on Coursera.},
  title = {{| Machine Learning III: Linear Algebra Review}},
  url = {https://class.coursera.org/ml-003/lecture/},
  options = {useprefix},
  titleaddon = {{Coursera}},
  author = {Ng, Andrew},
  urldate = {2013-06-14},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/N72CWJG4/index.html:text/html}
}

% Better BibLaTeX: generated
@article{Rosenblatt_1958,
  abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
  doi = {10.1037/h0042519},
  issn = {1939-1471(Electronic);0033-295X(Print)},
  pages = {386-408},
  rights = {{(c) 2012 APA, all rights reserved}},
  shorttitle = {{The perceptron}},
  title = {{The perceptron: A probabilistic model for information storage and organization in the brain}},
  volume = {{65}},
  options = {useprefix},
  number = {6},
  journaltitle = {{Psychological Review}},
  author = {Rosenblatt, F.},
  date = {1958},
  year = {1958},
  keywords = {brain,information storage,probabilistic model}
}

% Better BibLaTeX: generated
@article{Minsky_1969,
  pages = {88},
  shorttitle = {{Perceptron}},
  title = {{Perceptron: an introduction to computational geometry}},
  volume = {{19}},
  options = {useprefix},
  journaltitle = {{The MIT Press, Cambridge, expanded edition}},
  author = {Minsky, Marvin and Papert, Seymour},
  date = {1969},
  year = {1969}
}

% Better BibLaTeX: generated
@online{Dahl_2013,
  abstract = {What was your background prior to entering this challenge? We are a team of computer science and statistics academics. Ruslan Salakhutdinov and Geoff Hinton are professors at the University of Toro...},
  shorttitle = {{Deep Learning How I Did It}},
  title = {{Deep Learning How I Did It: Merck 1st place interview}},
  url = {http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/},
  options = {useprefix},
  titleaddon = {{no free hunch}},
  author = {Dahl, George},
  urldate = {2013-06-17},
  date = {2013},
  year = {2013},
  keywords = {code,geoff hinton,learning,machine,merck,model,neural,professor hinton},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/2M52PT7J/deep-learning-how-i-did-it-merck-1st-place-interview.html:text/html}
}

% Better BibLaTeX: generated
@article{Hinton_2006,
  pages = {504–507},
  title = {{Reducing the dimensionality of data with neural networks}},
  url = {http://www.sciencemag.org/content/313/5786/504.short},
  volume = {{313}},
  options = {useprefix},
  number = {5786},
  journaltitle = {{Science}},
  author = {Hinton, Geoffrey E. and Salakhutdinov, Ruslan R.},
  urldate = {2013-06-17},
  date = {2006},
  year = {2006},
  file = {[PDF] from uni-saarland.de:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/KGM75BT4/Hinton and Salakhutdinov - 2006 - Reducing the dimensionality of data with neural ne.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/WRD6BG4A/504.html:text/html}
}

% Better BibLaTeX: generated
@article{Ackley_1985,
  pages = {147–169},
  title = {{A learning algorithm for Boltzmann machines}},
  url = {http://www.sciencedirect.com/science/article/pii/S0364021385800124},
  volume = {{9}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Cognitive science}},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  urldate = {2013-06-17},
  date = {1985},
  year = {1985},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/G6CJZC4J/S0364021385800124.html:text/html}
}

% Better BibLaTeX: generated
@online{KDD_2013,
  title = {{Call For KDD Cup}},
  url = {http://www.kdd.org/kdd2013/call-for-cup},
  options = {useprefix},
  author = {{KDD}},
  urldate = {2013-07-23},
  date = {2013},
  year = {2013},
  file = {Call For KDD Cup | http\://www.kdd.org/kdd2013:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/WG5FVTJU/call-for-cup.html:text/html}
}

% Better BibLaTeX: generated
@inreference{_2013,
  abstract = {In computational geometry, the perceptron is an algorithm for supervised classification of an input into one of several possible non-binary outputs. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector describing a given input using the delta rule. The learning algorithm for perceptrons is an online algorithm, in that it processes elements in the training set one at a time.},
  rights = {{Creative Commons Attribution-ShareAlike License}},
  title = {{Perceptron}},
  url = {http://en.wikipedia.org/w/index.php?title=Perceptron\&oldid=557301943},
  options = {useprefix},
  booktitle = {{Wikipedia, the free encyclopedia}},
  urldate = {2013-06-17},
  date = {2013-05-29},
  year = {2013},
  langid = {english},
  note = {Page Version ID: 557301943},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/P3MWEXNI/index.html:text/html}
}

% Better BibLaTeX: generated
@article{Patil_2010,
  pages = {1},
  shorttitle = {{PyMC}},
  title = {{PyMC: Bayesian stochastic modelling in Python}},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3097064/},
  volume = {{35}},
  options = {useprefix},
  number = {4},
  journaltitle = {{Journal of statistical software}},
  author = {Patil, Anand and Huard, David and Fonnesbeck, Christopher J.},
  urldate = {2013-06-17},
  date = {2010},
  year = {2010},
  file = {[HTML] from nih.gov:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/3NWB7TGN/PMC3097064.html:text/html}
}

% Better BibLaTeX: generated
@video{Koller_2012,
  abstract = {Daphne Koller is enticing top universities to put their most intriguing courses online for free -- not just as a service, but as a way to research how people learn. With Coursera (cofounded by Andrew Ng), each keystroke, quiz, peer-to-peer discussion and self-graded assignment builds an unprecedented pool of data on how knowledge is processed.},
  shorttitle = {{Daphne Koller}},
  title = {{Daphne Koller: What we're learning from online education | Video on TED.com}},
  url = {http://www.ted.com/talks/daphne\_koller\_what\_we\_re\_learning\_from\_online\_education.html},
  options = {useprefix},
  editora = {Koller, Daphne},
  editoratype = {collaborator},
  urldate = {2013-06-24},
  date = {2012-08},
  year = {2012},
  keywords = {Computers,education,global issues,Internet,Talks,TED},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/83HZTXGW/daphne_koller_what_we_re_learning_from_online_education.html:text/html}
}

% Better BibLaTeX: generated
@book{Alpaydin_2010,
  isbn = {9780262012430  026201243X},
  location = {{Cambridge, Massachusetts; London}},
  title = {{Introduction to machine learning}},
  options = {useprefix},
  publisher = {{The MIT Press}},
  author = {Alpaydin, E},
  date = {2010},
  year = {2010},
  langid = {english}
}

% Better BibLaTeX: generated
@book{Rasmussen_2006,
  abstract = {"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics."--Jacket.},
  isbn = {026218253X 9780262182539},
  location = {{Cambridge, Mass.}},
  title = {{Gaussian processes for machine learning}},
  options = {useprefix},
  publisher = {{MIT Press}},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I},
  date = {2006},
  year = {2006},
  langid = {english}
}

% Better BibLaTeX: generated
@book{Marsland_2009,
  isbn = {9781420067187  1420067184},
  location = {{Boca Raton, Mass. \[u.a.}},
  shorttitle = {{Machine learning}},
  title = {{Machine learning: an algorithmic perspective}},
  options = {useprefix},
  publisher = {{CRC Press/Taylor \& Francis}},
  author = {Marsland, Stephen},
  date = {2009},
  year = {2009},
  langid = {english}
}

% Better BibLaTeX: generated
@book{Mitchell_1997,
  isbn = {0071154671 9780071154673},
  location = {{New York, NY \[u.a.}},
  title = {{Machine learning}},
  options = {useprefix},
  publisher = {{McGraw-Hill}},
  author = {Mitchell, Tom M},
  date = {1997},
  year = {1997},
  langid = {english}
}

% Better BibLaTeX: generated
@article{Ward_2006,
  abstract = {ObjectiveTo identify demographic and clinical characteristics that classify patients with systemic lupus erythematosus (SLE) at risk for in-hospital mortality.MethodsPatients hospitalized in California from 1996 to 2000 with a principal diagnosis of SLE (N = 3,839) were identified from a state hospitalization database. As candidate predictors of mortality, we used patient demographic characteristics; the presence or absence of 40 different clinical conditions listed among the discharge diagnoses; and 2 summary indexes derived from the discharge diagnoses, the Charlson Index and the SLE Comorbidity Index. Predictors of patients at increased risk of mortality were identified and validated using random forests, a statistical procedure that is a generalization of single classification trees. Random forests use bootstrapped samples of patients and randomly selected subsets of predictors to create individual classification trees, and this process is repeated to generate multiple trees (a forest). Classification is then done by majority vote across all trees.ResultsOf the 3,839 patients, 109 died during hospitalization. Selecting from all available predictors, the random forests had excellent predictive accuracy for classification of death. The mean classification error rate, averaged over 10 forests of 500 trees each, was 11.9\%. The most important predictors were the Charlson Index, respiratory failure, SLE Comorbidity Index, age, sepsis, nephritis, and thrombocytopenia.ConclusionInformation on clinical diagnoses can be used to accurately predict mortality among hospitalized patients with SLE. Random forests represent a useful technique to identify the most important predictors from a larger (often much larger) number and to validate the classification.},
  doi = {10.1002/art.21695},
  issn = {1529-0131},
  pages = {74–80},
  rights = {{Copyright © 2006 by the American College of Rheumatology}},
  shorttitle = {{Short-term prediction of mortality in patients with systemic lupus erythematosus}},
  title = {{Short-term prediction of mortality in patients with systemic lupus erythematosus: Classification of outcomes using random forests}},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/art.21695/abstract},
  volume = {{55}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Arthritis Care \& Research}},
  author = {Ward, Michael M. and Pajevic, Sinisa and Dreyfuss, Jonathan and Malley, James D.},
  urldate = {2013-07-16},
  date = {2006},
  year = {2006},
  langid = {english},
  keywords = {Classification tree,Hospitalization,Mortality,Random forest,Systemic lupus erythematosus},
  file = {Full Text PDF:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/TC4ZHWXS/Ward et al. - 2006 - Short-term prediction of mortality in patients wit.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/DIDEBIB3/abstract.html:text/html}
}

% Better BibLaTeX: generated
@article{Steinberg_2009,
  pages = {179–201},
  shorttitle = {{CART}},
  title = {{CART: classification and regression trees}},
  url = {http://books.google.co.uk/books?hl=en\&lr=\&id=\_kcEn-c9kYAC\&oi=fnd\&pg=PA179\&dq=dan+steinberg+cart\&ots=eQ7jtfUODm\&sig=Xs8kegu\_D4DcrPhT6TUkB0LCV1A},
  options = {useprefix},
  journaltitle = {{The Top Ten Algorithms in Data Mining}},
  author = {Steinberg, Dan and Colla, Phillip},
  urldate = {2013-09-12},
  date = {2009},
  year = {2009},
  note = {00245},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/CMM3XGQE/books.html:text/html}
}

% Better BibLaTeX: generated
@article{Morgan_1963,
  pages = {415–434},
  title = {{Problems in the analysis of survey data, and a proposal}},
  url = {http://amstat.tandfonline.com/doi/full/10.1080/01621459.1963.10500855},
  volume = {{58}},
  options = {useprefix},
  number = {302},
  journaltitle = {{Journal of the American Statistical Association}},
  author = {Morgan, James N. and Sonquist, John A.},
  urldate = {2013-09-17},
  date = {1963},
  year = {1963},
  note = {00873},
  file = {[PDF] from uiuc.edu:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/8UI33RE4/Morgan and Sonquist - 1963 - Problems in the analysis of survey data, and a pro.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/7HCASV3V/01621459.1963.html:text/html}
}

% Better BibLaTeX: generated
@article{Cortes_1995,
  abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
  doi = {10.1023/A:1022627411411},
  issn = {0885-6125},
  pages = {273-297},
  title = {{Support-Vector Networks}},
  volume = {{20}},
  options = {useprefix},
  number = {3},
  journaltitle = {{Machine Learning}},
  shortjournal = {{Mach. Learn.}},
  author = {Cortes, C. and Vapnik, V.},
  date = {1995-09},
  year = {1995},
  langid = {english},
  note = {11952},
  keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers}
}

% Better BibLaTeX: generated
@article{Einhorn_1972,
  abstract = {Access to powerful new computers has encouraged routine use of highly complex analytic techniques, often in the absence of any theory, hypotheses, or model to guide the researcher's expectations of results. The author examines the potential of such techniques for generating spurious results, and urges that in exploratory work the outcome be subjected to a more rigorous criterion than the usual tests of statistical significance.},
  doi = {10.1086/268019},
  issn = {0033-362X, 1537-5331},
  pages = {367-378},
  title = {{Alchemy in the Behavioral Sciences}},
  url = {http://poq.oxfordjournals.org/content/36/3/367},
  volume = {{36}},
  options = {useprefix},
  number = {3},
  journaltitle = {{Public Opinion Quarterly}},
  shortjournal = {{Public Opin Q}},
  author = {Einhorn, Hillel J.},
  urldate = {2013-09-18},
  date = {1972-09-21},
  year = {1972},
  langid = {english},
  note = {00060},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/X3J3BMFX/367.html:text/html}
}

% Better BibLaTeX: generated
@article{Breiman_1984,
  shorttitle = {{CART}},
  title = {{CART: Classification and regression trees}},
  volume = {{156}},
  options = {useprefix},
  journaltitle = {{Wadsworth: Belmont, CA}},
  author = {Breiman, Leo and Friedman, Jerome and Olshen, Richard and Stone, Charles and Steinberg, D. and Colla, P.},
  date = {1984},
  year = {1984},
  note = {00004}
}

% Better BibLaTeX: generated
@article{Doyle_1973,
  pages = {465–467},
  title = {{The use of automatic interaction detector and similar search procedures}},
  url = {http://www.jstor.org/stable/10.2307/3008131},
  options = {useprefix},
  journaltitle = {{Operational Research Quarterly}},
  author = {Doyle, Peter},
  urldate = {2013-09-18},
  date = {1973},
  year = {1973},
  note = {00056},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/DXU7KQHG/3008131.html:text/html}
}

% Better BibLaTeX: generated
@article{Cover_1967,
  pages = {21–27},
  title = {{Nearest neighbor pattern classification}},
  url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1053964},
  volume = {{13}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Information Theory, IEEE Transactions on}},
  author = {Cover, Thomas and Hart, Peter},
  urldate = {2013-09-19},
  date = {1967},
  year = {1967},
  note = {05055},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/AQB243F7/login.html:text/html}
}

% Better BibLaTeX: generated
@article{Friedman_1977,
  pages = {404-408},
  title = {{Recursive Partitioning Decision Rule for Nonparametric Classification}},
  volume = {{26}},
  options = {useprefix},
  number = {4},
  journaltitle = {{Ieee Transactions on Computers}},
  author = {Friedman, Jh},
  date = {1977},
  year = {1977},
  note = {00364}
}

% Better BibLaTeX: generated
@article{Quinlan_1986,
  pages = {81–106},
  title = {{Induction of decision trees}},
  url = {http://link.springer.com/article/10.1023/A:1022643204877},
  volume = {{1}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Machine learning}},
  author = {Quinlan, J. Ross},
  urldate = {2013-09-25},
  date = {1986},
  year = {1986},
  note = {12427},
  file = {[PDF] from googlecode.com:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/3VG28M3F/Quinlan - 1986 - Induction of decision trees.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/MAF3CH37/A1022643204877.html:text/html}
}

% Better BibLaTeX: generated
@article{Domingos_2012,
  pages = {78–87},
  title = {{A few useful things to know about machine learning}},
  url = {http://dl.acm.org/citation.cfm?id=2347755},
  volume = {{55}},
  options = {useprefix},
  number = {10},
  journaltitle = {{Communications of the ACM}},
  author = {Domingos, Pedro},
  urldate = {2013-09-25},
  date = {2012},
  year = {2012},
  note = {00027},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/K92BG2X7/citation.html:text/html}
}

% Better BibLaTeX: generated
@mvbook{Quinlan_1993,
  shorttitle = {{C4. 5}},
  title = {{C4. 5: programs for machine learning}},
  url = {http://books.google.co.uk/books?hl=en\&lr=\&id=HExncpjbYroC\&oi=fnd\&pg=PR7\&dq=quinlan+c4.5\&ots=nKr8dYr51o\&sig=e8CDMoHt0VGemFkhf8z9VMA8KlI},
  volume = {{1}},
  options = {useprefix},
  publisher = {{Morgan kaufmann}},
  author = {Quinlan, John Ross},
  urldate = {2013-09-26},
  date = {1993},
  year = {1993},
  note = {22318},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/N6GSGR8B/books.html:text/html}
}

% Better BibLaTeX: generated
@mvbook{Bellman_1961,
  shorttitle = {{Adaptive control processes}},
  title = {{Adaptive control processes: a guided tour}},
  url = {http://www.getcited.org/pub/101191710},
  volume = {{4}},
  options = {useprefix},
  publisher = {{Princeton university press Princeton}},
  author = {Bellman, Richard},
  urldate = {2013-09-30},
  date = {1961},
  year = {1961},
  note = {02427},
  file = {Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/JA2JAC9D/101191710.html:text/html}
}

% Better BibLaTeX: generated
@article{Chang_2011,
  pages = {27},
  shorttitle = {{LIBSVM}},
  title = {{LIBSVM: a library for support vector machines}},
  url = {http://dl.acm.org.ezproxy.lancs.ac.uk/citation.cfm?id=1961199},
  volume = {{2}},
  options = {useprefix},
  number = {3},
  journaltitle = {{ACM Transactions on Intelligent Systems and Technology (TIST)}},
  author = {Chang, Chih-Chung and Lin, Chih-Jen},
  urldate = {2013-10-04},
  date = {2011},
  year = {2011},
  note = {14513},
  file = {[PDF] from 140.112.30.28:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/9X4U49SA/Chang and Lin - 2011 - LIBSVM a library for support vector machines.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/K9XNAVFS/citation.html:text/html}
}

% Better BibLaTeX: generated
@article{Burges_1998,
  pages = {121–167},
  title = {{A tutorial on support vector machines for pattern recognition}},
  url = {http://link.springer.com.ezproxy.lancs.ac.uk/article/10.1023/A:1009715923555},
  volume = {{2}},
  options = {useprefix},
  number = {2},
  journaltitle = {{Data mining and knowledge discovery}},
  author = {Burges, Christopher JC},
  urldate = {2013-10-04},
  date = {1998},
  year = {1998},
  note = {12162},
  file = {[PDF] from mingzeng.net:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/29STDTR3/Burges - 1998 - A tutorial on support vector machines for pattern .pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/MQ5JNWFJ/A1009715923555.html:text/html}
}

% Better BibLaTeX: generated
@article{Fisher_1936,
  pages = {179–188},
  title = {{The use of multiple measurements in taxonomic problems}},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/full},
  volume = {{7}},
  options = {useprefix},
  number = {2},
  journaltitle = {{Annals of eugenics}},
  author = {Fisher, Ronald A.},
  urldate = {2013-10-04},
  date = {1936},
  year = {1936},
  note = {08904},
  file = {[PDF] from adelaide.edu.au:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/IIB6XP2G/Fisher - 1936 - The use of multiple measurements in taxonomic prob.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/MUEZJMAQ/full.html:text/html}
}

% Better BibLaTeX: generated
@article{Vapnik_1971,
  pages = {264–280},
  title = {{On the uniform convergence of relative frequencies of events to their probabilities}},
  url = {http://epubs.siam.org/doi/abs/10.1137/1116025},
  volume = {{16}},
  options = {useprefix},
  number = {2},
  journaltitle = {{Theory of Probability \& Its Applications}},
  author = {Vapnik, Vladimir N. and Chervonenkis, A. Ya},
  urldate = {2013-10-11},
  date = {1971},
  year = {1971},
  note = {02515},
  file = {[PDF] from zju88.org:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/J7TCIZWC/Vapnik and Chervonenkis - 1971 - On the uniform convergence of relative frequencies.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/IF97DCJ2/1116025.html:text/html}
}

% Better BibLaTeX: generated, soft conflict
@article{Pedregosa_2011a,
  pages = {2825–2830},
  title = {{Scikit-learn: Machine Learning in Python}},
  volume = {{12}},
  options = {useprefix},
  journaltitle = {{Journal of Machine Learning Research}},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  date = {2011},
  year = {2011},
  note = {00285}
}

% Better BibLaTeX: generated
@article{Valiant_1984,
  pages = {1134–1142},
  title = {{A theory of the learnable}},
  url = {http://dl.acm.org/citation.cfm?id=1972},
  volume = {{27}},
  options = {useprefix},
  number = {11},
  journaltitle = {{Communications of the ACM}},
  author = {Valiant, Leslie G.},
  urldate = {2013-12-16},
  date = {1984},
  year = {1984},
  note = {04407},
  file = {[PDF] from iitk.ac.in:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/C43SG9FS/Valiant - 1984 - A theory of the learnable.pdf:application/pdf;Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/GPXTHEXZ/citation.html:text/html}
}

% Better BibLaTeX: generated
@book{Jain_2008,
  abstract = {Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into taxonomic ranks: domain, kingdom, phylum, class, etc.). Cluster analysis is the formal study of algorithms and methods for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is exploratory in nature to find structure in data. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty of designing a general purpose clustering algorithm and the illposed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection, and data clustering and large scale data clustering.},
  shorttitle = {{Data Clustering}},
  title = {{Data Clustering: 50 Years Beyond K-Means}},
  options = {useprefix},
  author = {Jain, Anil K.},
  date = {2008},
  year = {2008},
  note = {00044},
  file = {Citeseer - Full Text PDF:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/U56GQPVZ/Jain - 2008 - Data Clustering 50 Years Beyond K-Means.pdf:application/pdf;Citeseer - Snapshot:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/B2IQPERU/summary.html:text/html}
}

% Better BibLaTeX: generated
@book{Solovey_2012,
  abstract = {From World War II to the early 1970s, social science research expanded in dramatic and unprecedented fashion in the United States, which became the world's acknowledged leader in the field. This volume examines how, why, and with what consequences this rapid and yet contested expansion depended on the entanglement of the social sciences with the Cold War. Utilizing the controversial but useful concept of "Cold War Social Science," the contributions gathered here reveal how scholars from established disciplines and new interdisciplinary fields of study made important contributions to long-standing debates about knowledge production, liberal democracy, and human nature in an era of diplomatic tension and ideological conflict.},
  isbn = {9781137013224},
  pagetotal = {289},
  shorttitle = {{Cold War Social Science}},
  title = {{Cold War Social Science: Knowledge Production, Liberal Democracy, and Human Nature}},
  options = {useprefix},
  publisher = {{Palgrave Macmillan}},
  author = {Solovey, Mark and Cravens, Hamilton},
  date = {2012-01-31},
  year = {2012},
  langid = {english},
  note = {00006},
  keywords = {History / General,History / Social History,History / United States / 20th Century,Political Science / History \& Theory,Political Science / Political Ideologies / Democracy,SOCIAL SCIENCE / Methodology,SOCIAL SCIENCE / Research}
}

% Better BibLaTeX: generated
@article{Flach_2001,
  pages = {199–222},
  shorttitle = {{On the state of the art in machine learning}},
  title = {{On the state of the art in machine learning: A personal review}},
  url = {http://www.sciencedirect.com/science/article/pii/S0004370201001254},
  volume = {{131}},
  options = {useprefix},
  number = {1},
  journaltitle = {{Artificial Intelligence}},
  author = {Flach, Peter A.},
  urldate = {2014-03-26},
  date = {2001},
  year = {2001},
  file = {[HTML] from sciencedirect.com:/home/mackenza/.mozilla/firefox/w5dcspnj.default/zotero/storage/ZHP82QBG/S0004370201001254.html:text/html}
}
