
@article{Ribarsky_2009,
  title = {Science of {{Analytical Reasoning}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.28},
  doi = {10.1057/ivs.2009.28},
  timestamp = {2017-05-19T07:26:56Z},
  number = {4},
  author = {Ribarsky, William and Fisher, Brian and Pottenger, William M},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {254--262}
}

@incollection{Wild_2007,
  title = {Investigating {{Unstructured Texts}} with {{Latent Semantic Analysis}}},
  url = {http://dx.doi.org/10.1007/978-3-540-70981-7_43},
  abstract = {Latent semantic analysis (LSA) is an algorithm applied to approximate the meaning of texts, thereby exposing semantic structure to computation. LSA combines the classical vector-space model — well known in computational linguistics — with a singular value decomposition (SVD), a two-mode factor analysis. Thus, bag-of-words representations of texts can be mapped into a modified vector space that is assumed to reflect semantic structure. In this contribution the authors describe thelsapackage for the statistical language and environment R and illustrate its proper use through examples from the areas of automated essay scoring and knowledge representation.},
  timestamp = {2017-05-19T07:26:57Z},
  booktitle = {Advances in {{Data Analysis}}},
  author = {Wild, Fridolin and Stahl, Christina},
  urldate = {2009-10-02},
  date = {2007},
  pages = {383--390}
}

@article{Gelfand_1994,
  title = {On {{Markov Chain Monte Carlo Acceleration}}},
  volume = {3},
  issn = {1061-8600},
  timestamp = {2017-05-19T07:26:57Z},
  number = {3},
  author = {Gelfand, A. E and Sahu, S. K},
  date = {1994},
  pages = {261--276}
}

@article{Pike_2009,
  title = {The {{Science}} of {{Interaction}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.22},
  doi = {10.1057/ivs.2009.22},
  timestamp = {2017-05-19T07:26:57Z},
  number = {4},
  author = {Pike, William A and Stasko, John and Chang, Remco and O′Connell, Theresa A},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {263--274}
}

@article{Fienberg_2006,
  title = {When {{Did Bayesian Inference Become}} "{{Bayesian}}"?},
  volume = {1},
  url = {http://ba.stat.cmu.edu/journal/2006/vol01/issue01/fienberg.pdf},
  doi = {10.1214/06-BA101},
  timestamp = {2017-05-19T07:26:57Z},
  number = {1},
  author = {Fienberg, \&\#32;Stephen E},
  date = {2006},
  pages = {1\&ndash;40}
}

@article{Vann_2006,
  title = {Interest in {{Production}}: {{On}} the {{Configuration Of}}},
  shorttitle = {Interest in {{Production}}},
  timestamp = {2017-05-19T07:26:57Z},
  author = {Vann, K. and Bowker, G. C},
  date = {2006},
  pages = {71}
}

@article{Papachristos_2009,
  title = {Murder by {{Structure}}: {{Dominance Relations}} and the {{Social Structure}} of {{Gang Homicide}}},
  volume = {115},
  url = {http://dx.doi.org/10.1086/597791},
  doi = {10.1086/597791},
  shorttitle = {Murder by {{Structure}}},
  timestamp = {2017-05-19T07:26:57Z},
  number = {1},
  author = {Papachristos, Andrew V.},
  urldate = {2010-01-13},
  date = {2009-07-01},
  pages = {74--128}
}

@article{Morgan_2009,
  title = {{{ShortRead}}: {{A Bioconductor Package}} for {{Input}}, {{Quality Assessment}} and {{Exploration}} of {{High}}-{{Throughput Sequence Data}}},
  volume = {25},
  url = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/25/19/2607},
  doi = {10.1093/bioinformatics/btp450},
  shorttitle = {{{ShortRead}}},
  abstract = {Summary: ShortRead is a package for input, quality assessment, manipulation and output of high-throughput sequencing data. ShortRead is provided in the R and Bioconductor environments, allowing ready access to additional facilities for advanced statistical analysis, data transformation, visualization and integration with diverse genomic resources. Availability and Implementation: This package is implemented in R and available at the Bioconductor web site; the package contains a vignette' outlining typical work flows. Contact: mtmorgan@fhcrc.org},
  timestamp = {2017-05-19T07:26:57Z},
  number = {19},
  author = {Morgan, Martin and Anders, Simon and Lawrence, Michael and Aboyoun, Patrick and Pages, Herve and Gentleman, Robert},
  urldate = {2010-01-04},
  date = {2009-10-01},
  pages = {2607--2608}
}

@article{Vance_2009,
  title = {Data {{Analysts Captivated}} by {{R}}’s {{Power}}},
  issn = {0362-4331},
  url = {http://www.nytimes.com/2009/01/07/technology/business-computing/07program.html?_r=3&scp=1&sq=robert%20gentleman&st=cse},
  timestamp = {2017-05-19T07:26:57Z},
  author = {Vance, Ashlee},
  urldate = {2009-10-02},
  date = {2009-01-07},
  keywords = {Computers and the Internet,Data Mining,Enterprise Computing,Programming Languages,Software,Statistics}
}

@article{Wilkinson_2007,
  title = {Bayesian {{Methods}} in {{Bioinformatics}} and {{Computational Systems Biology}}},
  volume = {8},
  url = {http://bib.oxfordjournals.org/cgi/content/abstract/8/2/109},
  doi = {10.1093/bib/bbm007},
  abstract = {Bayesian methods are valuable, inter alia, whenever there is a need to extract information from data that are uncertain or subject to any kind of error or noise (including measurement error and experimental error, as well as noise or random variation intrinsic to the process of interest). Bayesian methods offer a number of advantages over more conventional statistical techniques that make them particularly appropriate for complex data. It is therefore no surprise that Bayesian methods are becoming more widely used in the fields of genetics, genomics, bioinformatics and computational systems biology, where making sense of complex noisy data is the norm. This review provides an introduction to the growing literature in this area, with particular emphasis on recent developments in Bayesian bioinformatics relevant to computational systems biology.},
  timestamp = {2017-05-19T07:26:57Z},
  number = {2},
  author = {Wilkinson, Darren J.},
  urldate = {2010-02-13},
  date = {2007-03-01},
  pages = {109--116}
}

@article{Wong_2009,
  title = {Visual {{Analytics}}: {{Building}} a {{Vibrant}} and {{Resilient National Science}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.24},
  doi = {10.1057/ivs.2009.24},
  shorttitle = {Visual {{Analytics}}},
  timestamp = {2017-05-19T07:26:57Z},
  number = {4},
  author = {Wong, Pak Chung and Thomas, Jim},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {302--308}
}

@article{Scholtz_2009,
  title = {Visual {{Analytics Technology Transition Progress}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.20},
  doi = {10.1057/ivs.2009.20},
  timestamp = {2017-05-19T07:26:57Z},
  number = {4},
  author = {Scholtz, Jean and Cook, Kristin A and Whiting, Mark A and Lemon, Doug and Greenblatt, Howard},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {294--301}
}

@article{Simpson_2010,
  title = {Beyond {{Atopy}}: {{Multiple Patterns}} of {{Sensitization}} in {{Relation}} to {{Asthma}} in a {{Birth Cohort Study}}},
  volume = {181},
  issn = {1535-4970},
  doi = {10.1164/rccm.200907-1101OC},
  shorttitle = {Beyond {{Atopy}}},
  abstract = {RATIONALE The pattern of IgE response (over time or to specific allergens) may reflect different atopic vulnerabilities which are related to the presence of asthma in a fundamentally different way from current definition of atopy. OBJECTIVES To redefine the atopic phenotype by identifying latent structure within a complex dataset, taking into account the timing and type of sensitization to specific allergens, and relating these novel phenotypes to asthma. METHODS In a population-based birth cohort in which multiple skin and IgE tests have been taken throughout childhood, we used a machine learning approach to cluster children into multiple atopic classes in an unsupervised way. We then investigated the relation between these classes and asthma (symptoms, hospitalizations, lung function and airway reactivity). MEASUREMENTS AND MAIN RESULTS A five-class model indicated a complex latent structure, in which children with atopic vulnerability were clustered into four distinct classes (Multiple Early [112/1053, 10.6\%]; Multiple Late [171/1053, 16.2\%]; Dust Mite [47/1053, 4.5\%]; and Non-dust Mite [100/1053, 9.5\%]), with a fifth class describing children with No Latent Vulnerability (623/1053, 59.2\%). The association with asthma was considerably stronger for Multiple Early compared with other classes and conventionally defined atopy (odds ratio [95\% CI]: 29.3 [11.1-77.2] versus 12.4 [4.8-32.2] versus 11.6 [4.8-27.9] for Multiple Early class versus Ever Atopic versus Atopic age 8). Lung function and airway reactivity were significantly poorer among children in Multiple Early class. Cox regression demonstrated a highly significant increase in risk of hospital admissions for wheeze/asthma after age 3 yr only among children in the Multiple Early class (HR 9.2 [3.5-24.0], P \$$<$\$ 0.001). CONCLUSIONS IgE antibody responses do not reflect a single phenotype of atopy, but several different atopic vulnerabilities which differ in their relation with asthma presence and severity.},
  timestamp = {2017-05-19T07:26:57Z},
  number = {11},
  author = {Simpson, Angela and Tan, Vincent Y F and Winn, John and Svensén, Markus and Bishop, Christopher M and Heckerman, David E and Buchan, Iain and Custovic, Adnan},
  date = {2010-06-01},
  pages = {1200--1206},
  keywords = {Animals,Asthma,Child,Cluster Analysis,Cohort Studies,Disease Susceptibility,Female,Great Britain,Hospitalization,Humans,Immunoglobulin E,Male,Mothers,Multivariate Analysis,Phenotype,Plethysmography,Pyroglyphidae,Respiratory Function Tests,Respiratory Sounds,Skin Tests,Smoking,Spirometry,Whole Body}
}

@article{Robins_2007,
  title = {An {{Introduction}} to {{Exponential Random Graph}} ({{P}}*) {{Models}} for {{Social Networks}}},
  volume = {29},
  issn = {0378-8733},
  url = {http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/B6VD1-4M4CVKM-1/2/df27f691fa8b1fcfc94380da74bbab77},
  doi = {10.1016/j.socnet.2006.08.002},
  abstract = {This article provides an introductory summary to the formulation and application of exponential random graph models for social networks. The possible ties among nodes of a network are regarded as random variables, and assumptions about dependencies among these random tie variables determine the general form of the exponential random graph model for the network. Examples of different dependence assumptions and their associated models are given, including Bernoulli, dyad-independent and Markov random graph models. The incorporation of actor attributes in social selection models is also reviewed. Newer, more complex dependence assumptions are briefly outlined. Estimation procedures are discussed, including new methods for Monte Carlo maximum likelihood estimation. We foreshadow the discussion taken up in other papers in this special edition: that the homogeneous Markov random graph models of Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association 81, 832-842] are not appropriate for many observed networks, whereas the new model specifications of Snijders et al. [Snijders, T.A.B., Pattison, P., Robins, G.L., Handock, M. New specifications for exponential random graph models. Sociological Methodology, in press] offer substantial improvement.},
  timestamp = {2017-05-19T07:26:57Z},
  number = {2},
  author = {Robins, Garry and Pattison, Pip and Kalish, Yuval and Lusher, Dean},
  urldate = {2011-01-11},
  date = {2007-05},
  pages = {173--191},
  keywords = {Exponential random graph models,p* models,Statistical models for social networks}
}

@article{Thelwall_2006,
  title = {Web {{Issue Analysis}}: {{An Integrated Water Resource Management Case Study}}},
  volume = {57},
  shorttitle = {Web {{Issue Analysis}}},
  timestamp = {2017-05-19T07:26:57Z},
  number = {10},
  author = {Thelwall, M. and Vann, K. and Fairclough, R.},
  date = {2006},
  pages = {1303--1314}
}

@article{Rogers_2010,
  title = {Coming to {{Terms}}: {{A Conflict Analysis}} of the {{Usage}}, in {{Official}} and {{Unofficial Sources}}, of ‘{{Security Fence}}’, ‘{{Apartheid Wall}}’, and {{Other Terms}} for the {{Structure}} between {{Israel}} and the {{Palestinian Territories}}},
  volume = {3},
  url = {http://mwc.sagepub.com/content/3/2/202.abstract},
  doi = {10.1177/1750635210363924},
  shorttitle = {Coming to {{Terms}}},
  abstract = {The official terms for the dividing wall are ‘security fence’ on the Israeli side and ‘apartheid wall’ on the Palestinian side. Both terms fuse two contextually charged notions to describe the construction project. Beyond the two official terms, the structure has been given other names by sources appearing in the media space (e.g. the International Court of Justice’s ‘West Bank wall’) or by news organizations covering the issue (e.g. ‘barrier wall’). Using data from Google News, which includes official NGO as well as news sources, this article offers a media monitoring method that also seeks to create conflict indicators from the shifting language employed by officials, journalists and others to describe the structure. The authors discovered that the Palestinians and Israelis choose their words differently: the Israelis are consistent (yet relatively alone) in the way they use their terms; the Palestinians adopt their terminology according to the setting, using different terms for the structure in diplomatic and international court settings than ‘at home’. Having identified ‘setting’ as an important variable in the study of language use as conflict indicator, the study also includes an analysis of diplomatic language in key debates on the obstacle at the UN Security Council. In all, it was found that, at particular moments in time, Israeli and Palestinian actors ‘come to terms’ most significantly around ‘separation wall’, coupling the Israeli left-of-centre adjective and the Palestinian noun, implying a peace-related arrangement distinctive from either side’s official position (as well as the current peace plans), and ultimately undesirable to those who share the term.},
  timestamp = {2017-05-19T07:26:57Z},
  number = {2},
  author = {Rogers, Richard and Ben-David, Anat},
  urldate = {2011-01-17},
  date = {2010},
  pages = {202 --229}
}

@online{_2004a,
  title = {From {{Paragraph}} to {{Graph}}: {{Latent Semantic Analysis}} for {{Information Visualization}}},
  url = {http://www.pnas.org/content/101/suppl.1/5214.full.pdf+html?frame=header},
  shorttitle = {From {{Paragraph}} to {{Graph}}},
  timestamp = {2017-05-19T07:26:57Z},
  urldate = {2010-01-26},
  date = {2004-04-06}
}

@article{Anderson_1999,
  title = {A {{P}}* {{Primer}}: {{Logit Models}} for {{Social Networks}}},
  volume = {21},
  issn = {0378-8733},
  url = {http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/B6VD1-3WNMVT7-3/2/426fd481fec6518425f293111c3b2ff8},
  doi = {10.1016/S0378-8733(98)00012-4},
  shorttitle = {A {{P}}* {{Primer}}},
  abstract = {A major criticism of the statistical models for analyzing social networks developed by Holland, Leinhardt, and others [Holland, P.W., Leinhardt, S., 1977. Notes on the statistical analysis of social network data; Holland, P.W., Leinhardt, S., 1981. An exponential family of probability distributions for directed graphs. Journal of the American Statistical Association. 76, pp. 33-65 (with discussion); Fienberg, S.E., Wasserman, S., 1981. Categorical data analysis of single sociometric relations. In: Leinhardt, S. (Ed.), Sociological Methodology 1981, San Francisco: Jossey-Bass, pp. 156-192; Fienberg, S.E., Meyer, M.M., Wasserman, S., 1985. Statistical analysis of multiple sociometric relations. Journal of the American Statistical Association, 80, pp. 51-67; Wasserman, S., Weaver, S., 1985. Statistical analysis of binary relational data: Parameter estimation. Journal of Mathematical Psychology. 29, pp. 406-427; Wasserman, S., 1987. Conformity of two sociometric relations. Psychometrika. 52, pp. 3-18] is the very strong independence assumption made on interacting individuals or units within a network or group. This limiting assumption is no longer necessary given recent developments on models for random graphs made by Frank and Strauss [Frank, O., Strauss, D., 1986. Markov graphs. Journal of the American Statistical Association. 81, pp. 832-842] and Strauss and Ikeda [Strauss, D., Ikeda, M., 1990. Pseudolikelihood estimation for social networks. Journal of the American Statistical Association. 85, pp. 204-212]. The resulting models are extremely flexible and easy to fit to data. Although Wasserman and Pattison [Wasserman, S., Pattison, P., 1996. Logit models and logistic regressions for social networks: I. An introduction to Markov random graphs and p*. Psychometrika. 60, pp. 401-426] present a derivation and extension of these models, this paper is a primer on how to use these important breakthroughs to model the relationships between actors (individuals, units) within a single network and provides an extension of the models to multiple networks. The models for multiple networks permit researchers to study how groups are similar and/or how they are different. The models for single and multiple networks and the modeling process are illustrated using friendship data from elementary school children from a study by Parker and Asher [Parker, J.G., Asher, S.R., 1993. Friendship and friendship quality in middle childhood: Links with peer group acceptance and feelings of loneliness and social dissatisfaction. Developmental Psychology. 29, pp. 611-621].},
  timestamp = {2017-05-19T07:26:57Z},
  number = {1},
  author = {Anderson, Carolyn J. and Wasserman, Stanley and Crouch, Bradley},
  urldate = {2011-01-11},
  date = {1999-01},
  pages = {37--66}
}

@incollection{Tsai_2009,
  title = {Probabilistic {{Techniques}} for {{Corporate Blog Mining}}},
  url = {http://dx.doi.org/10.1007/978-3-540-77018-3_5},
  abstract = {With the proliferation of blogs, or weblogs, in the recent years, information in the blogosphere is becoming increasingly difficult to access and retrieve. Previous studies have focused on analyzing personal blogs, but few have looked at corporate blogs, the numbers of which are dramatically rising. In this paper, we use probabilistic techniques to detect keywords from corporate blogs with respect to certain topics. We then demonstrate how this method can present the blogosphere in terms of topics with measurable keywords, hence tracking popular conversations and topics in the blogosphere. By applying a probabilistic approach, we can improve information retrieval in blog search and keywords detection, and provide an analytical foundation for the future of corporate blog search and mining.},
  timestamp = {2017-05-19T07:26:57Z},
  booktitle = {Emerging {{Technologies}} in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Tsai, Flora and Chen, Yun and Chan, Kap},
  urldate = {2010-01-21},
  date = {2009},
  pages = {35--44}
}

@article{Vance_2009a,
  title = {Supercomputing for the {{Masses}}},
  issn = {0362-4331},
  url = {http://www.nytimes.com/2009/11/23/technology/23compute.html?ref=ashlee_vance},
  timestamp = {2017-05-19T07:26:57Z},
  author = {Vance, Ashlee},
  urldate = {2010-06-11},
  date = {2009-11-23},
  keywords = {Advanced Micro Devices Inc,Computers and the Internet,Fees and Rates),Georgia Institute of Technology,Oak Ridge National Laboratory,Prices (Fares,Software,Supercomputers}
}

@article{Wilson_2008,
  title = {Tracing the {{Source}} of {{Campylobacteriosis}}},
  volume = {4},
  url = {http://dx.doi.org/10.1371/journal.pgen.1000203},
  doi = {10.1371/journal.pgen.1000203},
  abstract = {C. jejuni is a bacterium commonly found in the guts of birds and mammals. In humans, it is responsible for causing more gastro-enteritis than any other identified bacterial species. Humans may contract campylobacter from a variety of sources. Eating raw or undercooked meat or poultry, and poor food hygiene that leads to cross-contamination of uncooked food, can cause human disease. However, humans may be exposed to the feces of infected wild animals, and campylobacter can survive in water. Contamination of drinking water can lead to outbreaks, and previous genetic studies have suggested that livestock are not the principal source of human infection. We extracted campylobacter DNA from patients and compared it to campylobacter DNA found in livestock, wild animals, and the environment. We developed a new evolutionary model to identify the most probable source populations. In 97\% of cases, we identified chicken, cattle, or sheep as the source of infection. Very few cases were attributable to campylobacter found in wild animals or the environment. Our results imply that the primary transmission route is the food chain and also add new impetus to measures that reduce infection in livestock and prevent food-borne transmission.},
  timestamp = {2017-05-19T07:26:57Z},
  number = {9},
  author = {Wilson, Daniel J. and Gabriel, Edith and Leatherbarrow, Andrew J. H. and Cheesbrough, John and Gee, Steven and Bolton, Eric and Fox, Andrew and Fearnhead, Paul and Hart, C. Anthony and Diggle, Peter J.},
  urldate = {2011-01-17},
  date = {2008},
  pages = {e1000203}
}

@article{Morris_2009,
  title = {Concurrent {{Partnerships}} and {{HIV Prevalence Disparities}} by {{Race}}: {{Linking Science}} and {{Public Health Practice}}},
  volume = {99},
  url = {http://ajph.aphapublications.org/cgi/content/abstract/99/6/1023},
  doi = {10.2105/AJPH.2008.147835},
  shorttitle = {Concurrent {{Partnerships}} and {{HIV Prevalence Disparities}} by {{Race}}},
  abstract = {Concurrent sexual partnerships may help to explain the disproportionately high prevalence of HIV and other sexually transmitted infections among African Americans. The persistence of such disparities would also require strong assortative mixing by race. We examined descriptive evidence from 4 nationally representative US surveys and found consistent support for both elements of this hypothesis. Using a data-driven network simulation model, we found that the levels of concurrency and assortative mixing observed produced a 2.6-fold racial disparity in the epidemic potential among young African American adults.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {6},
  author = {Morris, Martina and Kurth, Ann E. and Hamilton, Deven T. and Moody, James and Wakefield, Steve},
  urldate = {2011-01-11},
  date = {2009-06-01},
  pages = {1023--1031}
}

@article{Osborne_2008,
  title = {Editors' {{Introduction Reinscribing British Sociology}}: {{Some Critical Reflections}}},
  volume = {56},
  url = {http://dx.doi.org/10.1111/j.1467-954X.2008.00803.x},
  doi = {10.1111/j.1467-954X.2008.00803.x},
  shorttitle = {Editors' {{Introduction Reinscribing British Sociology}}},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Osborne, Thomas and Rose, Nikolas and Savage, Mike},
  urldate = {2009-12-10},
  date = {2008},
  pages = {519--534}
}

@article{Kasik_2009,
  title = {Data {{Transformations}} and {{Representations}} for {{Computation}} and {{Visualization}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.27},
  doi = {10.1057/ivs.2009.27},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Kasik, David J and Ebert, David and Lebanon, Guy and Park, Haesun and Pottenger, William M},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {275--285}
}

@article{Kielman_2009,
  title = {Foundations and {{Frontiers}} in {{Visual Analytics}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.25},
  doi = {10.1057/ivs.2009.25},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Kielman, Joe and Thomas, Jim and May, Richard},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {239--246}
}

@article{Law_2008,
  title = {On {{Sociology}} and {{STS}}},
  volume = {56},
  url = {http://dx.doi.org/10.1111/j.1467-954X.2008.00808.x},
  doi = {10.1111/j.1467-954X.2008.00808.x},
  abstract = {This paper starts by exploring the development of Science, Technology and Society (STS) in the UK in the late 1960s, emphasising its interdiciplinary roots, and comparing and contrasting it with the concerns of Sociology. It then turns to more recent developments in STS, outlining the importance of material semiotics to important traditions within the discipline including those influenced by actor network theory, feminism, and postcolonialism. It notes, in consistency with the Foucauldian approach, that material semiotics implies that knowledge traditions are performative, helping to create the realities that they describe. The paper concludes by exploring the implications of this performatibity for the politics of research methods and for the future character of social science research.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Law, John},
  urldate = {2009-12-10},
  date = {2008},
  pages = {623--649}
}

@article{Robertson_2009,
  title = {Scale and {{Complexity}} in {{Visual Analytics}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.23},
  doi = {10.1057/ivs.2009.23},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Robertson, George and Ebert, David and Eick, Stephen and Keim, Daniel and Joy, Ken},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {247--253}
}

@article{Thomas_2009,
  title = {Challenges for {{Visual Analytics}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.26},
  doi = {10.1057/ivs.2009.26},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Thomas, Jim and Kielman, Joe},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {309--314}
}

@article{Rajaram_2010,
  title = {{{NeatMap}} - {{Non}}-{{Clustering Heat Map Alternatives}} in {{R}}},
  volume = {11},
  issn = {1471-2105},
  url = {http://www.biomedcentral.com/1471-2105/11/45},
  doi = {10.1186/1471-2105-11-45},
  abstract = {BACKGROUND:The clustered heat map is the most popular means of visualizing genomic data. It compactly displays a large amount of data in an intuitive format that facilitates the detection of hidden structures and relations in the data. However, it is hampered by its use of cluster analysis which does not always respect the intrinsic relations in the data, often requiring non-standardized reordering of rows/columns to be performed post-clustering. This sometimes leads to uninformative and/or misleading conclusions. Often it is more informative to use dimension-reduction algorithms (such as Principal Component Analysis and Multi-Dimensional Scaling) which respect the topology inherent in the data. Yet, despite their proven utility in the analysis of biological data, they are not as widely used. This is at least partially due to the lack of user-friendly visualization methods with the visceral impact of the heat map.RESULTS:NeatMap is an R package designed to meet this need. NeatMap offers a variety of novel plots (in 2 and 3 dimensions) to be used in conjunction with these dimension-reduction techniques. Like the heat map, but unlike traditional displays of such results, it allows the entire dataset to be displayed while visualizing relations between elements. It also allows superimposition of cluster analysis results for mutual validation. NeatMap is shown to be more informative than the traditional heat map with the help of two well-known microarray datasets.CONCLUSIONS:NeatMap thus preserves many of the strengths of the clustered heat map while addressing some of its deficiencies. It is hoped that NeatMap will spur the adoption of non-clustering dimension-reduction algorithms.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {1},
  author = {Rajaram, Satwik and Oono, Yoshi},
  urldate = {2011-01-25},
  date = {2010},
  pages = {45}
}

@online{CRAN_2010,
  title = {The {{Comprehensive R Archive Network}}},
  url = {http://www.stats.bris.ac.uk/R/},
  timestamp = {2017-05-19T07:26:58Z},
  author = {{CRAN}},
  urldate = {2010-05-05},
  date = {2010}
}

@article{Ritschard_2008,
  title = {Mining {{Event Histories}}: {{A Social Science Perspective}}},
  volume = {1},
  shorttitle = {Mining {{Event Histories}}},
  timestamp = {2017-05-19T07:26:58Z},
  number = {1},
  author = {Ritschard, G. and Gabadinho, A. and Muller, N. S and Studer, M.},
  date = {2008},
  pages = {68--90}
}

@article{Efron_2004,
  title = {Least {{Angle Regression}}},
  volume = {32},
  issn = {00905364},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/3448465},
  abstract = {The purpose of model selection algorithms such as All Subsets, Forward Selection and Backward Elimination is to choose a linear model on the basis of the same set of data to which the model will be applied. Typically we have available a large collection of possible covariates from which we hope to select a parsimonious set for the efficient prediction of a response variable. Least Angle Regression (LARS), a new model selection algorithm, is a useful and less greedy version of traditional forward selection methods. Three main properties are derived: (1) A simple modification of the LARS algorithm implements the Lasso, an attractive version of ordinary least squares that constrains the sum of the absolute regression coefficients; the LARS modification calculates all possible Lasso estimates for a given problem, using an order of magnitude less computer time than previous methods. (2) A different LARS modification efficiently implements Forward Stagewise linear regression, another promising new model selection method; this connection explains the similar numerical results previously observed for the Lasso and Stagewise, and helps us understand the properties of both methods, which are seen as constrained versions of the simpler LARS algorithm. (3) A simple approximation for the degrees of freedom of a LARS estimate is available, from which we derive a Cp estimate of prediction error; this allows a principled choice among the range of possible LARS estimates. LARS and its variants are computationally efficient: the paper describes a publicly available algorithm that requires only the same order of magnitude of computational effort as ordinary least squares applied to the full set of covariates.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {2},
  author = {Efron, Bradley and Hastie, Trevor and Johnstone, Iain and Tibshirani, Robert},
  urldate = {2010-11-18},
  date = {2004-04},
  pages = {407--451}
}

@article{Muller_2008,
  title = {Extracting {{Knowledge}} from {{Life Courses}}: {{Clustering}} and {{Visualization}}},
  volume = {5182},
  shorttitle = {Extracting {{Knowledge}} from {{Life Courses}}},
  timestamp = {2017-05-19T07:26:58Z},
  author = {Muller, N. S and Gabadinho, A. and Ritschard, G. and Studer, M.},
  date = {2008},
  pages = {176--185}
}

@article{Savage_2008,
  title = {Elizabeth {{Bott}} and the {{Formation}} of {{Modern British Sociology}}},
  volume = {56},
  url = {http://dx.doi.org/10.1111/j.1467-954X.2008.00806.x},
  doi = {10.1111/j.1467-954X.2008.00806.x},
  abstract = {This paper examines the contribution of Elizabeth Bott's Family and Social Network to the elaboration of modern British sociology. I show that although Bott is often identified as one of the key figures in the emergence of social network analysis, this misunderstands her contribution. I show how her work drew strongly on key aspects of the research programme of the Tavistock Institute of Human Relations, and that it was her use of the in-depth interview, allied to an interest in probing class identities, which was to be seminal. This case study is used to show how a focus on the practical inscription techniques mobilised by social scientists can give a radically different perspective on the discipline than approaches which focus on schools of thought or 'great men'.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Savage, Mike},
  urldate = {2009-12-10},
  date = {2008},
  pages = {579--605}
}

@online{Hardy_2010,
  title = {Power in the {{Numbers Page}} 2 of 3 - {{Forbes}}.{{Com}}},
  url = {http://www.forbes.com/forbes/2010/0524/opinions-software-norman-nie-spss-ideas-opinions_2.html},
  timestamp = {2017-05-19T07:26:58Z},
  author = {Hardy, Quentin},
  urldate = {2010-06-10},
  date = {2010-05-24}
}

@article{Uprichard_2008,
  title = {{{SPSS}} as an '{{Inscription Device}}': {{From Causality}} to {{Description}}?},
  volume = {56},
  url = {http://dx.doi.org/10.1111/j.1467-954X.2008.00807.x},
  doi = {10.1111/j.1467-954X.2008.00807.x},
  shorttitle = {{{SPSS}} as an '{{Inscription Device}}'},
  abstract = {This paper examines the development of SPSS from 1968 to 2008, and the manner in which it has been used in teaching and research in British Sociology. We do this in order to reveal some of the changes that have taken place in statistical reasoning as an inscription device in the discipline over this period. We conclude that to characterise these changes as a shift from 'causal' to more 'descriptive' modes of analysis is too simplistic. Such a shift is certainly apparent, but it meshes in complex ways with a range of other 2013 just as important 2013 changes, that together mark a phase-shift in the functioning of sociological quantification.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Uprichard, Emma and Burrows, Roger and Byrne, David},
  urldate = {2009-12-10},
  date = {2008},
  pages = {606--622}
}

@article{Bennett_2009,
  title = {Counting and {{Seeing}} the {{Social Action}} of {{Literary Form}}: {{Franco Moretti}} and the {{Sociology}} of {{Literature}}},
  volume = {3},
  url = {http://cus.sagepub.com/cgi/content/abstract/3/2/277},
  doi = {10.1177/1749975509105535},
  shorttitle = {Counting and {{Seeing}} the {{Social Action}} of {{Literary Form}}},
  abstract = {This paper reviews Franco Moretti's use of statistics and techniques for visualizing the action of literary forms, and assesses their implications for the development of cultural sociology. It compares Moretti's use of such methods with the work of Pierre Bourdieu, contrasting the principles of sociological analysis developed by Bourdieu with Moretti's preoccupation with the analysis of literary form as illustrated by his accounts of the development of the English novel and the role of clues in the organization of detective stories. His attempt to use evolutionary principles of explanation to account for the development of literary forms is probed by considering its similarities to earlier evolutionary accounts of the development of design traits. While welcoming the methodological challenge posed by Moretti's work, its lack of an adequate account of the role of literary institutions is criticized, as are the effects of the forms of abstraction that his analyses rest upon.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {2},
  author = {Bennett, Tony},
  urldate = {2010-02-02},
  date = {2009-07-01},
  pages = {277--297}
}

@article{Abbott_2000,
  title = {Sequence {{Analysis}} and {{Optimal Matching Methods}} in {{Sociology}}: {{Review}} and {{Prospect}}: {{Sequence Analysis}}},
  volume = {29},
  shorttitle = {Sequence {{Analysis}} and {{Optimal Matching Methods}} in {{Sociology}}},
  timestamp = {2017-05-19T07:26:58Z},
  number = {1},
  author = {Abbott, A. and Tsay, A.},
  date = {2000},
  pages = {3--33}
}

@article{Lieberson_2008,
  title = {{{IMPLICATION ANALYSIS}}: {{A PRAGMATIC PROPOSAL FOR LINKING THEORY AND DATA IN THE SOCIAL SCIENCES}}},
  volume = {38},
  issn = {1467-9531},
  url = {http://dx.doi.org/10.1111/j.1467-9531.2008.00199.x},
  doi = {10.1111/j.1467-9531.2008.00199.x},
  abstract = {Sociology and other social sciences struggle to emulate a model of scientific evidence that is often inappropriate. Not only do social researchers encounter special limits, but they are also handicapped by a distorted and idealized picture of practices in the “hard sciences.” Ironically, while often obliged to use data of lower quality, sociology employs standards for evaluating a theory that are not attained in the hard sciences. After a brief review of these obstacles, we describe a set of procedures for using empirical data to rigorously evaluate theories and hypotheses without resorting to the mimicking of hard science. The interaction between theory and evidence normally involves deriving implications from the theory (usually referred to as hypotheses) and then ascertaining how closely the empirical evidence meets these implications. The appropriateness of the implications is a key factor in the entire operation, linking as they do the data and the theory. The evaluation of a theory is no better than the theory's implications (as generated by the investigator) coupled with the quality and appropriateness of the evidence. It is our impression, however, that because this step is insufficiently addressed, there are unnecessary problems in the evaluation of theories. We use the term “Implication Analysis” to describe our efforts to review and improve current procedures.},
  timestamp = {2017-05-19T07:26:58Z},
  number = {1},
  author = {Lieberson, Stanley and Horwich, Joel},
  date = {2008},
  pages = {1--50}
}

@article{Chinchor_2009,
  title = {The {{Science}} of {{Analytic Reporting}}},
  volume = {8},
  issn = {1473-8716},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/ivs.2009.21},
  doi = {10.1057/ivs.2009.21},
  timestamp = {2017-05-19T07:26:58Z},
  number = {4},
  author = {Chinchor, Nancy and Pike, William A},
  urldate = {2010-03-30},
  date = {2009-24},
  pages = {286--293}
}

@online{CRAN_2010a,
  title = {{{CRAN Task Views}}},
  url = {http://www.stats.bris.ac.uk/R/web/views/},
  timestamp = {2017-05-19T07:26:59Z},
  author = {{CRAN}},
  urldate = {2010-05-05},
  date = {2010}
}

@article{Savage_2009,
  title = {Some {{Further Reflections}} on the {{Coming Crisis}} of {{Empirical Sociology}}},
  volume = {43},
  url = {http://soc.sagepub.com/cgi/content/abstract/43/4/762},
  doi = {10.1177/0038038509105420},
  abstract = {We respond to the two comments on our article `The Coming Crisis of Empirical Sociology' from Rosemary Crompton (2008) and Richard Webber (2009) which have been published in Sociology , as well as issues arising from the wider debate generated by our article. We urge sociologists to recognize the gravity of the challenges posed by the proliferation of social data and to become more vociferous in contributing to political debates over method and data.},
  timestamp = {2017-05-19T07:26:59Z},
  number = {4},
  author = {Savage, Mike and Burrows, Roger},
  urldate = {2009-11-25},
  date = {2009-08-01},
  pages = {762--772}
}

@book{Bland_2000,
  title = {An {{Introduction}} to {{Medical Statistics}}},
  volume = {132},
  timestamp = {2017-05-19T07:26:59Z},
  publisher = {{Oxford University Press Oxford}},
  author = {Bland, M.},
  date = {2000}
}

@article{Blasius_2008,
  title = {Lifestyles in {{Distressed Neighborhoods}}: {{A Test}} of {{Bourdieu}}'s "{{Taste}} of {{Necessity}}" {{Hypothesis}}},
  volume = {36},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/B6VC3-4RWBWPY-1/2/e10850a182d5d140366c074efed53a78},
  doi = {10.1016/j.poetic.2007.12.001},
  shorttitle = {Lifestyles in {{Distressed Neighborhoods}}},
  abstract = {In his theory of social inequality and lifestyle groups, Bourdieu (1979) argued that lower classes exhibit a "taste of necessity". His main argument is that members of the lower classes are not able to sufficiently convert economic capital into cultural or social capital and vice versa, i.e. to successfully increase their capital volume. This hypothesis has neither been operationalized nor tested so far. We will give an explicit formulation of Bourdieu's theory and develop a test, using indicators derived from Bourdieu's work Distinction. We then apply our model to data from lower class members living in distressed neighborhoods in Cologne, Germany. Groups belonging to the lower classes are located in a "social space", with dimensions to be interpreted as "capital volume" and "composition of cultural and economic capital". We show that members of the lower classes cannot sufficiently increase their capital volume since they cannot efficiently convert "cultural capital" into "economic capital" and vice versa, a fact that supports Bourdieu's assumption of a "taste of necessity".},
  timestamp = {2017-05-19T07:26:59Z},
  number = {1},
  author = {Blasius, Jörg and Friedrichs, Jürgen},
  urldate = {2010-04-23},
  date = {2008-02},
  pages = {24--44}
}

@online{_q,
  title = {Journal of {{Statistical Software}} — {{Show}}},
  url = {http://www.jstatsoft.org/v25/i05},
  timestamp = {2017-05-19T07:26:59Z},
  urldate = {2009-09-22}
}

@article{GOODREAU_2009,
  title = {Birds of a {{Feather}}, or {{Friend}} of a {{Friend}}? {{Using Exponential Random Graph Models}} to {{Investigate Adolescent Social Networks}}},
  volume = {46},
  issn = {0070-3370},
  shorttitle = {Birds of a {{Feather}}, or {{Friend}} of a {{Friend}}?},
  abstract = {In this article, we use newly developed statistical methods to examine the generative processes that give rise to widespread patterns in friendship networks. The methods incorporate both traditional demographic measures on individuals (age, sex, and race) and network measures for structural processes operating on individual, dyadic, and triadic levels. We apply the methods to adolescent friendship networks in 59 U.S. schools from the National Longitudinal Survey of Adolescent Health (Add Health). We model friendship formation as a selection process constrained by individuals’ sociality (propensity to make friends), selective mixing in dyads (friendships within race, grade, or sex categories are differentially likely relative to cross-category friendships), and closure in triads (a friend’s friends are more likely to become friends), given local population composition. Blacks are generally the most cohesive racial category, although when whites are in the minority, they display stronger selective mixing than do blacks when blacks are in the minority. Hispanics exhibit disassortative selective mixing under certain circumstances; in other cases, they exhibit assortative mixing but lack the higher-order cohesion common in other groups. Grade levels are always highly cohesive, while females form triangles more than males. We conclude with a discussion of how network analysis may contribute to our understanding of sociodemographic structure and the processes that create it.},
  timestamp = {2017-05-19T07:26:59Z},
  number = {1},
  author = {GOODREAU, STEVEN M. and KITTS, JAMES A. and MORRIS, MARTINA},
  date = {2009-02},
  pages = {103--125},
  pmcid = {2831261}
}

@article{Hornik_2009,
  title = {Open-{{Source Machine Learning}}: {{R Meets Weka}}},
  volume = {24},
  url = {http://dx.doi.org.ezproxy.lancs.ac.uk/10.1007/s00180-008-0119-7},
  doi = {10.1007/s00180-008-0119-7},
  shorttitle = {Open-{{Source Machine Learning}}},
  abstract = {Abstract Two of the prime open-source environments available for machine/statistical learning in data mining and knowledge discovery are the software packages Weka and R which have emerged from the machine learning and statistics communities, respectively. To make the different sets of tools from both environments available in a single unified system, an R package RWeka is suggested which interfaces Weka’s functionality to R. With only a thin layer of (mostly R) code, a set of general interface generators is provided which can set up interface functions with the usual “R look and feel”, re-using Weka’s standardized interface of learner classes (including classifiers, clusterers, associators, filters, loaders, savers, and stemmers) with associated methods.},
  timestamp = {2017-05-19T07:26:59Z},
  number = {2},
  author = {Hornik, Kurt and Buchta, Christian and Zeileis, Achim},
  urldate = {2010-03-22},
  date = {2009-05-01},
  pages = {225--232}
}

@article{Gabadinho_2008,
  title = {Mining {{Sequence Data}} in {{R}} with {{TraMineR}}},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Gabadinho, A. and Ritschard, G. and Studer, M. and M\$$\backslash$backslash\$üller, N. S.},
  date = {2008}
}

@article{Neumann_2010,
  title = {Phenotypic {{Profiling}} of the {{Human Genome}} by {{Time}}-{{Lapse Microscopy Reveals Cell Division Genes}}},
  volume = {464},
  issn = {0028-0836},
  url = {http://dx.doi.org/10.1038/nature08869},
  doi = {10.1038/nature08869},
  timestamp = {2017-05-19T07:26:59Z},
  number = {7289},
  author = {Neumann, Beate and Walter, Thomas and Hériché, Jean-Karim and Bulkescher, Jutta and Erfle, Holger and Conrad, Christian and Rogers, Phill and Poser, Ina and Held, Michael and Liebel, Urban and Cetin, Cihan and Sieckmann, Frank and Pau, Gregoire and Kabbe, Rolf and Wünsche, Annelie and Satagopam, Venkata and Schmitz, Michael H. A. and Chapuis, Catherine and Gerlich, Daniel W. and Schneider, Reinhard and Eils, Roland and Huber, Wolfgang and Peters, Jan-Michael and Hyman, Anthony A. and Durbin, Richard and Pepperkok, Rainer and Ellenberg, Jan},
  urldate = {2010-05-07},
  date = {2010-04-01},
  pages = {721--727}
}

@article{Eglen_2009,
  title = {A {{Quick Guide}} to {{Teaching R Programming}} to {{Computational Biology Students}}},
  volume = {5},
  url = {http://dx.doi.org/10.1371/journal.pcbi.1000482},
  doi = {10.1371/journal.pcbi.1000482},
  timestamp = {2017-05-19T07:26:59Z},
  number = {8},
  author = {Eglen, Stephen J.},
  urldate = {2009-09-24},
  date = {2009},
  pages = {e1000482}
}

@article{undefinedAldrich_1997,
  title = {R.{{A}}. {{Fisher}} and the {{Making}} of {{Maximum Likelihood}} 1912-1922},
  volume = {12},
  issn = {0883-4237},
  url = {http://projecteuclid.org.ezproxy.lancs.ac.uk/euclid.ss/1030037906},
  doi = {10.1214/ss/1030037906},
  abstract = {In 1922 R. A. Fisher introduced the method of maximum likelihood. He first presented the numerical procedure in 1912. This paper considers Fisher's changing justifications for the method, the concepts he developed around it (including likelihood, sufficiency, efficiency and information) and the approaches he discarded (including inverse probability).},
  timestamp = {2017-05-19T07:26:59Z},
  number = {3},
  author = {undefined Aldrich, John},
  urldate = {2011-01-18},
  date = {1997-09},
  pages = {162--176},
  options = {useprefix=true}
}

@online{_r,
  title = {Quantitative {{Analysis}} of {{Culture Using Millions}} of {{Digitized Books}} | {{Science}}/{{AAAS}}},
  url = {http://www.sciencemag.org.ezproxy.lancs.ac.uk/content/early/2010/12/15/science.1199644},
  timestamp = {2017-05-19T07:26:59Z},
  urldate = {2010-12-21}
}

@article{Gabadinho_2009,
  title = {Mining {{Sequence Data}} in {{R}} with {{TraMineR}}: {{A User}}’s {{Guide}}},
  shorttitle = {Mining {{Sequence Data}} in {{R}} with {{TraMineR}}},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Gabadinho, A. and Ritschard, G. and Studer, M. and M\$$\backslash$backslash\$üller, N. S.},
  date = {2009}
}

@article{Comaroff_2006,
  title = {Figuring {{Crime}}: {{Quantifacts}} and the {{Production}} of the {{Un}}/{{Real}}},
  volume = {18},
  shorttitle = {Figuring {{Crime}}},
  timestamp = {2017-05-19T07:26:59Z},
  number = {1},
  author = {Comaroff, J. and Comaroff, J. L},
  date = {2006},
  pages = {209}
}

@online{_s,
  title = {A {{Survey Method}} for {{Characterizing Daily Life Experience}}: {{The Day Reconstruction Method}} | {{Science}}/{{AAAS}}},
  url = {http://www.sciencemag.org.ezproxy.lancs.ac.uk/content/306/5702/1776.abstract?ijkey=8a73442658af852b8905bb23630537cedd1a31fb&keytype2=tf_ipsecsha},
  timestamp = {2017-05-19T07:26:59Z},
  urldate = {2010-11-21}
}

@article{Cambrosio_2004,
  title = {Mapping {{Collaborative Work}} and {{Innovation}} in {{Biomedicine}}: {{A Computer}}-{{Assisted Analysis}} of {{Antibody Reagent Workshops}}},
  volume = {34},
  issn = {03063127},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/3182994},
  shorttitle = {Mapping {{Collaborative Work}} and {{Innovation}} in {{Biomedicine}}},
  abstract = {This paper analyses a major episode in contemporary biomedical research using a new semi-quantitative approach. In the late 1970s, immunologists began producing new kinds of antibodies targeting molecules on the surface of normal and malignant blood cells. These tools quickly transformed biomedical research in immunology and oncology-hematology. Laboratories worldwide produced thousands of these new reagents and reorganized the classification, diagnosis, and prognosis of diseases such as leukemia and the lymphomas. The rapid development of these reagents initially generated considerable confusion. To avoid the impending chaos, researchers in the field, officially supported by the World Health Organization and the International Union of Immunological Societies, launched an ongoing series of distributed workshops that led to the establishment of a nomenclature of antibody reagents and cell surface molecules. The First Workshop (1981-82) mobilized 54 research groups from 14 countries and resulted in the establishment of 15 antibody/molecule categories. By the late 1990s the number of these categories had increased to more than 247 and the number of participating laboratories had risen to more than 500. Sociological analyses of this kind of large-scale collaborative research usually adopt one of two equally unsatisfactory alternatives: either they provide thick descriptions of selected sites, thus missing the figurational dimension of the collaborative network, or they attempt to account for figurational complexity by reducing it to a few quantitative indicators, thus destroying for all practical purposes the very phenomena under investigation. To avoid these two alternatives, we opted for a combination of ethnographic methods (interviews, content analysis) and a computer-based analysis of the more than 6000 antibodies examined during the first six workshops, using Réseau-Lu, a software program specifically designed for the treatment of heterogeneous relational data.},
  timestamp = {2017-05-19T07:26:59Z},
  number = {3},
  author = {Cambrosio, Alberto and Keating, Peter and Mogoutov, Andrei},
  urldate = {2011-01-17},
  date = {2004-06-01},
  pages = {325--364}
}

@online{Varian_2009,
  title = {Official {{Google Research Blog}}: {{Predicting}} the {{Present}} with {{Google Trends}}},
  url = {http://googleresearch.blogspot.com/2009/04/predicting-present-with-google-trends.html},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Varian, Hal and Choi, Hyunyoung},
  urldate = {2011-05-23},
  date = {2009}
}

@article{Qiu_2011,
  title = {Extracting a {{Cellular Hierarchy}} from {{High}}-{{Dimensional Cytometry Data}} with {{SPADE}}},
  volume = {29},
  issn = {1087-0156, 1546-1696},
  url = {http://www.nature.com/doifinder/10.1038/nbt.1991},
  doi = {10.1038/nbt.1991},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Qiu, Peng and Simonds, Erin F and Bendall, Sean C and Gibbs, Kenneth D and Bruggner, Robert V and Linderman, Michael D and Sachs, Karen and Nolan, Garry P and Plevritis, Sylvia K},
  urldate = {2011-11-07},
  date = {2011-10-02},
  pages = {886--891}
}

@online{R-bloggers_2011,
  title = {R-{{Bloggers}} | {{R News}} \& {{Tutorials}} from the {{Web}}},
  url = {http://r-bloggers.com/},
  timestamp = {2017-05-19T07:26:59Z},
  author = {{R-bloggers}},
  urldate = {2011-05-05},
  date = {2011}
}

@article{Bayes_1763,
  title = {An {{Essay}} towards {{Solving}} a {{Problem}} in the {{Doctrine}} of {{Chance}}. {{By}} the {{Late Rev}}. {{Mr}}. {{Bayes}}, {{Communicated}} by {{Mr}}. {{Price}}, in a {{Letter}} to {{John Canton}}, {{M}}. {{A}}. and {{F}}. {{R}}. {{S}}.},
  volume = {53},
  url = {http://www.stat.ucla.edu/history/essay.pdf},
  doi = {10.1098/rstl.1763.0053},
  timestamp = {2017-05-19T07:26:59Z},
  number = {0},
  author = {Bayes, Thomas and Price, Richard},
  date = {1763},
  pages = {370--418}
}

@article{Piccarreta_2010,
  title = {Exploring {{Sequences}}: {{A Graphical Tool Based}} on {{Multi}}-{{Dimensional Scaling}}},
  volume = {173},
  issn = {09641998},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/20622583},
  shorttitle = {Exploring {{Sequences}}},
  abstract = {Sequence analysis has become one of the most used and discussed tools to describe life course trajectories. We introduce a new tool for the graphical exploratory analysis of sequences. Our plots combine standard sequence plots with the results that are provided by multi-dimensional scaling. We apply our procedure to describe work and family careers of Israeli women by using data from the Israel Social Mobility Survey. We first focus on some preliminary choices relative to the definition of the sequences: the age span, the length of the sequences and the set of states registered in each time period. We then describe how our plots can be used to gain insights about the main features of sequences and about the relationships between sequences and external information.},
  timestamp = {2017-05-19T07:26:59Z},
  number = {1},
  author = {Piccarreta, Raffaella and Lior, Orna},
  urldate = {2011-03-09},
  date = {2010-01-01},
  pages = {165--184}
}

@book{Savage_2005,
  title = {The {{Savage Number}}: {{How Much Money Do You Need}} to {{Retire}}?},
  isbn = {0-471-72799-7},
  shorttitle = {The {{Savage Number}}},
  timestamp = {2017-05-19T07:26:59Z},
  publisher = {{John Wiley \& Sons}},
  author = {Savage, Terry},
  date = {2005-06-24}
}

@online{Inc_2011,
  title = {Description - {{R Package Recommendation Engine}} - {{Kaggle}}},
  url = {http://www.kaggle.com/c/R},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Inc, Kaggle},
  urldate = {2011-05-24},
  date = {2011}
}

@online{Inc_2009a,
  title = {Predictive {{Analytics World Conference}}: {{Agenda}}},
  url = {http://www.predictiveanalyticsworld.com/sanfrancisco/2009/agenda.php#usergroup},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Inc, Prediction Impact},
  urldate = {2011-05-24},
  date = {2009}
}

@online{Muenchen_2011,
  title = {Popularity - {{R4stats}}.{{Com}}},
  url = {http://sites.google.com/site/r4statistics/popularity},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Muenchen, Robert},
  urldate = {2011-05-24},
  date = {2011}
}

@online{Raymond_2003,
  title = {Munging},
  url = {http://www.catb.org/jargon/html/B/brick.html},
  timestamp = {2017-05-19T07:26:59Z},
  author = {Raymond, Eric},
  urldate = {2009-06-18},
  date = {2003}
}

@article{Pritchard_1999,
  title = {Population {{Growth}} of {{Human Y Chromosomes}}: {{A Study}} of {{Y Chromosome Microsatellites}}},
  volume = {16},
  shorttitle = {Population {{Growth}} of {{Human Y Chromosomes}}},
  timestamp = {2017-05-19T07:27:00Z},
  number = {12},
  author = {Pritchard, \&\#32;J. K},
  date = {1999},
  pages = {1791--1798}
}

@article{Beaumont_2002,
  title = {Approximate {{Bayesian Computation}} in {{Population Genetics}}},
  volume = {162},
  url = {http://www.genetics.org/cgi/content/abstract/162/4/2025},
  timestamp = {2017-05-19T07:27:00Z},
  number = {4},
  author = {Beaumont, \&\#32;M. A},
  date = {2002-12-01},
  pages = {2025--2035}
}

@article{Plagnol_2004,
  title = {Approximate {{Bayesian Computation}} and {{MCMC}}},
  url = {http://www-gene.cimr.cam.ac.uk/vplagnol/papers/vpst-web.pdf},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Plagnol, \&\#32;V},
  date = {2004}
}

@article{Tomassini_2010,
  title = {Robust {{Bayesian Uncertainty Analysis}} of {{Climate System Properties Using Markov Chain Monte Carlo Methods}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Tomassini, L. and Reichert, P. and Knutti, R. and Stocker, T. F and Borsuk, M. E},
  date = {2010}
}

@article{Meinshausen_2009,
  title = {Greenhouse-{{Gas Emission Targets}} for {{Limiting Global Warming}} to 2 {{C}}},
  volume = {458},
  timestamp = {2017-05-19T07:27:00Z},
  number = {7242},
  author = {Meinshausen, M. and Meinshausen, N. and Hare, W. and Raper, S. C.B and Frieler, K. and Knutti, R. and Frame, D. J and Allen, M. R},
  date = {2009},
  pages = {1158--1162}
}

@article{Collins_2007,
  title = {Ensembles and {{Probabilities}}: {{A New Era}} in the {{Prediction}} of {{Climate Change}}},
  volume = {365},
  url = {http://rsta.royalsocietypublishing.org/content/365/1857/1957.abstract},
  doi = {10.1098/rsta.2007.2068},
  shorttitle = {Ensembles and {{Probabilities}}},
  abstract = {Predictions of future climate are of central importance in determining actions to adapt to the impacts of climate change and in formulating targets to reduce emissions of greenhouse gases. In the absence of analogues of the future, physically based numerical climate models must be used to make predictions. New approaches are under development to deal with a number of sources of uncertainty that arise in the prediction process. This paper introduces some of the concepts and issues in these new approaches, which are discussed in more detail in the papers contained in this issue.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {1857},
  author = {Collins, Mat},
  urldate = {2011-06-21},
  date = {2007},
  pages = {1957 --1970}
}

@article{Contractor_2011,
  title = {Multidimensional {{Networks}} and the {{Dynamics}} of {{Sociomateriality}}: {{Bringing Technology}} inside the {{Network}}},
  volume = {5},
  shorttitle = {Multidimensional {{Networks}} and the {{Dynamics}} of {{Sociomateriality}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Contractor, N. and Monge, P. R and Leonardi, P.},
  date = {2011},
  pages = {682--720}
}

@article{Powell_2005,
  title = {Network {{Dynamics}} and {{Field Evolution}}: {{The Growth}} of {{Interorganizational Collaboration}} in the {{Life Sciences}}},
  volume = {110},
  shorttitle = {Network {{Dynamics}} and {{Field Evolution}}},
  timestamp = {2017-05-19T07:27:00Z},
  number = {4},
  author = {Powell, W. W and White, D. R and Koput, K. W and Owen-Smith, J.},
  date = {2005},
  pages = {1132--1205}
}

@article{Diaconis_2009,
  title = {The {{Markov Chain Monte Carlo Revolution}}},
  volume = {46},
  timestamp = {2017-05-19T07:27:00Z},
  number = {2},
  author = {Diaconis, P.},
  date = {2009},
  pages = {179--205}
}

@article{Lodewyckx_2011,
  title = {A {{Hierarchical State Space Approach}} to {{Affective Dynamics}}},
  volume = {55},
  issn = {0022-2496},
  url = {http://www.sciencedirect.com/science/article/pii/S0022249610001057},
  doi = {16/j.jmp.2010.08.004},
  abstract = {\$$<$\$p\$$>$\$\$$<$\$br/\$$>$\$Linear dynamical system theory is a broad theoretical framework that has been applied in various research areas such as engineering, econometrics and recently in psychology. It quantifies the relations between observed inputs and outputs that are connected through a set of latent state variables. State space models are used to investigate the dynamical properties of these latent quantities. These models are especially of interest in the study of emotion dynamics, with the system representing the evolving emotion components of an individual. However, for simultaneous modeling of individual and population differences, a hierarchical extension of the basic state space model is necessary. Therefore, we introduce a Bayesian hierarchical model with random effects for the system parameters. Further, we apply our model to data that were collected using the Oregon adolescent interaction task: 66 normal and 67 depressed adolescents engaged in a conflict-oriented interaction with their parents and second-to-second physiological and behavioral measures were obtained. System parameters in normal and depressed adolescents were compared, which led to interesting discussions in the light of findings in recent literature on the links between cardiovascular processes, emotion dynamics and depression. We illustrate that our approach is flexible and general: The model can be applied to any time series for multiple systems (where a system can represent any entity) and moreover, one is free to focus on various components of this versatile model.\$$<$\$/p\$$>$\$},
  timestamp = {2017-05-19T07:27:00Z},
  number = {1},
  author = {Lodewyckx, Tom and Tuerlinckx, Francis and Kuppens, Peter and Allen, Nicholas B. and Sheeber, Lisa},
  urldate = {2011-08-23},
  date = {2011-02},
  pages = {68--83},
  keywords = {Bayesian hierarchical modeling,Cardiovascular processes,Emotions,Linear dynamical system,State space modeling}
}

@article{King_2011,
  title = {Ensuring the {{Data}}-{{Rich Future}} of the {{Social Sciences}}},
  volume = {331},
  url = {http://www.sciencemag.org/content/331/6018/719.abstract},
  doi = {10.1126/science.1197872},
  abstract = {Massive increases in the availability of informative social science data are making dramatic progress possible in analyzing, understanding, and addressing many major societal problems. Yet the same forces pose severe challenges to the scientific infrastructure supporting data sharing, data management, informatics, statistical methodology, and research ethics and policy, and these are collectively holding back progress. I address these changes and challenges and suggest what can be done.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6018},
  author = {King, Gary},
  urldate = {2011-08-26},
  date = {2011-02-11},
  pages = {719 --721}
}

@article{Vinson_2011,
  title = {The {{Allure}} of {{Synthetic Biology}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1235.short},
  doi = {10.1126/science.333.6047.1235},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Vinson, Valda and Pennisi, Elizabeth},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1235}
}

@article{Bohannon_2011,
  title = {The {{Life Hacker}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1236.short},
  doi = {10.1126/science.333.6047.1236},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Bohannon, John},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1236 --1237}
}

@article{Service_2011,
  title = {Algae's {{Second Try}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1238.short},
  doi = {10.1126/science.333.6047.1238},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Service, Robert F.},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1238 --1239}
}

@article{Kean_2011,
  title = {A {{Lab}} of {{Their Own}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1240.short},
  doi = {10.1126/science.333.6047.1240},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Kean, Sam},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1240 --1241}
}

@article{Reardon_2011,
  title = {Visions of {{Synthetic Biology}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1242.short},
  doi = {10.1126/science.333.6047.1242},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Reardon, Sara},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1242 --1243}
}

@article{Nandagopal_2011,
  title = {Synthetic {{Biology}}: {{Integrated Gene Circuits}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1244.abstract},
  doi = {10.1126/science.1207084},
  shorttitle = {Synthetic {{Biology}}},
  abstract = {A major goal of synthetic biology is to develop a deeper understanding of biological design principles from the bottom up, by building circuits and studying their behavior in cells. Investigators initially sought to design circuits “from scratch” that functioned as independently as possible from the underlying cellular system. More recently, researchers have begun to develop a new generation of synthetic circuits that integrate more closely with endogenous cellular processes. These approaches are providing fundamental insights into the regulatory architecture, dynamics, and evolution of genetic circuits and enabling new levels of control across diverse biological systems.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Nandagopal, Nagarajan and Elowitz, Michael B.},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1244 --1248}
}

@article{Ruder_2011,
  title = {Synthetic {{Biology Moving}} into the {{Clinic}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1248.abstract},
  doi = {10.1126/science.1206843},
  abstract = {Synthetic biology is an emerging field focused on engineering biomolecular systems and cellular capabilities for a variety of applications. Substantial progress began a little over a decade ago with the creation of synthetic gene networks inspired by electrical engineering. Since then, the field has designed and built increasingly complex circuits and constructs and begun to use these systems in a variety of settings, including the clinic. These efforts include the development of synthetic biology therapies for the treatment of infectious diseases and cancer, as well as approaches in vaccine development, microbiome engineering, cell therapy, and regenerative medicine. Here, we highlight advances in the biomedical application of synthetic biology and discuss the field’s clinical potential.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Ruder, Warren C. and Lu, Ting and Collins, James J.},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1248 --1252}
}

@article{Schwille_2011,
  title = {Bottom-{{Up Synthetic Biology}}: {{Engineering}} in a {{Tinkerer}}’s {{World}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1252.abstract},
  doi = {10.1126/science.1211701},
  shorttitle = {Bottom-{{Up Synthetic Biology}}},
  abstract = {How synthetic can “synthetic biology” be? A literal interpretation of the name of this new life science discipline invokes expectations of the systematic construction of biological systems with cells being built module by module—from the bottom up. But can this possibly be achieved, taking into account the enormous complexity and redundancy of living systems, which distinguish them quite remarkably from design features that characterize human inventions? There are several recent developments in biology, in tight conjunction with quantitative disciplines, that may bring this literal perspective into the realm of the possible. However, such bottom-up engineering requires tools that were originally designed by nature’s greatest tinkerer: evolution.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Schwille, Petra},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1252 --1254}
}

@article{Erickson_2011,
  title = {Synthetic {{Biology}}: {{Regulating Industry Uses}} of {{New Biotechnologies}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1254.abstract},
  doi = {10.1126/science.1211066},
  shorttitle = {Synthetic {{Biology}}},
  abstract = {In our view, synthetic biology is an extension of the continuum of genetic science that has been used safely for more than 40 years by the biotechnology industry in the development of commercial products. Examples of synthetic biology use by biotechnology companies illustrate the potential to substantially reduce research and development time and to increase speed to market. Improvements in the speed and cost of DNA synthesis are enabling scientists to design modified bacterial chromosomes that can be used in the production of renewable chemicals, biofuels, bioproducts, renewable specialty chemicals, pharmaceutical intermediates, fine chemicals, food ingredients, and health care products. Regulatory options should support innovation and commercial development of new products while protecting the public from potential harms.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Erickson, Brent and Singh, Rina and Winters, Paul},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1254 --1256}
}

@article{Alberts_2011,
  title = {A {{Grand Challenge}} in {{Biology}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1200.short},
  doi = {10.1126/science.1213238},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Alberts, Bruce},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1200}
}

@article{Xie_2011,
  title = {Multi-{{Input RNAi}}-{{Based Logic Circuit}} for {{Identification}} of {{Specific Cancer Cells}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1307.abstract},
  doi = {10.1126/science.1205527},
  abstract = {Engineered biological systems that integrate multi-input sensing, sophisticated information processing, and precisely regulated actuation in living cells could be useful in a variety of applications. For example, anticancer therapies could be engineered to detect and respond to complex cellular conditions in individual cells with high specificity. Here, we show a scalable transcriptional/posttranscriptional synthetic regulatory circuit—a cell-type “classifier”—that senses expression levels of a customizable set of endogenous microRNAs and triggers a cellular response only if the expression levels match a predetermined profile of interest. We demonstrate that a HeLa cancer cell classifier selectively identifies HeLa cells and triggers apoptosis without affecting non-HeLa cell types. This approach also provides a general platform for programmed responses to other complex cell states.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Xie, Zhen and Wroblewska, Liliana and Prochazka, Laura and Weiss, Ron and Benenson, Yaakov},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1307 --1311}
}

@article{Mondragon-Palomino_2011,
  title = {Entrainment of a {{Population}} of {{Synthetic Genetic Oscillators}}},
  volume = {333},
  url = {http://www.sciencemag.org/content/333/6047/1315.abstract},
  doi = {10.1126/science.1205369},
  abstract = {Biological clocks are self-sustained oscillators that adjust their phase to the daily environmental cycles in a process known as entrainment. Molecular dissection and mathematical modeling of biological oscillators have progressed quite far, but quantitative insights on the entrainment of clocks are relatively sparse. We simultaneously tracked the phases of hundreds of synthetic genetic oscillators relative to a common external stimulus to map the entrainment regions predicted by a detailed model of the clock. Synthetic oscillators were frequency-locked in wide intervals of the external period and showed higher-order resonance. Computational simulations indicated that natural oscillators may contain a positive-feedback loop to robustly adapt to environmental cycles.},
  timestamp = {2017-05-19T07:27:00Z},
  number = {6047},
  author = {Mondragón-Palomino, Octavio and Danino, Tal and Selimkhanov, Jangir and Tsimring, Lev and Hasty, Jeff},
  urldate = {2011-09-02},
  date = {2011},
  pages = {1315 --1319}
}

@article{Blondel_2008,
  title = {Fast {{Unfolding}} of {{Communities}} in {{Large Networks}}},
  volume = {2008},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Blondel, V. D and Guillaume, J. L and Lambiotte, R. and Lefebvre, E.},
  date = {2008},
  pages = {P10008}
}

@article{Pivovarov_2011,
  title = {Clustering and {{Classification}} in {{Text Collections Using Graph Modularity}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Pivovarov, G. and Trunov, S.},
  date = {2011}
}

@article{Pons_2010,
  title = {Post-{{Processing Hierarchical Community Structures}}: {{Quality Improvements}} and {{Multi}}-{{Scale View}}},
  shorttitle = {Post-{{Processing Hierarchical Community Structures}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Pons, P. and Latapy, M.},
  date = {2010}
}

@article{Huens_2006,
  title = {Large {{Graphs}} and {{Networks}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Huens, E.},
  date = {2006}
}

@article{Belak_2010,
  title = {Cross-{{Community Dynamics}} in {{Science}}: {{How Information Retrieval Affects Semantic Web}} and {{Vice Versa}}},
  shorttitle = {Cross-{{Community Dynamics}} in {{Science}}},
  timestamp = {2017-05-19T07:27:00Z},
  author = {Belák, V. and Karnstedt, M. and Hayes, C.},
  date = {2010}
}

@inproceedings{LeMerrer_2009,
  title = {Centralities: {{Capturing}} the {{Fuzzy Notion}} of {{Importance}} in {{Social Graphs}}},
  shorttitle = {Centralities},
  timestamp = {2017-05-19T07:27:00Z},
  booktitle = {Proceedings of the {{Second ACM EuroSys Workshop}} on {{Social Network Systems}}},
  author = {Le Merrer, E. and Trédan, G.},
  date = {2009},
  pages = {33--38}
}

@article{Brandes_2001,
  title = {A {{Faster Algorithm}} for {{Betweenness Centrality}}*},
  volume = {25},
  timestamp = {2017-05-19T07:27:01Z},
  number = {2},
  author = {Brandes, U.},
  date = {2001},
  pages = {163--177}
}

@article{Fox_2011,
  title = {Changing the {{Equation}} on {{Scientific Data Visualization}}},
  volume = {331},
  url = {http://www.sciencemag.org/content/331/6018/705.abstract},
  doi = {10.1126/science.1197654},
  abstract = {An essential facet of the data deluge is the need for different types of users to apply visualizations to understand how data analyses and queries relate to each other. Unfortunately, visualization too often becomes an end product of scientific analysis, rather than an exploration tool that scientists can use throughout the research life cycle. However, new database technologies, coupled with emerging Web-based technologies, may hold the key to lowering the cost of visualization generation and allow it to become a more integral part of the scientific process.},
  timestamp = {2017-05-19T07:27:01Z},
  number = {6018},
  author = {Fox, Peter and Hendler, James},
  urldate = {2011-09-19},
  date = {2011-02-11},
  pages = {705 --708}
}

@article{Park_2001,
  title = {Flight {{Kinematics}} of the {{Barn Swallow}} ({{Hirundo Rustica}}) over a {{Wide Range}} of {{Speeds}} in a {{Wind Tunnel}}},
  volume = {204},
  timestamp = {2017-05-19T07:27:01Z},
  number = {15},
  author = {Park, K. J and Rosén, M. and Hedenstr\$$\backslash$backslash\$öm, A.},
  date = {2001},
  pages = {2741}
}

@book{Cramer_2003,
  title = {Logit {{Models}} from {{Economics}} and {{Other Fields}}},
  timestamp = {2017-05-19T07:27:01Z},
  publisher = {{Cambridge Univ Pr}},
  author = {Cramer, J. S},
  date = {2003}
}

@article{Creager_2009,
  title = {Technical {{Matters}}: {{Method}}, {{Knowledge}} and {{Infrastructure}} in {{Twentieth}}-{{Century Life Science}}},
  volume = {6},
  issn = {1548-7091},
  shorttitle = {Technical {{Matters}}},
  abstract = {Conceptual breakthroughs in science tend to garner accolades and attention. But, as the invention of tissue culture and the development of isotopic tracers show, innovative methods open up new fields and enable the solution of longstanding problems.},
  timestamp = {2017-05-19T07:27:01Z},
  number = {10},
  author = {Creager, Angela N. H. and Landecker, Hannah},
  date = {2009-10},
  pages = {701--705},
  pmcid = {2907909}
}

@article{Wallace_2011,
  title = {A {{Small World}} of {{Citations}}? {{The Influence}} of {{Collaboration Networks}} on {{Citation Practices}}},
  url = {http://arxiv.org/abs/1107.5469},
  shorttitle = {A {{Small World}} of {{Citations}}?},
  abstract = {This paper examines the proximity of authors to those they cite using degrees of separation in a co-author network, essentially using collaboration networks to expand on the notion of self-citations. While the proportion of direct self-citations (including co-authors of both citing and cited papers) is relatively constant in time and across specialties in the natural sciences (10\% of citations) and the social sciences (20\%), the same cannot be said for citations to authors who are members of the co-author network. Differences between fields and trends over time lie not only in the degree of co-authorship which defines the large-scale topology of the collaboration network, but also in the referencing practices within a given discipline, computed by defining a propensity to cite at a given distance within the collaboration network. Overall, there is little tendency to cite those nearby in the collaboration network, excluding direct self-citations. By analyzing these social references, we characterize the social capital of local collaboration networks in terms of the knowledge production within scientific fields. These results have implications for the long-standing debate over biases common to most types of citation analysis, and for understanding citation practices across scientific disciplines over the past 50 years. In addition, our findings have important practical implications for the availability of 'arm's length' expert reviewers of grant applications and manuscripts.},
  timestamp = {2017-05-19T07:27:01Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1107.5469},
  author = {Wallace, Matthew L and Larivière, Vincent and Gingras, Yves},
  urldate = {2011-10-03},
  date = {2011-07-27},
  keywords = {Computer Science - Digital Libraries,Computer Science - Social and Information Networks,Physics - Physics and Society}
}

@article{Gower_1971,
  title = {A {{General Coefficient}} of {{Similarity}} and {{Some}} of {{Its Properties}}},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Gower, J.C.},
  date = {1971},
  pages = {857--871}
}

@online{Black_2005,
  title = {Greedy {{Algorithm}}},
  url = {http://xlinux.nist.gov/dads//HTML/greedyalgo.html},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Black, Paul E.},
  urldate = {2011-10-06},
  date = {2005}
}

@online{Computing_2011,
  title = {{{useR}}! 2011},
  url = {http://www.warwick.ac.uk/statsdept/user-2011/},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Computing, R. Foundation for Statistical},
  urldate = {2011-10-07},
  date = {2011}
}

@article{Rajapakse_2011,
  title = {Dynamics and {{Control}} of {{State}}-{{Dependent Networks}} for {{Probing Genomic Organization}}},
  volume = {108},
  url = {http://www.pnas.org/content/108/42/17257.abstract},
  doi = {10.1073/pnas.1113249108},
  abstract = {A state-dependent dynamic network is a collection of elements that interact through a network, whose geometry evolves as the state of the elements changes over time. The genome is an intriguing example of a state-dependent network, where chromosomal geometry directly relates to genomic activity, which in turn strongly correlates with geometry. Here we examine various aspects of a genomic state-dependent dynamic network. In particular, we elaborate on one of the important ramifications of viewing genomic networks as being state-dependent, namely, their controllability during processes of genomic reorganization such as in cell differentiation.},
  timestamp = {2017-05-19T07:27:01Z},
  number = {42},
  author = {Rajapakse, Indika and Groudine, Mark and Mesbahi, Mehran},
  urldate = {2011-10-20},
  date = {2011-10-18},
  pages = {17257 --17262}
}

@article{Abdallah_2011,
  title = {Mathematical {{Controllability}} of {{Genomic Networks}}},
  volume = {108},
  url = {http://www.pnas.org/content/108/42/17243.short},
  doi = {10.1073/pnas.1114108108},
  timestamp = {2017-05-19T07:27:01Z},
  number = {42},
  author = {Abdallah, Chaouki T.},
  urldate = {2011-10-25},
  date = {2011-10-18},
  pages = {17243 --17244}
}

@book{Jain_1988,
  location = {{Englewood Cliffs, N.J}},
  title = {Algorithms for {{Clustering Data}}},
  isbn = {0-13-022278-X},
  timestamp = {2017-05-19T07:27:01Z},
  series = {Prentice Hall advanced reference series},
  publisher = {{Prentice Hall}},
  author = {Jain, Anil K},
  date = {1988},
  keywords = {Cluster Analysis,Computer algorithms,Data processing}
}

@article{Smillie_2011,
  title = {Ecology {{Drives}} a {{Global Network}} of {{Gene Exchange Connecting}} the {{Human Microbiome}}},
  volume = {advance online publication},
  issn = {1476-4687},
  url = {http://dx.doi.org/10.1038/nature10571},
  doi = {10.1038/nature10571},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Smillie, Chris S. and Smith, Mark B. and Friedman, Jonathan and Cordero, Otto X. and David, Lawrence A. and Alm, Eric J.},
  urldate = {2011-11-02},
  year = {online October 30, 2011}
}

@article{Herrgard_2008,
  title = {A {{Consensus Yeast Metabolic Network Reconstruction Obtained}} from a {{Community Approach}} to {{Systems Biology}}},
  volume = {26},
  issn = {1087-0156},
  url = {http://dx.doi.org/10.1038/nbt1492},
  doi = {10.1038/nbt1492},
  timestamp = {2017-05-19T07:27:01Z},
  number = {10},
  author = {Herrgard, Markus J and Swainston, Neil and Dobson, Paul and Dunn, Warwick B and Arga, K Yalcin and Arvas, Mikko and Buthgen, Nils and Borger, Simon and Costenoble, Roeland and Heinemann, Matthias and Hucka, Michael and Le Novere, Nicolas and Li, Peter and Liebermeister, Wolfram and Mo, Monica L and Oliveira, Ana Paula and Petranovic, Dina and Pettifer, Stephen and Simeonidis, Evangelos and Smallbone, Kieran and Spasie, Irena and Weichart, Dieter and Brent, Roger and Broomhead, David S and Westerhoff, Hans V and Kurdar, Betul and Penttila, Merja and Klipp, Edda and Palsson, Bernhard O and Sauer, Uwe and Oliver, Stephen G and Mendes, Pedro and Nielsen, Jens and Kell, Douglas B},
  urldate = {2011-11-08},
  date = {2008-10},
  pages = {1155--1160}
}

@article{Segre_2002,
  title = {Analysis of {{Optimality}} in {{Natural}} and {{Perturbed Metabolic Networks}}},
  volume = {99},
  url = {http://www.pnas.org/content/99/23/15112.abstract},
  doi = {10.1073/pnas.232349399},
  abstract = {An important goal of whole-cell computational modeling is to integrate detailed biochemical information with biological intuition to produce testable predictions. Based on the premise that prokaryotes such as Escherichia coli have maximized their growth performance along evolution, flux balance analysis (FBA) predicts metabolic flux distributions at steady state by using linear programming. Corroborating earlier results, we show that recent intracellular flux data for wild-type E. coli JM101 display excellent agreement with FBA predictions. Although the assumption of optimality for a wild-type bacterium is justifiable, the same argument may not be valid for genetically engineered knockouts or other bacterial strains that were not exposed to long-term evolutionary pressure. We address this point by introducing the method of minimization of metabolic adjustment (MOMA), whereby we test the hypothesis that knockout metabolic fluxes undergo a minimal redistribution with respect to the flux configuration of the wild type. MOMA employs quadratic programming to identify a point in flux space, which is closest to the wild-type point, compatibly with the gene deletion constraint. Comparing MOMA and FBA predictions to experimental flux data for E. coli pyruvate kinase mutant PB25, we find that MOMA displays a significantly higher correlation than FBA. Our method is further supported by experimental data for E. coli knockout growth rates. It can therefore be used for predicting the behavior of perturbed metabolic networks, whose growth performance is in general suboptimal. MOMA and its possible future extensions may be useful in understanding the evolutionary optimization of metabolism.},
  timestamp = {2017-05-19T07:27:01Z},
  number = {23},
  author = {Segrè, Daniel and Vitkup, Dennis and Church, George M.},
  urldate = {2011-11-12},
  date = {2002-11-12},
  pages = {15112 --15117}
}

@article{Raftery_1986,
  title = {Choosing {{Models}} for {{Cross}}-{{Classifications}}.},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Raftery, A.E.},
  date = {1986}
}

@article{Guttman_1944,
  title = {A {{Basis}} for {{Scaling Qualitative Data}}},
  volume = {9},
  issn = {0003-1224},
  doi = {10.2307/2086306},
  timestamp = {2017-05-19T07:27:01Z},
  number = {2},
  author = {Guttman, Louis},
  date = {1944-04-01},
  pages = {139--150},
  eprinttype = {jstor},
  eprint = {2086306}
}

@article{Petrie_1899,
  title = {Sequences in {{Prehistoric Remains}}},
  volume = {29},
  issn = {0959-5295},
  doi = {10.2307/2843012},
  timestamp = {2017-05-19T07:27:01Z},
  issue = {3/4},
  author = {Petrie, W. M. Flinders},
  date = {1899-01-01},
  pages = {295--301},
  eprinttype = {jstor},
  eprint = {2843012}
}

@article{Brault_1993,
  title = {Pod-{{Specific Demography}} of {{Killer Whales}} ({{Orcinus Orca}})},
  volume = {74},
  issn = {00129658},
  url = {http://www.esajournals.org/doi/abs/10.2307/1940073},
  doi = {10.2307/1940073},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Brault, Solange and Caswell, Hal},
  urldate = {2011-11-18},
  date = {1993-07},
  pages = {1444}
}

@article{Edwards_2002,
  title = {Metabolic {{Modelling}} of {{Microbes}}: {{The Flux}}-{{Balance Approach}}},
  volume = {4},
  shorttitle = {Metabolic {{Modelling}} of {{Microbes}}},
  timestamp = {2017-05-19T07:27:01Z},
  number = {3},
  author = {Edwards, J.S. and Covert, M. and Palsson, B.},
  date = {2002},
  pages = {133--140}
}

@article{Besag_1989,
  title = {Digital {{Image Processing}}},
  volume = {16},
  timestamp = {2017-05-19T07:27:01Z},
  number = {3},
  author = {Besag, J.},
  date = {1989},
  pages = {395--407}
}

@article{Gilks_1994,
  title = {A {{Language}} and {{Program}} for {{Complex Bayesian Modelling}}},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Gilks, W.R. and Thomas, A. and Spiegelhalter, D.J.},
  date = {1994},
  pages = {169--177}
}

@article{Lunn_2009,
  title = {The {{BUGS Project}}: {{Evolution}}, {{Critique}} and {{Future Directions}}},
  volume = {28},
  shorttitle = {The {{BUGS Project}}},
  timestamp = {2017-05-19T07:27:01Z},
  number = {25},
  author = {Lunn, D. and Spiegelhalter, D. and Thomas, A. and Best, N.},
  date = {2009},
  pages = {3049--3067}
}

@article{Spiegelhalter_1996,
  title = {Hepatitis {{B}}: {{A Case Study}} in {{MCMC Methods}}},
  volume = {21},
  shorttitle = {Hepatitis {{B}}},
  timestamp = {2017-05-19T07:27:01Z},
  author = {Spiegelhalter, D.J. and Best, N.G. and Gilks, W.R. and Inskip, H.},
  date = {1996},
  pages = {43}
}

@article{Smith_1995,
  title = {A {{Conversation}} with {{Dennis Lindley}}},
  volume = {10},
  timestamp = {2017-05-19T07:27:02Z},
  number = {3},
  author = {Smith, A.},
  date = {1995},
  pages = {305--319}
}

@book{Horton_2010,
  title = {Using {{R}} for {{Data Management}}, {{Statistical Analysis}}, and {{Graphics}}},
  isbn = {978-1-4398-2755-0},
  abstract = {Using R for Data Management, Statistical Analysis, and Graphics presents an easy way to learn how to perform an analytical task in R, without having to navigate through the extensive, idiosyncratic, and sometimes unwieldly software documentation and vast number of add-on packages. Organized by short, clear descriptive entries, the book covers many common tasks, such as data management, descriptive summaries, inferential procedures, regression analysis, multivariate methods, and the creation of graphics.Through the extensive indexing, cross-referencing, and worked examples in this text, users can directly find and implement the material they need. The text includes convenient indices organized by topic and R syntax. Demonstrating the R code in action and facilitating exploration, the authors present example analyses that employ a single dataset from the HELP study. They also provides several case studies of more complex applications. Datasets and code are available for download on the book's Web site.Helping to improve your analytical skills, this book lucidly summarizes the aspects of R most often used by statistical analysts. New users of R will find the simple approach easy to understand while more sophisticated users will appreciate the invaluable source of task-oriented information.},
  timestamp = {2017-05-19T07:27:02Z},
  publisher = {{CRC Press}},
  author = {Horton, Nicholas J. and Kleinman, Ken},
  date = {2010-07-28},
  keywords = {Business & Economics / Statistics,Computers / Database Management / General,Computers / Mathematical & Statistical Software,Computers / Programming Languages / General,Database management,Mathematical statistics,Mathematical statistics - Data processing,Mathematics / Probability & Statistics / General,Open source software,R,R (Computer program language)}
}

@article{White_1970,
  title = {Matching, {{Vacancies}}, and {{Mobility}}},
  volume = {78},
  timestamp = {2017-05-19T07:27:02Z},
  number = {1},
  author = {White, Harrison},
  date = {1970},
  pages = {97--105}
}

@book{Kaufman_1990,
  location = {{New York}},
  title = {Finding {{Groups}} in {{Data}}},
  timestamp = {2017-05-19T07:27:02Z},
  publisher = {{Wiley Online Library}},
  author = {Kaufman, Leonard and Rousseeuw, Peter J.},
  date = {1990}
}

@article{Chase_1991,
  title = {Vacancy {{Chains}}},
  timestamp = {2017-05-19T07:27:02Z},
  author = {Chase, I.D.},
  date = {1991},
  pages = {133--154}
}

@article{White_1971,
  title = {Multipliers, {{Vacancy Chains}}, and {{Filtering}} in {{Housing}}},
  volume = {37},
  timestamp = {2017-05-19T07:27:02Z},
  number = {2},
  author = {White, H.C.},
  date = {1971},
  pages = {88--94}
}

@article{Aisenbrey_2010,
  title = {New {{Life}} for {{Old Ideas}}: {{The}}" {{Second Wave}}" of {{Sequence Analysis Bringing}} the" {{Course}}" {{Back}} into the {{Life Course}}},
  volume = {38},
  shorttitle = {New {{Life}} for {{Old Ideas}}},
  timestamp = {2017-05-19T07:27:02Z},
  number = {3},
  author = {Aisenbrey, S. and Fasang, A.E.},
  date = {2010},
  pages = {420--462}
}

@article{Elzinga_2008,
  title = {Sequence {{Analysis}}: {{Metric Representations}} of {{Categorical Time Series}}},
  shorttitle = {Sequence {{Analysis}}},
  timestamp = {2017-05-19T07:27:02Z},
  author = {Elzinga, C.H.},
  date = {2008}
}

@article{Elzinga_2010,
  title = {Complexity of {{Categorical Time Series}}},
  volume = {38},
  timestamp = {2017-05-19T07:27:02Z},
  number = {3},
  author = {Elzinga, C.H.},
  date = {2010},
  pages = {463--481}
}

@article{Elzinga_2003,
  title = {Sequence {{Similarity}}},
  volume = {32},
  timestamp = {2017-05-19T07:27:02Z},
  number = {1},
  author = {Elzinga, C.H.},
  date = {2003},
  pages = {3}
}

@article{Fisher_1938,
  title = {The {{Statistical Utilization}} of {{Multiple Measurements}}},
  volume = {8},
  timestamp = {2017-05-19T07:27:02Z},
  number = {4},
  author = {Fisher, R.A.},
  date = {1938},
  pages = {376--386}
}

@article{Rao_1948,
  title = {The {{Utilization}} of {{Multiple Measurements}} in {{Problems}} of {{Biological Classification}}},
  volume = {10},
  timestamp = {2017-05-19T07:27:02Z},
  number = {2},
  author = {Rao, C.R.},
  date = {1948},
  pages = {159--203}
}

@book{Prell_2011,
  title = {Social {{Network Analysis}}: {{History}}, {{Theory}} and {{Methodology}}},
  isbn = {1-4129-4715-4},
  shorttitle = {Social {{Network Analysis}}},
  timestamp = {2017-05-19T07:27:02Z},
  publisher = {{Sage Publications Ltd}},
  author = {Prell, Christina},
  date = {2011-10-26}
}

@article{Friedman_2010,
  title = {Regularization {{Paths}} for {{Generalized Linear Models}} via {{Coordinate Descent}}},
  volume = {33},
  timestamp = {2017-05-19T07:27:02Z},
  number = {1},
  author = {Friedman, J. and Hastie, T. and Tibshirani, R.},
  date = {2010},
  pages = {1}
}

@article{Pritchard_2000,
  title = {Inference of {{Population Structure Using Multilocus Genotype Data}}},
  volume = {155},
  timestamp = {2017-05-19T07:27:02Z},
  number = {2},
  author = {Pritchard, J. K and Stephens, M. and Donnelly, P.},
  date = {2000},
  pages = {945--959}
}

@article{Butts_2003,
  title = {Network {{Inference}}, {{Error}}, and {{Informant}} (in) {{Accuracy}}: {{A Bayesian Approach}}},
  volume = {25},
  shorttitle = {Network {{Inference}}, {{Error}}, and {{Informant}} (in) {{Accuracy}}},
  timestamp = {2017-05-19T07:27:03Z},
  number = {2},
  author = {Butts, C. T},
  date = {2003},
  pages = {103--140}
}

@article{Ramoni_2002,
  title = {Bayesian {{Clustering}} by {{Dynamics}}},
  volume = {47},
  issn = {0885-6125},
  url = {http://portal.acm.org/citation.cfm?id=584647.584652},
  doi = {10.1023/A:1013635829250},
  abstract = {This paper introduces a Bayesian method for clustering dynamic processes. The method models dynamics as Markov chains and then applies an agglomerative clustering procedure to discover the most probable set of clusters capturing different dynamics. To increase efficiency, the method uses an entropy-based heuristic search strategy. A controlled experiment suggests that the method is very accurate when applied to artificial time series in a broad range of conditions and, when applied to clustering sensor data from mobile robots, it produces clusters that are meaningful in the domain of application.},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Ramoni, Marco and Sebastiani, Paola and Cohen, Paul},
  urldate = {2011-03-29},
  date = {2002-04},
  pages = {91--121},
  keywords = {algorithms,bayesian learning,clustering,entropy,experimentation,heuristic search,learning,markov chains,time series}
}

@article{Snijders_2010,
  title = {Introduction to {{Stochastic Actor}}-{{Based Models}} for {{Network Dynamics}}},
  volume = {32},
  issn = {0378-8733},
  url = {http://www.sciencedirect.com/science/article/pii/S0378873309000069},
  doi = {10.1016/j.socnet.2009.02.004},
  abstract = {Stochastic actor-based models are models for network dynamics that can represent a wide variety of influences on network change, and allow to estimate parameters expressing such influences, and test corresponding hypotheses. The nodes in the network represent social actors, and the collection of ties represents a social relation. The assumptions posit that the network evolves as a stochastic process ‘driven by the actors’, i.e., the model lends itself especially for representing theories about how actors change their outgoing ties. The probabilities of tie changes are in part endogenously determined, i.e., as a function of the current network structure itself, and in part exogenously, as a function of characteristics of the nodes (‘actor covariates’) and of characteristics of pairs of nodes (‘dyadic covariates’). In an extended form, stochastic actor-based models can be used to analyze longitudinal data on social networks jointly with changing attributes of the actors: dynamics of networks and behavior. This paper gives an introduction to stochastic actor-based models for dynamics of directed networks, using only a minimum of mathematics. The focus is on understanding the basic principles of the model, understanding the results, and on sensible rules for model selection.},
  timestamp = {2017-05-19T07:27:03Z},
  number = {1},
  author = {Snijders, Tom A.B. and van de Bunt, Gerhard G. and Steglich, Christian E.G.},
  urldate = {2012-06-11},
  date = {2010-01},
  pages = {44--60},
  keywords = {Agent-based model,Longitudinal,Markov chain,Peer influence,Peer selection,Statistical modeling},
  options = {useprefix=true}
}

@online{Inc_,
  title = {Background - {{Facebook Recruiting Competition}} - {{Kaggle}}},
  url = {http://www.kaggle.com/c/FacebookRecruiting/details/Background},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Inc, Kaggle},
  urldate = {2012-07-03}
}

@online{Inc_2012,
  title = {{{TopCoder}}, {{Inc}}. | {{Home}} of the {{World}}'s {{Largest Development Community}}},
  url = {http://www.topcoder.com/},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Inc, Topcoder},
  urldate = {2012-07-05},
  date = {2012}
}

@online{Inc_2011a,
  title = {How {{I Did It}}: {{Ming}}-{{Hen Tsai}} on {{Finishing Third}} in the {{R Competition}} | {{No Free Hunch}}},
  url = {http://blog.kaggle.com/2011/02/11/how-i-did-it-ming-hen-tsai-on-finishing-third-in-the-r-competition/},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Inc, Kaggle},
  urldate = {2012-07-05},
  date = {2011}
}

@online{_t,
  title = {Bay {{Area useR Group}} ({{R Programming Language}})},
  url = {http://www.meetup.com/R-Users/events/9573566/},
  abstract = {2009 Kick-off Meeting Welcome \&amp; Upcoming Meeting Plan. Panel Discussion - The R and Science of Predictive Analytics: Four Case Studies in R Bo Cowgill, Google Itamar Rosenn, Facebook},
  timestamp = {2017-05-19T07:27:03Z},
  urldate = {2012-07-03},
  keywords = {Bay Area useRs,California,club,community,event,group,Information Architecture,meetup,San Francisco,USA}
}

@article{Wasserman_1996,
  title = {Logit {{Models}} and {{Logistic Regressions}} for {{Social Networks}}: {{I}}. {{An Introduction}} to {{Markov Graphs And}}\&lt;{{I}}\&gt;{{P}}\&lt;/{{I}}\&gt;},
  volume = {61},
  issn = {0033-3123},
  url = {http://www.springerlink.com/content/t2w46715636r2h11/abstract/},
  doi = {10.1007/BF02294547},
  shorttitle = {Logit {{Models}} and {{Logistic Regressions}} for {{Social Networks}}},
  timestamp = {2017-05-19T07:27:03Z},
  number = {3},
  author = {Wasserman, Stanley and Pattison, Philippa},
  urldate = {2012-06-13},
  date = {1996},
  pages = {401--425},
  keywords = {Behavioral Science}
}

@online{Kaggle_2012a,
  title = {Description - {{Facebook Recruiting Competition}} - {{Kaggle}}},
  url = {http://www.kaggle.com/c/FacebookRecruiting},
  timestamp = {2017-05-19T07:27:03Z},
  author = {{Kaggle}},
  urldate = {2012-07-05},
  date = {2012}
}

@online{Google_,
  title = {Google {{Code Jam}}},
  url = {http://code.google.com/codejam},
  timestamp = {2017-05-19T07:27:03Z},
  author = {{Google}},
  urldate = {2012-07-05}
}

@online{Inc_2011b,
  title = {Dave {{Slate}} on {{Winning}} the {{R Challenge}} | {{No Free Hunch}}},
  url = {http://blog.kaggle.com/2011/02/15/dave-slate-on-winning-the-r-challenge/},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Inc, Kaggle},
  urldate = {2012-07-05},
  date = {2011}
}

@book{Gelman_2003,
  edition = {2},
  title = {Bayesian {{Data Analysis}}, {{Second Edition}}},
  isbn = {1-58488-388-X},
  timestamp = {2017-05-19T07:27:03Z},
  publisher = {{Chapman and Hall/CRC}},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Rubin, Donald B.},
  date = {2003-07-29}
}

@article{Tierney_1994,
  title = {Markov {{Chains}} for {{Exploring Posterior Distributions}}},
  volume = {22},
  issn = {0090-5364},
  abstract = {Several Markov chain methods are available for sampling from a posterior distribution. Two important examples are the Gibbs sampler and the Metropolis algorithm. In addition, several strategies are available for constructing hybrid algorithms. This paper outlines some of the basic methods and strategies and discusses some related theoretical and practical issues. On the theoretical side, results from the theory of general state space Markov chains can be used to obtain convergence rates, laws of large numbers and central limit theorems for estimates obtained from Markov chain methods. These theoretical results can be used to guide the construction of more efficient algorithms. For the practical use of Markov chain methods, standard simulation methodology provides several variance reduction techniques and also give guidance on the choice of sample size and allocation.},
  timestamp = {2017-05-19T07:27:03Z},
  number = {4},
  author = {Tierney, Luke},
  date = {1994-12-01},
  pages = {1701--1728},
  eprinttype = {jstor},
  eprint = {2242477}
}

@article{Casella_1992,
  title = {Explaining the {{Gibbs Sampler}}},
  volume = {46},
  issn = {0003-1305},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475878},
  doi = {10.1080/00031305.1992.10475878},
  abstract = {Abstract Computer-intensive algorithms, such as the Gibbs sampler, have become increasingly popular statistical tools, both in applied and theoretical work. The properties of such algorithms, however, may sometimes not be obvious. Here we give a simple explanation of how and why the Gibbs sampler works. We analytically establish its properties in a simple case and provide insight for more complicated cases. There are also a number of examples.},
  timestamp = {2017-05-19T07:27:03Z},
  number = {3},
  author = {Casella, George and George, Edward I.},
  urldate = {2012-10-18},
  date = {1992},
  pages = {167--174}
}

@article{Honaker_2010,
  title = {What to {{Do}} about {{Missing Values}} in {{Time}}-{{Series Cross}}-{{Section Data}}},
  volume = {54},
  issn = {0092-5853},
  doi = {10.2307/25652223},
  abstract = {Applications of modern methods for analyzing data with missing values, based primarily on multiple imputation, have in the last half-decade become common in American politics and political behavior. Scholars in this subset of political science have thus increasingly avoided the biases and inefficiencies caused by ad hoc methods like listwise deletion and best guess imputation. However, researchers in much of comparative politics and international relations, and others with similar data, have been unable to do the same because the best available imputation methods work poorly with the time-series cross-section data structures common in these fields. We attempt to rectify this situation with three related developments. First, we build a multiple imputation model that allows smooth time trends, shifts across cross-sectional units, and correlations over time and space, resulting in far more accurate imputations. Second, we enable analysts to incorporate knowledge from area studies experts via priors on individual missing cell values, rather than on difficult-to-interpret model parameters. Third, because these tasks could not be accomplished within existing imputation algorithms, in that they cannot handle as many variables as needed even in the simpler cross-sectional data for which they were designed, we also develop a new algorithm that substantially expands the range of computationally feasible data types and sizes for which multiple imputation can be used. These developments also make it possible to implement the methods introduced here in freely available open source software that is considerably more reliable than existing algorithms.},
  timestamp = {2017-05-19T07:27:03Z},
  number = {2},
  author = {Honaker, James and King, Gary},
  date = {2010-04-01},
  pages = {561--581},
  eprinttype = {jstor},
  eprint = {25652223}
}

@book{Teetor_2011,
  title = {R {{Cookbook}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=KIHuSXyhawEC&oi=fnd&pg=PR5&dq=teetor+R+cookbook&ots=d4Uj6FIU_p&sig=6QY0uaRENGFS3a1B6cmJ2I9yw1g},
  timestamp = {2017-05-19T07:27:03Z},
  publisher = {{O'Reilly Media, Incorporated}},
  author = {Teetor, Paul},
  urldate = {2013-06-26},
  date = {2011}
}

@book{Matloff_2011,
  location = {{San Francisco}},
  title = {Art of {{R Programming}}},
  url = {http://www.books24x7.com/marc.asp?bookid=44507},
  timestamp = {2017-05-19T07:27:03Z},
  publisher = {{No Starch Press}},
  author = {Matloff, Norman S},
  urldate = {2013-06-26},
  date = {2011}
}

@book{Adler_2010,
  location = {{Sebastopol, Calif.}},
  title = {R in a {{Nutshell}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=IOmnlDvVZ_EC&oi=fnd&pg=PR5&dq=r+in+a+nutshell&ots=to8tKeDgSH&sig=AzkSem6yUG6dsnij0R4NxfZP–w},
  timestamp = {2017-05-19T07:27:03Z},
  publisher = {{O'Reilly Publishers}},
  author = {Adler, Joseph and Beyer, Jörg},
  urldate = {2013-06-27},
  date = {2010}
}

@online{Wikibooks_2013,
  title = {R {{Programming}} - {{Wikibooks}}, {{Open Books}} for an {{Open World}}},
  url = {http://en.wikibooks.org/wiki/R_Programming},
  timestamp = {2017-05-19T07:27:03Z},
  author = {{Wikibooks}},
  urldate = {2013-06-27},
  date = {2013}
}

@inproceedings{Xie_2012,
  location = {{Warwick, UK}},
  title = {New {{Tools}} for {{Reproducible Research}} with {{R}}},
  url = {http://www.r-project.org/conferences/useR-2012/InvitedXieAllaire.pdf},
  timestamp = {2017-05-19T07:27:03Z},
  author = {Xie, Yihui and Allaire, J. J.},
  urldate = {2013-07-01},
  date = {2012}
}

@article{Perez_2007,
  title = {{{IPython}}. {{A System}} for {{Interactive Scientific Computing}}},
  volume = {9},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4160251},
  shorttitle = {{{IPython}}},
  timestamp = {2017-05-19T07:27:03Z},
  number = {3},
  author = {Perez, Fernando and Granger, Brian E.},
  urldate = {2013-07-01},
  date = {2007},
  pages = {21--29}
}

@online{Macfarlane_2013,
  title = {Pandoc - {{Pandoc User}}’s {{Guide}}},
  url = {http://johnmacfarlane.net/pandoc/README.html},
  timestamp = {2017-05-19T07:27:04Z},
  author = {Macfarlane, John},
  urldate = {2013-07-02},
  date = {2013}
}

@article{Hird_2012,
  title = {Digesting {{Difference}}: {{Metabolism}} and the {{Question}} of {{Sexual Difference}}},
  volume = {20},
  issn = {1080-6520},
  url = {http://muse.jhu.edu/journals/configurations/v020/20.3.hird.html},
  shorttitle = {Digesting {{Difference}}},
  abstract = {Abstract Elizabeth Grosz’s research program offers a thoughtful and complex argument for sexual difference as ontology. Gathering together Grosz’s considerable writing, which she synthesizes in her most recent book, Becoming Undone, this essay explores Grosz’s engagement of sexual difference through evolutionary theory. This refraction invites challenging questions with which feminist theory might think through one of its defining issues. A close reading of Grosz’s work reveals contradictions, tensions, and problems in discussions of being versus becoming; duration versus the stasis of sexual difference; and neo-Darwinian humanism versus Darwinian inhumanism, and the former’s consequent normalizing of sexual difference. The essay concludes with a discussion of metabolism as sexual difference’s potential foil. Refracting metabolism – as a force – through evolutionary theory excites the significant contradictions that sexual difference as ontology sustains in Grosz’s analysis.},
  timestamp = {2017-05-19T07:27:04Z},
  number = {3},
  author = {Hird, Myra J.},
  urldate = {2013-07-02},
  date = {2012},
  pages = {213--237}
}

@book{Halvorsen_2012,
  title = {{{ElemStatLearn}}: {{Data Sets}}, {{Functions}} and {{Examples}} from the {{Book}}: "{{The Elements}} of {{Statistical Learning}}, {{Data Mining}}, {{Inference}}, and {{Prediction}}" by {{Trevor Hastie}}, {{Robert Tibshirani}} and {{Jerome Friedman}}.},
  url = {http://CRAN.R-project.org/package=ElemStatLearn},
  timestamp = {2017-05-19T07:27:04Z},
  author = {Halvorsen, packaging by Kjetil},
  date = {2012}
}

@book{Conway_2012,
  location = {{Sebastopol, CA}},
  title = {Machine {{Learning}} for {{Hackers}}},
  isbn = {978-1-4493-3054-5 1-4493-3054-1 978-1-4493-3053-8 1-4493-3053-3},
  url = {http://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=436647},
  abstract = {If you're an experienced programmer interested in crunching data, this book will get you started with machine learning–a toolkit of algorithms that enables computers to train themselves to automate useful tasks. Authors Drew Conway and John Myles White help you understand machine learning and statistics tools through a series of hands-on case studies, instead of a traditional math-heavy presentation. Each chapter focuses on a specific problem in machine learning, such as classification, prediction, optimization, and recommendation. Using the R programming language, you'll learn how to analyze s.},
  timestamp = {2017-05-19T07:27:04Z},
  publisher = {{O'Reilly}},
  author = {Conway, Drew and White, John Myles},
  urldate = {2013-07-04},
  date = {2012}
}

@book{Russell_2011,
  location = {{Sebastopol, CA}},
  title = {Mining the {{Social Web}}},
  isbn = {978-1-4493-8834-8 1-4493-8834-5},
  abstract = {Facebook, Twitter, and LinkedIn generate a tremendous amount of valuable social data, but how can you find out who's making connections with social media, what they're talking about, or where they're located? This book shows you how to answer these questions and more. Each chapter introduces techniques for mining data in different areas of the social web, including blogs and email.},
  timestamp = {2017-05-19T07:27:04Z},
  publisher = {{O'Reilly}},
  author = {Russell, Matthew A},
  date = {2011}
}

@online{Lewis_1997,
  title = {Reuters-21578 {{Text Categorization Collection}}},
  url = {http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html},
  timestamp = {2017-05-19T07:25:07Z},
  author = {Lewis, David},
  urldate = {2014-10-16},
  date = {1997}
}

@online{Davenport_2012,
  title = {Data {{Scientist}}: {{The Sexiest Job}} of the 21st {{Century}}},
  url = {http://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century/ar/1},
  shorttitle = {Data {{Scientist}}},
  abstract = {Business management magazine, blogs, case studies, articles, books, and webinars from Harvard Business Review, addressing today's topics and challenges in business management.},
  timestamp = {2017-05-19T07:25:08Z},
  author = {Davenport, Thomas and {Patil}},
  urldate = {2014-05-05},
  date = {2012},
  keywords = {Accounting,business management articles resources,business resources books articles case studies,communication,entrepreneurship,execution,finance,Harvard Business School Publishing,HBO,HBP,HBR,HBSP,innovation,international global business strategy,leadership,managing people,operations,organizational development,technology}
}

@book{Galloway_2004,
  location = {{Cambridge, Mass.}},
  title = {Protocol: {{How Control Exists}} after {{Decentralization}}},
  timestamp = {2017-05-19T07:25:08Z},
  series = {Leonardo (Series) (Cambridge, Mass.)},
  publisher = {{MIT Press}},
  author = {Galloway, Alexander R.},
  date = {2004},
  keywords = {Computer network protocols,Computer networks - Management,Computer networks - Security measures,Electronic data processing - Distributed processing}
}

@inproceedings{Anjos_2012,
  title = {Bob: {{A Free Signal Processing}} and {{Machine Learning Toolbox}} for {{Researchers}}},
  url = {http://dl.acm.org/citation.cfm?id=2396517},
  shorttitle = {Bob},
  timestamp = {2017-05-19T07:25:08Z},
  booktitle = {Proceedings of the 20th {{ACM International Conference}} on {{Multimedia}}},
  publisher = {{ACM}},
  author = {Anjos, André and El-Shafey, Laurent and Wallace, Roy and Günther, Manuel and McCool, Christopher and Marcel, Sébastien},
  urldate = {2014-05-05},
  date = {2012},
  pages = {1449--1452}
}

@online{Rotella_2012,
  title = {Is {{Data The New Oil}}?},
  url = {http://www.forbes.com/sites/perryrotella/2012/04/02/is-data-the-new-oil/},
  abstract = {Recently, on a CNBC Squawk Box segment, “The Pulse of Silicon Valley,” host Joe Kernan posed the question, “What is the next really big thing?” to Ann Winblad, the legendary investor and senior partner at Hummer-Winblad. Her response: “Data is the new oil.” Winblad talked about predictive analytics as the new [...]},
  timestamp = {2017-05-19T07:25:08Z},
  author = {Rotella, Perry},
  urldate = {2014-05-06},
  date = {2012-02-02},
  keywords = {Building the Organization of Tomorrow,CEO Network,Leaders,leadership,Life In The New Workplace,Strategies Solutions,Strategies & Solutions}
}

@article{Curtin_2013,
  title = {{{MLPACK}}: {{A Scalable C}}++ {{Machine Learning Library}}},
  volume = {14},
  url = {http://dl.acm.org/citation.cfm?id=2502606},
  shorttitle = {{{MLPACK}}},
  timestamp = {2017-05-19T07:25:08Z},
  number = {1},
  author = {Curtin, Ryan R. and Cline, James R. and Slagle, Neil P. and March, William B. and Ram, Parikshit and Mehta, Nishant A. and Gray, Alexander G.},
  urldate = {2014-05-05},
  date = {2013},
  pages = {801--805}
}

@online{OreillyMedia_2014,
  title = {O'{{Reilly Strata Conference}}: {{Making Data Work}}},
  url = {http://strataconf.com/},
  shorttitle = {O'{{Reilly Strata Conference}}},
  abstract = {O'Reilly Strata Conference is about big data technology and strategy for business managers, data analysts, developers, and data scientists.},
  timestamp = {2017-05-19T07:25:08Z},
  author = {{Oreilly Media}},
  urldate = {2014-05-07},
  date = {2014}
}

@book{Deleuze_1993,
  location = {{London}},
  title = {The {{Fold}} : {{Leibniz}} and the {{Baroque}}},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{Athlone Press}},
  author = {Deleuze, Gilles},
  date = {1993}
}

@article{Wu_2008,
  title = {Top 10 {{Algorithms}} in {{Data Mining}}},
  volume = {14},
  timestamp = {2017-05-19T07:25:08Z},
  number = {1},
  author = {Wu, X. and Kumar, V. and Ross Quinlan, J. and Ghosh, J. and Yang, Q. and Motoda, H. and McLachlan, G. J and Ng, A. and Liu, B. and Yu, P. S and {others}},
  date = {2008},
  pages = {1--37}
}

@book{Coopmans_2014,
  title = {Representation in {{Scientific Practice Revisited}}},
  isbn = {978-0-262-52538-1},
  abstract = {Representation in Scientific Practice, published by the MIT Press in 1990, helped coalesce a long-standing interest in scientific visualization among historians, philosophers, and sociologists of science and remains a touchstone for current investigations in science and technology studies. This volume revisits the topic, taking into account both the changing conceptual landscape of STS and the emergence of new imaging technologies in scientific practice. It offers cutting-edge research on a broad array of fields that study information as well as short reflections on the evolution of the field by leading scholars, including some of the contributors to the 1990 volume. The essays consider the ways in which viewing experiences are crafted in the digital era; the embodied nature of work with digital technologies; the constitutive role of materials and technologies – from chalk oards to brain scans – in the production of new scientific knowledge; the metaphors and images mobilized by communities of practice; and the status and significance of scientific imagery in professional and popular culture. ContributorsMorana Alac, Michael Barany, Anne Beaulieu, Annamaria Carusi, Catelijne Coopmans, Lorraine Daston, Sarah de Rijcke, Joseph Dumit, Emma Frow, Yann Giraud, Aud Sissel Hoel, Martin Kemp, Bruno Latour, John Law, Michael Lynch, Donald MacKenzie, Cyrus Mody, Natasha Myers, Rachel Prentice, Arie Rip, Martin Ruivenkamp, Lucy Suchman, Janet Vertesi, Steve Woolgar},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{MIT Press}},
  author = {Coopmans, Catelijne and Vertesi, Janet and Lynch, Michael E. and Woolgar, Steve},
  date = {2014-01-03},
  keywords = {Science / Essays,Social Science / Media Studies}
}

@online{_,
  title = {Publications},
  url = {http://catelijnecoopmans.com/publications/},
  timestamp = {2017-05-19T07:25:08Z},
  urldate = {2014-07-19}
}

@article{Wiedemann_0,
  title = {Between {{Swarm}}, {{Network}}, and {{Multitude}}: {{Anonymous}} and the {{Infrastructures}} of the {{Common}}},
  volume = {0},
  issn = {1600-910X},
  url = {http://dx.doi.org/10.1080/1600910X.2014.895768},
  doi = {10.1080/1600910X.2014.895768},
  shorttitle = {Between {{Swarm}}, {{Network}}, and {{Multitude}}},
  abstract = {I use Anonymous as an illustrative case for more general reflections on collectivities in the age of computerization that are not based on shared identities. Whereas theories of collective behavior focus on circular reaction within assemblies of bodies, for the phenomena that this article addresses, communication technology plays a constitutive role in the process of connecting people and turning connectivity into collectivity. In order to explore this Internet-based connectivity and its processes of assembling collectivity outside and beyond practices of representation, I approach Anonymous with the notion of Tarde's public and further investigate the dynamics of constituting collectivity with a ‘new materialist’ perspective that asks to what extent Anonymous can be interpreted either as swarm, network, or multitude. A focus on the interplay of Internet infrastructures and affection, which can produce experiences of the common and thus constitute collectivity, challenges the distinction of mediation and emergence.},
  timestamp = {2017-05-19T07:25:08Z},
  number = {0},
  author = {Wiedemann, Carolin},
  urldate = {2014-06-12},
  year = {0},
  pages = {1--18}
}

@book{Haraway_1997,
  location = {{New York ; London}},
  title = {Modest-{{Witness}}@{{Second}}-{{Millennium}}.{{FemaleMan}}-{{Meets}}-{{OncoMouse}}: {{Feminism}} and {{Technoscience}}},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{Routledge}},
  author = {Haraway, Donna},
  date = {1997},
  keywords = {Computers and civilization,Feminist criticism,Feminist theory,Science - Social aspects,Technology - Social aspects}
}

@book{Guattari_1984,
  location = {{Harmondsworth, Middlesex, England ; New York, N.Y., U.S.A.}},
  title = {Molecular {{Revolution}} : {{Psychiatry}} and {{Politics}}},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{Penguin}},
  author = {Guattari, Félix},
  date = {1984},
  keywords = {Psychiatry Political aspects.,Social psychiatry.}
}

@online{Issenberg_2012,
  title = {The {{Definitive Story}} of {{How President Obama Mined Voter Data}} to {{Win A Second Term}} | {{MIT Technology Review}}},
  url = {http://www.technologyreview.com/featuredstory/509026/how-obamas-team-used-big-data-to-rally-voters/},
  abstract = {How President Obama’s campaign used big data to rally individual voters.},
  timestamp = {2017-05-19T07:25:08Z},
  author = {Issenberg, Sasha},
  urldate = {2013-01-09},
  date = {2012}
}

@article{Galloway_2014,
  title = {The {{Cybernetic Hypothesis}}},
  volume = {25},
  issn = {1040-7391, 1527-1986},
  url = {http://differences.dukejournals.org/cgi/doi/10.1215/10407391-2420021},
  doi = {10.1215/10407391-2420021},
  timestamp = {2017-05-19T07:25:08Z},
  number = {1},
  author = {Galloway, Alexander},
  urldate = {2014-07-29},
  date = {2014-01-01},
  pages = {107--131}
}

@book{Dewey_1957,
  location = {{Boston}},
  edition = {1st Beacon paperback ed.},
  title = {Reconstruction in {{Philosophy}}},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{Beacon Press}},
  author = {Dewey, John},
  date = {1957},
  keywords = {Philosophy}
}

@book{Suchman_2006,
  edition = {2},
  title = {Human and {{Machine Reconfigurations}}: {{Plans}} and {{Situated Actions}}},
  isbn = {0-521-67588-X},
  shorttitle = {Human and {{Machine Reconfigurations}}},
  timestamp = {2017-05-19T07:25:08Z},
  publisher = {{Cambridge University Press}},
  author = {Suchman, Lucy},
  date = {2006-12-04}
}

@book{Burkill_1978,
  title = {A {{First Course}} in {{Mathematical Analysis}}},
  isbn = {978-0-521-29468-3},
  abstract = {This straightforward course based on the idea of a limit is intended for students who have acquired a working knowledge of the calculus and are ready for a more systematic treatment which also brings in other limiting processes, such as the summation of infinite series and the expansion of trigonometric functions as power series. Particular attention is given to clarity of exposition and the logical development of the subject matter. A large number of examples is included, with hints for the solution of many of them.},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{Cambridge University Press}},
  author = {Burkill, J. C.},
  date = {1978-12-14}
}

@book{Bowker_2005,
  title = {Memory {{Practices}} in the {{Sciences}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{MIT Press Cambridge, MA}},
  author = {Bowker, G. C},
  date = {2005}
}

@book{Shapin_1989,
  location = {{Princeton ; Oxford}},
  title = {Leviathan and the {{Air}}-{{Pump}} : {{Hobbes}}, {{Boyle}}, and the {{Experimental Life}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{Princeton University Press}},
  author = {Shapin, Steven and Schaffer, Simon},
  date = {1989},
  keywords = {& Hobbes,1588-1679 - Contributions in philosophy of science,1627-1691,1627-1691 - Contributions in philosophy of science,Boyle,Hobbes,Philosophy of science. Theories of Boyle,Robert,Science - Philosophy - History - 17th century,Thomas}
}

@book{Arendt_1998,
  location = {{Chicago ; London}},
  title = {The {{Human Condition}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{University of Chicago Press}},
  author = {Arendt, Hannah},
  date = {1998}
}

@book{Galloway_2007,
  location = {{Minneapolis}},
  title = {The {{Exploit}} : {{A Theory}} of {{Networks}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{University of Minnesota Press}},
  author = {Galloway, Alexander R and Thacker, Eugene},
  date = {2007},
  keywords = {Bioinformatics Philosophy.,Computer network protocols.,Computer networks.,Social networks.,Sovereignty.}
}

@book{Deleuze_1988,
  location = {{New York}},
  title = {Bergsonism},
  timestamp = {2017-06-01T21:16:35Z},
  publisher = {{Zone Books}},
  author = {Deleuze, Gilles},
  translator = {Habberjam, Barbara and Tomlinson, Hugh},
  date = {1988},
  keywords = {1859-1941.,Bergson,Henri}
}

@online{Larsen_2012,
  title = {How {{ProPublica}}’s {{Message Machine Reverse Engineers Political Microtargeting}}},
  url = {http://www.propublica.org/nerds/item/how-propublicas-message-machine-reverse-engineers-political-microtargeting},
  abstract = {How the message machine works.},
  timestamp = {2017-05-19T07:25:09Z},
  author = {Larsen, Jeff},
  urldate = {2014-08-28},
  date = {2012}
}

@book{Massumi_2002,
  location = {{Durham, N.C}},
  title = {Parables for the {{Virtual}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{Duke University Press}},
  author = {Massumi, Brian},
  date = {2002}
}

@online{Madrigal_2014,
  title = {How {{Netflix Reverse Engineered Hollywood}}},
  url = {http://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/},
  abstract = {To understand how people look for movies, the video service created 76,897 micro-genres. We took the genre descriptions, broke them down to their key words, … and built our own new-genre generator.},
  timestamp = {2017-05-19T07:25:09Z},
  author = {Madrigal, Alexis C.},
  urldate = {2014-08-28},
  date = {2014}
}

@book{Whitehead_1956,
  location = {{New York,}},
  title = {Modes of {{Thought}}; {{Six Lectures Delivered}} in {{Wellesley College}}, {{Massachusetts}}, and {{Two Lectures}} in the {{University}} of {{Chicago}}},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{Cambridge University Press}},
  author = {Whitehead, Alfred North},
  date = {1956},
  keywords = {Philosophy.}
}

@article{Vance_2011,
  title = {This {{Tech Bubble Is Different}}},
  url = {http://www.businessweek.com/magazine/content/11_17/b4225060960537.htm},
  abstract = {Tech bubbles happen, but we usually gain from the innovation left behind. This one—driven by social networking—could leave us empty-handed},
  timestamp = {2017-05-19T07:25:09Z},
  author = {Vance, Ashlee},
  urldate = {2014-08-29},
  date = {2011-04-14},
  keywords = {ad-tech culture,dot-com bubble,Facebook,Google,Groupon,Silicon Valley,social networks,Zynga}
}

@article{Warner_1964,
  title = {Experience with {{Baye}}'s {{Theorem}} for {{Computer Diagnosis}} of {{Congenital Heart Disease}}*},
  volume = {115},
  issn = {1749-6632},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1964.tb50648.x/abstract},
  doi = {10.1111/j.1749-6632.1964.tb50648.x},
  timestamp = {2017-05-19T07:25:09Z},
  number = {2},
  author = {Warner, Homer R. and Toronto, Alan F. and Veasy, L. George},
  urldate = {2014-10-06},
  date = {1964-07-01},
  pages = {558--567}
}

@inproceedings{Mohamed_2011,
  title = {Deep {{Belief Networks Using Discriminative Features}} for {{Phone Recognition}}},
  isbn = {978-1-4577-0538-0},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5947494},
  doi = {10.1109/ICASSP.2011.5947494},
  timestamp = {2017-05-19T07:25:09Z},
  publisher = {{IEEE}},
  author = {Mohamed, Abdel-rahman and Sainath, Tara N. and Dahl, George and Ramabhadran, Bhuvana and Hinton, Geoffrey E. and Picheny, Michael A.},
  urldate = {2014-09-05},
  date = {2011-05},
  pages = {5060--5063}
}

@article{Jones_2014,
  title = {Computer {{Science}}: {{The Learning Machines}}},
  volume = {505},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/505146a},
  doi = {10.1038/505146a},
  shorttitle = {Computer {{Science}}},
  timestamp = {2017-05-19T07:25:09Z},
  number = {7482},
  author = {Jones, Nicola},
  urldate = {2014-09-05},
  date = {2014-01-08},
  pages = {146--148}
}

@article{Adams_2009,
  title = {Anticipation: {{Technoscience}}, {{Life}}, {{Affect}}, {{Temporality}}},
  volume = {28},
  issn = {1755-6341},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/sub.2009.18},
  doi = {10.1057/sub.2009.18},
  shorttitle = {Anticipation},
  timestamp = {2017-05-19T07:25:10Z},
  number = {1},
  author = {Adams, Vincanne and Murphy, Michelle and Clarke, Adele E},
  urldate = {2009-09-16},
  date = {2009},
  pages = {246--265}
}

@book{James_1996,
  location = {{Lincoln}},
  title = {Essays in {{Radical Empiricism}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{University of Nebraska Press}},
  author = {James, William},
  date = {1996},
  keywords = {Experience.,Modern.,Philosophy,Pragmatism.}
}

@book{Mackenzie_1990,
  location = {{Cambridge, Mass.}},
  title = {Inventing {{Accuracy}} : {{An Historical Sociology}} of {{Nuclear Missile Guidance}}},
  timestamp = {2017-05-19T07:25:10Z},
  series = {Inside technology},
  publisher = {{MIT Press}},
  author = {Mackenzie, Donald A},
  date = {1990}
}

@book{Lash_2007,
  location = {{Cambridge}},
  title = {Global {{Culture Industry}} : {{The Mediation}} of {{Things}}},
  isbn = {978-0-7456-2482-2},
  shorttitle = {Global {{Culture Industry}}},
  abstract = {Includes bibliographical references (p. 218-228) and index.},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Polity}},
  author = {Lash, Scott and Lury, Celia},
  date = {2007},
  keywords = {Brand name products Social aspects.,Capitalism.,Clothing and dress Symbolic aspects.,cultural studies,Globalization.,Popular culture Philosophy.}
}

@article{Amoore_2011,
  title = {Data {{Derivatives On}} the {{Emergence}} of a {{Security Risk Calculus}} for {{Our Times}}},
  volume = {28},
  url = {http://tcs.sagepub.com/content/28/6/24.short},
  timestamp = {2017-05-19T07:25:10Z},
  number = {6},
  author = {Amoore, Louise},
  urldate = {2014-09-15},
  date = {2011},
  pages = {24--43}
}

@article{Torgerson_1952,
  title = {Multidimensional {{Scaling}}: {{I}}. {{Theory}} and {{Method}}},
  volume = {17},
  url = {http://link.springer.com/article/10.1007/BF02288916},
  shorttitle = {Multidimensional {{Scaling}}},
  timestamp = {2017-05-19T07:25:10Z},
  number = {4},
  author = {Torgerson, Warren S.},
  urldate = {2015-10-22},
  date = {1952},
  pages = {401--419}
}

@book{Derrida_2002,
  location = {{Cambridge}},
  title = {Echographies of {{Television}} : {{Filmed Interviews}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Polity Press}},
  author = {Derrida, Jacques and Stiegler, Bernard},
  date = {2002},
  keywords = {Television broadcasting - Philosophy,Television broadcasting - Social aspects,Television - Psychological aspects}
}

@book{Virno_2004,
  location = {{Los Angeles}},
  title = {A {{Grammar}} of the {{Multitude}} : {{For}} an {{Analysis}} of {{Contemporary Forms}} of {{Life}}},
  timestamp = {2017-05-19T07:25:10Z},
  series = {Semiotext(e) foreign agents series},
  publisher = {{Semiotext(e)}},
  author = {Virno, Paolo},
  date = {2004},
  keywords = {Political science - Philosophy}
}

@book{Gell_1998,
  location = {{Oxford}},
  title = {Art and {{Agency}} : {{An Anthropological Theory}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Clarendon Press}},
  author = {Gell, Alfred},
  date = {1998},
  keywords = {Art and anthropology,Art and society}
}

@online{Arthur_2013,
  title = {Kittydar},
  url = {http://harthur.github.io/kittydar/},
  timestamp = {2017-05-19T07:25:10Z},
  author = {Arthur, Heather},
  urldate = {2014-09-16},
  date = {2013}
}

@online{Arthur_2012,
  title = {Harthur/{{Kittydar}}},
  url = {https://github.com/harthur/kittydar},
  abstract = {kittydar - Face detection for cats in JavaScript - demo for a TXJS talk},
  timestamp = {2017-05-19T07:25:10Z},
  author = {Arthur, Heather},
  urldate = {2014-09-16},
  date = {2012}
}

@article{Totaro_2014,
  title = {The {{Concept}} of {{Algorithm}} as an {{Interpretative Key}} of {{Modern Rationality}}},
  url = {http://tcs.sagepub.com/content/early/2014/03/17/0263276413510051.abstract},
  timestamp = {2017-05-19T07:25:10Z},
  author = {Totaro, Paolo and Ninno, Domenico},
  urldate = {2014-09-16},
  date = {2014},
  pages = {29--49}
}

@article{Pasquinelli_2014,
  title = {Italian {{Operaismo}} and the {{Information Machine}}},
  issn = {0263-2764, 1460-3616},
  url = {http://tcs.sagepub.com.ezproxy.lancs.ac.uk/content/early/2014/02/02/0263276413514117},
  doi = {10.1177/0263276413514117},
  abstract = {The political economy of the information machine is discussed within the Marxist tradition of Italian operaismo by posing the hypothesis of an informational turn already at work in the age of the industrial revolution. The idea of valorizing information introduced by Alquati (1963) in a pioneering Marxist approach to cybernetics is used to examine the paradigms of mass intellectuality, immaterial labour and cognitive capitalism developed by Lazzarato, Marazzi, Negri, Vercellone and Virno since the 1990s. The concept of machinic by Deleuze and Guattari (1972, 1980) is then adopted to extend Marx’s analysis of the industrial machine to the algorithms of digital machines. If the industrial machine can be described as a bifurcation of the domains of energy and information, this essay proposes to conceive the information machine itself as a further bifurcation between information and metadata. In conclusion, the hypothesis of the society of metadata is outlined as the current evolution of that society of control pictured by Deleuze (1990) in relation to the power embodied in databases.},
  timestamp = {2017-05-19T07:25:10Z},
  author = {Pasquinelli, Matteo},
  urldate = {2014-09-16},
  date = {2014-02-02},
  pages = {1--20},
  keywords = {algorithm,cognitive capitalism,immaterial labour,information machine,metadata,operaismo}
}

@book{Hayles_1999,
  location = {{Chicago, Ill. ; London}},
  title = {How {{We Became Posthuman}} : {{Virtual Bodies}} in {{Cybernetics}}, {{Literature}}, {{And}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{University of Chicago Press}},
  author = {Hayles, N. Katherine},
  date = {1999},
  keywords = {Artificial intelligence,Computer Science,Cybernetics,Virtual reality in literature}
}

@book{Badiou_2004,
  location = {{London ; New York}},
  title = {Theoretical {{Writings}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Continuum}},
  author = {Badiou, Alain},
  editor = {Brassier, Ray and Toscano, Alberto},
  date = {2004},
  keywords = {Methodology.,Philosophy.}
}

@book{Rabinow_2003,
  location = {{Princeton and Oxford}},
  title = {Anthropos {{Today}}. {{Reflections}} on {{Modern Equipment}}},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Princeton University Press}},
  author = {Rabinow, Paul},
  date = {2003}
}

@incollection{Bowker_2010,
  location = {{Oxford}},
  title = {A {{Plea}} for {{Pleats}}},
  timestamp = {2017-05-19T07:25:10Z},
  booktitle = {Deleuzian {{Intersections}}: {{Science}}, {{Technology}}, {{Anthropology}}},
  publisher = {{Berghahn Books}},
  author = {Bowker, Geoffrey C.},
  editor = {Jensen, Caspar Bruin},
  date = {2010},
  pages = {123}
}

@book{Lantz_2013,
  location = {{Birmingham}},
  title = {Machine {{Learning}} with {{R}}},
  isbn = {978-1-78216-214-8},
  abstract = {R gives you access to the cutting-edge software you need to prepare data for machine learning. No previous knowledge required - this book will take you methodically through every stage of applying machine learning. Overview Harness the power of R for statistical computing and data science Use R to apply common machine learning algorithms with real-world applications Prepare, examine, and visualize data for analysis Understand how to choose between machine learning models Packed with clear instructions to explore, forecast, and classify data In Detail Machine learning, at its core, is concerned with transforming data into actionable knowledge. This fact makes machine learning well-suited to the present-day era of "big data" and "data science". Given the growing prominence of R—a cross-platform, zero-cost statistical programming environment—there has never been a better time to start applying machine learning. Whether you are new to data science or a veteran, machine learning with R offers a powerful set of methods for quickly and easily gaining insight from your data. "Machine Learning with R" is a practical tutorial that uses hands-on examples to step through real-world application of machine learning. Without shying away from the technical details, we will explore Machine Learning with R using clear and practical examples. Well-suited to machine learning beginners or those with experience. Explore R to find the answer to all of your questions. How can we use machine learning to transform data into action? Using practical examples, we will explore how to prepare data for analysis, choose a machine learning method, and measure the success of the process. We will learn how to apply machine learning methods to a variety of common tasks including classification, prediction, forecasting, market basket analysis, and clustering. By applying the most effective machine learning methods to real-world problems, you will gain hands-on experience that will transform the way you think about data. "Machine Learning with R" will provide you with the analytical tools you need to quickly gain insight from complex data. What you will learn from this book Understand the basic terminology of machine learning and how to differentiate among various machine learning approaches Use R to prepare data for machine learning Explore and visualize data with R Classify data using nearest neighbor methods Learn about Bayesian methods for classifying data Predict values using decision trees, rules, and support vector machines Forecast numeric values using linear regression Model data using neural networks Find patterns in data using association rules for market basket analysis Group data into clusters for segmentation Evaluate and improve the performance of machine learning models Learn specialized machine learning techniques for text mining, social network data, and “big” data Approach Written as a tutorial to explore and understand the power of R for machine learning. This practical guide that covers all of the need to know topics in a very systematic way. For each machine learning approach, each step in the process is detailed, from preparing the data for analysis to evaluating the results. These steps will build the knowledge you need to apply them to your own data science tasks.},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{Packt Publishing}},
  author = {Lantz, Brett},
  date = {2013}
}

@book{Kirk_2014,
  location = {{Sebastopol, Calif.}},
  edition = {1 edition},
  title = {Thoughtful {{Machine Learning}}: {{A Test}}-{{Driven Approach}}},
  isbn = {978-1-4493-7406-8},
  shorttitle = {Thoughtful {{Machine Learning}}},
  abstract = {Apply a fully test-driven approach to machine-learning algorithms, and save yourself the pain of missing mistakes in your analyses. Most data scientists have run an analysis and simply accepted any answer that wasn’t an error message. But just because it runs doesn’t mean it’s correct. Missed mistakes can ruin research and harm reputations.All of that can be avoided by writing tests and building checks into your work. This book shows you how to write tests and build checks into their work. Using the Ruby programming language, software developers, business analysts, and CTOs will learn how to test machine-learning code, and understand what’s happening "behind the scenes."Code machine-learning algorithms in a test-driven wayGain confidence to utilize machine learningDissect algorithms from the granular pieces using unit testsGet real-world examples of utilizing machine learning code},
  timestamp = {2017-05-19T07:25:10Z},
  publisher = {{O'Reilly Media}},
  author = {Kirk, Matthew},
  date = {2014}
}

@book{Suchman_1987,
  location = {{Cambridge}},
  title = {Plans and {{Situated Actions}} : {{The Problem}} of {{Human}}-{{Machine Communication}}},
  timestamp = {2017-05-19T07:25:11Z},
  publisher = {{Cambridge University Press}},
  author = {Suchman, Lucy A},
  date = {1987},
  keywords = {Electronic digital computers,Man. Communication with computer systems,Man-machine systems}
}

@article{Stengers_2008,
  title = {Experimenting with {{Refrains}}: {{Subjectivity}} and the {{Challenge}} of {{Escaping Modern Dualism}}},
  volume = {22},
  issn = {1755-6341},
  url = {http://www.palgrave-journals.com/doifinder/10.1057/sub.2008.6},
  doi = {10.1057/sub.2008.6},
  shorttitle = {Experimenting with {{Refrains}}},
  timestamp = {2017-05-19T07:25:11Z},
  number = {1},
  author = {Stengers, Isabelle},
  urldate = {2009-07-23},
  date = {2008-05},
  pages = {38--59}
}

@article{Maron_1961,
  title = {Automatic {{Indexing}}: {{An Experimental Inquiry}}},
  volume = {8},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Maron, M.E.},
  date = {1961},
  pages = {404--417}
}

@online{deCastro_,
  title = {The {{Politics}} of {{Ontology}}: {{Anthropological Positions}} — {{Cultural Anthropology}}},
  url = {http://culanth.org/fieldsights/462-the-politics-of-ontology-anthropological-positions},
  shorttitle = {The {{Politics}} of {{Ontology}}},
  timestamp = {2017-05-19T07:25:11Z},
  author = {de Castro, Eduardo Viveiros and Pedersen, Morten Axel and Holbraad, Martin},
  urldate = {2014-09-25},
  options = {useprefix=true}
}

@book{Heidegger_1977,
  location = {{New York ; London}},
  title = {The {{Question Concerning Technology}}, and {{Other Essays}}},
  timestamp = {2017-05-19T07:25:11Z},
  series = {Harper colophon books},
  publisher = {{Harper and Row}},
  author = {Heidegger, Martin and Lovitt, William},
  date = {1977},
  keywords = {essays,German - Addresses,German philosophy - Texts,lectures,Philosophy}
}

@book{Bailey_1965,
  location = {{London}},
  title = {Probability {{Methods}} of {{Diagnosis Based}} on {{Small Samples}}},
  timestamp = {2017-05-19T07:25:11Z},
  publisher = {{HM Stationery Office, London}},
  author = {Bailey, N. T. J.},
  date = {1965}
}

@online{Gomes_2014,
  title = {Machine-{{Learning Maestro Michael Jordan}} on the {{Delusions}} of {{Big Data}} and {{Other Huge Engineering Efforts}} - {{IEEE Spectrum}}},
  url = {http://spectrum.ieee.org/robotics/artificial-intelligence/machinelearning-maestro-michael-jordan-on-the-delusions-of-big-data-and-other-huge-engineering-efforts},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Gomes, Lee},
  urldate = {2015-03-05},
  date = {2014-10-03}
}

@online{Gomes_2015,
  title = {Facebook {{AI Director Yann LeCun}} on {{His Quest}} to {{Unleash Deep Learning}} and {{Make Machines Smarter}} - {{IEEE Spectrum}}},
  url = {http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/facebook-ai-director-yann-lecun-on-deep-learning},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Gomes, Lee},
  urldate = {2015-03-05},
  date = {2015-02-18}
}

@book{Lynch_1993,
  location = {{Cambridge}},
  title = {Scientific {{Practice}} and {{Ordinary Action}} : {{Ethnomethodology}} and {{Social}}},
  timestamp = {2017-05-19T07:25:11Z},
  publisher = {{Cambridge University Press}},
  author = {Lynch, Michael},
  date = {1993},
  keywords = {Ethnomethodology,Science,Science - Methodology,Science - Social aspects,Sociology,Sociology - Methodology}
}

@article{Deerwester_1990,
  title = {Indexing by {{Latent Semantic Analysis}}},
  volume = {41},
  url = {http://lsi.research.telcordia.com/lsi/papers/JASIS90.pdf},
  doi = {10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9},
  timestamp = {2017-05-19T07:25:11Z},
  number = {6},
  author = {Deerwester, Scott and Dumais, Susan and Landauer, Thomas and Furnas, George and Harshman, Richard},
  urldate = {2011-01-07},
  date = {1990},
  pages = {391--407}
}

@article{Stengers_2007,
  title = {The {{Cosmopolitical Proposal}}},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Stengers, Isabelle},
  date = {2007}
}

@article{Thrift_2004,
  title = {Movement-{{Space}}: {{The Changing Domain}} of {{Thinking Resulting}} from the {{Development}} of {{New Kinds}} of {{Spatial Awareness}}},
  volume = {33},
  timestamp = {2017-05-19T07:25:11Z},
  number = {4},
  author = {Thrift, Nigel},
  date = {2004},
  pages = {582--604}
}

@online{_a,
  title = {The {{Future}} of {{Employment}}: {{How Susceptible Are Jobs}} to {{Computerisation}}? | {{Publications}}},
  url = {http://www.oxfordmartin.ox.ac.uk/publications/view/1314},
  shorttitle = {The {{Future}} of {{Employment}}},
  timestamp = {2017-05-19T07:25:11Z},
  urldate = {2015-10-29}
}

@article{Ng_2002,
  title = {On {{Discriminative}} vs. {{Generative Classifiers}}: {{A Comparison}} of {{Logistic Regression}} and {{Naive Bayes}}},
  volume = {14},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=GbC8cqxGR7YC&oi=fnd&pg=PA841&dq=Andrew+Ng++Jordan+On+Discriminative+vs.+Generative+Classi%EF%AC%81ers&ots=ZwJ0K40zs6&sig=E6GNho6pxlHH1MSAc_RPOEHQkm0},
  shorttitle = {On {{Discriminative}} vs. {{Generative Classifiers}}},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Ng, Andrew and Jordan, Michael},
  urldate = {2014-10-07},
  date = {2002},
  pages = {841}
}

@article{Blei_2012,
  title = {Probabilistic {{Topic Models}}},
  volume = {55},
  url = {http://dl.acm.org/citation.cfm?id=2133826},
  timestamp = {2017-05-19T07:25:11Z},
  number = {4},
  author = {Blei, David M.},
  urldate = {2014-10-09},
  date = {2012},
  pages = {77--84}
}

@inproceedings{Rosen-Zvi_2004,
  title = {The {{Author}}-{{Topic Model}} for {{Authors}} and {{Documents}}},
  url = {http://dl.acm.org/citation.cfm?id=1036902},
  timestamp = {2017-05-19T07:25:11Z},
  booktitle = {Proceedings of the 20th {{Conference}} on {{Uncertainty}} in {{Artificial Intelligence}}},
  publisher = {{AUAI Press}},
  author = {Rosen-Zvi, Michal and Griffiths, Thomas and Steyvers, Mark and Smyth, Padhraic},
  urldate = {2014-10-09},
  date = {2004},
  pages = {487--494}
}

@article{Blei_2006,
  title = {Correlated {{Topic Models}}},
  volume = {18},
  url = {https://www.cs.cmu.edu/ lafferty/pub/ctm.pdf},
  timestamp = {2017-05-19T07:25:11Z},
  author = {Blei, David and Lafferty, John},
  urldate = {2014-10-09},
  date = {2006},
  pages = {147}
}

@article{Lash_2007a,
  title = {Power after {{Hegemony}}: {{Cultural Studies}} in {{Mutation}}?},
  volume = {24},
  url = {http://tcs.sagepub.com/content/24/3/55.short},
  timestamp = {2017-05-19T07:25:12Z},
  number = {3},
  author = {Lash, Scott},
  urldate = {2014-10-14},
  date = {2007},
  pages = {55--78}
}

@book{Stiegler_1998,
  location = {{Stanford, Calif.}},
  title = {Technics and {{Time}}, 1 : {{The Fault}} of {{Epimetheus}}},
  timestamp = {2017-05-19T07:25:12Z},
  series = {Meridian : crossing aesthetics},
  publisher = {{Stanford University Press}},
  author = {Stiegler, Bernard},
  date = {1998},
  keywords = {Technology - Philosophy}
}

@article{Knorr-Cetina_2000,
  title = {The {{Market}} as an {{Object}} of {{Attachment}}: {{Exploring Postsocial Relations}} in {{Financial Markets}}},
  volume = {25},
  timestamp = {2017-05-19T07:25:12Z},
  number = {2},
  author = {Knorr-Cetina, Karin and Bruegger, Urs},
  date = {2000},
  pages = {141--168}
}

@book{Helmreich_2000,
  location = {{Berkeley, Calif. ; London}},
  title = {Silicon {{Second Nature}} : {{Culturing Artificial Life}} in a {{Digital World}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{University of California Press}},
  author = {Helmreich, Stefan},
  date = {2000},
  keywords = {Biological systems - Computer simulation - Philosophy,Biological systems - Computer simulation - Research,Santa Fe Institute}
}

@book{Bollas_2008,
  location = {{London \& New York}},
  title = {The {{Evocative Object World}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{Routledge}},
  author = {Bollas, Christopher},
  date = {2008}
}

@book{Wilson_2010,
  title = {Affect and {{Artificial Intelligence}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{University of Washington Press}},
  author = {Wilson, Elizabeth A.},
  date = {2010}
}

@book{Watson_2007,
  location = {{New York}},
  title = {Recombinant {{DNA}} : {{Genes}} and {{Genomes}} : {{A Short Course}}},
  volume = {3rd},
  isbn = {9780716728665 0716728664 9781429203128 (pbk.) 1429203129 (pbk.)},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{W.H. Freeman : Cold Spring Harbor Laboratory Press}},
  author = {Watson, James D.},
  date = {2007},
  keywords = {DNA,Genomics.,Recombinant.,Recombinant DNA.,Recombinant DNA Research.}
}

@article{Hickins_2013,
  title = {How the {{NSA Could So Smart So Fast}}},
  issn = {0099-9660},
  url = {http://online.wsj.com/news/articles/SB10001424127887324049504578541271020665666},
  abstract = {Five years ago it would have been unimaginable for the National Security Agency to efficiently parse millions of phone and online records to prevent an impending terrorist attack. Today, a set of new technologies make it relatively affordable and manageable for it do so.},
  timestamp = {2017-05-19T07:25:12Z},
  author = {Hickins, Michael},
  urldate = {2014-10-21},
  date = {2013-06-12}
}

@online{Gulcehre_2014,
  title = {Welcome to {{Deep Learning}}},
  url = {http://deeplearning.net/},
  timestamp = {2017-05-19T07:25:12Z},
  author = {Gulcehre, Caglar},
  urldate = {2014-10-24},
  date = {2014}
}

@inproceedings{Dean_2006,
  title = {Experiences with {{MapReduce}}, an {{Abstraction}} for {{Large}}-{{Scale Computation}}},
  timestamp = {2017-05-19T07:25:12Z},
  booktitle = {International {{Conference}} on {{Parallel Architecture}} and {{Compilation Techniques}}},
  author = {Dean, J.},
  date = {2006}
}

@book{Latour_1993,
  location = {{New York ; London}},
  title = {We {{Have Never Been Modern}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{Harvester Wheatsheaf}},
  author = {Latour, Bruno},
  date = {1993},
  keywords = {Science. Related to,Society}
}

@article{Batt_2007,
  title = {Diagrammatic {{Thinking}} in {{Literature}} and {{Mathematics}}},
  volume = {11},
  issn = {1382-5577},
  url = {http://dx.doi.org/10.1080/13825570701409425},
  doi = {10.1080/13825570701409425},
  abstract = {This article discusses the way both mathematics and literature share an iconic character crucial to their specific semiotic regime, which can be traced back to the implication of the diagrammatic property of both natural language and formal language. Peirce and Wittgenstein are the main references. The contribution of Gilles Châtelet is evoked.},
  timestamp = {2017-05-19T07:25:12Z},
  number = {3},
  author = {Batt, Noëlle},
  urldate = {2014-11-25},
  date = {2007-12-01},
  pages = {241--249}
}

@book{Stengers_1997,
  location = {{Paris}},
  title = {Cosmopolitiques {{II}}: {{L}}'invention de {{La Mécanique}}: {{Pouvoir}} et {{Raison}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{La Decouverte}},
  author = {Stengers, Isabelle},
  date = {1997}
}

@book{Edwards_1996,
  location = {{Cambridge, MA; London}},
  title = {The {{Closed World}} : {{Computers}} and the {{Politics}} of {{Discourse}} in {{Cold War}}},
  timestamp = {2017-05-19T07:25:12Z},
  series = {Inside technology},
  publisher = {{MIT Press}},
  author = {Edwards, Paul N},
  date = {1996},
  keywords = {Computers,Computers - History,Military art and science - Data processing - History,Society. Effects of}
}

@incollection{Suchman_1992,
  location = {{Cambridge ; New York}},
  title = {Artificial {{Intelligence}} as {{Craftwork}}},
  timestamp = {2017-05-19T07:25:12Z},
  booktitle = {Understanding {{Practice}}: {{Perspectives}} on {{Activity}} and {{Context}}},
  publisher = {{Cambridge University Press}},
  author = {Suchman, Lucy A and Trigg, Randall H},
  editor = {Chaiklin, Seth and Lave, Jean},
  date = {1992},
  pages = {144--178}
}

@incollection{Latour_1990,
  location = {{Cambridge, MA London}},
  title = {Drawing {{Things Together}}},
  timestamp = {2017-05-19T07:25:12Z},
  booktitle = {Representation in {{Scientific Practice}}},
  publisher = {{MIT Press}},
  author = {Latour, Bruno},
  editor = {Lynch, Michael and Woolgar, Steve},
  date = {1990},
  pages = {20--68}
}

@article{Stengers_2005,
  title = {Deleuze and {{Guattari}}'s {{Last Enigmatic Message}}},
  volume = {10},
  timestamp = {2017-05-19T07:25:12Z},
  number = {1},
  author = {Stengers, Isabelle},
  date = {2005},
  pages = {151--167}
}

@book{Debaise_2007,
  location = {{Paris}},
  title = {Vie et {{Expérimentation Peirce}}, {{James}}, {{Dewey}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{Libraire Philosophique J.Vrin}},
  author = {Debaise, Didier},
  date = {2007}
}

@book{Derrida_1989,
  location = {{Lincoln}},
  title = {Edmund {{Husserl}}'s {{Origin}} of {{Geometry}}, an {{Introduction}}},
  timestamp = {2017-05-19T07:25:12Z},
  publisher = {{University of Nebraska Press}},
  author = {Derrida, Jacques},
  translator = {Leavey, John},
  date = {1989},
  keywords = {1859-1938. Frage nach dem Ursprung der Geometrie als intentional-historisches Problem.,Edmund,Husserl,Phenomenology.}
}

@book{_b,
  title = {Frontiers in {{Massive Data Analysis}}},
  url = {http://www.nap.edu/catalog.php?record_id=18374},
  abstract = {Data mining of massive data sets is transforming the way we think about crisis response, marketing, entertainment, cybersecurity and national intelligence. Collections of documents, images, videos, and networks are being thought of not merely as bit strings to be stored, indexed, and retrieved, but as potential sources of discovery and knowledge, requiring sophisticated analysis techniques that go far beyond classical indexing and keyword counting, aiming to find relational and semantic interpretations of the phenomena underlying the data. Frontiers in Massive Data Analysis examines the frontier of analyzing massive amounts of data, whether in a static database or streaming through a system. Data at that scale–terabytes and petabytes–is increasingly common in science (e.g., particle physics, remote sensing, genomics), Internet commerce, business analytics, national security, communications, and elsewhere. The tools that work to infer knowledge from data at smaller scales do not necessarily work, or work well, at such massive scale. New tools, skills, and approaches are necessary, and this report identifies many of them, plus promising research directions to explore. Frontiers in Massive Data Analysis discusses pitfalls in trying to infer knowledge from massive data, and it characterizes seven major classes of computation that are common in the analysis of massive data. Overall, this report illustrates the cross-disciplinary knowledge–from computer science, statistics, machine learning, and application disciplines–that must be brought to bear to make useful inferences from massive data.},
  timestamp = {2017-05-19T07:25:12Z},
  urldate = {2014-10-24}
}

@book{Elden_2006,
  location = {{Edinburgh}},
  title = {Speaking against {{Number}}: {{Heidegger}}, {{Language}} and the {{Politics}} of {{Calculation}}},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Edinburgh University Press}},
  author = {Elden, Stuart},
  date = {2006}
}

@book{Dewey_2004,
  location = {{Mineola, N.Y.}},
  title = {Essays in {{Experimental Logic}}},
  isbn = {0486437485 (pbk.)},
  url = {http://www.loc.gov/catdir/enhancements/fy0618/2004052766-d.html},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Dover Publications}},
  author = {Dewey, John},
  date = {2004},
  keywords = {Logic.,Realism.,Thought and thinking.}
}

@book{Whitehead_2013,
  location = {{London}},
  title = {The {{Concept}} of {{Nature}}},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Courier Dover Publications}},
  author = {Whitehead, Alfred North},
  date = {2013}
}

@book{Stengers_2002,
  location = {{Paris}},
  title = {Penser {{Avec Whitehead}} : {{Une Libre}} et {{Sauvage Création}} de {{Concepts}}},
  timestamp = {2017-05-19T07:25:13Z},
  series = {L'ordre philosophique},
  publisher = {{Seuil}},
  author = {Stengers, Isabelle},
  date = {2002},
  keywords = {1861-1947,Alfred North,Modern - 20th century,Philosophy,Whitehead}
}

@book{Habermas_1970,
  location = {{Boston}},
  title = {Toward a {{Rational Society}}; {{Student Protest}}, {{Science}}, and {{Politics}}},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Beacon Press}},
  author = {Habermas, JÃ¼rgen},
  date = {1970},
  keywords = {College students Political activity.,Education,Higher.}
}

@book{Stengers_2000,
  location = {{Minneapolis ; London}},
  title = {The {{Invention}} of {{Modern Science}}},
  timestamp = {2017-05-19T07:25:13Z},
  series = {Theory out of bounds ; v.19},
  publisher = {{University of Minnesota Press}},
  author = {Stengers, Isabelle},
  date = {2000},
  keywords = {Discoveries in science,Science - Philosophy}
}

@online{King_2014,
  title = {Dlib {{C}}++ {{Library}}},
  url = {http://dlib.net/ml_guide.svg},
  timestamp = {2017-05-19T07:25:13Z},
  author = {King, Davis},
  urldate = {2014-11-03},
  date = {2014}
}

@article{Feinerer_2008,
  title = {Text {{Mining Infrastructure}} in {{R}}},
  volume = {25},
  url = {http://www.jstatsoft.org/v25/i05/},
  timestamp = {2017-05-19T07:25:13Z},
  number = {5},
  author = {Feinerer, Ingo and Hornik, Kurt and Meyer, David},
  date = {2008-03},
  pages = {1--54}
}

@article{Amoore_2009,
  title = {Lines of {{Sight}}: {{On}} the {{Visualization}} of {{Unknown Futures}}.},
  volume = {13},
  issn = {13621025},
  url = {http://search.ebscohost.com/login.aspx?direct=true&db=a9h&AN=36353240&site=ehost-live},
  doi = {10.1080/13621020802586628},
  shorttitle = {Lines of {{Sight}}},
  abstract = {This article considers the specific mode of visualization that is at work in contemporary border security practices. Taking inspiration from art historian Jonathan Crary's genealogies of attention, it situates homeland security visuality in a particular economy of attention or attentiveness to the world. How is it that we come to focus on some elements of our way of life, establish them as normal and designate deviations from the norm? How does this algorithmic attentiveness break up the visual field, 'pixelating' sensory data so that it can be reintegrated to project a picture of a person? The pre-emptive lines of sight emerging in contemporary security practice become precisely a means of visualizing unknown futures. The article concludes with reflections on the creative artistic forms of attention that flourish even where the lines of sight of the consumer, the citizen, the border guard, the traveller, the migrant appear ever more directed and delimited. It is in these more creative modes of attention that we find one of the most important resources to contemporary political life - the capacity to question the 'better picture', to disrupt what we see as ordinary or out of the ordinary and confront the routines of our lives anew. [ABSTRACT FROM AUTHOR]},
  timestamp = {2017-05-19T07:25:13Z},
  number = {1},
  author = {Amoore, Louise},
  urldate = {2010-05-19},
  date = {2009-02},
  pages = {17--30},
  keywords = {2001-2009,borders,BORDER security,citizenship,HOMELAND security,NATIONAL security,resistance,security,technology,TERRORISM – Prevention,United States,UNITED States – Foreign relations – 21st century,'war on terror',WAR on Terrorism}
}

@book{Whitehead_1960,
  location = {{New York,}},
  title = {Process and {{Reality}}, an {{Essay}} in {{Cosmology}}},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Macmillan}},
  author = {Whitehead, Alfred North},
  date = {1960},
  keywords = {Cosmology. [from old catalog],Science Philosophy. [from old catalog]}
}

@book{Bishop_2006,
  location = {{New York}},
  title = {Pattern {{Recognition}} and {{Machine Learning}}},
  volume = {1},
  timestamp = {2017-05-19T07:25:13Z},
  publisher = {{Springer}},
  author = {Bishop, Christopher M.},
  date = {2006}
}

@book{Foucault_1991,
  location = {{London}},
  title = {The {{History}} of {{Sexuality}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Penguin : Viking : Pantheon}},
  author = {Foucault, Michel},
  translator = {Hurley, Robert},
  date = {1991}
}

@book{Thrift_2005,
  location = {{London}},
  title = {Knowing {{Capitalism}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{SAGE Publications}},
  author = {Thrift, N. J},
  date = {2005},
  keywords = {Capitalism.}
}

@book{Foucault_1997,
  location = {{New York}},
  title = {Ethics: {{Subjectivity}} and {{Truth}}},
  isbn = {1-56584-352-5},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{New Press}},
  author = {Foucault, Michel},
  editor = {Rabinow, Paul},
  date = {1997},
  keywords = {Ethics.,French 20th century.,Philosophy}
}

@incollection{Haraway_1999,
  title = {Situated {{Knowledges}}. {{The Science Question}} in {{Feminism}} and the {{Privilege}} of {{Partial Perspective}}},
  isbn = {0-415-91868-5 978-0-415-91868-8},
  timestamp = {2017-05-19T07:25:14Z},
  booktitle = {The {{Science Studies Reader}}},
  publisher = {{Routledge}},
  author = {Haraway, Donna},
  editor = {Biagioli, Mario},
  date = {1999},
  pages = {172--188}
}

@book{Collins_1990,
  location = {{Cambridge, MA.}},
  title = {Artificial {{Experts}}: {{Social Knowledge}} and {{Intelligent Machines}}},
  url = {http://www.citeulike.org/group/884/article/633745},
  shorttitle = {Artificial {{Experts}}},
  timestamp = {2017-05-19T07:25:14Z},
  series = {Inside technology},
  publisher = {{MIT Press}},
  author = {Collins, Harry M.},
  urldate = {2014-11-13},
  date = {1990}
}

@article{Pearson_1901,
  title = {{{LIII}}. {{On Lines}} and {{Planes}} of {{Closest Fit}} to {{Systems}} of {{Points}} in {{Space}}},
  volume = {2},
  issn = {1941-5982},
  url = {http://dx.doi.org/10.1080/14786440109462720},
  doi = {10.1080/14786440109462720},
  timestamp = {2017-05-19T07:25:14Z},
  number = {11},
  author = {Pearson, Karl},
  urldate = {2014-11-13},
  date = {1901-11-01},
  pages = {559--572}
}

@book{Dreyfus_1992,
  location = {{Cambridge, MA}},
  title = {What {{Computers Still Can}}'t {{Do}}: {{A Critique}} of {{Artificial Reason}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=7vS2y-mQmpAC&oi=fnd&pg=PR9&dq=dreyfus+what+computers&ots=1UYeWGwxUC&sig=Dwiwo2ys_PvqacqHxdXaBPo-Hs0},
  shorttitle = {What {{Computers Still Can}}'t {{Do}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{MIT Press}},
  author = {Dreyfus, Hubert L.},
  urldate = {2014-11-13},
  date = {1992}
}

@book{Dreyfus_1972,
  location = {{New York}},
  title = {What {{Computers Can}}'t {{Do}}},
  url = {http://philpapers.org/rec/DREWCC},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Harper \& Row}},
  author = {Dreyfus, Hubert L.},
  urldate = {2014-11-13},
  date = {1972}
}

@book{Bowker_1999,
  location = {{Cambridge MA}},
  title = {Sorting {{Things Out}}. {{Classification}} and {{Its Consequences}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{MIT Press}},
  author = {Bowker, Geoffrey C and Star, Susan Leigh},
  date = {1999}
}

@book{Venables_2002,
  location = {{New York}},
  title = {Modern {{Applied Statistics}} with {{S}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Springer}},
  author = {Venables, William N. and Ripley, Brian D.},
  date = {2002}
}

@book{James_2013,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  url = {http://link.springer.com/content/pdf/10.1007/978-1-4614-7138-7.pdf},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Springer}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  urldate = {2014-11-19},
  date = {2013}
}

@incollection{Marchese_2013,
  title = {Tables and {{Early Information Visualization}}},
  isbn = {978-1-4471-4302-4 978-1-4471-4303-1},
  url = {http://link.springer.com/chapter/10.1007/978-1-4471-4303-1_3},
  abstract = {This chapter considers the deep history of tables as visualization modalities. It covers a variety of tables that have appeared between 1900 BCE and 1400 CE that include: Sumerian accounting tables; chronicles; canon tables; medieval calendars; gridded tables such as urine and eclipse; and tables that communicate conceptual abstractions, such as religious dogma and degrees of blood relation. These tables represent some of the earliest and most significant milestones in information visualization. Analysis of these tables demonstrates that as early as 1300 BCE the need to visualize information had driven the invention of representations that transformed the way information has been communicated and used.},
  timestamp = {2017-05-19T07:25:14Z},
  booktitle = {Knowledge {{Visualization Currents}}},
  publisher = {{Springer London}},
  author = {Marchese, Dr Francis T.},
  editor = {Marchese, Francis T. and Banissi, Ebad},
  urldate = {2014-11-20},
  date = {2013-01-01},
  pages = {35--61},
  keywords = {Computer Graphics,Data Mining and Knowledge Discovery,User Interfaces and Human Computer Interaction,visualization}
}

@article{Beniger_1978,
  title = {Quantitative {{Graphics}} in {{Statistics}}: {{A Brief History}}},
  volume = {32},
  issn = {0003-1305},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/2683467},
  doi = {10.2307/2683467},
  shorttitle = {Quantitative {{Graphics}} in {{Statistics}}},
  abstract = {Quantitative graphics have been central to the development of science, and statistical graphics date from the earliest attempts to analyze data. Many familiar forms, including bivariate plots, statistical maps, bar charts, and coordinate paper, were used in the 18th century. Statistical graphics developed through attention to four problems: spatial organization (17th and 18th centuries), discrete comparison (18th and early 19th centuries), continuous distribution (19th century), and multivariate distribution and correlation (late 19th and early 20th centuries). Today, statistical graphics appear to be reemerging as an important analytic tool, with recent innovations exploiting computer graphics and related technologies.},
  timestamp = {2017-05-19T07:25:14Z},
  number = {1},
  author = {Beniger, James R. and Robyn, Dorothy L.},
  urldate = {2014-11-20},
  date = {1978-02-01},
  pages = {1--11}
}

@article{Ross_2000,
  title = {Systematic {{Variation}} in {{Gene Expression Patterns}} in {{Human Cancer Cell Lines}}},
  volume = {24},
  issn = {1061-4036},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/ng/journal/v24/n3/abs/ng0300_227.html},
  doi = {10.1038/73432},
  abstract = {We used cDNA microarrays to explore the variation in expression of approximately 8,000 unique genes among the 60 cell lines used in the National Cancer Institute's screen for anti-cancer drugs. Classification of the cell lines based solely on the observed patterns of gene expression revealed a correspondence to the ostensible origins of the tumours from which the cell lines were derived. The consistent relationship between the gene expression patterns and the tissue of origin allowed us to recognize outliers whose previous classification appeared incorrect. Specific features of the gene expression patterns appeared to be related to physiological properties of the cell lines, such as their doubling time in culture, drug metabolism or the interferon response. Comparison of gene expression patterns in the cell lines to those observed in normal breast tissue or in breast tumour specimens revealed features of the expression patterns in the tumours that had recognizable counterparts in specific cell lines, reflecting the tumour, stromal and inflammatory components of the tumour tissue. These results provided a novel molecular characterization of this important group of human cell lines and their relationships to tumours in vivo.},
  timestamp = {2017-05-19T07:25:14Z},
  number = {3},
  author = {Ross, Douglas T. and Scherf, Uwe and Eisen, Michael B. and Perou, Charles M. and Rees, Christian and Spellman, Paul and Iyer, Vishwanath and Jeffrey, Stefanie S. and Van de Rijn, Matt and Waltham, Mark and Pergamenschikov, Alexander and Lee, Jeffrey C. F. and Lashkari, Deval and Shalon, Dari and Myers, Timothy G. and Weinstein, John N. and Botstein, David and Brown, Patrick O.},
  urldate = {2014-11-25},
  date = {2000-03},
  pages = {227--235}
}

@book{Deleuze_1988a,
  location = {{Minneapolis}},
  title = {Foucault},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{University of Minnesota Press}},
  author = {Deleuze, Gilles},
  translator = {Hand, Seân},
  date = {1988}
}

@book{Foucault_1972,
  location = {{New York}},
  title = {The {{Archaeology}} of {{Knowledge}} and the {{Discourse}} on {{Language}}},
  shorttitle = {The {{Archaeology}} of {{Knowledge}} and the {{Discourse}} on {{Language}} ({{Trans}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Pantheon Books}},
  author = {Foucault, Michel},
  translator = {Sheridan-Smith, Allan},
  date = {1972}
}

@article{Hodge_1989,
  title = {Random {{Systematic}} versus {{Directed Ultrasound Guided Transrectal Core Biopsies}} of the {{Prostate}}.},
  volume = {142},
  url = {http://europepmc.org/abstract/MED/2659827},
  timestamp = {2017-05-19T07:25:14Z},
  number = {1},
  author = {Hodge, K. K. and McNeal, J. E. and Terris, M. K. and Stamey, T. A.},
  urldate = {2014-12-01},
  date = {1989},
  pages = {71--4}
}

@article{Stamey_1989,
  title = {Prostate {{Specific Antigen}} in the {{Diagnosis}} and {{Treatment}} of {{Adenocarcinoma}} of the {{Prostate}}. {{II}}. {{Radical Prostatectomy Treated Patients}}.},
  volume = {141},
  url = {http://europepmc.org/abstract/med/2468795},
  timestamp = {2017-05-19T07:25:14Z},
  number = {5},
  author = {Stamey, Thomas A. and Kabalin, John N. and McNeal, John E. and Johnstone, Iain M. and Freiha, F. and Redwine, Elise A. and Yang, Norman},
  urldate = {2014-12-01},
  date = {1989},
  pages = {1076--1083}
}

@article{Stamey_2004,
  title = {The {{Prostate Specific Antigen Era}} in the {{United States Is}} over for {{Prostate Cancer}}: {{What Happened}} in the {{Last}} 20 {{Years}}?},
  volume = {172},
  url = {http://www.sciencedirect.com/science/article/pii/S002253470561155X},
  shorttitle = {The {{Prostate Specific Antigen Era}} in the {{United States Is}} over for {{Prostate Cancer}}},
  timestamp = {2017-05-19T07:25:14Z},
  number = {4},
  author = {Stamey, Thomas A. and Caldwell, Mitchell and McNEAL, JOHN and Nolley, Rosalie and Hemenez, Marci and Downs, Joshua},
  urldate = {2014-12-01},
  date = {2004},
  pages = {1297--1301}
}

@article{Hansen_2012,
  title = {Foucault and {{Media}}: {{A Missed Encounter}}?},
  volume = {111},
  issn = {0038-2876, 1527-8026},
  url = {http://saq.dukejournals.org/content/111/3/497},
  doi = {10.1215/00382876-1596254},
  shorttitle = {Foucault and {{Media}}},
  abstract = {This essay stages an encounter between Michel Foucault’s work—especially his final thought concerning biopolitics, security, and population—and contemporary theorization of media’s experiential impact. The essay argues that the opportunity for such an encounter has been obscured largely due to the role played by Gilles Deleuze (in particular by the concept of “control society”) in filtering Foucault’s work for media theory. The essay develops an approach to Foucault’s late work that centers on the population as a vehicle for rethinking individualization beyond substance; such an approach makes it possible to retain certain aspects of the category of the individual that are simply jettisoned in the contemporary embrace of Deleuze’s “dividual.” The essay concludes by exploring how this rethinking of Foucault’s work on individualization facilitates exploration of the impact of twenty-first-century “atmospheric” media on human individuation.},
  timestamp = {2017-05-19T07:25:14Z},
  number = {3},
  author = {Hansen, Mark B. N.},
  urldate = {2014-12-03},
  date = {2012-06-20},
  pages = {497--528}
}

@book{McKinney_2012,
  location = {{Sebastapol, CA}},
  title = {Python for {{Data Analysis}}: {{Data Wrangling}} with {{Pandas}}, {{NumPy}}, and {{IPython}}},
  url = {http://shop.oreilly.com/product/0636920023784.do},
  abstract = {Looking for complete instructions on manipulating, processing, cleaning, and crunching structured data in Python? This hands-on book is packed with practical cases studies that show you how to effectively solve a broad set of data analysis...},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{O'Reilly \& Associates Inc}},
  author = {McKinney, Wes},
  date = {2012}
}

@book{Stigler_2002,
  title = {Statistics on the {{Table}}: {{The History}} of {{Statistical Concepts}} and {{Methods}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=qQusWukdPa4C&oi=fnd&pg=PR9&dq=stigler+concepts+statistics&ots=6ekF1LqIQL&sig=nNwRfar3NtBAIv-wAy-xp6WL7Ww},
  shorttitle = {Statistics on the {{Table}}},
  timestamp = {2017-05-19T07:25:14Z},
  publisher = {{Harvard University Press}},
  author = {Stigler, Stephen M.},
  urldate = {2014-12-05},
  date = {2002}
}

@online{Beyer_2011,
  title = {Gartner {{Says Solving}} '{{Big Data}}' {{Challenge Involves More Than Just Managing Volumes}} of {{Data}}},
  url = {http://www.gartner.com/newsroom/id/1731916},
  abstract = {Many IT leaders are attempting to manage},
  timestamp = {2017-05-19T07:25:14Z},
  author = {Beyer, Mark},
  urldate = {2015-01-20},
  date = {2011}
}

@article{Efron_1975,
  title = {The {{Efficiency}} of {{Logistic Regression Compared}} to {{Normal Discriminant Analysis}}},
  volume = {70},
  issn = {0162-1459},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/2285453},
  doi = {10.2307/2285453},
  abstract = {A random vector x arises from one of two multivariate normal distributions differing in mean but not covariance. A training set x$\backslash$textsubscript1, x$\backslash$textsubscript2, ⋯, x$\backslash$textsubscriptn of previous cases, along with their correct assignments, is known. These can be used to estimate Fisher's discriminant by maximum likelihood and then to assign x on the basis of the estimated discriminant, a method known as the normal discrimination procedure. Logistic regression does the same thing but with the estimation of Fisher's discriminant done conditionally on the observed values of x$\backslash$textsubscript1, x$\backslash$textsubscript2, ⋯, x$\backslash$textsubscriptn. This article computes the asymptotic relative efficiency of the two procedures. Typically, logistic regression is shown to be between one half and two thirds as effective as normal discrimination for statistically interesting values of the parameters.},
  timestamp = {2017-05-19T07:25:14Z},
  number = {352},
  author = {Efron, Bradley},
  urldate = {2015-01-24},
  date = {1975-12-01},
  pages = {892--898}
}

@article{Hassabis_2014,
  title = {Imagine {{All}} the {{People}}: {{How}} the {{Brain Creates}} and {{Uses Personality Models}} to {{Predict Behavior}}},
  volume = {24},
  issn = {1047-3211, 1460-2199},
  url = {http://cercor.oxfordjournals.org/content/24/8/1979},
  doi = {10.1093/cercor/bht042},
  shorttitle = {Imagine {{All}} the {{People}}},
  abstract = {The behaviors of other people are often central to envisioning the future. The ability to accurately predict the thoughts and actions of others is essential for successful social interactions, with far-reaching consequences. Despite its importance, little is known about how the brain represents people in order to predict behavior. In this functional magnetic resonance imaging study, participants learned the unique personality of 4 protagonists and imagined how each would behave in different scenarios. The protagonists' personalities were composed of 2 traits: Agreeableness and Extraversion. Which protagonist was being imagined was accurately inferred based solely on activity patterns in the medial prefrontal cortex using multivariate pattern classification, providing novel evidence that brain activity can reveal whom someone is thinking about. Lateral temporal and posterior cingulate cortex discriminated between different degrees of agreeableness and extraversion, respectively. Functional connectivity analysis confirmed that regions associated with trait-processing and individual identities were functionally coupled. Activity during the imagination task, and revealed by functional connectivity, was consistent with the default network. Our results suggest that distinct regions code for personality traits, and that the brain combines these traits to represent individuals. The brain then uses this “personality model” to predict the behavior of others in novel situations.},
  timestamp = {2017-05-19T07:25:15Z},
  number = {8},
  author = {Hassabis, Demis and Spreng, R. Nathan and Rusu, Andrei A. and Robbins, Clifford A. and Mar, Raymond A. and Schacter, Daniel L.},
  urldate = {2015-01-26},
  date = {2014-01-08},
  pages = {1979--1987},
  keywords = {default mode network,fMRI,MVPA,personality traits,simulation,social neuroscience}
}

@article{Hayles_2014,
  title = {Cognition {{Everywhere}}: {{The Rise}} of the {{Cognitive Nonconscious}} and the {{Costs}} of {{Consciousness}}},
  volume = {45},
  issn = {1080-661X},
  url = {http://muse.jhu.edu/login?auth=0&type=summary&url=/journals/new_literary_history/v045/45.2.hayles.pdf},
  doi = {10.1353/nlh.2014.0011},
  shorttitle = {Cognition {{Everywhere}}},
  timestamp = {2017-05-19T07:25:15Z},
  number = {2},
  author = {Hayles, N. Katherine},
  urldate = {2015-01-29},
  date = {2014},
  pages = {199--220}
}

@article{Meza_2010,
  title = {Steepest {{Descent}}},
  volume = {2},
  issn = {1939-0068},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/wics.117/abstract},
  doi = {10.1002/wics.117},
  abstract = {The steepest descent method has a rich history and is one of the simplest and best known methods for minimizing a function. While the method is not commonly used in practice due to its slow convergence rate, understanding the convergence properties of this method can lead to a better understanding of many of the more sophisticated optimization methods. Here, we give a short introduction and discuss some of the advantages and disadvantages of this method. Some recent results on modified versions of the steepest descent method are also discussed. WIREs Comp Stat 2010 2 719–722 DOI: 10.1002/wics.117 For further resources related to this article, please visit the WIREs website.},
  timestamp = {2017-05-19T07:25:15Z},
  number = {6},
  author = {Meza, Juan C.},
  urldate = {2015-02-03},
  date = {2010},
  pages = {719--722},
  keywords = {Cauchy,gradient,minimization,optimization}
}

@article{Petrova_1997,
  title = {The {{Origin}} of the {{Method}} of {{Steepest Descent}}},
  volume = {24},
  issn = {0315-0860},
  url = {http://www.sciencedirect.com/science/article/pii/S0315086096921461},
  doi = {10.1006/hmat.1996.2146},
  abstract = {The method of steepest descent, also known as the saddle-point method, is a natural development of Laplace's method applied to the asymptotic estimate of integrals of analytic functions. Mathematicians have often attributed the method of steepest descent to the physicist Peter Debye, who in 1909 worked it out in an asymptotic study of Bessel functions. Debye himself remarked that he had borrowed the idea of the method from an 1863 paper of Bernhard Riemann. The present article offers a detailed historical analysis of the creation of the method of steepest descent. We show that the method dates back to Cauchy and that, 25 years before Debye, the Russian mathematician Pavel Alexeevich Nekrasov had already used this technique and extended it to more general cases.Copyright 1997 Academic Press. La méthode de la descente la plus rapide, que l'on appelle actuellement méthode du col, représente un développement naturel de la méthode de Laplace pour l'estimation asymptotique des intégrales des fonctions analytiques. La méthode du col est généralement liée au nom du physicien Peter Debye, qui a utilisé en 1909 les idées que Riemann a présentées dans son article de 1863 afin de donner une analyse asymptotique des fonctions de Bessel. Le présent travail donne une étude bien detaillée de la création de la méthode du col. Tout d'abord nous montrons que la méthode du col remonte aux travaux de Cauchy et ensuite que le mathématicien russe Pavel Alexeevich Nekrasov a appliqué cette méthode un quart de siècle avant Debye et l'a étendue aux cas généraux.Copyright 1997 Academic Press. [FORMULA]},
  timestamp = {2017-05-19T07:25:15Z},
  number = {4},
  author = {Petrova, Svetlana S. and Solov'ev, Alexander D.},
  urldate = {2015-02-03},
  date = {1997-11},
  pages = {361--375},
  keywords = {asymptotic expansions,Bessel functions,estimate of integrals of analytic functions,Langrange series,Laplace's method,method of steepest descent,saddle-point}
}

@incollection{Robinson_2008,
  title = {Function},
  timestamp = {2017-05-19T07:25:15Z},
  booktitle = {Software {{Studies}}: {{A Lexicon}}},
  publisher = {{The MIT Press}},
  author = {Robinson, Derek},
  editor = {Fuller, M.},
  date = {2008},
  pages = {101--110}
}

@article{McCosker_2014,
  title = {Rethinking ‘{{Big Data}}’ as {{Visual Knowledge}}: {{The Sublime}} and the {{Diagrammatic}} in {{Data Visualisation}}},
  volume = {29},
  issn = {1472-586X},
  url = {http://dx.doi.org/10.1080/1472586X.2014.887268},
  doi = {10.1080/1472586X.2014.887268},
  shorttitle = {Rethinking ‘{{Big Data}}’ as {{Visual Knowledge}}},
  abstract = {Informational data, we are told, are proliferating ever more rapidly and with increasing complexity. In an age of ‘big data’ we are seeing a broad reaching, and often uncritical fascination with data visualisation and its potential for knowledge generation. At its extreme this represents a fantasy of knowing, or total knowledge. Nonetheless, for those working in visual anthropology, big data and data visualisation offer significant extensions to our ways of knowing and our categories of knowledge. In this article we probe the fascination and potential of data visualisation and its relevance for understanding human experience, social relations and networks. First, we argue that the celebration of informational aesthetics can be understood as a version of the Kantian mathematical sublime. Extending this analysis, we argue that productive possibilities for thinking about data visualisation are to be found in Deleuze’s engagement with the diagram. The diagram, for Deleuze, does not represent but rather operates both as expression and problem resolution. It is incomplete in the dual sense of never capturing the totality of the object and in its dynamism. This approach points to the merits of this investment in data visualisation (the way it works as expression and problem resolution), but highlights the need to be cautious about fetishising the sublimity of ‘beautiful data’.},
  timestamp = {2017-05-19T07:25:15Z},
  number = {2},
  author = {McCosker, Anthony and Wilken, Rowan},
  urldate = {2015-02-16},
  date = {2014-05-04},
  pages = {155--164}
}

@book{Cassirer_1923,
  location = {{Chicago}},
  title = {Substance and {{Function}}},
  timestamp = {2017-05-19T07:25:15Z},
  publisher = {{Open Court Publishing}},
  author = {Cassirer, Ernst},
  translator = {Swabey, William Curtis and Swabey, Marie Curtis},
  date = {1923}
}

@book{Lazzarato_2014,
  location = {{Cambridge, MA}},
  title = {Signs and {{Machines}}: {{Capitalism}} and the {{Production}} of {{Subjectivity}}},
  url = {http://mitpress.mit.edu/books/signs-and-machines},
  shorttitle = {Signs and {{Machines}}},
  timestamp = {2017-05-19T07:25:15Z},
  publisher = {{Semiotext (e)}},
  author = {Lazzarato, Maurizio},
  urldate = {2015-02-17},
  date = {2014}
}

@article{James_2014,
  title = {Leveraging {{Cloud Data}} to {{Mitigate User Experience}} from "{{Breaking Bad}}"},
  url = {http://arxiv.org/abs/1411.7955},
  abstract = {Low latency and high availability of an app or a web service are key, amongst other factors, to the overall user experience (which in turn directly impacts the bottomline). Exogenic and/or endogenic factors often give rise to breakouts in cloud data which makes maintaining high availability and delivering high performance very challenging. Although there exists a large body of prior research in breakout detection, existing techniques are not suitable for detecting breakouts in cloud data owing to being not robust in the presence of anomalies. To this end, we developed a novel statistical technique to automatically detect breakouts in cloud data. In particular, the technique employs Energy Statistics to detect breakouts in both application as well as system metrics. Further, the technique uses robust statistical metrics, viz., median, and estimates the statistical significance of a breakout through a permutation test. To the best of our knowledge, this is the first work which addresses breakout detection in the presence of anomalies. We demonstrate the efficacy of the proposed technique using production data and report Precision, Recall and F-measure measure. The proposed technique is 3.5 times faster than a state-of-the-art technique for breakout detection and is being currently used on a daily basis at Twitter.},
  timestamp = {2017-05-19T07:25:15Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.7955},
  author = {James, Nicholas A. and Kejariwal, Arun and Matteson, David S.},
  urldate = {2015-02-17},
  date = {2014-11-28},
  keywords = {Statistics - Methodology}
}

@online{Vallis_2014,
  title = {A {{Novel Technique}} for {{Long}}-{{Term Anomaly Detection}} in the {{Cloud}}},
  timestamp = {2017-05-19T07:25:15Z},
  author = {Vallis, Owen and Hochenbaum, Jordan and Kejariwal, Arun},
  date = {2014}
}

@book{Cherkassky_2007,
  location = {{Hoboken, N.J.}},
  title = {Learning from {{Data}}: {{Concepts}}, {{Theory}}, and {{Methods}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=IMGzP-IIaKAC&oi=fnd&pg=PR5&ots=2hrHWhccsX&sig=NZ7Hr-3f33s9ZReBd90RdjqSrv8},
  shorttitle = {Learning from {{Data}}},
  timestamp = {2017-05-19T07:25:15Z},
  publisher = {{John Wiley \& Sons}},
  author = {Cherkassky, Vladimir and Mulier, Filip M.},
  urldate = {2015-02-18},
  date = {2007}
}

@article{Fahey_2007,
  title = {French and {{Feminine}}: {{Hegemonic Masculinity}} and the {{Emasculation}} of {{John Kerry}} in the 2004 {{Presidential Race}}},
  volume = {24},
  url = {http://www.tandfonline.com/doi/abs/10.1080/07393180701262743},
  shorttitle = {French and {{Feminine}}},
  timestamp = {2017-05-19T07:25:15Z},
  number = {2},
  author = {Fahey, Anna Cornelia},
  urldate = {2015-03-02},
  date = {2007},
  pages = {132--150}
}

@article{Messerschmidt_2010,
  title = {Hegemonic {{Masculinities}} and {{Camouflaged Politics}}: {{Unmasking}} the {{Bush Dynesty}} and {{Its War Against Iraq}}},
  url = {http://works.bepress.com/james_messerschmidt/2/},
  shorttitle = {Hegemonic {{Masculinities}} and {{Camouflaged Politics}}},
  timestamp = {2017-05-19T07:25:15Z},
  author = {Messerschmidt, James},
  urldate = {2015-03-02},
  date = {2010}
}

@book{Foucault_1977,
  location = {{New York}},
  title = {Discipline and {{Punish}}: {{The Birth}} of the {{Prison}}},
  shorttitle = {Discipline and {{Punish}}},
  timestamp = {2017-05-19T07:25:15Z},
  publisher = {{Vintage}},
  author = {Foucault, Michel},
  translator = {Sheridan-Smith, Allan},
  date = {1977}
}

@online{IBM_2014,
  title = {{{IBM}}'s {{Watson Learns}} the {{Language}} of {{Science}}},
  url = {https://www-03.ibm.com/press/us/en/pressrelease/44697.wss},
  abstract = {Watson now has the ability to understand complex biology, chemistry symbols, IP and legal languages allowing scientists to make connections w/ data that others don't see},
  timestamp = {2017-05-19T07:25:15Z},
  type = {{{CTB10}}},
  author = {{IBM}},
  urldate = {2015-04-16},
  date = {2014-08-28}
}

@article{Khan_2001,
  title = {Classification and {{Diagnostic Prediction}} of {{Cancers Using Gene Expression Profiling}} and {{Artificial Neural Networks}}},
  volume = {7},
  url = {http://www.nature.com/nm/journal/v7/n6/abs/nm0601_673.html},
  timestamp = {2017-05-19T07:25:15Z},
  number = {6},
  author = {Khan, Javed and Wei, Jun S. and Ringner, Markus and Saal, Lao H. and Ladanyi, Marc and Westermann, Frank and Berthold, Frank and Schwab, Manfred and Antonescu, Cristina R. and Peterson, Carsten and {others}},
  urldate = {2015-04-17},
  date = {2001},
  pages = {673--679}
}

@article{Furey_2000,
  title = {Support {{Vector Machine Classification}} and {{Validation}} of {{Cancer Tissue Samples Using Microarray Expression Data}}},
  volume = {16},
  url = {http://bioinformatics.oxfordjournals.org/content/16/10/906.short},
  timestamp = {2017-05-19T07:25:16Z},
  number = {10},
  author = {Furey, Terrence S. and Cristianini, Nello and Duffy, Nigel and Bednarski, David W. and Schummer, Michel and Haussler, David},
  urldate = {2015-04-19},
  date = {2000},
  pages = {906--914}
}

@inproceedings{Cho_2003,
  title = {Machine {{Learning}} in {{DNA Microarray Analysis}} for {{Cancer Classification}}},
  url = {http://dl.acm.org/citation.cfm?id=820213},
  timestamp = {2017-05-19T07:25:16Z},
  booktitle = {Proceedings of the {{First Asia}}-{{Pacific Bioinformatics Conference}} on {{Bioinformatics}} 2003-{{Volume}} 19},
  publisher = {{Australian Computer Society, Inc.}},
  author = {Cho, Sung-Bae and Won, Hong-Hee},
  urldate = {2015-04-19},
  date = {2003},
  pages = {189--198}
}

@book{Durbin_1998,
  location = {{Cambridge, New York}},
  edition = {1 edition},
  title = {Biological {{Sequence Analysis}}: {{Probabilistic Models}} of {{Proteins}} and {{Nucleic Acids}}},
  isbn = {978-0-521-62971-3},
  shorttitle = {Biological {{Sequence Analysis}}},
  abstract = {Probablistic models are becoming increasingly important in analyzing the huge amount of data being produced by large-scale DNA-sequencing efforts such as the Human Genome Project. For example, hidden Markov models are used for analyzing biological sequences, linguistic-grammar-based probabilistic models for identifying RNA secondary structure, and probabilistic evolutionary models for inferring phylogenies of sequences from different organisms. This book gives a unified, up-to-date and self-contained account, with a Bayesian slant, of such methods, and more generally to probabilistic methods of sequence analysis. Written by an interdisciplinary team of authors, it is accessible to molecular biologists, computer scientists, and mathematicians with no formal knowledge of the other fields, and at the same time presents the state of the art in this new and important field.},
  timestamp = {2017-05-19T07:25:16Z},
  publisher = {{Cambridge University Press}},
  author = {Durbin, Richard and Eddy, Sean R. and Krogh, Anders and Mitchison, Graeme},
  date = {1998-05-13}
}

@book{Baldi_2002,
  location = {{Cambridge}},
  title = {{{DNA Microarrays}} and {{Gene Expression}} : {{From Experiments}} to {{Data Analysis}} and {{Modeling}}},
  isbn = {0-521-80022-6},
  shorttitle = {{{DNA Microarrays}} and {{Gene Expression}}},
  abstract = {Includes bibliographical references and index.},
  timestamp = {2017-05-19T07:25:16Z},
  publisher = {{Cambridge University Press}},
  author = {Baldi, Pierre},
  date = {2002},
  keywords = {DNA microarrays.,Gene expression.}
}

@article{Bishop_1986,
  title = {Maximum {{Likelihood Alignment}} of {{DNA Sequences}}},
  volume = {190},
  url = {http://www.sciencedirect.com/science/article/pii/0022283686902895},
  timestamp = {2017-05-19T07:25:16Z},
  number = {2},
  author = {Bishop, M. J. and Thompson, E. A.},
  urldate = {2015-04-21},
  date = {1986},
  pages = {159--165}
}

@article{Venter_2001,
  title = {The {{Sequence}} of the {{Human Genome}}},
  volume = {291},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/content/291/5507/1304},
  doi = {10.1126/science.1058040},
  abstract = {A 2.91-billion base pair (bp) consensus sequence of the euchromatic portion of the human genome was generated by the whole-genome shotgun sequencing method. The 14.8-billion bp DNA sequence was generated over 9 months from 27,271,853 high-quality sequence reads (5.11-fold coverage of the genome) from both ends of plasmid clones made from the DNA of five individuals. Two assembly strategies—a whole-genome assembly and a regional chromosome assembly—were used, each combining sequence data from Celera and the publicly funded genome effort. The public data were shredded into 550-bp segments to create a 2.9-fold coverage of those genome regions that had been sequenced, without including biases inherent in the cloning and assembly procedure used by the publicly funded group. This brought the effective coverage in the assemblies to eightfold, reducing the number and size of gaps in the final assembly over what would be obtained with 5.11-fold coverage. The two assembly strategies yielded very similar results that largely agree with independent mapping data. The assemblies effectively cover the euchromatic regions of the human chromosomes. More than 90\% of the genome is in scaffold assemblies of 100,000 bp or more, and 25\% of the genome is in scaffolds of 10 million bp or larger. Analysis of the genome sequence revealed 26,588 protein-encoding transcripts for which there was strong corroborating evidence and an additional ∼12,000 computationally derived genes with mouse matches or other weak supporting evidence. Although gene-dense clusters are obvious, almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence. Only 1.1\% of the genome is spanned by exons, whereas 24\% is in introns, with 75\% of the genome being intergenic DNA. Duplications of segmental blocks, ranging in size up to chromosomal lengths, are abundant throughout the genome and reveal a complex evolutionary history. Comparative genomic analysis indicates vertebrate expansions of genes associated with neuronal function, with tissue-specific developmental regulation, and with the hemostasis and immune systems. DNA sequence comparisons between the consensus sequence and publicly funded genome data provided locations of 2.1 million single-nucleotide polymorphisms (SNPs). A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average, but there was marked heterogeneity in the level of polymorphism across the genome. Less than 1\% of all SNPs resulted in variation in proteins, but the task of determining which SNPs have functional consequences remains an open challenge.},
  timestamp = {2017-05-19T07:25:16Z},
  number = {5507},
  author = {Venter, J. Craig and Adams, Mark D. and Myers, Eugene W. and Li, Peter W. and Mural, Richard J. and Sutton, Granger G. and Smith, Hamilton O. and Yandell, Mark and Evans, Cheryl A. and Holt, Robert A. and Gocayne, Jeannine D. and Amanatides, Peter and Ballew, Richard M. and Huson, Daniel H. and Wortman, Jennifer Russo and Zhang, Qing and Kodira, Chinnappa D. and Zheng, Xiangqun H. and Chen, Lin and Skupski, Marian and Subramanian, Gangadharan and Thomas, Paul D. and Zhang, Jinghui and Miklos, George L. Gabor and Nelson, Catherine and Broder, Samuel and Clark, Andrew G. and Nadeau, Joe and McKusick, Victor A. and Zinder, Norton and Levine, Arnold J. and Roberts, Richard J. and Simon, Mel and Slayman, Carolyn and Hunkapiller, Michael and Bolanos, Randall and Delcher, Arthur and Dew, Ian and Fasulo, Daniel and Flanigan, Michael and Florea, Liliana and Halpern, Aaron and Hannenhalli, Sridhar and Kravitz, Saul and Levy, Samuel and Mobarry, Clark and Reinert, Knut and Remington, Karin and Abu-Threideh, Jane and Beasley, Ellen and Biddick, Kendra and Bonazzi, Vivien and Brandon, Rhonda and Cargill, Michele and Chandramouliswaran, Ishwar and Charlab, Rosane and Chaturvedi, Kabir and Deng, Zuoming and Francesco, Valentina Di and Dunn, Patrick and Eilbeck, Karen and Evangelista, Carlos and Gabrielian, Andrei E. and Gan, Weiniu and Ge, Wangmao and Gong, Fangcheng and Gu, Zhiping and Guan, Ping and Heiman, Thomas J. and Higgins, Maureen E. and Ji, Rui-Ru and Ke, Zhaoxi and Ketchum, Karen A. and Lai, Zhongwu and Lei, Yiding and Li, Zhenya and Li, Jiayin and Liang, Yong and Lin, Xiaoying and Lu, Fu and Merkulov, Gennady V. and Milshina, Natalia and Moore, Helen M. and Naik, Ashwinikumar K. and Narayan, Vaibhav A. and Neelam, Beena and Nusskern, Deborah and Rusch, Douglas B. and Salzberg, Steven and Shao, Wei and Shue, Bixiong and Sun, Jingtao and Wang, Zhen Yuan and Wang, Aihui and Wang, Xin and Wang, Jian and Wei, Ming-Hui and Wides, Ron and Xiao, Chunlin and Yan, Chunhua and Yao, Alison and Ye, Jane and Zhan, Ming and Zhang, Weiqing and Zhang, Hongyu and Zhao, Qi and Zheng, Liansheng and Zhong, Fei and Zhong, Wenyan and Zhu, Shiaoping C. and Zhao, Shaying and Gilbert, Dennis and Baumhueter, Suzanna and Spier, Gene and Carter, Christine and Cravchik, Anibal and Woodage, Trevor and Ali, Feroze and An, Huijin and Awe, Aderonke and Baldwin, Danita and Baden, Holly and Barnstead, Mary and Barrow, Ian and Beeson, Karen and Busam, Dana and Carver, Amy and Center, Angela and Cheng, Ming Lai and Curry, Liz and Danaher, Steve and Davenport, Lionel and Desilets, Raymond and Dietz, Susanne and Dodson, Kristina and Doup, Lisa and Ferriera, Steven and Garg, Neha and Gluecksmann, Andres and Hart, Brit and Haynes, Jason and Haynes, Charles and Heiner, Cheryl and Hladun, Suzanne and Hostin, Damon and Houck, Jarrett and Howland, Timothy and Ibegwam, Chinyere and Johnson, Jeffery and Kalush, Francis and Kline, Lesley and Koduru, Shashi and Love, Amy and Mann, Felecia and May, David and McCawley, Steven and McIntosh, Tina and McMullen, Ivy and Moy, Mee and Moy, Linda and Murphy, Brian and Nelson, Keith and Pfannkoch, Cynthia and Pratts, Eric and Puri, Vinita and Qureshi, Hina and Reardon, Matthew and Rodriguez, Robert and Rogers, Yu-Hui and Romblad, Deanna and Ruhfel, Bob and Scott, Richard and Sitter, Cynthia and Smallwood, Michelle and Stewart, Erin and Strong, Renee and Suh, Ellen and Thomas, Reginald and Tint, Ni Ni and Tse, Sukyee and Vech, Claire and Wang, Gary and Wetter, Jeremy and Williams, Sherita and Williams, Monica and Windsor, Sandra and Winn-Deen, Emily and Wolfe, Keriellen and Zaveri, Jayshree and Zaveri, Karena and Abril, Josep F. and Guigó, Roderic and Campbell, Michael J. and Sjolander, Kimmen V. and Karlak, Brian and Kejariwal, Anish and Mi, Huaiyu and Lazareva, Betty and Hatton, Thomas and Narechania, Apurva and Diemer, Karen and Muruganujan, Anushya and Guo, Nan and Sato, Shinji and Bafna, Vineet and Istrail, Sorin and Lippert, Ross and Schwartz, Russell and Walenz, Brian and Yooseph, Shibu and Allen, David and Basu, Anand and Baxendale, James and Blick, Louis and Caminha, Marcelo and Carnes-Stine, John and Caulk, Parris and Chiang, Yen-Hui and Coyne, My and Dahlke, Carl and Mays, Anne Deslattes and Dombroski, Maria and Donnelly, Michael and Ely, Dale and Esparham, Shiva and Fosler, Carl and Gire, Harold and Glanowski, Stephen and Glasser, Kenneth and Glodek, Anna and Gorokhov, Mark and Graham, Ken and Gropman, Barry and Harris, Michael and Heil, Jeremy and Henderson, Scott and Hoover, Jeffrey and Jennings, Donald and Jordan, Catherine and Jordan, James and Kasha, John and Kagan, Leonid and Kraft, Cheryl and Levitsky, Alexander and Lewis, Mark and Liu, Xiangjun and Lopez, John and Ma, Daniel and Majoros, William and McDaniel, Joe and Murphy, Sean and Newman, Matthew and Nguyen, Trung and Nguyen, Ngoc and Nodell, Marc and Pan, Sue and Peck, Jim and Peterson, Marshall and Rowe, William and Sanders, Robert and Scott, John and Simpson, Michael and Smith, Thomas and Sprague, Arlan and Stockwell, Timothy and Turner, Russell and Venter, Eli and Wang, Mei and Wen, Meiyuan and Wu, David and Wu, Mitchell and Xia, Ashley and Zandieh, Ali and Zhu, Xiaohong},
  urldate = {2015-04-21},
  date = {2001-02-16},
  pages = {1304--1351}
}

@article{Myers_2000,
  title = {A {{Whole}}-{{Genome Assembly}} of {{Drosophila}}},
  volume = {287},
  url = {http://www.sciencemag.org/content/287/5461/2196.short},
  timestamp = {2017-05-19T07:25:16Z},
  number = {5461},
  author = {Myers, Eugene W. and Sutton, Granger G. and Delcher, Art L. and Dew, Ian M. and Fasulo, Dan P. and Flanigan, Michael J. and Kravitz, Saul A. and Mobarry, Clark M. and Reinert, Knut HJ and Remington, Karin A. and {others}},
  urldate = {2015-04-21},
  date = {2000},
  pages = {2196--2204}
}

@article{Henson_2012,
  title = {Next-{{Generation Sequencing}} and {{Large Genome Assemblies}}},
  volume = {13},
  issn = {1462-2416},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3960634/},
  doi = {10.2217/pgs.12.72},
  abstract = {The next-generation sequencing (NGS) revolution has drastically reduced time and cost requirements for sequencing of large genomes, and also qualitatively changed the problem of assembly. This article reviews the state of the art in de novo genome assembly, paying particular attention to mammalian-sized genomes. The strengths and weaknesses of the main sequencing platforms are highlighted, leading to a discussion of assembly and the new challenges associated with NGS data. Current approaches to assembly are outlined and the various software packages available are introduced and compared. The question of whether quality assemblies can be produced using short-read NGS data alone, or whether it must be combined with more expensive sequencing techniques, is considered. Prospects for future assemblers and tests of assembly performance are also discussed.},
  timestamp = {2017-05-19T07:25:16Z},
  number = {8},
  author = {Henson, Joseph and Tischler, German and Ning, Zemin},
  urldate = {2015-04-21},
  date = {2012-06},
  pages = {901--915},
  pmcid = {PMC3960634}
}

@article{Pevzner_2001,
  title = {An {{Eulerian Path Approach}} to {{DNA Fragment Assembly}}},
  volume = {98},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org.ezproxy.lancs.ac.uk/content/98/17/9748},
  doi = {10.1073/pnas.171285098},
  abstract = {For the last 20 years, fragment assembly in DNA sequencing followed the “overlap–layout–consensus” paradigm that is used in all currently available assembly tools. Although this approach proved useful in assembling clones, it faces difficulties in genomic shotgun assembly. We abandon the classical “overlap–layout–consensus” approach in favor of a new euler algorithm that, for the first time, resolves the 20-year-old “repeat problem” in fragment assembly. Our main result is the reduction of the fragment assembly to a variation of the classical Eulerian path problem that allows one to generate accurate solutions of large-scale sequencing problems. euler, in contrast to the celera assembler, does not mask such repeats but uses them instead as a powerful fragment assembly tool.},
  timestamp = {2017-05-19T07:25:16Z},
  number = {17},
  author = {Pevzner, Pavel A. and Tang, Haixu and Waterman, Michael S.},
  urldate = {2015-04-21},
  date = {2001-08-14},
  pages = {9748--9753}
}

@online{CNN_2011,
  title = {40 {{Under}} 40: {{Ones}} to {{Watch}}},
  url = {http://money.cnn.com/galleries/2011/news/companies/1110/gallery.40_under_40_ones_to_watch.fortune/},
  shorttitle = {40 {{Under}} 40},
  abstract = {In addition to Fortune's 40 Under 40 list, we're also keeping our eye on these 20 innovators, young guns from a wide range of industries and backgrounds.},
  timestamp = {2017-05-19T07:25:16Z},
  author = {{CNN}},
  urldate = {2013-01-22},
  date = {2011}
}

@book{Duda_2012,
  location = {{New York; London}},
  title = {Pattern {{Classification}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=Br33IRC3PkQC&oi=fnd&pg=PR3&dq=Duda+pattern&ots=2wyTOtgdDo&sig=7jJ1BRioJDiwsN61L2gTkiRgqWY},
  timestamp = {2017-05-19T07:25:16Z},
  publisher = {{John Wiley \& Sons}},
  author = {Duda, Richard O. and Hart, Peter E. and Stork, David G.},
  urldate = {2015-03-06},
  date = {2012}
}

@book{Ripley_2014,
  title = {Tree: {{Classification}} and {{Regression Trees}}},
  url = {http://CRAN.R-project.org/package=tree},
  timestamp = {2017-05-19T07:25:16Z},
  author = {Ripley, Brian},
  date = {2014}
}

@article{Hothorn_2006,
  title = {Unbiased {{Recursive Partitioning}}: {{A Conditional Inference Framework}}},
  volume = {15},
  timestamp = {2017-05-19T07:25:16Z},
  number = {3},
  author = {Hothorn, Torsten and Hornik, Kurt and Zeileis, Achim},
  date = {2006},
  pages = {651--674}
}

@book{Couldry_2012,
  location = {{Cambridge ; Malden, MA}},
  title = {Media, {{Society}}, {{World}}: {{Social Theory}} and {{Digital Media Practice}}},
  shorttitle = {Media, {{Society}}, {{World}}},
  timestamp = {2017-05-19T07:25:16Z},
  publisher = {{Polity}},
  author = {Couldry, Nick},
  date = {2012},
  keywords = {celebrity}
}

@book{Bishop_1995,
  location = {{Cambridge; New York}},
  title = {Neural {{Networks}} for {{Pattern Recognition}}},
  url = {http://www.engineering.upm.ro/master-ie/sacpi/mat_did/info068/docum/Neural%20Networks%20for%20Pattern%20Recognition.pdf},
  timestamp = {2017-05-19T07:25:16Z},
  publisher = {{Cambridge University Press}},
  author = {Bishop, Christopher M. and {others}},
  urldate = {2015-03-06},
  date = {1995}
}

@book{VanDijck_2013,
  location = {{Oxford ; New York}},
  edition = {1 edition},
  title = {The {{Culture}} of {{Connectivity}}: {{A Critical History}} of {{Social Media}}},
  isbn = {978-0-19-997078-0},
  shorttitle = {The {{Culture}} of {{Connectivity}}},
  timestamp = {2017-05-19T07:25:17Z},
  publisher = {{Oxford University Press}},
  author = {Van Dijck, Jose},
  date = {2013}
}

@article{Ramaswamy_2001,
  title = {Multiclass {{Cancer Diagnosis Using Tumor Gene Expression Signatures}}},
  volume = {98},
  url = {http://www.pnas.org/content/98/26/15149.short},
  timestamp = {2017-05-19T07:25:17Z},
  number = {26},
  author = {Ramaswamy, Sridhar and Tamayo, Pablo and Rifkin, Ryan and Mukherjee, Sayan and Yeang, Chen-Hsiang and Angelo, Michael and Ladd, Christine and Reich, Michael and Latulippe, Eva and Mesirov, Jill P. and {others}},
  urldate = {2015-04-23},
  date = {2001},
  pages = {15149--15154}
}

@article{Tibshirani_1996,
  title = {Regression {{Shrinkage}} and {{Selection}} via the {{Lasso}}},
  timestamp = {2017-05-19T07:25:17Z},
  author = {Tibshirani, Robert},
  date = {1996},
  pages = {267--288},
  eprinttype = {jstor},
  eprint = {2346178}
}

@article{Ta_1989,
  title = {Prostate {{Specific Antigen}} in the {{Diagnosis}} and {{Treatment}} of {{Adenocarcinoma}} of the {{Prostate}}. {{II}}. {{Radical Prostatectomy Treated Patients}}.},
  volume = {141},
  issn = {0022-5347},
  url = {http://europepmc.org/abstract/med/2468795},
  abstract = {Abstract: Serum prostate specific antigen was determined (Yang polyclonal radioimmunoassay) in 102 men before hospitalization for radical prostatectomy....},
  timestamp = {2017-05-19T07:25:17Z},
  number = {5},
  author = {Ta, Stamey and Jn, Kabalin and Je, McNeal and Im, Johnstone and F, Freiha and Ea, Redwine and N, Yang},
  urldate = {2015-04-23},
  date = {1989-05},
  pages = {1076--1083}
}

@article{Szymczak_2009,
  title = {Machine {{Learning}} in {{Genome}}-{{Wide Association Studies}}},
  volume = {33 Suppl 1},
  issn = {1098-2272},
  doi = {10.1002/gepi.20473},
  abstract = {Recently, genome-wide association studies have substantially expanded our knowledge about genetic variants that influence the susceptibility to complex diseases. Although standard statistical tests for each single-nucleotide polymorphism (SNP) separately are able to capture main genetic effects, different approaches are necessary to identify SNPs that influence disease risk jointly or in complex interactions. Experimental and simulated genome-wide SNP data provided by the Genetic Analysis Workshop 16 afforded an opportunity to analyze the applicability and benefit of several machine learning methods. Penalized regression, ensemble methods, and network analyses resulted in several new findings while known and simulated genetic risk variants were also identified. In conclusion, machine learning approaches are promising complements to standard single-and multi-SNP analysis methods for understanding the overall genetic architecture of complex human diseases. However, because they are not optimized for genome-wide SNP data, improved implementations and new variable selection procedures are required.},
  timestamp = {2017-05-19T07:25:17Z},
  author = {Szymczak, Silke and Biernacka, Joanna M. and Cordell, Heather J. and González-Recio, Oscar and König, Inke R. and Zhang, Heping and Sun, Yan V.},
  date = {2009},
  pages = {S51--57},
  keywords = {Artificial intelligence,Bayes Theorem,Genetic Predisposition to Disease,Genome-Wide Association Study,Humans,Molecular Epidemiology,Neural Networks (Computer),Polymorphism,Regression Analysis,Single Nucleotide}
}

@book{Gersho_1992,
  title = {Vector {{Quantization}} and {{Signal Compression}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=DwcDm6xgItUC&oi=fnd&pg=PR13&dq=gersho+gray+signal&ots=trpHj-lPkK&sig=vpmRDBlY41sI6y7mpt64plapGUI},
  timestamp = {2017-05-19T07:25:17Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Gersho, Allen and Gray, Robert M.},
  urldate = {2015-04-30},
  date = {1992}
}

@article{Rabiner_1989,
  title = {A {{Tutorial}} on {{Hidden Markov Models}} and {{Selected Applications}} in {{Speech Recognition}}},
  volume = {77},
  url = {http://ieeexplore.ieee.org.ezproxy.lancs.ac.uk/xpls/abs_all.jsp?arnumber=18626},
  timestamp = {2017-05-19T07:25:17Z},
  number = {2},
  author = {Rabiner, Lawrence},
  urldate = {2015-04-30},
  date = {1989},
  pages = {257--286}
}

@article{Dasarathy_1991,
  title = {Nearest {{Neighbor}} (\$\{\$$\backslash$vphantom\}{{NN}}\$$\backslash$vphantom\{\}\$) {{Norms}}:\$\{\$$\backslash$vphantom\}{{NN}}\$$\backslash$vphantom\{\}\$ {{Pattern Classification Techniques}}},
  url = {http://www.citeulike.org/group/1778/article/930342},
  shorttitle = {Nearest {{Neighbor}} (\$\{\$$\backslash$vphantom\}{{NN}}\$$\backslash$vphantom\{\}\$) {{Norms}}},
  timestamp = {2017-05-19T07:25:17Z},
  author = {Dasarathy, Belur V.},
  urldate = {2015-04-30},
  date = {1991}
}

@online{Photos_2015,
  title = {Gray {{Tabby Cat}} with {{Green Eyes Close Up}}},
  url = {http://www.photos-public-domain.com/2012/05/08/gray-tabby-cat-with-green-eyes-close-up/},
  abstract = {Free high resolution close up photo of a gray tabby cat with green eyes. Free picture for any use.},
  timestamp = {2017-05-19T07:25:17Z},
  author = {Photos, Public Domain},
  urldate = {2015-04-30},
  date = {2015}
}

@article{Hinton_1989,
  title = {Connectionist {{Learning Procedures}}},
  volume = {40},
  url = {http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/pii/0004370289900490},
  timestamp = {2017-05-19T07:25:17Z},
  number = {1},
  author = {Hinton, Geoffrey E.},
  urldate = {2015-05-18},
  date = {1989},
  pages = {185--234}
}

@online{Hof_2014,
  title = {Chinese {{Search Giant Baidu Thinks AI Pioneer Andrew Ng Can Help It Challenge Google}} and {{Become}} a {{Global Power}}},
  url = {http://www.technologyreview.com/featuredstory/530016/a-chinese-internet-giant-starts-to-dream/},
  abstract = {Baidu is a fixture of online life in China, but it wants to become a global power. Can one of the world’s leading artificial intelligence researchers help it challenge Silicon Valley’s biggest companies?},
  timestamp = {2017-05-19T07:25:17Z},
  author = {Hof, Robert D.},
  urldate = {2015-05-18},
  date = {2014-08-14}
}

@article{Markoff_2012,
  title = {In a {{Big Network}} of {{Computers}}, {{Evidence}} of {{Machine Learning}}},
  issn = {0362-4331},
  url = {http://www.nytimes.com/2012/06/26/technology/in-a-big-network-of-computers-evidence-of-machine-learning.html},
  abstract = {A neural network of computer processors, fed millions of YouTube videos, taught itself to recognize cats, a feat of significance for fields like speech recognition.},
  timestamp = {2017-05-19T07:25:18Z},
  author = {Markoff, John},
  urldate = {2015-05-18},
  date = {2012-06-25},
  keywords = {Andrew Y,Artificial intelligence,Cats,Computers and the Internet,Computer Vision,Google Inc,neural networks,Ng,Research,Stanford University,Voice Recognition Systems}
}

@book{Barry_2013,
  title = {Interdisciplinarity: {{Reconfigurations}} of the {{Social}} and {{Natural Sciences}}},
  isbn = {978-1-136-65838-9},
  shorttitle = {Interdisciplinarity},
  abstract = {The idea that research should become more interdisciplinary has become commonplace. According to influential commentators, the unprecedented complexity of problems such as climate change or the social implications of biomedicine demand interdisciplinary efforts integrating both the social and natural sciences. In this context, the question of whether a given knowledge practice is too disciplinary, or interdisciplinary, or not disciplinary enough has become an issue for governments, research policy makers and funding agencies. Interdisciplinarity, in short, has emerged as a key political preoccupation; yet the term tends to obscure as much as illuminate the diverse practices gathered under its rubric. This volume offers a new approach to theorising interdisciplinarity, showing how the boundaries between the social and natural sciences are being reconfigured. It examines the current preoccupation with interdisciplinarity, notably the ascendance of a particular discourse in which it is associated with a transformation in the relations between science, technology and society. Contributors address attempts to promote collaboration between, on the one hand, the natural sciences and engineering and, on the other, the social sciences, arts and humanities. From ethnography in the IT industry to science and technology studies, environmental science to medical humanities, cybernetics to art-science, the collection interrogates how interdisciplinarity has come to be seen as a solution not only to enhancing relations between science and society, but the pursuit of accountability and the need to foster innovation. Interdisciplinarity is essential reading for scholars, students and policy makers across the social sciences, arts and humanities, including anthropology, geography, sociology, science and technology studies and cultural studies, as well as all those engaged in interdisciplinary research. It will have particular relevance for those concerned with the knowledge economy, science policy, environmental politics, applied anthropology, ELSI research, medical humanities, and art-science.},
  timestamp = {2017-05-19T07:25:18Z},
  publisher = {{Routledge}},
  author = {Barry, Andrew and Born, Georgina},
  date = {2013-06-26},
  keywords = {Social Science / Anthropology / General,Social Science / Human Geography,Social Science / Sociology / General}
}

@article{Barry_2008,
  title = {Logics of {{Interdisciplinarity}}},
  volume = {37},
  issn = {0308-5147},
  url = {http://dx.doi.org/10.1080/03085140701760841},
  doi = {10.1080/03085140701760841},
  abstract = {This paper interrogates influential contemporary accounts of interdisciplinarity, in which it is portrayed as offering new ways of rendering science accountable to society and/or of forging closer relations between scientific research and innovation. The basis of the paper is an eighteen-month empirical study of three interdisciplinary fields that cross the boundaries between the natural sciences or engineering, on the one hand, and the social sciences or arts, on the other. The fields are: 1) environmental and climate change research, 2) ethnography in the IT industry and 3) art-science. In the first part of the paper, in contrast to existing accounts, we question the idea that interdisciplinarity should be understood in terms of the synthesis of two or more disciplines. We stress the forms of agonism and antagonism that often characterize relations between disciplinary and interdisciplinary research, and distinguish between three modes of interdisciplinarity. In the second part we outline three distinctive logics or rationales that guide interdisciplinary research. In addition to the logics of accountability and innovation, we identify the logic of ontology, that is, an orientation apparent in diverse interdisciplinary practices in each of our three fields towards effecting ontological transformation in the objects and relations of research. While the three logics are interdependent, they are not reducible to each other and are differently entangled in each of the fields. We point to the potential for invention in such interdisciplinary practices and, against the equation of disciplinary research with autonomy, to the possibility of forms of interdisciplinary autonomy.},
  timestamp = {2017-05-19T07:25:18Z},
  number = {1},
  author = {Barry, Andrew and Born, Georgina and Weszkalnys, Gisa},
  urldate = {2015-05-18},
  date = {2008-02-01},
  pages = {20--49}
}

@online{_c,
  title = {Anomaly {{Detection}}: {{The Mathematization}} of the {{Abnormal}} in the {{Metadata Society}}},
  url = {https://www.academia.edu/10369819/Anomaly_Detection_The_Mathematization_of_the_Abnormal_in_the_Metadata_Society},
  shorttitle = {Anomaly {{Detection}}},
  abstract = {Anomaly Detection: The Mathematization of the Abnormal in the Metadata Society},
  timestamp = {2017-05-19T07:25:18Z},
  urldate = {2015-06-25}
}

@book{Richert_2013,
  location = {{Birmingham}},
  title = {Building {{Machine Learning Systems}} with {{Python}}},
  isbn = {978-1-78216-140-0},
  abstract = {As the Big Data explosion continues at an almost incomprehensible rate, being able to understand and process it becomes even more challenging. With Building Machine Learning Systems with Python, you'll learn everything you need to tackle the modern data deluge - by harnessing the unique capabilities of Python and its extensive range of numerical and scientific libraries, you will be able to create complex algorithms that can 'learn' from data, allowing you to uncover patterns, make predictions, and gain a more in-depth understanding of your data. Featuring a wealth of real-world examples, this book provides gives you with an accessible route into Python machine learning. Learn the Iris dataset, find out how to build complex classifiers, and get to grips with clustering through practical examples that deliver complex ideas with clarity. Dig deeper into machine learning, and discover guidance on classification and regression, with practical machine learning projects outlining effective strategies for sentiment analysis and basket analysis. The book also takes you through the latest in computer vision, demonstrating how image processing can be used for pattern recognition, as well as showing you how to get a clearer picture of your data and trends by using dimensionality reduction. Keep up to speed with one of the most exciting trends to emerge from the world of data science and dig deeper into your data with Python with this unique data science tutorial. Learn how to create machine learning algorithms using the flexibility of Python Get to grips with scikit-learn and other Python scientific libraries that support machine learning projects Employ computer vision using mahotas for image processing that will help you uncover patterns and trends in your data Learn topic modelling and build a topic model for Wikipedia Analyze Twitter data using sentiment analysis Get to grips with classification and regression with real-world examples},
  timestamp = {2017-05-19T07:25:18Z},
  publisher = {{Packt Publishing}},
  author = {Richert, Willi and Coelho, Luis Pedro},
  date = {2013}
}

@article{Rumelhart_1986,
  title = {Learning {{Representations}} by {{Back}}-{{Propagating Errors}}},
  volume = {323},
  url = {http://www.nature.com/nature/journal/v323/n6088/abs/323533a0.html},
  doi = {10.1038/323533a0},
  timestamp = {2017-05-19T07:25:18Z},
  number = {6088},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  urldate = {2015-05-22},
  date = {1986-10-09},
  pages = {533--536}
}

@online{Zare_2012,
  title = {Difference between {{Logistic Regression}} and {{Neural Networks}} - {{Cross Validated}}},
  url = {http://stats.stackexchange.com/questions/43538/difference-between-logistic-regression-and-neural-networks},
  timestamp = {2017-05-19T07:25:18Z},
  author = {Zare, Douglas},
  urldate = {2015-05-26},
  date = {2012-12-07}
}

@online{DrivenData_2015,
  title = {{{DrivenData}}: {{Data Science Competitions}}},
  url = {http://www.drivendata.org/competitions/},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{DrivenData}},
  urldate = {2015-05-28},
  date = {2015}
}

@article{LeCun_1989,
  title = {Backpropagation {{Applied}} to {{Handwritten Zip Code Recognition}}},
  volume = {1},
  url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541},
  timestamp = {2017-05-19T07:25:18Z},
  number = {4},
  author = {LeCun, Yann and Boser, Bernhard and Denker, John S. and Henderson, Donnie and Howard, Richard E. and Hubbard, Wayne and Jackel, Lawrence D.},
  urldate = {2015-05-28},
  date = {1989},
  pages = {541--551}
}

@article{LeCun_1998,
  title = {Gradient-{{Based Learning Applied}} to {{Document Recognition}}},
  volume = {86},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=726791},
  timestamp = {2017-05-19T07:25:18Z},
  number = {11},
  author = {LeCun, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
  urldate = {2015-05-28},
  date = {1998},
  pages = {2278--2324}
}

@article{Liu_2003,
  title = {Handwritten {{Digit Recognition}}: {{Benchmarking}} of {{State}}-of-the-{{Art Techniques}}},
  volume = {36},
  issn = {0031-3203},
  doi = {10.1016/S0031-3206(03)00085-2},
  shorttitle = {Handwritten {{Digit Recognition}}},
  abstract = {This paper presents the results of handwritten digit recognition on well-known image databases using state-of-the-art feature extraction and classification techniques. The tested databases are CENPARMI, CEDAR, and MNIST. On the test data set of each database, 80 recognition accuracies are given by combining eight classifiers with ten feature vectors. The features include chaincode feature, gradient feature, profile structure feature, and peripheral direction contributivity. The gradient feature is extracted from either binary image or gray-scale image. The classifiers include the k-nearest neighbor classifier, three neural classifiers, a learning vector quantization classifier, a discriminative learning quadratic discriminant function (DLQDF) classifier, and two support vector classifiers (SVCs). All the classifiers and feature vectors give high recognition accuracies. Relatively, the chaincode feature and the gradient feature show advantage over other features, and the profile structure feature shows efficiency as a complementary feature. The SVC with RBF kernel (SVC-rbf) gives the highest accuracy in most cases but is extremely expensive in storage and computation. Among the non-SV classifiers, the polynomial classifier and DLQDF give the highest accuracies. The results of non-SV classifiers are competitive to the best ones previously reported on the same databases. (C) 2003 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.},
  timestamp = {2017-05-19T07:25:18Z},
  number = {10},
  author = {Liu, C. L. and Nakashima, K. and Sako, H. and Fujisawa, H.},
  date = {2003-10},
  pages = {2271--2285},
  keywords = {algorithms,character-recognition,Classification,discriminative learning,Feature extraction,features,gradient,handwritten digit recognition,line,neural-network,numeral recognition,pattern classification,support vector classifier,support vector machines,the state of the art}
}

@article{Hinton_2006,
  title = {A {{Fast Learning Algorithm}} for {{Deep Belief Nets}}},
  volume = {18},
  issn = {0899-7667},
  doi = {10.1162/neco.2006.18.7.1527},
  abstract = {We show how to use "complementary priors" to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
  timestamp = {2017-05-19T07:25:18Z},
  number = {7},
  author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
  date = {2006-07},
  pages = {1527--1554},
  keywords = {machines,networks,recognition}
}

@online{Kaggle_2015,
  title = {Competitions | {{Kaggle}}},
  url = {https://www.kaggle.com/solutions/competitions},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{Kaggle}},
  urldate = {2015-06-03},
  date = {2015}
}

@online{Kaggle_2015a,
  title = {Facebook {{Recruiting IV}}: {{Human}} or {{Robot}}? | {{Kaggle}}},
  url = {https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{Kaggle}},
  urldate = {2015-06-03},
  date = {2015}
}

@online{Kaggle_2015b,
  title = {About | {{Kaggle}}},
  url = {https://www.kaggle.com/about},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{Kaggle}},
  urldate = {2015-06-03},
  date = {2015}
}

@article{Neyland_2015,
  title = {On {{Organizing Algorithms}}},
  volume = {32},
  issn = {0263-2764, 1460-3616},
  url = {http://tcs.sagepub.com/content/32/1/119},
  doi = {10.1177/0263276414530477},
  abstract = {This short paper acts as a comment on Totaro and Ninno's ‘The Concept of Algorithm as an Interpretative Key of Modern Rationality’ and also introduces some new avenues for exploring the organization of algorithms. In recent discussion of algorithms, concerns have been expressed regarding the apparent power, agential capacity and control that algorithms command of our lives (Beer, 2009; Lash, 2007; Slavin, 2011; Spring, 2011; Stalder and Mayer, 2009). The logic of order, if there is one within these discussions, appears somewhat distinct from the metaphor of recursion suggested by Totaro and Ninno. Using this distinction as a starting point, the paper explores alternative metaphors from which to begin an engagement with political questions of algorithmic ordering. The paper argues for engaging with associative metaphors of: algorithmic account, fluidity, absent-presence and sociality. The paper explores these associative metaphors through an important set of emerging questions regarding organizing algorithms: who and what is included or excluded, on what terms and to what ends?},
  timestamp = {2017-05-19T07:25:18Z},
  number = {1},
  author = {Neyland, Daniel},
  urldate = {2015-06-03},
  date = {2015-01-01},
  pages = {119--132},
  keywords = {algorithms,metaphors,order,recursive,surveillance}
}

@online{Mullig_2015,
  title = {Chmullig | {{Kaggle}}},
  url = {https://www.kaggle.com/users/46736/chmullig},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{Mullig}},
  urldate = {2015-06-04},
  date = {2015}
}

@online{Kaggle_2015c,
  title = {Description - {{Leaping Leaderboard Leapfrogs}} | {{Kaggle}}},
  url = {https://www.kaggle.com/c/leapfrogging-leaderboards},
  timestamp = {2017-05-19T07:25:18Z},
  author = {{Kaggle}},
  urldate = {2015-06-04},
  date = {2015}
}

@book{Erickson_2013,
  title = {How {{Reason Almost Lost Its Mind}}: {{The Strange Career}} of {{Cold War Rationality}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=-b0BAgAAQBAJ&oi=fnd&pg=PR5&dq=erickson+cold+war&ots=BGlorQcl-D&sig=Hx5igFgX9mILEE8gR54prrayKaU},
  shorttitle = {How {{Reason Almost Lost Its Mind}}},
  timestamp = {2017-05-19T07:25:18Z},
  publisher = {{University of Chicago Press}},
  author = {Erickson, Paul and Klein, Judy L. and Daston, Lorraine and Lemov, Rebecca and Sturm, Thomas and Gordin, Michael D.},
  urldate = {2015-06-04},
  date = {2013}
}

@book{Fuller_2012,
  location = {{Cambridge, Mass}},
  title = {Evil {{Media}}},
  isbn = {978-0-262-01785-5},
  abstract = {Evil Media develops a philosophy of media power that extends the concept of media beyond its tried and trusted use in the games of meaning, symbolism, and truth. It addresses the gray zones in which media exist as corporate work systems, algorithms and data structures, twenty-first century self-improvement manuals, and pharmaceutical techniques. Evil Media invites the reader to explore and understand the abstract infrastructure of the present day. From search engines to flirting strategies, from the value of institutional stupidity to the malicious minutiae of databases, this book shows how the devil is in the details. The title takes the imperative "Don't be evil" and asks, what would be done any differently in contemporary computational and networked media were that maxim reversed. Media here are about much more and much less than symbols, stories, information, or communication: media do things. They incite and provoke, twist and bend, leak and manage. In a series of provocative stratagems designed to be used, Evil Media sets its reader an ethical challenge: either remain a transparent intermediary in the networks and chains of communicative power or become oneself an active, transformative medium.},
  timestamp = {2017-05-19T07:25:19Z},
  publisher = {{MIT Press}},
  author = {Fuller, Matthew and Goffey, Andrew},
  date = {2012}
}

@book{Foucault_1998,
  location = {{London}},
  title = {The {{Will}} to {{Knowledge}}: {{The History}} of {{Sexuality}}},
  volume = {1},
  url = {http://philpapers.org/rec/FOUTWT},
  shorttitle = {The {{Will}} to {{Knowledge}}},
  timestamp = {2017-05-19T07:25:19Z},
  publisher = {{Penguin}},
  author = {Foucault, Michel},
  translator = {Hurley, Robert},
  urldate = {2015-06-15},
  date = {1998}
}

@online{Kaggle_2012,
  title = {The {{Hewlett Foundation}}: {{Automated Essay Scoring}} | {{Kaggle}}},
  url = {https://www.kaggle.com/c/asap-aes},
  timestamp = {2017-05-19T07:25:19Z},
  author = {{Kaggle}},
  urldate = {2015-07-01},
  date = {2012}
}

@online{McMillan_2013,
  title = {How {{Google Retooled Android With Help From Your Brain}}},
  url = {http://www.wired.com/2013/02/android-neural-network/},
  abstract = {When Google built the latest version of its Android mobile operating system, the web giant made some big changes to the way the OS interprets your voice commands. It installed a voice recognition system based on what's called a neural network – a computer network that behaves much like the human brain.},
  timestamp = {2017-05-19T07:25:19Z},
  author = {McMillan, Robert},
  urldate = {2015-08-04},
  date = {2013-02-18}
}

@online{Kaggle_2015d,
  title = {Data {{Science Jobs Forum}} | {{Kaggle}}},
  url = {https://www.kaggle.com/jobs},
  timestamp = {2017-05-19T07:25:19Z},
  author = {{Kaggle}},
  urldate = {2015-07-02},
  date = {2015}
}

@online{Kaggle_2015e,
  title = {Description - {{Facebook Recruiting IV}}: {{Human}} or {{Robot}}? | {{Kaggle}}},
  url = {https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot},
  timestamp = {2017-05-19T07:25:19Z},
  author = {{Kaggle}},
  urldate = {2015-07-02},
  date = {2015}
}

@online{Dieleman_2014,
  title = {Benanne/{{Kaggle}}-{{Galaxies}}},
  url = {https://github.com/benanne/kaggle-galaxies},
  abstract = {kaggle-galaxies - Winning solution for the Galaxy Challenge on Kaggle (http://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge)},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Dieleman, Sander},
  urldate = {2015-07-02},
  date = {2014}
}

@online{Dieleman_2015,
  title = {Benanne/{{Kaggle}}-{{Ndsb}}},
  url = {https://github.com/benanne/kaggle-ndsb},
  abstract = {kaggle-ndsb - Winning solution for the National Data Science Bowl competition on Kaggle (plankton classification)},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Dieleman, Sander},
  urldate = {2015-07-02},
  date = {2015}
}

@article{Simonyan_2014,
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  url = {http://arxiv.org/abs/1409.1556},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  timestamp = {2017-05-19T07:25:19Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.1556},
  author = {Simonyan, Karen and Zisserman, Andrew},
  urldate = {2015-07-03},
  date = {2014-09-04},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@book{McClelland_1986,
  location = {{Cambridge, MA \& London}},
  title = {Parallel {{Distributed Processing}}. {{Explorations}} in the {{Microstructure}} of {{Cognition}}},
  volume = {1},
  timestamp = {2017-05-19T07:25:19Z},
  publisher = {{MIT Press}},
  author = {McClelland, James L. and Rumelhart, David E.},
  date = {1986}
}

@online{Dieleman_2015a,
  title = {Classifying {{Plankton}} with {{Deep Neural Networks}}},
  url = {http://benanne.github.io/2015/03/17/plankton.html},
  abstract = {The Reslab team's solution for the National Data Science Bowl on Kaggle.},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Dieleman, Sander},
  urldate = {2015-07-03},
  date = {2015}
}

@book{Rumelhart_1986a,
  title = {{{PARALLEL DISTRIBUTED PROCESSING}}},
  url = {http://www.ulb.tu-darmstadt.de/tocs/123104785.pdf},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Rumelhart, James L. McClelland David E.},
  urldate = {2015-07-03},
  date = {1986}
}

@online{Kaggle_2015f,
  title = {Private {{Leaderboard}} - {{National Data Science Bowl}} | {{Kaggle}}},
  url = {https://www.kaggle.com/c/datasciencebowl/leaderboard},
  timestamp = {2017-05-19T07:25:19Z},
  author = {{Kaggle}},
  urldate = {2015-07-03},
  date = {2015}
}

@inproceedings{Glorot_2010,
  title = {Understanding the {{Difficulty}} of {{Training Deep Feedforward Neural Networks}}},
  url = {http://machinelearning.wustl.edu/mlpapers/paper_files/AISTATS2010_GlorotB10.pdf},
  timestamp = {2017-05-19T07:25:19Z},
  booktitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Glorot, Xavier and Bengio, Yoshua},
  urldate = {2015-07-03},
  date = {2010},
  pages = {249--256}
}

@online{ILSVRC_2014,
  title = {{{ImageNet Large Scale Visual Recognition Competition}} 2014 ({{ILSVRC2014}})},
  url = {http://www.image-net.org/challenges/LSVRC/2014/},
  timestamp = {2017-05-19T07:25:19Z},
  author = {{ILSVRC}},
  urldate = {2015-07-06},
  date = {2014}
}

@online{Dettmers_2015,
  title = {Which {{GPU}}(s) to {{Get}} for {{Deep Learning}}: {{My Experience}} and {{Advice}} for {{Using GPUs In}}},
  url = {https://timdettmers.wordpress.com/2014/08/14/which-gpu-for-deep-learning/},
  shorttitle = {Which {{GPU}}(s) to {{Get}} for {{Deep Learning}}},
  abstract = {You want a cheap high performance GPU for deep learning? In this blog post I will guide through the choices, so you can find the GPU which is best for you.},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Dettmers, Tim},
  urldate = {2015-07-08},
  date = {2015}
}

@online{_d,
  title = {Google's {{Deep Learning Machine Learns}} to {{Synthesize Real World Images}}},
  url = {http://www.technologyreview.com/view/539051/googles-deep-learning-machine-learns-to-synthesize-real-world-images/},
  abstract = {Give Google’s DeepStereo algorithm two images of a scene and it will synthesize a third image from a different point of view.},
  timestamp = {2017-05-19T07:25:19Z},
  urldate = {2015-07-09}
}

@online{Arthur_2015,
  title = {Artificial {{Intelligence}}: {{Don}}’t {{Fear AI}}. {{It}}’s {{Already}} on {{Your Phone}} – and {{Useful}}},
  url = {http://www.theguardian.com/technology/2015/jun/15/artificial-intelligence-ai-smartphones-machine-learning},
  shorttitle = {Artificial {{Intelligence}}},
  abstract = {Machine learning and machine intelligence is already incorporated in apps such as Google Photos, Google Now and Apple Maps, and it can make your life easier},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Arthur, Charles},
  urldate = {2015-07-09},
  date = {2015-06-15}
}

@online{Garling_2015,
  title = {Andrew {{Ng}}: {{Why}} '{{Deep Learning}}' {{Is}} a {{Mandate}} for {{Humans}}, {{Not Just Machines}} | {{WIRED}}},
  url = {http://www.wired.com/2015/05/andrew-ng-deep-learning-mandate-humans-not-just-machines/},
  timestamp = {2017-05-19T07:25:19Z},
  author = {Garling, Caleb},
  urldate = {2015-07-09},
  date = {2015}
}

@article{Flynn_2015,
  title = {{{DeepStereo}}: {{Learning}} to {{Predict New Views}} from the {{World}}'s {{Imagery}}},
  url = {http://arxiv.org/abs/1506.06825},
  shorttitle = {{{DeepStereo}}},
  abstract = {Deep networks have recently enjoyed enormous success when applied to recognition and classification problems in computer vision, but their use in graphics problems has been limited. In this work, we present a novel deep architecture that performs new view synthesis directly from pixels, trained from a large number of posed image sets. In contrast to traditional approaches which consist of multiple complex stages of processing, each of which require careful tuning and can fail in unexpected ways, our system is trained end-to-end. The pixels from neighboring views of a scene are presented to the network which then directly produces the pixels of the unseen view. The benefits of our approach include generality (we only require posed image sets and can easily apply our method to different domains), and high quality results on traditionally difficult scenes. We believe this is due to the end-to-end nature of our system which is able to plausibly generate pixels according to color, depth, and texture priors learnt automatically from the training data. To verify our method we show that it can convincingly reproduce known test views from nearby imagery. Additionally we show images rendered from novel viewpoints. To our knowledge, our work is the first to apply deep learning to the problem of new view synthesis from sets of real-world, natural imagery.},
  timestamp = {2017-05-19T07:25:19Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.06825},
  author = {Flynn, John and Neulander, Ivan and Philbin, James and Snavely, Noah},
  urldate = {2015-07-09},
  date = {2015-06-22},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@inproceedings{Tanenbaum_2014,
  title = {Critical {{Making Hackathon}}: {{Situated Hacking}}, {{Surveillance}} and {{Big Data Proposal}}},
  url = {http://dl.acm.org/citation.cfm?id=2560476},
  shorttitle = {Critical {{Making Hackathon}}},
  timestamp = {2017-05-19T07:25:19Z},
  booktitle = {{{CHI}}'14 {{Extended Abstracts}} on {{Human Factors}} in {{Computing Systems}}},
  publisher = {{ACM}},
  author = {Tanenbaum, Karen and Tanenbaum, Joshua G. and Williams, Amanda M. and Ratto, Matt and Resch, Gabriel and Gamba Bari, Antonio},
  urldate = {2015-07-22},
  date = {2014},
  pages = {17--20}
}

@article{Wylie_2014,
  title = {Institutions for {{Civic Technoscience}}: {{How Critical Making Is Transforming Environmental Research}}},
  volume = {30},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01972243.2014.875783},
  shorttitle = {Institutions for {{Civic Technoscience}}},
  timestamp = {2017-05-19T07:25:19Z},
  number = {2},
  author = {Wylie, Sara Ann and Jalbert, Kirk and Dosemagen, Shannon and Ratto, Matt},
  urldate = {2015-07-22},
  date = {2014},
  pages = {116--126}
}

@inproceedings{Record_2013,
  title = {{{DIY Prosthetics Workshops}}:‘{{Critical Making}}’for {{Public Understanding}} of {{Human Augmentation}}},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6613110},
  shorttitle = {{{DIY Prosthetics Workshops}}},
  timestamp = {2017-05-19T07:25:19Z},
  booktitle = {Technology and {{Society}} ({{ISTAS}}), 2013 {{IEEE International Symposium On}}},
  publisher = {{IEEE}},
  author = {Record, Isaac and Ratto, Matt and Ratelle, Amy and Ieraci, Adriana and Czegledy, Nina},
  urldate = {2015-07-22},
  date = {2013},
  pages = {117--125}
}

@article{Mellon_2013,
  title = {Where and {{When Can We Use Google Trends}} to {{Measure Issue Salience}}?},
  volume = {46},
  issn = {1537-5935},
  url = {http://journals.cambridge.org/article_S1049096513000279},
  doi = {10.1017/S1049096513000279},
  abstract = {Google search data have several major advantages over traditional survey data. First, the high costs of running frequent surveys mean that most survey questions are only asked occasionally making comparisons over time difficult. By contrast, Google Trends provides information on search trends measured weekly. Second, there are many countries where surveys are only conducted sporadically, whereas Google search data are available anywhere in the world where sufficient numbers of people use its search engine. The Google Trends website allows researchers to download data for almost all countries at no cost and to download time series of any search term's popularity over time (provided enough people have searched for it). For these reasons, Google Trends is an attractive data source for social scientists.},
  timestamp = {2017-05-19T07:25:19Z},
  issue = {02},
  author = {Mellon, Jonathan},
  urldate = {2015-07-23},
  date = {2013-04},
  pages = {280--290}
}

@article{Cleveland_1992,
  title = {Local {{Regression Models}}},
  url = {ftp://www.cs.bell-labs.com/cm/stat/doc/smoothing_econhb.ps},
  timestamp = {2017-05-19T07:25:20Z},
  author = {Cleveland, William S. and Grosse, Eric and Shyu, William M.},
  urldate = {2015-07-24},
  date = {1992},
  pages = {309--376}
}

@article{Graves_2013,
  title = {Generating {{Sequences With Recurrent Neural Networks}}},
  url = {http://arxiv.org/abs/1308.0850},
  abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
  timestamp = {2017-05-19T07:25:20Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1308.0850},
  author = {Graves, Alex},
  urldate = {2015-07-24},
  date = {2013-08-04},
  keywords = {Computer Science - Computation and Language,Computer Science - Neural and Evolutionary Computing}
}

@book{Pickering_2009,
  location = {{Chicago ; London}},
  title = {The {{Cybernetic Brain}}},
  url = {http://www.press.uchicago.edu/ucp/books/book/chicago/C/bo8169881.html},
  abstract = {\$$<$\$div\$$>$\$\$$<$\$/div\$$>$\$Cybernetics is often thought of as a grim military or industrial science of control. But as Andrew Pickering reveals in this beguiling book, a much more lively and experimental strain of cybernetics can be traced from the 1940s to the present.\$$<$\$br\$$>$\$\$$<$\$br\$$>$\$$\backslash$emphThe Cybernetic Brain explores a largely forgotten group of British thinkers, including Grey Walter, Ross Ashby, Gregory Bateson, R. D. Laing, Stafford Beer, and Gordon Pask, and their singular work in a dazzling array of fields. Psychiatry, engineering, management, politics, music, architecture, education, tantric yoga, the Beats, and the sixties counterculture all come into play as Pickering follows the history of cybernetics’ impact on the world, from contemporary robotics and complexity theory to the Chilean economy under Salvador Allende. What underpins this fascinating history, Pickering contends, is a shared but unconventional vision of the world as ultimately unknowable, a place where genuine novelty is always emerging. And thus, Pickering avers, the history of cybernetics provides us with an imaginative model of open-ended experimentation in stark opposition to the modern urge to achieve domination over nature and each other.},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{University Of Chicago Press}},
  author = {Pickering, Andrew},
  urldate = {2015-07-27},
  date = {2009}
}

@book{Golumbia_2009,
  location = {{Cambridge, Mass}},
  title = {The {{Cultural Logic}} of {{Computation}}},
  isbn = {978-0-674-03292-7},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{Harvard University Press}},
  author = {Golumbia, David},
  date = {2009-04-17}
}

@incollection{Gillespie_2014,
  location = {{Cambridge, MA}},
  title = {The {{Relevance}} of {{Algorithms}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=zeK2AgAAQBAJ&oi=fnd&pg=PA167&dq=gillespie+tarleton&ots=GmjJQZ-2ue&sig=Omo2OeadgqNvz17IupCqELPagdg},
  timestamp = {2017-05-19T07:25:20Z},
  booktitle = {Media {{Technologies}}: {{Essays}} on {{Communication}}, {{Materiality}}, and {{Society}}},
  publisher = {{MIT Press}},
  author = {Gillespie, Tarleton},
  editor = {Gillespie, Tarleton and Boczkowski, Pablo and Foot, Kirsten A.},
  urldate = {2015-08-04},
  date = {2014},
  pages = {167--194}
}

@book{Aristotle_1981,
  location = {{Hammondsworth, UK}},
  title = {Nicomachean {{Ethics}}},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{Penguin Books}},
  author = {{Aristotle}},
  date = {1981}
}

@book{Jockers_2013,
  location = {{Urbana}},
  title = {Macroanalysis: {{Digital Methods}} and {{Literary History}}},
  isbn = {978-0-252-07907-8},
  shorttitle = {Macroanalysis},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{University of Illinois Press}},
  author = {Jockers, Matthew L.},
  date = {2013}
}

@inproceedings{Pasquinelli_2015,
  location = {{Berlin}},
  title = {Anomaly {{Detection}}: {{The Mathematization}} of the {{Abnormal}} in the {{Metadata Society}}},
  url = {https://www.academia.edu/10369819/Anomaly_Detection_The_Mathematization_of_the_Abnormal_in_the_Metadata_Society},
  shorttitle = {Anomaly {{Detection}}},
  abstract = {Anomaly Detection: The Mathematization of the Abnormal in the Metadata Society},
  timestamp = {2017-05-19T07:25:20Z},
  author = {Pasquinelli, Matteo},
  urldate = {2015-09-01},
  date = {2015-01-28}
}

@book{Morton_2013,
  title = {Hyperobjects: {{Philosophy}} and {{Ecology After}} the {{End}} of the {{World}}},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{Univ Of Minnesota Press}},
  author = {Morton, Timothy},
  date = {2013}
}

@online{Muenchen_2014,
  title = {The {{Popularity}} of {{Data Analysis Software}}},
  url = {http://r4stats.com/articles/popularity/},
  abstract = {by Robert A. Muenchen Abstract: This article presents various ways of measuring the popularity or market share of software for advanced analytics software including: Alpine, Alteryx, Angoss, C / C+...},
  timestamp = {2017-05-19T07:25:20Z},
  author = {Muenchen, Robert A.},
  urldate = {2015-09-02},
  date = {2014}
}

@article{Lee_1999,
  title = {Learning the {{Parts}} of {{Objects}} by {{Non}}-{{Negative Matrix Factorization}}},
  volume = {401},
  issn = {0028-0836},
  doi = {10.1038/44565},
  abstract = {Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
  timestamp = {2017-05-19T07:25:20Z},
  number = {6755},
  author = {Lee, D. D. and Seung, H. S.},
  date = {1999-10-21},
  pages = {788--791},
  keywords = {algorithms,Face,Humans,learning,Models,Neurological,perception,Semantics}
}

@article{Seaver_2015,
  title = {The {{Nice Thing}} about {{Context Is That Everyone Has It}}},
  volume = {37},
  issn = {0163-4437, 1460-3675},
  url = {http://mcs.sagepub.com.ezproxy.lancs.ac.uk/content/37/7/1101},
  doi = {10.1177/0163443715594102},
  abstract = {In their ‘Critical Questions for Big Data’, danah boyd and Kate Crawford warn: ‘Taken out of context, Big Data loses its meaning’. In this short commentary, I contextualize this claim about context. The idea that context is crucial to meaning is shared across a wide range of disciplines, including the field of ‘context-aware’ recommender systems. These personalization systems attempt to take a user’s context into account in order to make better, more useful, more meaningful recommendations. How are we to square boyd and Crawford’s warning with the growth of big data applications that are centrally concerned with something they call ‘context’? I suggest that the importance of context is uncontroversial; the controversy lies in determining what context is. Drawing on the work of cultural and linguistic anthropologists, I argue that context is constructed by the methods used to apprehend it. For the developers of ‘context-aware’ recommender systems, context is typically operationalized as a set of sensor readings associated with a user’s activity. For critics like boyd and Crawford, context is that unquantified remainder that haunts mathematical models, making numbers that appear to be identical actually different from each other. These understandings of context seem to be incompatible, and their variability points to the importance of identifying and studying ‘context cultures’–ways of producing context that vary in goals and techniques, but which agree that context is key to data’s significance. To do otherwise would be to take these contextualizations out of context.},
  timestamp = {2017-05-19T07:25:20Z},
  number = {7},
  author = {Seaver, Nick},
  urldate = {2015-09-24},
  date = {2015-10-01},
  pages = {1101--1109},
  keywords = {algorithms,big data,context,cultural anthropology,recommender systems}
}

@article{Cranor_1998,
  title = {Spam!},
  volume = {41},
  url = {http://dl.acm.org/citation.cfm?id=280336},
  timestamp = {2017-05-19T07:25:20Z},
  number = {8},
  author = {Cranor, Lorrie Faith and LaMacchia, Brian A.},
  urldate = {2015-09-11},
  date = {1998},
  pages = {74--83}
}

@book{Harman_2002,
  title = {Tool-{{Being}}: {{Heidegger}} and the {{Metaphysics}} of {{Objects}}},
  isbn = {978-0-8126-9444-4},
  shorttitle = {Tool-{{Being}}},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{Open Court Publishing}},
  author = {Harman, Graham},
  date = {2002-10-01}
}

@article{Gardy_2011,
  title = {Whole-{{Genome Sequencing}} and {{Social}}-{{Network Analysis}} of a {{Tuberculosis Outbreak}}},
  volume = {364},
  issn = {0028-4793},
  url = {http://www.nejm.org/doi/full/10.1056/NEJMoa1003176},
  doi = {10.1056/NEJMoa1003176},
  timestamp = {2017-05-19T07:25:20Z},
  number = {8},
  author = {Gardy, Jennifer L. and Johnston, James C. and Sui, Shannan J. Ho and Cook, Victoria J. and Shah, Lena and Brodkin, Elizabeth and Rempel, Shirley and Moore, Richard and Zhao, Yongjun and Holt, Robert and Varhol, Richard and Birol, Inanc and Lem, Marcus and Sharma, Meenu K. and Elwood, Kevin and Jones, Steven J.M. and Brinkman, Fiona S.L. and Brunham, Robert C. and Tang, Patrick},
  urldate = {2011-07-25},
  date = {2011-02},
  pages = {730--739}
}

@book{Husserl_1970,
  location = {{Chicago, Ill.}},
  title = {Crisis of {{European Sciences}} and {{Transcendental Phenomenology}}},
  timestamp = {2017-05-19T07:25:20Z},
  publisher = {{Northwestern University Press}},
  author = {Husserl, E.},
  date = {1970}
}

@online{_e,
  title = {Machines {{That Learn}} in the {{Wild}}: {{Machine Learning Capabilities}}, {{Limitations}} and {{Implications}} | {{Nesta}}},
  url = {http://www.nesta.org.uk/publications/machines-learn-wild-machine-learning-capabilities-limitations-and-implications},
  shorttitle = {Machines {{That Learn}} in the {{Wild}}},
  abstract = {This report explores the current capabilities and limitations of machine learning algorithms and looks at future challenges.},
  timestamp = {2017-05-19T07:25:20Z},
  urldate = {2016-03-08}
}

@article{Gutig_2016,
  title = {Spiking {{Neurons Can Discover Predictive Features}} by {{Aggregate}}-{{Label Learning}}},
  volume = {351},
  issn = {1095-9203},
  doi = {10.1126/science.aab4113},
  abstract = {The brain routinely discovers sensory clues that predict opportunities or dangers. However, it is unclear how neural learning processes can bridge the typically long delays between sensory clues and behavioral outcomes. Here, I introduce a learning concept, aggregate-label learning, that enables biologically plausible model neurons to solve this temporal credit assignment problem. Aggregate-label learning matches a neuron's number of output spikes to a feedback signal that is proportional to the number of clues but carries no information about their timing. Aggregate-label learning outperforms stochastic reinforcement learning at identifying predictive clues and is able to solve unsegmented speech-recognition tasks. Furthermore, it allows unsupervised neural networks to discover reoccurring constellations of sensory features even when they are widely dispersed across space and time.},
  timestamp = {2017-05-19T07:25:20Z},
  number = {6277},
  author = {Gütig, Robert},
  date = {2016-03-04},
  pages = {aab4113}
}

@article{Bauer_2008,
  title = {Mining {{Data}}, {{Gathering Variables}} and {{Recombining Information}}: {{The Flexible Architecture}} of {{Epidemiological Studies}}},
  volume = {39},
  issn = {1369-8486},
  url = {http://www.sciencedirect.com/science/article/pii/S1369848608000721},
  doi = {10.1016/j.shpsc.2008.09.008},
  shorttitle = {Mining {{Data}}, {{Gathering Variables}} and {{Recombining Information}}},
  abstract = {Since the second half of the twentieth century, biomedical research has made increasing use of epidemiological methods to establish empirical evidence on a population level. This paper is about practices with data in epidemiological research, based on a case study in Denmark. I propose an epistemology of record linkage that invites exploration of epidemiological studies as heterogeneous assemblages. Focusing on data collecting, sampling and linkage, I examine how data organisation and processing become productive beyond the context of their collection. The case study looks at how a local population database established in 1976 to investigate possibilities for the prevention of cardiovascular disease is used thirty years later to test hypotheses on the aetiology of breast cancer. For two breast cancer investigations based on the same core data set, I follow the underlying record linkage practice and describe how research objects such as molecular markers become relevant with respect to public health through information networking. Epidemiological association studies function as tools that performatively enrol different contexts into statistical risk estimation, thereby configuring options for research as well as for clinical testing and public health policy.},
  timestamp = {2017-05-19T07:25:20Z},
  number = {4},
  author = {Bauer, Susanne},
  urldate = {2011-11-02},
  date = {2008-12},
  pages = {415--428},
  keywords = {Biobanks,Breast cancer aetiology,Collecting,Data Mining,Population registries,Risk factor epidemiology}
}

@article{Read_2008,
  title = {Dynamic {{Social Networks}} and the {{Implications}} for the {{Spread}} of {{Infectious Disease}}},
  volume = {5},
  issn = {1742-5689},
  doi = {10.1098/rsif.2008.0013},
  abstract = {Understanding the nature of human contact patterns is crucial for predicting the impact of future pandemics and devising effective control measures. However, few studies provide a quantitative description of the aspects of social interactions that are most relevant to disease transmission. Here, we present the results from a detailed diary-based survey of casual (conversational) and close contact (physical) encounters made by a small peer group of 49 adults who recorded 8,661 encounters with 3,528 different individuals over 14 non-consecutive days. We find that the stability of interactions depends on the intimacy of contact and social context. Casual contact encounters mostly occur in the workplace and are predominantly irregular, while close contact encounters mostly occur at home or in social situations and tend to be more stable. Simulated epidemics of casual contact transmission involve a large number of non-repeated encounters, and the social network is well captured by a random mixing model. However, the stability of the social network should be taken into account for close contact infections. Our findings have implications for the modelling of human epidemics and planning pandemic control policies based on social distancing methods.},
  timestamp = {2017-05-19T07:25:21Z},
  number = {26},
  author = {Read, Jonathan M and Eames, Ken T D and Edmunds, W John},
  date = {2008-09-06},
  pages = {1001--1007},
  keywords = {Adult,Biological,Communicable Diseases,Contact Tracing,Disease Outbreaks,Disease Transmission,Infectious,Models,Social Support}
}

@article{Ross_1917,
  title = {An {{Application}} of the {{Theory}} of {{Probabilities}} to the {{Study}} of a {{Priori Pathometry}}. {{Part II}}},
  volume = {93},
  timestamp = {2017-05-19T07:25:21Z},
  number = {650},
  author = {Ross, Ronald and Hudson, H.P.},
  date = {1917},
  pages = {212--225}
}

@online{Organisation_2009,
  title = {{{WHO}} | {{Pandemic}} ({{H1N1}}) 2009 - {{Update}} 103},
  url = {http://www.who.int/csr/don/2010_06_04/en/index.html},
  timestamp = {2017-05-19T07:25:21Z},
  author = {Organisation, World Health},
  urldate = {2012-01-17},
  date = {2009}
}

@article{Kermack_1932,
  title = {Contributions to the {{Mathematical Theory}} of {{Epidemics}}. {{II}}. {{The Problem}} of {{Endemicity}}},
  volume = {138},
  url = {http://rspa.royalsocietypublishing.org/content/138/834/55.short},
  doi = {10.1098/rspa.1932.0171},
  timestamp = {2017-05-19T07:25:21Z},
  number = {834},
  author = {Kermack, W. O. and McKendrick, A. G.},
  urldate = {2012-01-19},
  date = {1932-10-01},
  pages = {55 --83}
}

@book{Keeling_2008,
  title = {Modeling {{Infectious Diseases}} in {{Humans}} and {{Animals}}},
  timestamp = {2017-05-19T07:25:21Z},
  publisher = {{Princeton Univ Pr}},
  author = {Keeling, M.J. and Rohani, P.},
  date = {2008}
}

@book{Anderson_1992,
  title = {Infectious {{Diseases}} of {{Humans}}: {{Dynamics}} and {{Control}}},
  volume = {26},
  shorttitle = {Infectious {{Diseases}} of {{Humans}}},
  timestamp = {2017-05-19T07:25:21Z},
  publisher = {{Wiley Online Library}},
  author = {Anderson, R.M. and May, R.M.},
  date = {1992}
}

@article{Hardy_2002,
  title = {Statistical {{Methods}} in {{Epidemiology}}: {{Karl Pearson}}, {{Ronald Ross}}, {{Major Greenwood}} and {{Austin Bradford Hill}}, 1900–1945},
  volume = {47},
  shorttitle = {Statistical {{Methods}} in {{Epidemiology}}},
  timestamp = {2017-05-19T07:25:21Z},
  number = {2},
  author = {Hardy, A. and Magnello, M.E.},
  date = {2002},
  pages = {80--89}
}

@article{Ross_1916,
  title = {An {{Application}} of the {{Theory}} of {{Probabilities}} to the {{Study}} of a {{Priori Pathometry}}. {{Part I}}},
  volume = {92},
  timestamp = {2017-05-19T07:25:21Z},
  number = {638},
  author = {Ross, Ronald},
  date = {1916},
  pages = {204}
}

@article{House_2011,
  title = {Modelling {{Behavioural Contagion}}},
  volume = {8},
  url = {http://rsif.royalsocietypublishing.org/content/8/59/909.abstract},
  doi = {10.1098/rsif.2011.0014},
  abstract = {The last decade has seen much work on quantitative understanding of human behaviour, with online social interaction offering the possibility of more precise measurement of behavioural phenomena than was previously possible. A parsimonious model is proposed that incorporates several observed features of behavioural contagion not seen in existing epidemic model schemes, leading to metastable behavioural dynamics.},
  timestamp = {2017-05-19T07:25:21Z},
  number = {59},
  author = {House, Thomas},
  urldate = {2012-01-19},
  date = {2011-06-06},
  pages = {909 --912}
}

@book{Ellner_2006,
  location = {{Princeton}},
  title = {Dynamic {{Models}} in {{Biology}}},
  volume = {13},
  timestamp = {2017-05-19T07:25:21Z},
  publisher = {{Princeton Univ Pr}},
  author = {Ellner, S.P. and Guckenheimer, J.},
  date = {2006}
}

@article{Kermack_1927,
  title = {A {{Contribution}} to the {{Mathematical Theory}} of {{Epidemics}}},
  volume = {115},
  url = {http://rspa.royalsocietypublishing.org/content/115/772/700.short},
  doi = {10.1098/rspa.1927.0118},
  timestamp = {2017-05-19T07:25:21Z},
  number = {772},
  author = {Kermack, W. O. and McKendrick, A. G.},
  urldate = {2012-01-19},
  date = {1927},
  pages = {700 --721}
}

@article{Funk_2010,
  title = {Modelling the {{Influence}} of {{Human Behaviour}} on the {{Spread}} of {{Infectious Diseases}}: {{A Review}}},
  volume = {7},
  url = {http://rsif.royalsocietypublishing.org/content/7/50/1247.abstract},
  doi = {10.1098/rsif.2010.0142},
  shorttitle = {Modelling the {{Influence}} of {{Human Behaviour}} on the {{Spread}} of {{Infectious Diseases}}},
  abstract = {Human behaviour plays an important role in the spread of infectious diseases, and understanding the influence of behaviour on the spread of diseases can be key to improving control efforts. While behavioural responses to the spread of a disease have often been reported anecdotally, there has been relatively little systematic investigation into how behavioural changes can affect disease dynamics. Mathematical models for the spread of infectious diseases are an important tool for investigating and quantifying such effects, not least because the spread of a disease among humans is not amenable to direct experimental study. Here, we review recent efforts to incorporate human behaviour into disease models, and propose that such models can be broadly classified according to the type and source of information which individuals are assumed to base their behaviour on, and according to the assumed effects of such behaviour. We highlight recent advances as well as gaps in our understanding of the interplay between infectious disease dynamics and human behaviour, and suggest what kind of data taking efforts would be helpful in filling these gaps.},
  timestamp = {2017-05-19T07:25:21Z},
  number = {50},
  author = {Funk, Sebastian and Salathé, Marcel and Jansen, Vincent A. A.},
  urldate = {2012-01-19},
  date = {2010},
  pages = {1247 --1256}
}

@article{Mossong_2008,
  title = {Social {{Contacts}} and {{Mixing Patterns Relevant}} to the {{Spread}} of {{Infectious Diseases}}},
  volume = {5},
  timestamp = {2017-05-19T07:25:21Z},
  number = {3},
  author = {Mossong, J. and Hens, N. and Jit, M. and Beutels, P. and Auranen, K. and Mikolajczyk, R. and Massari, M. and Salmaso, S. and Tomba, G.S. and Wallinga, J. and {others}},
  date = {2008},
  pages = {e74}
}

@article{Fisher_1922,
  title = {On the {{Mathematical Foundations}} of {{Theoretical Statistics}}},
  volume = {222},
  url = {http://digital.library.adelaide.edu.au/dspace/handle/2440/15172},
  doi = {10.1098/rsta.1922.0009},
  timestamp = {2017-05-19T07:25:21Z},
  issue = {594–604},
  author = {Fisher, \&\#32;R. A},
  date = {1922},
  pages = {309--368}
}

@online{Wikipedia_2012,
  title = {Likelihood {{Function}} - {{Wikipedia}}, the {{Free Encyclopedia}}},
  url = {http://en.wikipedia.org/wiki/Likelihood_function},
  timestamp = {2017-05-19T07:25:21Z},
  author = {{Wikipedia}},
  urldate = {2012-01-23},
  date = {2012}
}

@article{Wearing_2005,
  title = {Appropriate {{Models}} for the {{Management}} of {{Infectious Diseases}}},
  volume = {2},
  timestamp = {2017-05-19T07:25:21Z},
  number = {7},
  author = {Wearing, H.J. and Rohani, P. and Keeling, M.J.},
  date = {2005},
  pages = {e174}
}

@article{Prior_2011,
  title = {Talking about {{Colds}} and {{Flu}}: {{The Lay Diagnosis}} of {{Two Common Illnesses}} among {{Older British People}}},
  volume = {73},
  issn = {0277-9536},
  doi = {10.1016/j.socscimed.2010.09.054},
  shorttitle = {Talking about {{Colds}} and {{Flu}}},
  abstract = {This paper reports on a study of the ways in which 54 older people in South Wales (UK) talk about the symptoms and causes of cold and influenza (flu). The study was designed to understand why older people might reject or accept the offer of seasonal flu vaccine, and in the course of the interviews respondents were also asked to express their views about the nature and causes of the two key illnesses. The latter are among the most common infections in human beings. In terms of the biomedical paradigm the common cold is caused by numerous respiratory viruses, whilst flu is caused by the influenza virus. Medical diagnosis is usually made on clinical grounds without laboratory confirmation. Symptoms of flu include sudden onset of fever and cough, and colds are characterized by sneezing, sore throat, and runny nose, but in practice the symptoms often overlap. In this study we examine the degree by which the views of lay people with respect to both diagnosis and epidemiology diverge with that which is evident in biomedical discourse. Our results indicate that whilst most of the identified symptoms are common to lay and professional people, the former integrate symptoms into a markedly different observational frame from the latter. And as far as causation is concerned it is clear that lay people emphasize the role of 'resistance' and 'immunity' at least as much as 'infection' in accounting for the onset of colds and flu. The data are analyzed using novel methods that focus on the co-occurrence of concepts and are displayed as semantic networks. As well as reporting on its findings the authors draw out some implications of the study for social scientific and policy discussions concerning lay diagnosis, lay expertise and the concept of an expert patient. (C) 2010 Elsevier Ltd. All rights reserved.},
  timestamp = {2017-05-19T07:25:22Z},
  number = {6},
  author = {Prior, Lindsay and Evans, Meirion R. and Prout, Hayley},
  date = {2011-09},
  pages = {922--928},
  keywords = {care,Colds and Influenza,Co-occurrence relations,cross-cultural perspectives,Expert patients,influenza,Lay diagnosis,Lay expertise,patient}
}

@article{Stephenson_2009,
  title = {Securitising {{Health}}: {{Australian Newspaper Coverage}} of {{Pandemic Influenza}}},
  volume = {31},
  issn = {0141-9889},
  doi = {10.1111/j.1467-9566.2009.01162.x},
  shorttitle = {Securitising {{Health}}},
  abstract = {This paper analyses contemporary Australian newspaper coverage of the threat of pandemic influenza in humans, specifically in the light of recent transformations in biomedical and public health understandings of infectious disease as continuously emerging. Our analysis suggests that the spectre of pandemic influenza is characterised, in newspaper accounts, as invoking a specific form of nation building. The Australian nation is depicted as successfully securing itself in the face of a threat from Asia (and in the absence of an effective international health body). What is described in newspaper accounts reflects a shift in the public health response to infectious disease. This response does not entail a direct focus on protecting either the population or national territory. Instead, it involves the continuous rehearsal of readiness to react to disasters through the networking of government and private agencies responsible for maintaining critical infrastructure. In this way, coverage of pandemic influenza positions health as central to national security, with little reporting of the reasons for or the potential implications of this alliance. Thus, the imperative to 'be prepared' is presented as self-evident.},
  timestamp = {2017-05-19T07:25:22Z},
  number = {4},
  author = {Stephenson, Niamh and Jamieson, Michelle},
  date = {2009-05},
  pages = {525--539},
  keywords = {diseases,emerging infectious disease,epidemic,media,national,pandemic influenza,preparedness,sars,securitisation of health,transnational,virus samples}
}

@book{Kunitz_2007,
  title = {The {{Health}} of {{Populations}}: {{General Theories}} and {{Particular Realities}}},
  isbn = {978-0-19-530807-5},
  shorttitle = {The {{Health}} of {{Populations}}},
  abstract = {In the maelstrom of current public health debate over the social determinants of health, this book offers a well-balanced discussion on the roots of prevalent strains of thought on the matter. While this area of research deals in complex problems, it is often dominated by those who deploy rather categorical, partisan positions, citing from a wide range of contradictory statistical studies. Stephen Kunitz brings a measured, balanced and independent perspective to bear on the debate, taking a step back from current arguments to look at the fundamental issues through a socio-historical lens. Part I describes how ideas about the costs and benefits of industrialization, and about the causes of disease, have been used by writers from different ideological persuasions to explain the health of populations. Part II focuses on some of the ideas that have been particularly influential in contemporary debates: factors such as standard of living, community and its loss, inequality, and globalization. The fact that these have been used to support differing explanations of the determinants of population health suggests that there are no easy generalizations in a field with so many discrepant findings. Scientists often ignore anomalous findings in the interests of advancing a particular paradigm, until the anomalies outweigh the norm and a new paradigm is created. This book argues that in considering social determinants of health, no meaningful over-arching explanations may be possible. Rather, it is by immersion in the reality of particular contexts - work settings, historical periods, geopolitical regions, and governmental credos - that we may gain a better understanding of the way in which social forces shape patterns of health and disease.},
  timestamp = {2017-05-19T07:25:22Z},
  publisher = {{Oxford University Press}},
  author = {Kunitz, Stephen J.},
  date = {2007},
  keywords = {Business & Economics / Development / General,Culture,Epidemiology,Industrialization,Industrialization - Health aspects,Medical / Epidemiology,Medical / General,Medical / Health Care Delivery,Medical / History,Medical / Public Health,Population,Public Health,Public health - Economic aspects,Public health/ Economic aspects,Public health - History,Public health/ History,Public health - Social aspects,Public health/ Social aspects,Social Environment,Social Science / Anthropology / Cultural,Social Science / Demography}
}

@article{Baguelin_2010,
  title = {Vaccination against {{Pandemic Influenza A}}/{{H1N1v}} in {{England}}: {{A Real}}-{{Time Economic Evaluation}}},
  volume = {28},
  shorttitle = {Vaccination against {{Pandemic Influenza A}}/{{H1N1v}} in {{England}}},
  timestamp = {2017-05-19T07:25:22Z},
  number = {12},
  author = {Baguelin, M. and Hoek, A.J.V. and Jit, M. and Flasche, S. and White, P.J. and Edmunds, W.J.},
  date = {2010},
  pages = {2370--2384}
}

@article{Miller_2010,
  title = {Incidence of 2009 {{Pandemic Influenza A H1N1 Infection}} in {{England}}: {{A Cross}}-{{Sectional Serological Study}}},
  volume = {375},
  shorttitle = {Incidence of 2009 {{Pandemic Influenza A H1N1 Infection}} in {{England}}},
  timestamp = {2017-05-19T07:25:22Z},
  number = {9720},
  author = {Miller, E. and Hoschler, K. and Hardelid, P. and Stanford, E. and Andrews, N. and Zambon, M.},
  date = {2010},
  pages = {1100--1108}
}

@article{Baguelin_2011,
  title = {Age-{{Specific Incidence}} of {{A}}/{{H1N1}} 2009 {{Influenza Infection}} in {{England}} from {{Sequential Antibody Prevalence Data Using Likelihood}}-{{Based Estimation}}},
  volume = {6},
  timestamp = {2017-05-19T07:25:22Z},
  number = {2},
  author = {Baguelin, M. and Hoschler, K. and Stanford, E. and Waight, P. and Hardelid, P. and Andrews, N. and Miller, E.},
  date = {2011},
  pages = {e17074}
}

@article{Prosser_2011,
  title = {Cost-{{Effectiveness}} of 2009 {{Pandemic Influenza A}} ({{H1N1}}) {{Vaccination}} in the {{United States}}},
  volume = {6},
  timestamp = {2017-05-19T07:25:22Z},
  number = {7},
  author = {Prosser, L.A. and Lavelle, T.A. and Fiore, A.E. and Bridges, C.B. and Reed, C. and Jain, S. and Dunham, K.M. and Meltzer, M.I.},
  date = {2011},
  pages = {e22308}
}

@online{HPA_2012,
  title = {{{HPA}} - {{What}} the {{Health Protection Agency Does}}},
  url = {http://www.hpa.org.uk/AboutTheHPA/WhatTheHealthProtectionAgencyDoes/},
  timestamp = {2017-05-19T07:25:22Z},
  author = {{HPA}},
  urldate = {2012-02-10},
  date = {2012}
}

@article{Merl_2009,
  title = {A {{Statistical Framework}} for the {{Adaptive Management}} of {{Epidemiological Interventions}}},
  volume = {4},
  url = {UR - http://dx.doi.org/10.1371/journal.pone.0005807,http://dx.doi.org/10.1371/journal.pone.0005807},
  doi = {10.1371/journal.pone.0005807},
  abstract = {Epidemiological interventions aim to control the spread of infectious disease through various mechanisms, each carrying a different associated cost. We describe a flexible statistical framework for generating optimal epidemiological interventions that are designed to minimize the total expected cost of an emerging epidemic while simultaneously propagating uncertainty regarding the underlying disease model parameters through to the decision process. The strategies produced through this framework are adaptive: vaccination schedules are iteratively adjusted to reflect the anticipated trajectory of the epidemic given the current population state and updated parameter estimates. Using simulation studies based on a classic influenza outbreak, we demonstrate the advantages of adaptive interventions over non-adaptive ones, in terms of cost and resource efficiency, and robustness to model misspecification.},
  timestamp = {2017-05-19T07:25:22Z},
  number = {6},
  author = {Merl, Daniel and Johnson, Leah R. and Gramacy, Robert B. and Mangel, Marc},
  urldate = {2012-02-22},
  date = {2009-06-05},
  pages = {e5807}
}

@online{_f,
  title = {{{CRAN}} - {{Package Amei}}},
  url = {http://cran.r-project.org/web/packages/amei/index.html},
  timestamp = {2017-05-19T07:25:22Z},
  urldate = {2012-02-22}
}

@article{Munster_2011,
  title = {Nerves of {{Data}}: {{The Neurological Turn}} in/against {{Networked Media}} : {{Computational Culture}}},
  volume = {1},
  url = {http://computationalculture.net/article/nerves-of-data},
  timestamp = {2017-05-19T07:25:22Z},
  number = {1},
  author = {Munster, Anna},
  urldate = {2012-03-09},
  date = {2011}
}

@article{Mitchell_2010,
  title = {The {{Grill}}: {{Tom Mitchell}}},
  url = {http://www.computerworld.com/s/article/346917/The_Grill_Tom_Mitchell},
  shorttitle = {The {{Grill}}},
  timestamp = {2017-05-19T07:25:22Z},
  author = {Mitchell, Tom},
  urldate = {2012-03-09},
  year = {2010-02-22T06:00-05:00}
}

@article{Golub_1999,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}}},
  volume = {286},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  timestamp = {2017-05-19T07:25:22Z},
  number = {5439},
  author = {Golub, TR and Slonim, DK and Tamayo, P. and Huard, C. and Gassenbeck, M. and Mesirov, JP and Coller, H. and Loh, ML and Downing, JR and Caligiuri, MA and {others}},
  date = {1999},
  pages = {531--537}
}

@online{_g,
  title = {The {{Company}} for {{Apache Lucene Solr Open Source Search}} | {{Lucid Imagination}}},
  url = {http://www.lucidimagination.com/},
  timestamp = {2017-05-19T07:25:22Z},
  urldate = {2012-03-15}
}

@book{Clarke_2010,
  title = {Information {{Retrieval}}: {{Implementing}} and {{Evaluating Search Engines}}},
  isbn = {0-262-02651-1},
  shorttitle = {Information {{Retrieval}}},
  timestamp = {2017-05-19T07:25:22Z},
  publisher = {{The MIT Press}},
  author = {Clarke, Charles L. A. and Buettcher, Stefan and Cormack, Gordon V.},
  date = {2010-07-23}
}

@article{Ensmenger_2012,
  title = {Is {{Chess}} the {{Drosophila}} of {{Artificial Intelligence}}? {{A Social History}} of an {{Algorithm}}},
  volume = {42},
  issn = {0306-3127, 1460-3659},
  url = {http://sss.sagepub.com.ezproxy.lancs.ac.uk/content/42/1/5},
  doi = {10.1177/0306312711424596},
  shorttitle = {Is {{Chess}} the {{Drosophila}} of {{Artificial Intelligence}}?},
  abstract = {Since the mid 1960s, researchers in computer science have famously referred to chess as the ‘drosophila’ of artificial intelligence (AI). What they seem to mean by this is that chess, like the common fruit fly, is an accessible, familiar, and relatively simple experimental technology that nonetheless can be used productively to produce valid knowledge about other, more complex systems. But for historians of science and technology, the analogy between chess and drosophila assumes a larger significance. As Robert Kohler has ably described, the decision to adopt drosophila as the organism of choice for genetics research had far-reaching implications for the development of 20th century biology. In a similar manner, the decision to focus on chess as the measure of both human and computer intelligence had important and unintended consequences for AI research. This paper explores the emergence of chess as an experimental technology, its significance in the developing research practices of the AI community, and the unique ways in which the decision to focus on chess shaped the program of AI research in the decade of the 1970s. More broadly, it attempts to open up the virtual black box of computer software – and of computer games in particular – to the scrutiny of historical and sociological analysis.},
  timestamp = {2017-05-19T07:25:22Z},
  number = {1},
  author = {Ensmenger, Nathan},
  urldate = {2012-05-28},
  date = {2012-02-01},
  pages = {5--30},
  keywords = {Artificial intelligence,computing,drosophila,experimental technology}
}

@book{Foucault_1992,
  location = {{London}},
  title = {The {{Order}} of {{Things}}: {{An Archaeology}} of {{Human Sciences}}},
  timestamp = {2017-05-19T07:25:23Z},
  publisher = {{Routledge}},
  author = {Foucault, Michel},
  translator = {Sheridan-Smith, Allan},
  year = {1992 [1966]}
}

@online{Mason_2012,
  title = {Hilary {{Mason}} - {{Machine Learning}} for {{Hackers}}},
  url = {http://vimeo.com/43547079},
  abstract = {Vimeo is the home for high-quality videos and the people who love them.},
  timestamp = {2017-05-19T07:25:23Z},
  author = {Mason, Hilary},
  urldate = {2012-07-06},
  date = {2012-06-06}
}

@book{Koren_2009,
  title = {Matrix {{Factorization Techniques}} for {{Recommender Systems}}},
  abstract = {As the Netflix Prize competition has demonstrated, matrix factorization models are superior to classic nearest-neighbor techniques for producing product recommendations, allowing the incorporation of additional information such as implicit feedback, temporal effects, and confidence levels. Modern consumers are inundated with choices. Electronic retailers and content providers offer a huge selection of products, with unprecedented opportunities to meet a variety of special needs and tastes. Matching consumers with the most appropriate products is key to enhancing user satisfaction and loyalty. Therefore, more retailers have become interested in recommender systems, which analyze patterns of user interest in products to provide personalized recommendations that suit a user’s taste. Because good personalized recommendations can add another dimension to the user experience, e-commerce leaders like Amazon.com and Netflix have made recommender systems a salient part of their websites. Such systems are particularly useful for entertainment products such as movies, music, and TV shows. Many customers will view the same movie, and each customer is likely to view numerous different movies. Customers have proven willing to indicate their level of satisfaction with particular movies, so a huge volume of data is available about which movies appeal to which customers. Companies can analyze this data to recommend movies to particular customers. Recommender system strategies Broadly speaking, recommender systems are based on one of two strategies. The content filtering approach creates a profile for each user or product to characterize its nature. For example, a movie profile could include attributes regarding its genre, the participating actors, its box office popularity, and so forth. User profiles might include demographic information or answers provided on a suitable questionnaire. The profiles allow programs to associate users with matching products. Of course, content-based strategies require gathering external information that might not be available or easy to collect. A known successful realization of content filtering is the Music Genome Project, which is used for the Internet radio service Pandora.com. A trained music analyst scores},
  timestamp = {2017-05-19T07:25:23Z},
  author = {Koren, Yehuda and Bell, Robert and Volinsky, Chris},
  date = {2009}
}

@online{Dataists_2012,
  title = {Dataists » {{A Taxonomy}} of {{Data Science}}},
  url = {http://www.dataists.com/2010/09/a-taxonomy-of-data-science/},
  timestamp = {2017-05-19T07:25:23Z},
  author = {{Dataists}},
  urldate = {2012-07-06},
  date = {2012}
}

@book{Peirce_1998,
  title = {The {{Essential Peirce}} - {{Volume}} 2: {{Selected Philosophical Writings}}: (1893-1913) v. 2},
  isbn = {0-253-21190-5},
  shorttitle = {The {{Essential Peirce}} - {{Volume}} 2},
  timestamp = {2017-05-19T07:25:23Z},
  publisher = {{Indiana University Press}},
  author = {Peirce, Charles Sanders},
  date = {1998}
}

@book{Peirce_1992,
  title = {The {{Essential Peirce}}: 1867-1893 v. 1: {{Selected Philosophical Writings}}},
  isbn = {0-253-20721-5},
  shorttitle = {The {{Essential Peirce}}},
  timestamp = {2017-05-19T07:25:23Z},
  publisher = {{John Wiley \& Sons}},
  author = {Peirce, Charles Sanders},
  date = {1992}
}

@article{Berlant_2007,
  title = {Nearly {{Utopian}}, {{Nearly Normal}}: {{Post}}-{{Fordist Affect}} in {{La Promesse}} and {{Rosetta}}},
  volume = {19},
  url = {http://lucian.uchicago.edu/blogs/politicalfeeling/files/2007/10/berlant-la-promesse.pdf},
  shorttitle = {Nearly {{Utopian}}, {{Nearly Normal}}},
  timestamp = {2017-05-19T07:25:23Z},
  number = {2},
  author = {Berlant, L.},
  urldate = {2012-07-09},
  date = {2007},
  pages = {273}
}

@book{Barad_2007,
  title = {Meeting the {{Universe Halfway}}: {{Quantum Physics}} and the {{Entanglement}} of {{Matter}} and {{Meaning}}},
  shorttitle = {Meeting the {{Universe Halfway}}},
  timestamp = {2017-05-19T07:25:23Z},
  publisher = {{Duke University Press Books}},
  author = {Barad, Karen},
  date = {2007}
}

@article{Langley_2011,
  title = {The {{Changing Science}} of {{Machine Learning}}},
  volume = {82},
  url = {http://www.springerlink.com/index/J067H855N8223338.pdf},
  timestamp = {2017-05-19T07:25:23Z},
  number = {3},
  author = {Langley, P.},
  urldate = {2012-06-21},
  date = {2011},
  pages = {275--279}
}

@article{Carstens_2011,
  title = {Sentiment {{Analysis}}},
  url = {http://www.doc.ic.ac.uk/teaching/distinguished-projects/2011/l.carstens.pdf},
  timestamp = {2017-05-19T07:25:23Z},
  author = {Carstens, L. and Intelligence, S. A},
  urldate = {2012-06-21},
  date = {2011}
}

@online{NIST_2012,
  title = {Gallery of {{Distributions}}},
  url = {http://www.itl.nist.gov/div898/handbook/eda/section3/eda366.htm},
  timestamp = {2017-05-19T07:25:23Z},
  author = {{NIST}},
  urldate = {2012-09-21},
  date = {2012}
}

@book{Sivia_2006,
  location = {{Oxford; New York}},
  title = {Data {{Analysis}}: {{A Bayesian Tutorial}}},
  isbn = {978-0-19-856832-2},
  shorttitle = {Data {{Analysis}}},
  abstract = {Statistics lectures have been a source of much bewilderment and frustration for generations of students. This book attempts to remedy the situation by expounding a logical and unified approach to the whole subject of data analysis. This text is intended as a tutorial guide for senior undergraduates and research students in science and engineering. After explaining the basic principles of Bayesian probability theory, their use is illustrated with a variety of examples ranging from elementary parameter estimation to image processing. Other topics covered include reliability analysis, multivariate optimization, least-squares and maximum likelihood, error-propagation, hypothesis testing, maximum entropy and experimental design. The Second Edition of this successful tutorial book contains a new chapter on extensions to the ubiquitous least-squares procedure, allowing for the straightforward handling of outliers and unknown correlated noise, and a cutting-edge contribution from John Skilling on a novel numerical technique for Bayesian computation called 'nested sampling'.},
  timestamp = {2017-05-19T07:25:23Z},
  publisher = {{Oxford University Press}},
  author = {Sivia, Devinderjit and Skilling, John},
  date = {2006},
  keywords = {Mathematics / Applied,Mathematics / Probability & Statistics / Bayesian Analysis,Mathematics / Probability & Statistics / General,Science / Physics / General}
}

@article{White_1997,
  title = {Can {{Mathematics Be Social}}? {{Flexible Representations}} for {{Interaction Process}} and {{Its Sociocultural Constructions}}},
  volume = {12},
  url = {http://www.springerlink.com/index/N6519757452H6188.pdf},
  shorttitle = {Can {{Mathematics Be Social}}?},
  timestamp = {2017-05-19T07:25:23Z},
  author = {White, H. C.},
  urldate = {2012-10-05},
  date = {1997},
  pages = {53--71}
}

@article{Holmberg_2012,
  title = {Making {{Predictions}}: {{Computing Populations}}},
  issn = {0162-2439, 1552-8251},
  url = {http://sth.sagepub.com/content/early/2012/04/27/0162243912439610},
  doi = {10.1177/0162243912439610},
  shorttitle = {Making {{Predictions}}},
  abstract = {Statistics constitute the social universe of which they are gathered. The foundation necessary to develop quantified knowledge about society is the population. If quantified knowledge changes society, the question arises on how individuals become to be represented as population. The population has to be extracted from individuals in a process that we call “populationisation.” This encompasses the development of the individual into a segment of a population through the compilation of individual data into population data and its analysis. To describe the process of populationisation, we follow a statistical risk assessment tool, the German Diabetes Risk Score, from its inception in a cohort study to its entry into the public sphere of German society. The population is extracted from individuals that function as research subjects through an identification number. Preprocessed information is entered into a dynamic database that enables its rearrangement according to main aggregates. Through populationisation, a signified is enacted that can be sliced up and that is equal in all its parts. Now predictions can be computed and fed back to society as tools of moral judgment. The acting individual and “society” are—numerically and literally!—entangled in the production and enactment of risk knowledge.},
  timestamp = {2017-05-19T07:25:23Z},
  author = {Holmberg, Christine and Bischof, Christine and Bauer, Susanne},
  urldate = {2012-10-08},
  date = {2012-05-03}
}

@article{MacKenzie_1978,
  title = {Statistical {{Theory}} and {{Social Interests A Case}}-{{Study}}},
  volume = {8},
  url = {http://sss.sagepub.com/content/8/1/35.short},
  timestamp = {2017-05-19T07:25:24Z},
  number = {1},
  author = {MacKenzie, D.},
  urldate = {2012-10-08},
  date = {1978},
  pages = {35--83}
}

@book{Wasserman_2003,
  location = {{New York}},
  title = {All of {{Statistics}}: {{A Concise Course}} in {{Statistical Inference}}},
  shorttitle = {All of {{Statistics}}},
  timestamp = {2017-05-19T07:25:24Z},
  publisher = {{Springer}},
  author = {Wasserman, Larry},
  date = {2003}
}

@book{Moore_2009,
  location = {{New York; London}},
  edition = {5th Edition},
  title = {The {{Basic Practice}} of {{Statistics}}},
  isbn = {1-4292-2426-6},
  timestamp = {2017-05-19T07:25:24Z},
  publisher = {{W. H. Freeman}},
  author = {Moore, David S.},
  date = {2009}
}

@book{Silver_2012,
  location = {{New York; London}},
  title = {The {{Signal}} and the {{Noise}}: {{The Art}} and {{Science}} of {{Prediction}}},
  isbn = {1-84614-752-2},
  shorttitle = {The {{Signal}} and the {{Noise}}},
  timestamp = {2017-05-19T07:25:24Z},
  publisher = {{Allen Lane}},
  author = {Silver, Nate},
  date = {2012}
}

@article{Efron_1979,
  title = {Bootstrap {{Methods}}: {{Another Look}} at the {{Jackknife}}},
  volume = {7},
  url = {http://projecteuclid.org/euclid.aos/1176344552},
  shorttitle = {Bootstrap {{Methods}}},
  timestamp = {2017-05-19T07:25:24Z},
  number = {1},
  author = {Efron, B.},
  urldate = {2012-10-19},
  date = {1979},
  pages = {1--26}
}

@article{Gelfand_1990,
  title = {Illustration of {{Bayesian Inference}} in {{Normal Data Models Using Gibbs Sampling}}},
  volume = {85},
  url = {http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1990.10474968},
  timestamp = {2017-05-19T07:25:24Z},
  number = {412},
  author = {Gelfand, A. E. and Hills, S. E. and Racine-Poon, A. and Smith, A. F. M.},
  urldate = {2012-10-19},
  date = {1990},
  pages = {972--985}
}

@article{Jackman_2000,
  title = {Estimation and {{Inference}} via {{Bayesian Simulation}}: {{An Introduction}} to {{Markov Chain Monte Carlo}}},
  volume = {44},
  issn = {0092-5853},
  doi = {10.2307/2669318},
  shorttitle = {Estimation and {{Inference}} via {{Bayesian Simulation}}},
  abstract = {Bayesian statistics have made great strides in recent years, developing a class of methods for estimation and inference via stochastic simulation known as Markov Chain Monte Carlo (MCMC) methods. MCMC constitutes a revolution in statistical practice with effects beginning to be felt in the social sciences: models long consigned to the "too hard" basket are now within reach of quantitative researchers. I review the statistical pedigree of MCMC and the underlying statistical concepts. I demonstrate some of the strengths and weaknesses of MCMC and offer practical suggestions for using MCMC in social-science settings. Simple, illustrative examples include a probit model of voter turnout and a linear regression for time-series data with autoregressive disturbances. I conclude with a more challenging application, a multinomial probit model, to showcase the power of MCMC methods.},
  timestamp = {2017-05-19T07:25:24Z},
  number = {2},
  author = {Jackman, Simon},
  date = {2000-04-01},
  pages = {375--404},
  eprinttype = {jstor},
  eprint = {2669318}
}

@article{Adkins_2009,
  title = {Introduction: {{What Is}} the {{Empirical}}?},
  volume = {12},
  issn = {1368-4310},
  url = {http://est.sagepub.com/content/12/1/5.full.pdf+html},
  doi = {10.1177/1368431008099641},
  shorttitle = {Introduction},
  timestamp = {2017-05-19T07:25:24Z},
  number = {1},
  author = {Adkins, L. and Lury, C.},
  urldate = {2012-10-26},
  date = {2009-02-01},
  pages = {5--20}
}

@article{Gane_2009,
  title = {Concepts and the `{{New}}' {{Empiricism}}},
  volume = {12},
  issn = {1368-4310, 1461-7137},
  url = {http://est.sagepub.com.ezproxy.lancs.ac.uk/content/12/1/83},
  doi = {10.1177/1368431008099645},
  abstract = {This article examines the role of concepts in the so-called 'new' empiricism that is currently emerging from the writings of Gilles Deleuze. It asks what concepts are, and how they might be put to work to present the 'pure difference' of the empirical world. In addressing these questions, a number of parallels and contrasts are drawn between the writings of Deleuze and Max Weber. It is shown that many of Deleuze's key arguments about concepts- in particular, that they are pedagogical, multiple, networked and problem-oriented in basis - are anticipated by Weber's sociological methodology of concept formation. This leads, finally, to a consideration of whether the creation of concepts as a practice belongs primarily within the domain of philosophy (as argued by Deleuze), or if it is a key part of social scientific work more generally.},
  timestamp = {2017-05-19T07:25:24Z},
  number = {1},
  author = {Gane, Nicholas},
  urldate = {2012-10-26},
  date = {2009-01-02},
  pages = {83--97},
  keywords = {concepts,Deleuze,empiricism,ideal-types,neo-Kantianism,Weber}
}

@article{Lash_2009,
  title = {Afterword: {{In Praise}} of the {{A Posteriori Sociology}} and the {{Empirical}}},
  volume = {12},
  issn = {1368-4310, 1461-7137},
  url = {http://est.sagepub.com.ezproxy.lancs.ac.uk/content/12/1/175},
  doi = {10.1177/1368431008099646},
  shorttitle = {Afterword},
  abstract = {This article begins with discussions of rationalist, a priori and empiricist, a posteriori thinking in philosophy. It then argues that classically, sociology is rationalist or a priori. Sociology — Weber, Simmel, Durkheim and Marx — moves from Kant's epistemological a priori to the social a priori. It moves from the question of how knowledge is possible to the question of how society is possible. This question of the possibility of society becomes quickly one of social control and social order in functionalism and Parsons. The article argues instead for an aposteriorist, de facto empiricist sociology that breaks with this ultimately normative question. This aposteriorist sociology would instead investigate social processes in their very factuality, their open-endedness, complexity, and path dependency. A priorism in sociology, I would argue, is dominant in both positivism and phenomenology. The article opposes to phenomenology's transcendentaI rationalism a `transcendental empiricism' that is illustrated with Edmund Burke's English and aposteriori aesthetics of the sublime. Sociology today needs to be relevant to study of `emerging' nations like China. The article argues for an aposteriorist, empiricist sociology here, and looks at debates on property law in today's China. Here we look at rationalist and a priori notions of clear, distinct and divisible property in Continental reception of Roman law. We counterpose to this English, empiricist (a posteriori) Common Law notions of property as a bundle of rights, in which property is not clear and distinct but vague like a boundary object. We look at how this is instantiated in China. With François Jullien, we contrast a Chinese, effectively empiricist, aposteriorist notion of the universal to Western rationalist and a priori universalism. We look at the implications for international geopolitics and a possible Chinese route to democracy. With Jullien, we counterpose an aposteriorist Chinese notion of `activity' to the Western a priori notions of `action' found in Weber and Parsons. The Chinese `activity' is more processual, more relational, less goal-oriented, more path-dependent than our Western notion of `action'. The article argues that in the twenty-first century when national social control is partly displaced by global uncertainty, and when the ascendancy of the West is coming increasingly under question, that such an empiricist, aposteriorist sociology is suitable.},
  timestamp = {2017-05-19T07:25:24Z},
  number = {1},
  author = {Lash, Scott},
  urldate = {2012-10-26},
  date = {2009-01-02},
  pages = {175--187},
  keywords = {action,a posteriori,China,empiricism,property,rationalism,social a priori,the sublime}
}

@online{_h,
  title = {Daniel {{Wolpert}} on {{TED}}: {{Noise Reduction}} and the {{Bayesian Brain}}},
  url = {http://neuroconscience.com/2012/02/09/daniel-wolpert-on-ted-noise-reduction-and-the-bayesian-brain/},
  shorttitle = {Daniel {{Wolpert}} on {{TED}}},
  abstract = {This has to be the best introduction to the Bayesian Brain hypothesis I have ever seen. I’m normally somewhat cautious about my endorsement of this view, but Daniel really draws you in. Beaut...},
  timestamp = {2017-05-19T07:25:24Z},
  urldate = {2012-11-06}
}

@online{Scherer_2012,
  title = {How {{Obama}}'s {{Data Crunchers Helped Him Win}} - {{CNN}}.{{Com}}},
  url = {http://www.cnn.com/2012/11/07/tech/web/obama-campaign-tech-team/index.html},
  abstract = {In late spring, the backroom number crunchers who powered Barack Obama's campaign to victory noticed that George Clooney had an almost gravitational tug on West Coast females ages 40 to 49. The women were far and away the single demographic group most likely to hand over cash, for a chance to dine in Hollywood with Clooney — and Obama.},
  timestamp = {2017-05-19T07:25:24Z},
  author = {Scherer, Michael},
  urldate = {2012-11-20},
  date = {2012}
}

@article{Pang_2009,
  title = {The {{Labor Factor}} in the {{Creative Economy}} a {{Marxist Reading}}},
  volume = {27},
  url = {http://socialtext.dukejournals.org/content/27/2_99/55.short},
  timestamp = {2017-05-19T07:25:25Z},
  issue = {2 99},
  author = {Pang, L.},
  urldate = {2012-12-05},
  date = {2009},
  pages = {55--76}
}

@book{Gamerman_2006,
  title = {Markov {{Chain Monte Carlo}}: {{Stochastic Simulation}} for {{Bayesian Inference}}},
  volume = {68},
  shorttitle = {Markov {{Chain Monte Carlo}}},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{Chapman \& Hall/CRC}},
  author = {Gamerman, Dani and Lopes, Hedibert F.},
  date = {2006}
}

@article{Brownstein_2009,
  title = {Influenza {{A}} ({{H1N1}}) {{Virus}}, 2009—online {{Monitoring}}},
  volume = {360},
  url = {http://www.nejm.org/doi/full/10.1056/nejmp0904012},
  timestamp = {2017-05-19T07:25:25Z},
  number = {21},
  author = {Brownstein, John S. and Freifeld, Clark C. and Madoff, Lawrence C.},
  urldate = {2013-03-04},
  date = {2009},
  pages = {2156--2156}
}

@article{Lakhani_2013,
  title = {Prize-{{Based Contests Can Provide Solutions}} to {{Computational Biology Problems}}},
  volume = {31},
  issn = {1087-0156},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nbt/journal/v31/n2/full/nbt.2495.html},
  doi = {10.1038/nbt.2495},
  timestamp = {2017-05-19T07:25:25Z},
  number = {2},
  author = {Lakhani, Karim R. and Boudreau, Kevin J. and Loh, Po-Ru and Backstrom, Lars and Baldwin, Carliss and Lonstein, Eric and Lydon, Mike and MacCormack, Alan and Arnaout, Ramy A. and Guinan, Eva C.},
  urldate = {2013-02-11},
  date = {2013},
  pages = {108--111}
}

@book{Sampson_2012,
  title = {Virality: {{Contagion Theory}} in the {{Age}} of {{Networks}}},
  isbn = {0-8166-7005-6},
  shorttitle = {Virality},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{University of Minnesota Press}},
  author = {Sampson, Tony D.},
  date = {2012-06-26}
}

@book{Parikka_2007,
  title = {Digital {{Contagions}}: {{A Media Archaeology}} of {{Computer Viruses}}},
  isbn = {0-8204-8837-2},
  shorttitle = {Digital {{Contagions}}},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{Peter Lang Publishing Inc}},
  author = {Parikka, Jussi},
  date = {2007-06-01}
}

@article{Butler_2013,
  title = {When {{Google Got Flu Wrong}}},
  volume = {494},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/news/when-google-got-flu-wrong-1.12413},
  doi = {10.1038/494155a},
  timestamp = {2017-05-19T07:25:25Z},
  number = {7436},
  author = {Butler, Declan},
  urldate = {2013-03-08},
  date = {2013-02-13},
  pages = {155--156}
}

@book{Vapnik_1999,
  edition = {2nd ed. 2000},
  title = {The {{Nature}} of {{Statistical Learning Theory}}},
  isbn = {0-387-98780-0},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{Springer}},
  author = {Vapnik, Vladimir},
  date = {1999-12-01}
}

@article{Martin_2009,
  title = {Toward an {{Anthropology}} of {{Immunology}}: {{The Body}} as {{Nation State}}},
  volume = {4},
  url = {http://onlinelibrary.wiley.com/doi/10.1525/maq.1990.4.4.02a00030/abstract},
  shorttitle = {Toward an {{Anthropology}} of {{Immunology}}},
  timestamp = {2017-05-19T07:25:25Z},
  number = {4},
  author = {Martin, Emily},
  urldate = {2013-03-11},
  date = {2009},
  pages = {410--426}
}

@article{SIU_2006,
  title = {Sars: {{Reception}} and {{Interpretation}} in {{Three Chinese Cities}} ({{Coll Routledge Contemporary China Series}})},
  url = {http://www.lavoisier.fr/livre/notice.asp?id=OKRWALALOSAOWL},
  shorttitle = {Sars},
  timestamp = {2017-05-19T07:25:25Z},
  author = {SIU, Helen},
  urldate = {2013-03-11},
  date = {2006}
}

@article{Law_2011,
  title = {Veterinary {{Realities}}: {{What Is Foot}} and {{Mouth Disease}}?},
  volume = {51},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9523.2010.00520.x/full},
  shorttitle = {Veterinary {{Realities}}},
  timestamp = {2017-05-19T07:25:25Z},
  number = {1},
  author = {Law, John and Mol, Annemarie},
  urldate = {2013-03-11},
  date = {2011},
  pages = {1--16}
}

@article{Carlsson_2009,
  title = {Topology and {{Data}}},
  volume = {46},
  url = {http://www.ams.org/images/carlsson-notes.pdf},
  timestamp = {2017-05-19T07:25:25Z},
  number = {2},
  author = {Carlsson, Gunnar},
  urldate = {2013-03-12},
  date = {2009},
  pages = {255}
}

@article{Ghrist_2008,
  title = {Barcodes: {{The Persistent Topology}} of {{Data}}},
  volume = {45},
  url = {http://www.ams.org/bull/2008-45-01/S0273-0979-07-01191-3/},
  shorttitle = {Barcodes},
  timestamp = {2017-05-19T07:25:25Z},
  number = {1},
  author = {Ghrist, Robert},
  urldate = {2013-03-12},
  date = {2008},
  pages = {61}
}

@inproceedings{Singh_2007,
  title = {Topological {{Methods}} for the {{Analysis}} of {{High Dimensional Data Sets}} and 3d {{Object Recognition}}},
  volume = {22},
  url = {http://comptop.stanford.edu/preprints/mapperPBG.pdf},
  timestamp = {2017-05-19T07:25:25Z},
  booktitle = {Eurographics {{Symposium}} on {{Point}}-{{Based Graphics}}},
  author = {Singh, Gurjeet and Mémoli, Facundo and Carlsson, Gunnar},
  urldate = {2013-03-12},
  date = {2007}
}

@article{Nicolau_2011,
  title = {Topology {{Based Data Analysis Identifies}} a {{Subgroup}} of {{Breast Cancers}} with a {{Unique Mutational Profile}} and {{Excellent Survival}}},
  volume = {108},
  url = {http://www.pnas.org/content/108/17/7265.short},
  timestamp = {2017-05-19T07:25:25Z},
  number = {17},
  author = {Nicolau, Monica and Levine, Arnold J. and Carlsson, Gunnar},
  urldate = {2013-03-12},
  date = {2011},
  pages = {7265--7270}
}

@article{Manovich_2011,
  title = {’{{Trending}}: {{The Promises}} and the {{Challenges}} of {{Big Social Data}}.’},
  url = {http://www.manovich.net/DOCS/Manovich_trending_paper.pdf},
  shorttitle = {’{{Trending}}},
  timestamp = {2017-05-19T07:25:25Z},
  author = {Manovich, Lev},
  urldate = {2013-03-12},
  date = {2011}
}

@book{Manovich_2011a,
  title = {Cultural {{Software}}},
  url = {http://www.manovich.net/DOCS/Manoich.Cultural_Software.2011.pdf},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{\$$\backslash$backslash\$vCervenec}},
  author = {Manovich, Lev},
  urldate = {2013-03-12},
  date = {2011}
}

@article{Manovich_2009,
  title = {Software {{Takes Command}}. 2008},
  timestamp = {2017-05-19T07:25:25Z},
  author = {Manovich, Lev},
  date = {2009}
}

@article{Galloway_2013,
  title = {The {{Poverty}} of {{Philosophy}}: {{Realism}} and {{Post}}-{{Fordism}}},
  volume = {39},
  issn = {0093-1896},
  doi = {10.1086/668529},
  shorttitle = {The {{Poverty}} of {{Philosophy}}},
  timestamp = {2017-05-19T07:25:25Z},
  number = {2},
  author = {Galloway, Alexander R.},
  date = {2013-01-01},
  pages = {347--366},
  eprinttype = {jstor},
  eprint = {10.1086/668529}
}

@article{Krzywinski_2009,
  title = {Circos: {{An Information Aesthetic}} for {{Comparative Genomics}}},
  volume = {19},
  url = {http://genome.cshlp.org/content/early/2009/06/15/gr.092759.109.abstract},
  doi = {10.1101/gr.092759.109},
  abstract = {We created a visualization tool, called Circos, to facilitate the identification and analysis of similarities and differences arising from comparisons of genomes. Our tool is effective in displaying variation in genome structure and, generally, any other kind of positional relationships between genomic intervals. Such data are routinely produced by sequence alignments, hybridization arrays, genome mapping, and genotyping studies. Circos uses a circular ideogram layout to facilitate the display of relationships between pairs of positions by the use of ribbons, which encode the position, size, and orientation of related genomic elements. Circos is capable of displaying data as scatter, line and histogram plots, heat maps, tiles, connectors and text. Bitmap or vector images can be created from GFF-style data inputs and hierarchical configuration files, which can be easily generated by automated tools, making Circos suitable for rapid deployment in data analysis and reporting pipelines.},
  timestamp = {2017-05-19T07:25:25Z},
  author = {Krzywinski, Martin I and Schein, Jacqueline E and Birol, Inanc and Connors, Joseph and Gascoyne, Randy and Horsman, Doug and Jones, Steven J and Marra, Marco A},
  date = {2009},
  pages = {1639--1645}
}

@inproceedings{Ma_2009,
  title = {Identifying {{Suspicious URLs}}: {{An Application}} of {{Large}}-{{Scale Online Learning}}},
  url = {http://dl.acm.org/citation.cfm?id=1553462},
  shorttitle = {Identifying {{Suspicious URLs}}},
  timestamp = {2017-05-19T07:25:25Z},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2009},
  pages = {681--688}
}

@inproceedings{Ma_2009a,
  title = {Beyond {{Blacklists}}: {{Learning}} to {{Detect Malicious Web Sites}} from {{Suspicious URLs}}},
  url = {http://dl.acm.org/citation.cfm?id=1557153},
  shorttitle = {Beyond {{Blacklists}}},
  timestamp = {2017-05-19T07:25:25Z},
  booktitle = {Proceedings of the 15th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2009},
  pages = {1245--1254}
}

@article{Ma_2011,
  title = {Learning to {{Detect Malicious URLs}}},
  volume = {2},
  url = {http://dl.acm.org/citation.cfm?id=1961202},
  timestamp = {2017-05-19T07:25:25Z},
  number = {3},
  author = {Ma, Justin and Saul, Lawrence K. and Savage, Stefan and Voelker, Geoffrey M.},
  urldate = {2013-03-18},
  date = {2011},
  pages = {30}
}

@book{Lepinay_2011,
  title = {Codes of {{Finance}} : {{Engineering Derivatives}} in a {{Global Bank}}},
  isbn = {0-691-15150-4},
  shorttitle = {Codes of {{Finance}}},
  timestamp = {2017-05-19T07:25:25Z},
  publisher = {{Princeton Princeton University Press}},
  author = {Lépinay, Vincent Antonin},
  date = {2011}
}

@article{McCormack_2012,
  title = {Geography and {{Abstraction Towards}} an {{Affirmative Critique}}},
  volume = {36},
  issn = {0309-1325, 1477-0288},
  url = {http://phg.sagepub.com/content/36/6/715},
  doi = {10.1177/0309132512437074},
  abstract = {A critique of abstraction has become one of the most important reference points for contemporary human geography. The terms of this critique have, however, been limited by the tendency to oppose the abstract to the lived. This paper argues that abstraction can be affirmed as a necessary element of understandings of lived worlds in the making. Doing this requires revisiting the relation between abstraction and two matters of disciplinary concern: experience and materiality. These matters of concern are drawn together via one technology of abstraction, the diagram, before an affirmative critique of abstraction for geographical thinking is outlined in concluding.},
  timestamp = {2017-05-19T07:25:25Z},
  number = {6},
  author = {McCormack, Derek},
  urldate = {2013-04-19},
  date = {2012-12-01},
  pages = {715--734},
  keywords = {abstraction,critique,diagram,experience,line,materiality}
}

@article{Le_2011,
  title = {Building {{High}}-{{Level Features Using Large Scale Unsupervised Learning}}},
  url = {http://arxiv.org/abs/1112.6209},
  abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8\% accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70\% relative im- provement over the previous state-of-the-art.},
  timestamp = {2017-05-19T07:25:25Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1112.6209},
  author = {Le, Quoc V. and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S. and Dean, Jeff and Ng, Andrew Y.},
  urldate = {2013-04-21},
  date = {2011-12-28},
  keywords = {Computer Science - Learning}
}

@article{Goffey_2008,
  title = {Abstract {{Experience}}},
  volume = {25},
  issn = {0263-2764, 1460-3616},
  url = {http://tcs.sagepub.com/content/25/4/15},
  doi = {10.1177/0263276408091980},
  abstract = {The speculative philosophy of Alfred North Whitehead offers critical social and cultural theory an unusual way of rethinking the place and value of experience in its concerns. This article explores the challenges that Whitehead's approach to experience, deliberately contrasted with the subject-object thinking of modernity, creates. The article seeks to provide an account of the importance of Whitehead's appeal to naïve experience and of how this appeal counters some of the problems of more recent and more familiar accounts of the fate of experience which draw on some of the same historical points of reference — especially Romantic poetry. In particular, the article suggests that Whitehead's broadly impersonal conception of the open structure of experience as constructive process mitigates the `pathos of finitude' attendant upon critical accounts which presume the unity of experience and then ask how this unity is shattered under modernity. Whitehead's work is situated transversally to analysis and phenomenology and is argued to accord a value to and role for abstraction which calls for a more experimental approach to the topic. While `naïve experience' clearly differs from the understanding of experience evident in other accounts, the article also suggests that it is not incompatible with a more Foucauldian kind of singular history.},
  timestamp = {2017-05-19T07:25:25Z},
  number = {4},
  author = {Goffey, Andrew},
  urldate = {2013-04-19},
  date = {2008-01-07},
  pages = {15--30},
  keywords = {abstraction,critical theory,Culture,experience}
}

@online{OccupyData_2013,
  title = {Occupy {{Data}}},
  url = {http://occupy-data.org/},
  timestamp = {2017-05-19T07:25:26Z},
  author = {{OccupyData}},
  urldate = {2013-04-23},
  date = {2013}
}

@book{Whitehead_1970,
  edition = {Reissue},
  title = {Science and the {{Modern World}}},
  isbn = {0-684-83639-4},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{Simon and Schuster}},
  author = {Whitehead, Alfred North},
  date = {1970-04-11}
}

@article{Thrun_2006,
  title = {Stanley: {{The Robot That Won}} the {{DARPA Grand Challenge}}},
  volume = {23},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.20147/abstract},
  shorttitle = {Stanley},
  timestamp = {2017-05-19T07:25:26Z},
  number = {9},
  author = {Thrun, Sebastian and Montemerlo, Mike and Dahlkamp, Hendrik and Stavens, David and Aron, Andrei and Diebel, James and Fong, Philip and Gale, John and Halpenny, Morgan and Hoffmann, Gabriel},
  urldate = {2013-04-26},
  date = {2006},
  pages = {661--692}
}

@article{Briggs_2009,
  title = {Biocommunicability and the {{Biopolitics}} of {{Pandemic Threats}}},
  volume = {28},
  issn = {0145-9740},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01459740903070410},
  doi = {10.1080/01459740903070410},
  abstract = {In this article we assess accounts of the H1N1 virus or “swine flu” to draw attention to the ways in which discourse about biosecurity and global health citizenship during times of pandemic alarms supports calls for the creation of global surveillance systems and naturalizes forms of governance. We propose a medical anthropology of epidemics to complement an engaged anthropology aimed at better and more critical forms of epidemic surveillance. A medical anthropology of epidemics provides insights into factors and actors that shape the ongoing production of knowledge about epidemics, how dominant and competing accounts circulate and interact, how different stakeholders (citizens, politicians, journalists, and policymakers) access and interpret information available from different sources—including through a variety of new digital venues—and what they do with it. These insights together provide a compelling agenda for medical anthropology and anyone working in health-related fields.},
  timestamp = {2017-05-19T07:25:26Z},
  number = {3},
  author = {Briggs, Charles L. and Nichter, Mark},
  urldate = {2013-05-01},
  date = {2009},
  pages = {189--198}
}

@article{boyd_2012,
  title = {Critical {{Questions}} for {{Big Data}}},
  volume = {15},
  issn = {1369-118X},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1369118X.2012.678878},
  doi = {10.1080/1369118X.2012.678878},
  abstract = {The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what ‘research’ means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric.},
  timestamp = {2017-05-19T07:25:26Z},
  number = {5},
  author = {{boyd}, danah and Crawford, Kate},
  urldate = {2013-05-08},
  date = {2012},
  pages = {662--679}
}

@book{Munster_2013,
  title = {An {{Aesthesia}} of {{Networks}}: {{Conjunctive Experience}} in {{Art}} and {{Technology}}},
  url = {http://mitpress.mit.edu/books/aesthesia-networks/},
  shorttitle = {An {{Aesthesia}} of {{Networks}}},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{MIT Press}},
  author = {Munster, Anna},
  urldate = {2013-05-14},
  date = {2013}
}

@book{Parisi_2013,
  location = {{Cambridge ; Malden, MA}},
  title = {Contagious {{Architecture}}: {{Computation}}, {{Aesthetics}} and {{Space}}},
  isbn = {0-262-01863-2},
  shorttitle = {Contagious {{Architecture}}},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{MIT Press}},
  author = {Parisi, Luciana},
  date = {2013}
}

@book{Murphy_2012,
  location = {{Cambridge, MA}},
  title = {Machine {{Learning}}: {{A Probabilistic Perspective}}},
  isbn = {978-0-262-01802-9 0-262-01802-0},
  shorttitle = {Machine {{Learning}}},
  abstract = {"This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package–PMTK (probabilistic modeling toolkit)–that is freely available online"–Back cover.},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{MIT Press}},
  author = {Murphy, Kevin P},
  date = {2012}
}

@article{BBC_2012,
  title = {Google '{{Brain}}' {{Machine Spots Cats}}},
  url = {http://www.bbc.co.uk/news/technology-18595351},
  abstract = {A Google research team has trained a network of 1,000 computers wired up like the human brain to recognise cats.},
  timestamp = {2017-05-19T07:25:26Z},
  author = {{BBC}},
  urldate = {2013-06-06},
  date = {2012-06-26}
}

@article{Breiman_2001,
  title = {Statistical {{Modeling}}: {{The Two Cultures}} (with {{Comments}} and a {{Rejoinder}} by the {{Author}})},
  volume = {16},
  url = {http://projecteuclid.org/euclid.ss/1009213726},
  shorttitle = {Statistical {{Modeling}}},
  timestamp = {2017-05-19T07:25:26Z},
  number = {3},
  author = {Breiman, Leo},
  urldate = {2013-06-10},
  date = {2001},
  pages = {199--231}
}

@article{Wacquant_2010,
  title = {Participant {{Observation}}/{{Observant Participation}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=pLSAay_xwjEC&oi=fnd&pg=PA69&dq=wacquant+observant+&ots=LUgGkfHYRD&sig=WwrRprm32d0QB4H8LScW8zlINHc},
  timestamp = {2017-05-19T07:25:26Z},
  author = {Wacquant, Loïc},
  urldate = {2013-06-11},
  date = {2010},
  pages = {69}
}

@book{Barber_2011,
  location = {{Cambridge; New York}},
  title = {Bayesian {{Reasoning}} and {{Machine Learning}}},
  isbn = {978-0-521-51814-7 0-521-51814-8},
  abstract = {"Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online"– "Vast amounts of data present amajor challenge to all thoseworking in computer science, and its many related fields, who need to process and extract value from such data. Machine learning technology is already used to help with this task in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis and robot locomotion. As its usage becomes more widespread, no student should be without the skills taught in this book. Designed for final-year undergraduate and graduate students, this gentle introduction is ideally suited to readers without a solid background in linear algebra and calculus. It covers everything from basic reasoning to advanced techniques in machine learning, and rucially enables students to construct their own models for real-world problems by teaching them what lies behind the methods. Numerous examples and exercises are included in the text. Comprehensive resources for students and instructors are available online"–},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{Cambridge University Press}},
  author = {Barber, David},
  date = {2011}
}

@book{Wacquant_2004,
  location = {{Oxford}},
  title = {Body and {{Soul}}. {{Notebooks}} of an {{Apprentice Boxer}}},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{Oxford University Press}},
  author = {Wacquant, Loic},
  date = {2004}
}

@article{Olazaran_1996,
  title = {A {{Sociological Study}} of the {{Official History}} of the {{Perceptrons Controversy}}},
  volume = {26},
  issn = {0306-3127, 1460-3659},
  url = {http://sss.sagepub.com/content/26/3/611},
  doi = {10.1177/030631296026003005},
  abstract = {In this paper, I analyze the controversy within Artificial Intelligence (AI) which surrounded the `perceptron' project (and neural nets in general) in the late 1950s and early 1960s. I devote particular attention to the proofs and arguments of Minsky and Papert, which were interpreted as showing that further progress in neural nets was not possible, and that this approach to AI had to be abandoned. I maintain that this official interpretation of the debate was a result of the emergence, institutionalization and (importantly) legitimation of the symbolic AI approach (with its resource allocation system and authority structure). At the `research-area' level, there was considerable interpretative flexibility. This interpretative flexibility was further demonstrated by the revival of neural nets in the late 1980s, and subsequent rewriting of the official history of the debate.},
  timestamp = {2017-05-19T07:25:26Z},
  number = {3},
  author = {Olazaran, Mikel},
  urldate = {2013-06-17},
  date = {1996-01-08},
  pages = {611--659}
}

@online{Ng_,
  title = {| {{Machine Learning III}}: {{Linear Algebra Review}}},
  url = {https://class.coursera.org/ml-003/lecture/},
  abstract = {Video Lecture: in Machine Learning on Coursera.},
  timestamp = {2017-05-19T07:25:26Z},
  author = {Ng, Andrew},
  urldate = {2013-06-14}
}

@article{Rosenblatt_1958,
  title = {The {{Perceptron}}: {{A Probabilistic Model}} for {{Information Storage}} and {{Organization}} in the {{Brain}}},
  volume = {65},
  issn = {1939-1471(Electronic);0033-295X(Print)},
  doi = {10.1037/h0042519},
  shorttitle = {The {{Perceptron}}},
  abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references.},
  timestamp = {2017-05-19T07:25:26Z},
  number = {6},
  author = {Rosenblatt, F.},
  date = {1958},
  pages = {386--408},
  keywords = {brain,information storage,probabilistic model}
}

@article{Minsky_1969,
  title = {Perceptron: {{An Introduction}} to {{Computational Geometry}}},
  volume = {19},
  shorttitle = {Perceptron},
  timestamp = {2017-05-19T07:25:26Z},
  author = {Minsky, Marvin and Papert, Seymour},
  date = {1969},
  pages = {88}
}

@online{Dahl_2013,
  title = {Deep {{Learning How I Did It}}: {{Merck}} 1st {{Place Interview}}},
  url = {http://blog.kaggle.com/2012/11/01/deep-learning-how-i-did-it-merck-1st-place-interview/},
  shorttitle = {Deep {{Learning How I Did It}}},
  abstract = {What was your background prior to entering this challenge? We are a team of computer science and statistics academics. Ruslan Salakhutdinov and Geoff Hinton are professors at the University of Toro...},
  timestamp = {2017-05-19T07:25:26Z},
  author = {Dahl, George},
  urldate = {2013-06-17},
  date = {2013},
  keywords = {code,geoff hinton,learning,machine,merck,model,neural,professor hinton}
}

@article{Hinton_2006a,
  title = {Reducing the {{Dimensionality}} of {{Data}} with {{Neural Networks}}},
  volume = {313},
  url = {http://www.sciencemag.org/content/313/5786/504.short},
  timestamp = {2017-05-19T07:25:26Z},
  number = {5786},
  author = {Hinton, Geoffrey E. and Salakhutdinov, Ruslan R.},
  urldate = {2013-06-17},
  date = {2006},
  pages = {504--507}
}

@article{Ackley_1985,
  title = {A {{Learning Algorithm}} for {{Boltzmann Machines}}},
  volume = {9},
  url = {http://www.sciencedirect.com/science/article/pii/S0364021385800124},
  timestamp = {2017-05-19T07:25:26Z},
  number = {1},
  author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
  date = {1985},
  pages = {147--169}
}

@online{IBM_2013,
  title = {{{IBM PureData System}}},
  url = {http://www-01.ibm.com/software/data/puredata/},
  timestamp = {2017-05-19T07:25:26Z},
  author = {{IBM}},
  urldate = {2013-06-21},
  date = {2013}
}

@online{KDD_2013,
  title = {Call {{For KDD Cup}}},
  url = {http://www.kdd.org/kdd2013/call-for-cup},
  timestamp = {2017-05-19T07:25:26Z},
  author = {{KDD}},
  urldate = {2013-07-23},
  date = {2013}
}

@article{Patil_2010,
  title = {{{PyMC}}: {{Bayesian Stochastic Modelling}} in {{Python}}},
  volume = {35},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3097064/},
  shorttitle = {{{PyMC}}},
  timestamp = {2017-05-19T07:25:26Z},
  number = {4},
  author = {Patil, Anand and Huard, David and Fonnesbeck, Christopher J.},
  urldate = {2013-06-17},
  date = {2010},
  pages = {1}
}

@online{LeCun_2012,
  title = {{{MNIST Handwritten Digit Database}}, {{Yann LeCun}}, {{Corinna Cortes}} and {{Chris Burges}}},
  url = {http://yann.lecun.com/exdb/mnist/},
  timestamp = {2017-05-19T07:25:26Z},
  author = {LeCun, Yann and Cortes, Corinna},
  urldate = {2013-06-24},
  date = {2012}
}

@book{Bogost_2012,
  title = {Alien {{Phenomenology}}, or {{What It}}'s like to {{Be}} a {{Thing}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=MwaK2aUclo8C&oi=fnd&pg=PP2&dq=ian+bogost+alien&ots=bRcDxTYd2w&sig=IyStFB_1583RBe48OKZzhEh5_h8},
  timestamp = {2017-05-19T07:25:26Z},
  publisher = {{U of Minnesota Press}},
  author = {Bogost, Ian},
  urldate = {2013-08-07},
  date = {2012}
}

@article{Callon_1983,
  title = {From {{Translations}} to {{Problematic Networks}}: {{An Introduction}} to {{Co}}-{{Word Analysis}}},
  volume = {22},
  issn = {0539-0184, 1461-7412},
  url = {http://ssi.sagepub.com/content/22/2/191},
  doi = {10.1177/053901883022002003},
  shorttitle = {From {{Translations}} to {{Problematic Networks}}},
  timestamp = {2017-05-19T07:25:26Z},
  number = {2},
  author = {Callon, Michel and Courtial, Jean-Pierre and Turner, William A. and Bauin, Serge},
  urldate = {2013-08-12},
  date = {1983-01-03},
  pages = {191--235}
}

@book{Alpaydin_2010,
  location = {{Cambridge, Massachusetts; London}},
  title = {Introduction to {{Machine Learning}}},
  isbn = {978-0-262-01243-0 0-262-01243-X},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{MIT Press}},
  author = {Alpaydin, Ethem},
  date = {2010}
}

@book{Rasmussen_2006,
  location = {{Cambridge, Mass.}},
  title = {Gaussian {{Processes}} for {{Machine Learning}}},
  isbn = {0-262-18253-X 978-0-262-18253-9},
  abstract = {"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics."–Jacket.},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{MIT Press}},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I},
  date = {2006}
}

@book{Marsland_2009,
  location = {{Boca Raton, Mass. [u.a.}},
  title = {Machine {{Learning}}: {{An Algorithmic Perspective}}},
  isbn = {978-1-4200-6718-7 1-4200-6718-4},
  shorttitle = {Machine {{Learning}}},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{CRC Press/Taylor \& Francis}},
  author = {Marsland, Stephen},
  date = {2009}
}

@book{Mitchell_1997,
  location = {{New York, NY [u.a.}},
  title = {Machine {{Learning}}},
  isbn = {0-07-115467-1 978-0-07-115467-3},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{McGraw-Hill}},
  author = {Mitchell, Tom M},
  date = {1997}
}

@incollection{Stengers_2011,
  location = {{Melbourne}},
  title = {Wondering about {{Materialism}}},
  timestamp = {2017-05-19T07:25:27Z},
  booktitle = {The {{Speculative Turn}}: {{Continental Materialism}} and {{Realism}}},
  publisher = {{re.press}},
  author = {Stengers, Isabelle},
  date = {2011},
  pages = {368--380}
}

@article{Ward_2006,
  title = {Short-{{Term Prediction}} of {{Mortality}} in {{Patients}} with {{Systemic Lupus Erythematosus}}: {{Classification}} of {{Outcomes Using Random Forests}}},
  volume = {55},
  issn = {1529-0131},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/art.21695/abstract},
  doi = {10.1002/art.21695},
  shorttitle = {Short-{{Term Prediction}} of {{Mortality}} in {{Patients}} with {{Systemic Lupus Erythematosus}}},
  abstract = {ObjectiveTo identify demographic and clinical characteristics that classify patients with systemic lupus erythematosus (SLE) at risk for in-hospital mortality.MethodsPatients hospitalized in California from 1996 to 2000 with a principal diagnosis of SLE (N = 3,839) were identified from a state hospitalization database. As candidate predictors of mortality, we used patient demographic characteristics; the presence or absence of 40 different clinical conditions listed among the discharge diagnoses; and 2 summary indexes derived from the discharge diagnoses, the Charlson Index and the SLE Comorbidity Index. Predictors of patients at increased risk of mortality were identified and validated using random forests, a statistical procedure that is a generalization of single classification trees. Random forests use bootstrapped samples of patients and randomly selected subsets of predictors to create individual classification trees, and this process is repeated to generate multiple trees (a forest). Classification is then done by majority vote across all trees.ResultsOf the 3,839 patients, 109 died during hospitalization. Selecting from all available predictors, the random forests had excellent predictive accuracy for classification of death. The mean classification error rate, averaged over 10 forests of 500 trees each, was 11.9\%. The most important predictors were the Charlson Index, respiratory failure, SLE Comorbidity Index, age, sepsis, nephritis, and thrombocytopenia.ConclusionInformation on clinical diagnoses can be used to accurately predict mortality among hospitalized patients with SLE. Random forests represent a useful technique to identify the most important predictors from a larger (often much larger) number and to validate the classification.},
  timestamp = {2017-05-19T07:25:27Z},
  number = {1},
  author = {Ward, Michael M. and Pajevic, Sinisa and Dreyfuss, Jonathan and Malley, James D.},
  urldate = {2013-07-16},
  date = {2006},
  pages = {74--80},
  keywords = {Classification tree,Hospitalization,Mortality,Random forest,Systemic lupus erythematosus}
}

@article{Steinberg_2009,
  title = {{{CART}}: {{Classification}} and {{Regression Trees}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=_kcEn-c9kYAC&oi=fnd&pg=PA179&dq=dan+steinberg+cart&ots=eQ7jtfUODm&sig=Xs8kegu_D4DcrPhT6TUkB0LCV1A},
  shorttitle = {{{CART}}},
  timestamp = {2017-05-19T07:25:27Z},
  author = {Steinberg, Dan and Colla, Phillip},
  urldate = {2013-09-12},
  date = {2009},
  pages = {179--201}
}

@article{Morgan_1963,
  title = {Problems in the {{Analysis}} of {{Survey Data}}, and a {{Proposal}}},
  volume = {58},
  url = {http://amstat.tandfonline.com/doi/full/10.1080/01621459.1963.10500855},
  timestamp = {2017-05-19T07:25:27Z},
  number = {302},
  author = {Morgan, James N. and Sonquist, John A.},
  urldate = {2013-09-17},
  date = {1963},
  pages = {415--434}
}

@article{Cortes_1995,
  title = {Support-{{Vector Networks}}},
  volume = {20},
  issn = {0885-6125},
  doi = {10.1023/A:1022627411411},
  abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data. High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
  timestamp = {2017-05-19T07:25:27Z},
  number = {3},
  author = {Cortes, C. and Vapnik, V.},
  date = {1995-09},
  pages = {273--297},
  keywords = {efficient learning algorithms,neural networks,pattern recognition,polynomial classifiers,radial basis function classifiers}
}

@article{Einhorn_1972,
  title = {Alchemy in the {{Behavioral Sciences}}},
  volume = {36},
  issn = {0033-362X, 1537-5331},
  url = {http://poq.oxfordjournals.org/content/36/3/367},
  doi = {10.1086/268019},
  abstract = {Access to powerful new computers has encouraged routine use of highly complex analytic techniques, often in the absence of any theory, hypotheses, or model to guide the researcher's expectations of results. The author examines the potential of such techniques for generating spurious results, and urges that in exploratory work the outcome be subjected to a more rigorous criterion than the usual tests of statistical significance.},
  timestamp = {2017-05-19T07:25:27Z},
  number = {3},
  author = {Einhorn, Hillel J.},
  urldate = {2013-09-18},
  date = {1972-09-21},
  pages = {367--378}
}

@book{Breiman_1984,
  location = {{Belmont}},
  title = {{{CART}}: {{Classification}} and {{Regression Trees}}},
  volume = {156},
  shorttitle = {{{CART}}},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{Wadsworth}},
  author = {Breiman, Leo and Friedman, Jerome and Olshen, Richard and Stone, Charles and Steinberg, D. and Colla, P.},
  date = {1984}
}

@article{Doyle_1973,
  title = {The {{Use}} of {{Automatic Interaction Detector}} and {{Similar Search Procedures}}},
  timestamp = {2017-05-19T07:25:27Z},
  author = {Doyle, Peter},
  date = {1973},
  pages = {465--467},
  eprinttype = {jstor},
  eprint = {10.2307/3008131}
}

@article{Cover_1967,
  title = {Nearest {{Neighbor Pattern Classification}}},
  volume = {13},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1053964},
  timestamp = {2017-05-19T07:25:27Z},
  number = {1},
  author = {Cover, Thomas and Hart, Peter},
  urldate = {2013-09-19},
  date = {1967},
  pages = {21--27}
}

@article{Friedman_1977,
  title = {Recursive {{Partitioning Decision Rule}} for {{Nonparametric Classification}}},
  volume = {26},
  timestamp = {2017-05-19T07:25:27Z},
  number = {4},
  author = {Friedman, Jh},
  date = {1977},
  pages = {404--408}
}

@article{Quinlan_1986,
  title = {Induction of {{Decision Trees}}},
  volume = {1},
  url = {http://link.springer.com/article/10.1023/A:1022643204877},
  timestamp = {2017-05-19T07:25:27Z},
  number = {1},
  author = {Quinlan, J. Ross},
  urldate = {2013-09-25},
  date = {1986},
  pages = {81--106}
}

@article{Domingos_2012,
  title = {A {{Few Useful Things}} to {{Know}} about {{Machine Learning}}},
  volume = {55},
  url = {http://dl.acm.org/citation.cfm?id=2347755},
  timestamp = {2017-05-19T07:25:27Z},
  number = {10},
  author = {Domingos, Pedro},
  urldate = {2013-09-25},
  date = {2012},
  pages = {78--87}
}

@book{Quinlan_1993,
  location = {{San Francisco, Calif.}},
  title = {C4. 5: {{Programs}} for {{Machine Learning}}},
  volume = {1},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=HExncpjbYroC&oi=fnd&pg=PR7&dq=quinlan+c4.5&ots=nKr8dYr51o&sig=e8CDMoHt0VGemFkhf8z9VMA8KlI},
  shorttitle = {C4. 5},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{Morgan Kaufmann}},
  author = {Quinlan, John Ross},
  urldate = {2013-09-26},
  date = {1993}
}

@book{Bellman_1961,
  location = {{Princeton N.J.}},
  title = {Adaptive {{Control Processes}}: {{A Guided Tour}}},
  volume = {4},
  url = {http://www.getcited.org/pub/101191710},
  shorttitle = {Adaptive {{Control Processes}}},
  timestamp = {2017-05-19T07:25:27Z},
  publisher = {{Princeton University Press}},
  author = {Bellman, Richard},
  urldate = {2013-09-30},
  date = {1961}
}

@article{Chang_2011,
  title = {{{LIBSVM}}: {{A Library}} for {{Support Vector Machines}}},
  volume = {2},
  url = {http://dl.acm.org.ezproxy.lancs.ac.uk/citation.cfm?id=1961199},
  shorttitle = {{{LIBSVM}}},
  timestamp = {2017-05-19T07:25:27Z},
  number = {3},
  author = {Chang, Chih-Chung and Lin, Chih-Jen},
  urldate = {2013-10-04},
  date = {2011},
  pages = {27}
}

@article{Burges_1998,
  title = {A {{Tutorial}} on {{Support Vector Machines}} for {{Pattern Recognition}}},
  volume = {2},
  url = {http://link.springer.com.ezproxy.lancs.ac.uk/article/10.1023/A:1009715923555},
  timestamp = {2017-05-19T07:25:27Z},
  number = {2},
  author = {Burges, Christopher JC},
  urldate = {2013-10-04},
  date = {1998},
  pages = {121--167}
}

@article{Vapnik_1971,
  title = {On the {{Uniform Convergence}} of {{Relative Frequencies}} of {{Events}} to {{Their Probabilities}}},
  volume = {16},
  url = {http://epubs.siam.org/doi/abs/10.1137/1116025},
  timestamp = {2017-05-19T07:25:27Z},
  number = {2},
  author = {Vapnik, Vladimir N. and Chervonenkis, A. Ya},
  urldate = {2013-10-11},
  date = {1971},
  pages = {264--280}
}

@article{Beer_2013,
  title = {Popular {{Culture}}, {{Digital Archives}} and the {{New Social Life}} of {{Data}}},
  volume = {30},
  url = {http://tcs.sagepub.com/content/early/2013/04/15/0263276413476542.abstract},
  timestamp = {2017-05-19T07:25:27Z},
  number = {4},
  author = {Beer, David and Burrows, Roger},
  urldate = {2013-11-22},
  date = {2013},
  pages = {47--71}
}

@book{Rajaraman_2012,
  title = {Mining of {{Massive Datasets}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=OefRhZyYOb0C&oi=fnd&pg=PR5&dq=mining+massive+datasets&ots=aMxxn8InBR&sig=6KdQr6kQaAbaKRMKZ_TywQ8u91s},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Cambridge University Press}},
  author = {Rajaraman, Anand and Ullman, Jeffrey David},
  urldate = {2013-11-27},
  date = {2012}
}

@book{Marx_1986,
  location = {{Moscow}},
  title = {Capital {{A Critique}} of {{Political Economy}}. {{The Process}} of {{Production}} of {{Capital}}},
  shorttitle = {Capital},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Progress}},
  author = {Marx, Karl},
  date = {1986}
}

@book{Mayer-Schonberger_2013,
  location = {{Boston}},
  title = {Big {{Data}}: {{A Revolution That Will Transform How We Live}}, {{Work}}, and {{Think}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=uy4lh-WEhhIC&oi=fnd&pg=PP1&dq=schonberger+big+data&ots=Jrk7hiJVHT&sig=QVKugcrFF4Jq5eO7xd8exEEG_Hk},
  shorttitle = {Big {{Data}}},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Eamon Dolan/Houghton Mifflin Harcourt}},
  author = {Mayer-Schönberger, Viktor and Cukier, Kenneth},
  urldate = {2013-11-28},
  date = {2013}
}

@article{Crisci_2012,
  title = {A {{Review}} of {{Supervised Machine Learning Algorithms}} and {{Their Applications}} to {{Ecological Data}}},
  volume = {240},
  url = {http://www.sciencedirect.com/science/article/pii/S0304380012001081},
  timestamp = {2017-05-19T07:25:28Z},
  author = {Crisci, C. and Ghattas, B. and Perera, G.},
  urldate = {2013-12-05},
  date = {2012},
  pages = {113--122}
}

@book{Flach_2012,
  title = {Machine {{Learning}}: {{The Art}} and {{Science}} of {{Algorithms That Make Sense}} of {{Data}}},
  shorttitle = {Machine {{Learning}}},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Cambridge University Press}},
  author = {Flach, Peter},
  date = {2012}
}

@article{Toscano_2008,
  title = {The {{Open Secret}} of {{Real Abstraction}}},
  volume = {20},
  issn = {0893-5696},
  url = {http://www.tandfonline.com/doi/abs/10.1080/08935690801917304},
  doi = {10.1080/08935690801917304},
  abstract = {This article revisits the Marxist debate on ‘real abstraction’ in order to evaluate the relevance of this concept to a period marked by the rise of cognitive capitalism and a proliferation of discourses on abstraction in social theory. The article touches on the interpretive debates around Marx's 1857 Introduction and tries to identify the tensions and contradictions at work in the distinctive contributions of Louis Althusser, Alfred Sohn-Rethel, and Roberto Finelli to thinking on the specific status of abstraction, in terms of both the methodology of Marxism and the logic and ontology of capitalism. These foundational debates are then contrasted with attempts by Paolo Virno and Lorenzo Cillario to think the contemporary figures of abstraction in terms of its politicization, on the one hand, and its operational role in the labor process, on the other.},
  timestamp = {2017-05-19T07:25:28Z},
  number = {2},
  author = {Toscano, Alberto},
  urldate = {2014-01-14},
  date = {2008},
  pages = {273--287}
}

@book{Ripley_1996,
  location = {{Cambridge ; New York}},
  title = {Pattern {{Recognition}} and {{Neural Networks}}. 1996},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Cambridge University Press}},
  author = {Ripley, Brian},
  date = {1996}
}

@article{Smith_2013,
  title = {Theses on the {{Philosophy}} of {{History}}: {{The Work}} of {{Research}} in the {{Age}} of {{Digital Searchability}} and {{Distributability}}},
  volume = {12},
  issn = {1470-4129, 1741-2994},
  url = {http://vcu.sagepub.com.ezproxy.lancs.ac.uk/content/12/3/375},
  doi = {10.1177/1470412913507505},
  shorttitle = {Theses on the {{Philosophy}} of {{History}}},
  abstract = {What is it to conduct research in the second decade of the 21st century? What is the nature (or what are the modalities) of the work that we as researchers do? What is research as a praxis? And how have recent shifts in paradigms of knowledge generation and distribution – especially around the archive and the Internet, and the Internet as archival – transformed profoundly what we as researchers do, how we do it, and in fact even our very capacity to do it? In this article, I begin from the idea of research as a praxis, and from the figure of the researcher as a locus for the discovery of knowledges by way of acts of searching and gathering. In 15 theses I engage critically with challenges raised recently for the idea of ‘history’ as a form of knowledge by our own épistémè of re-search; one whose conditions and conditions of possibility are delineated by the emergence of our late capitalist global algorithmic knowledge economy, and the Internet with its distinct operations of searchability and distributability. Because this is our present moment’s épistémè of re-search, I argue that our being in thrall of the archive has dangerous future consequences: in fact it is perilous for the very idea of the future itself as a category of historical time. Concerned by this situation and thus responding forcefully to it, in offering a few grains of dissent I will ‘look with care’ at how we might navigate our way fractiously and thus productively through such a predicament.},
  timestamp = {2017-05-19T07:25:28Z},
  number = {3},
  author = {Smith, Marquard},
  urldate = {2013-12-11},
  date = {2013-12-01},
  pages = {375--403},
  keywords = {curiosity,History,hope,knowledge,metadata,Research,the archival,the archive,the Internet}
}

@book{Venables_2000,
  title = {S {{Programming}}},
  isbn = {978-0-387-98966-2},
  abstract = {S is a high-level language for manipulating, analysing and displaying data. It forms the basis of two highly acclaimed and widely used data analysis software systems, the commercial S-PLUS® and the Open Source R. This book provides an in-depth guide to writing software in the S language under either or both of those systems. It is intended for readers who have some acquaintance with the S language and want to know how to use it more effectively, for example to build re-usable tools for streamlining routine data analysis or to implement new statistical methods. One of the outstanding strengths of the S language is the ease with which it can be extended by users. S is a functional language, and functions written by users are first-class objects treated in the same way as functions provided by the system. S code is eminently readable and so a good way to document precisely what algorithms were used, and as much of the implementations are themselves written in S, they can be studied as models and to understand their subtleties. The current implementations also provide easy ways for S functions to call compiled code written in C, Fortran and similar languages; this is documented here in depth. Increasingly S is being used for statistical or graphical analysis within larger software systems or for whole vertical-market applications. The interface facilities are most developed on Windows® and these are covered with worked examples. The authors have written the widely used Modern Applied Statistics with S-PLUS, now in its third edition, and several software libraries that enhance S-PLUS and R; these and the examples used in both books are available on the Internet. Dr. W.N. Venables is a senior Statistician with the CSIRO/CMIS Environmetrics Project in Australia, having been at the Department of Statistics, University of Adelaide for many years previously. Professor B.D. Ripley holds the Chair of Applied Statistics at the University of Oxford, and is the author of four other books on spatial statistics, simulation, pattern recognition and neural networks. Both authors are known and respected throughout the international S and R communities, for their books, workshops, short courses, freely available software and through their extensive contributions to the S-news and R mailing lists.},
  timestamp = {2017-05-19T07:25:28Z},
  publisher = {{Springer}},
  author = {Venables, William and Ripley, B. D.},
  date = {2000-04-20},
  keywords = {Computers / Mathematical & Statistical Software,Computers / Programming Languages / General,Mathematics / Probability & Statistics / Stochastic Processes}
}

@book{Cox_2012,
  title = {Speaking {{Code}}: {{Coding}} as {{Aesthetic}} and {{Political Expression}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=wgnSUL0zh5gC&oi=fnd&pg=PR2&dq=code+speech+freedom+alex+mit+press&ots=IzF3Hw5cJc&sig=Zh_szUmz064Yd9-1ntF2WXmUBf4},
  shorttitle = {Speaking {{Code}}},
  timestamp = {2017-05-19T07:25:29Z},
  publisher = {{MIT Press}},
  author = {Cox, Geoff},
  urldate = {2013-12-12},
  date = {2012}
}

@article{Valiant_1984,
  title = {A {{Theory}} of the {{Learnable}}},
  volume = {27},
  url = {http://dl.acm.org/citation.cfm?id=1972},
  timestamp = {2017-05-19T07:25:29Z},
  number = {11},
  author = {Valiant, Leslie G.},
  urldate = {2013-12-16},
  date = {1984},
  pages = {1134--1142}
}

@book{Jain_2008,
  title = {Data {{Clustering}}: 50 {{Years Beyond K}}-{{Means}}},
  shorttitle = {Data {{Clustering}}},
  abstract = {Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into taxonomic ranks: domain, kingdom, phylum, class, etc.). Cluster analysis is the formal study of algorithms and methods for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is exploratory in nature to find structure in data. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty of designing a general purpose clustering algorithm and the illposed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection, and data clustering and large scale data clustering.},
  timestamp = {2017-05-19T07:25:29Z},
  author = {Jain, Anil K.},
  date = {2008}
}

@article{Bowker_1993,
  title = {How to {{Be Universal}}: {{Some Cybernetic Strategies}}, 1943-70},
  volume = {23},
  issn = {0306-3127},
  url = {http://sss.sagepub.com.ezproxy.lancs.ac.uk/content/23/1/107.full.pdf+html},
  doi = {10.1177/030631293023001004},
  shorttitle = {How to {{Be Universal}}},
  timestamp = {2017-05-19T07:25:29Z},
  number = {1},
  author = {Bowker, G.},
  urldate = {2013-12-17},
  date = {1993-02-01},
  pages = {107--127}
}

@book{Lanier_2013,
  location = {{London}},
  title = {Who {{Owns}} the {{Future}}?},
  isbn = {978-1-84614-522-3 1-84614-522-8 978-0-241-95722-6 0-241-95722-2},
  abstract = {Shows how the new power paradigm operates, how it is conceived and controlled, and why it is leading to a collapse in living standards. Arguing that the 'information economy' ruins markets, this title reminds us that markets should reward more people, not fewer.},
  timestamp = {2017-05-19T07:25:29Z},
  publisher = {{Allen Lane}},
  author = {Lanier, Jaron},
  date = {2013}
}

@online{Cukier_2013,
  title = {The {{Rise}} of {{Big Data}}. {{How It}}'s {{Changing}} the {{Way We Think About}} the {{World}}},
  url = {http://www.foreignaffairs.com/articles/139104/kenneth-neil-cukier-and-viktor-mayer-schoenberger/the-rise-of-big-data},
  timestamp = {2017-05-19T07:25:29Z},
  author = {Cukier, Kenneth Neil and {Mayer-Schoenberger}},
  urldate = {2014-02-10},
  date = {2013}
}

@book{Solovey_2012,
  title = {Cold {{War Social Science}}: {{Knowledge Production}}, {{Liberal Democracy}}, and {{Human Nature}}},
  isbn = {978-1-137-01322-4},
  shorttitle = {Cold {{War Social Science}}},
  abstract = {From World War II to the early 1970s, social science research expanded in dramatic and unprecedented fashion in the United States, which became the world's acknowledged leader in the field. This volume examines how, why, and with what consequences this rapid and yet contested expansion depended on the entanglement of the social sciences with the Cold War. Utilizing the controversial but useful concept of "Cold War Social Science," the contributions gathered here reveal how scholars from established disciplines and new interdisciplinary fields of study made important contributions to long-standing debates about knowledge production, liberal democracy, and human nature in an era of diplomatic tension and ideological conflict.},
  timestamp = {2017-05-19T07:25:29Z},
  publisher = {{Palgrave Macmillan}},
  author = {Solovey, Mark and Cravens, Hamilton},
  date = {2012-01-31},
  keywords = {History / General,History / Social History,History / United States / 20th Century,Political Science / History & Theory,Political Science / Political Ideologies / Democracy,SOCIAL SCIENCE / Methodology,SOCIAL SCIENCE / Research}
}

@article{Mapstone_2014,
  title = {Plasma {{Phospholipids Identify Antecedent Memory Impairment}} in {{Older Adults}}},
  volume = {advance online publication},
  issn = {1078-8956},
  url = {http://www.nature.com/nm/journal/vaop/ncurrent/full/nm.3466.html},
  doi = {10.1038/nm.3466},
  abstract = {Alzheimer's disease causes a progressive dementia that currently affects over 35 million individuals worldwide and is expected to affect 115 million by 2050 (ref. 1). There are no cures or disease-modifying therapies, and this may be due to our inability to detect the disease before it has progressed to produce evident memory loss and functional decline. Biomarkers of preclinical disease will be critical to the development of disease-modifying or even preventative therapies. Unfortunately, current biomarkers for early disease, including cerebrospinal fluid tau and amyloid-β levels, structural and functional magnetic resonance imaging and the recent use of brain amyloid imaging or inflammaging, are limited because they are either invasive, time-consuming or expensive. Blood-based biomarkers may be a more attractive option, but none can currently detect preclinical Alzheimer's disease with the required sensitivity and specificity. Herein, we describe our lipidomic approach to detecting preclinical Alzheimer's disease in a group of cognitively normal older adults. We discovered and validated a set of ten lipids from peripheral blood that predicted phenoconversion to either amnestic mild cognitive impairment or Alzheimer's disease within a 2–3 year timeframe with over 90\% accuracy. This biomarker panel, reflecting cell membrane integrity, may be sensitive to early neurodegeneration of preclinical Alzheimer's disease.},
  timestamp = {2017-05-19T07:25:29Z},
  author = {Mapstone, Mark and Cheema, Amrita K. and Fiandaca, Massimo S. and Zhong, Xiaogang and Mhyre, Timothy R. and MacArthur, Linda H. and Hall, William J. and Fisher, Susan G. and Peterson, Derick R. and Haley, James M. and Nazar, Michael D. and Rich, Steven A. and Berlau, Dan J. and Peltz, Carrie B. and Tan, Ming T. and Kawas, Claudia H. and Federoff, Howard J.},
  urldate = {2014-03-11},
  date = {2014-03-09}
}

@article{Warner_1961,
  title = {A {{Mathematical Approach}} to {{Medical Diagnosis}}: {{Application}} to {{Congenital Heart Disease}}},
  volume = {177},
  url = {http://jama.jamanetwork.com/article.aspx?articleid=331443},
  shorttitle = {A {{Mathematical Approach}} to {{Medical Diagnosis}}},
  timestamp = {2017-05-19T07:25:29Z},
  number = {3},
  author = {Warner, Homer R. and Toronto, Alan F. and Veasey, L. George and Stephenson, Robert},
  urldate = {2014-03-17},
  date = {1961},
  pages = {177--183}
}

@article{Titterington_1981,
  title = {Comparison of {{Discrimination Techniques Applied}} to a {{Complex Data Set}} of {{Head Injured Patients}}},
  timestamp = {2017-05-19T07:25:29Z},
  author = {Titterington, D. M. and Murray, G. D. and Murray, L. S. and Spiegelhalter, D. J. and Skene, A. M. and Habbema, J. D. F. and Gelpke, G. J.},
  date = {1981},
  pages = {145--175},
  eprinttype = {jstor},
  eprint = {2981918}
}

@article{Michie_1994,
  title = {Machine {{Learning}}, {{Neural}} and {{Statistical Classification}}},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.27.355},
  timestamp = {2017-05-19T07:25:29Z},
  author = {Michie, Donald and Spiegelhalter, David J. and Taylor, Charles C.},
  urldate = {2014-03-17},
  date = {1994}
}

@article{Hand_2001,
  title = {Idiot's {{Bayes}} - {{Not}} so {{Stupid}} after {{All}}?},
  volume = {69},
  issn = {0306-7734},
  doi = {10.2307/1403452},
  abstract = {Folklore has it that a very simple supervised classification rule, based on the typically false assumption that the predictor variables are independent, can be highly effective, and often more effective than sophisticated rules. We examine the evidence for this, both empirical, as observed in real data applications, and theoretical, summarising explanations for why this simple rule might be effective.},
  timestamp = {2017-05-19T07:25:29Z},
  number = {3},
  author = {Hand, D. J. and Yu, K. M.},
  date = {2001-12},
  pages = {385--398},
  keywords = {acute abdomen,acute abdominal-pain,assisted diagnosis,assuming independence,Classification,computer-aided diagnosis,decision,diagnosis,distributions,identification,independence model,naive Bayes,simple Bayes,supervised classification,theorem}
}

@article{Domingos_1997,
  title = {On the {{Optimality}} of the {{Simple Bayesian Classifier}} under {{Zero}}-{{One Loss}}},
  volume = {29},
  url = {http://link.springer.com/article/10.1023/A:1007413511361},
  timestamp = {2017-05-19T07:25:29Z},
  issue = {2-3},
  author = {Domingos, Pedro and Pazzani, Michael},
  urldate = {2014-03-24},
  date = {1997},
  pages = {103--130}
}

@incollection{Lewis_1998,
  title = {Naive ({{Bayes}}) at {{Forty}}: {{The Independence Assumption}} in {{Information Retrieval}}},
  url = {http://link.springer.com/chapter/10.1007/BFb0026666},
  shorttitle = {Naive ({{Bayes}}) at {{Forty}}},
  timestamp = {2017-05-19T07:25:29Z},
  booktitle = {Machine {{Learning}}: {{ECML}}-98},
  publisher = {{Springer}},
  author = {Lewis, David D.},
  urldate = {2014-03-24},
  date = {1998},
  pages = {4--15}
}

@article{Flach_2001,
  title = {On the {{State}} of the {{Art}} in {{Machine Learning}}: {{A Personal Review}}},
  volume = {131},
  url = {http://www.sciencedirect.com/science/article/pii/S0004370201001254},
  shorttitle = {On the {{State}} of the {{Art}} in {{Machine Learning}}},
  timestamp = {2017-05-19T07:25:29Z},
  number = {1},
  author = {Flach, Peter A.},
  urldate = {2014-03-26},
  date = {2001},
  pages = {199--222}
}

@article{Lazer_2014,
  title = {The {{Parable}} of {{Google Flu}}: {{Traps}} in {{Big Data Analysis}}},
  volume = {343},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/content/343/6176/1203},
  doi = {10.1126/science.1248506},
  shorttitle = {The {{Parable}} of {{Google Flu}}},
  timestamp = {2017-05-19T07:25:29Z},
  number = {6176},
  author = {Lazer, David and Kennedy, Ryan and King, Gary and Vespignani, Alessandro},
  urldate = {2014-03-28},
  date = {2014-03-14},
  pages = {1203--1205}
}

@online{Jonze_2014,
  title = {Her: {{A Spike Jonze Love Story}}},
  url = {http://www.herthemovie.com/#/about},
  timestamp = {2017-05-19T07:25:30Z},
  author = {Jonze, Spike},
  urldate = {2014-04-04},
  date = {2014}
}

@inproceedings{Tang_2010,
  title = {Overlapping {{Experiment Infrastructure}}: {{More}}, {{Better}}, {{Faster Experimentation}}},
  url = {http://dl.acm.org/citation.cfm?id=1835810},
  shorttitle = {Overlapping {{Experiment Infrastructure}}},
  timestamp = {2017-05-19T07:25:30Z},
  booktitle = {Proceedings of the 16th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  publisher = {{ACM}},
  author = {Tang, Diane and Agarwal, Ashish and O'Brien, Deirdre and Meyer, Mike},
  urldate = {2014-04-13},
  date = {2010},
  pages = {17--26}
}

@book{Witten_2005,
  title = {Data {{Mining}}: {{Practical Machine Learning Tools}} and {{Techniques}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=QTnOcZJzlUoC&oi=fnd&pg=PR17&dq=witten+data+mining&ots=3gpEclZjOh&sig=fJWant_52rRAyelcWkW1vEVFg3I},
  shorttitle = {Data {{Mining}}},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Morgan Kaufmann}},
  author = {Witten, Ian H. and Frank, Eibe},
  urldate = {2014-04-24},
  date = {2005}
}

@article{Guyon_2003,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  volume = {3},
  url = {http://dl.acm.org/citation.cfm?id=944968},
  timestamp = {2017-05-19T07:25:30Z},
  author = {Guyon, Isabelle and Elisseeff, André},
  urldate = {2014-04-25},
  date = {2003},
  pages = {1157--1182}
}

@online{Ltd_2014,
  title = {Home| {{The First A}}.{{I}}. {{Home Console}}},
  url = {http://emospark.com/},
  abstract = {EmoSPARK - The World First A.I. Home Console},
  timestamp = {2017-05-19T07:25:30Z},
  author = {Ltd, Emoshape},
  urldate = {2014-05-01},
  date = {2014}
}

@article{Amoore_2015,
  title = {Life beyond {{Big Data}}: {{Governing}} with {{Little Analytics}}},
  volume = {44},
  issn = {0308-5147},
  url = {http://dx.doi.org/10.1080/03085147.2015.1043793},
  doi = {10.1080/03085147.2015.1043793},
  shorttitle = {Life beyond {{Big Data}}},
  abstract = {The twenty-first-century rise of big data marks a significant break with statistical notions of what is of interest or concern. The vast expansion of digital data has been closely intertwined with the development of advanced analytical algorithms with which to make sense of the data. The advent of techniques of knowledge discovery affords some capacity for the analytics to derive the object or subject of interest from clusters and patterns in large volumes of data, otherwise imperceptible to human reading. Thus, the scale of the big in big data is of less significance to contemporary forms of knowing and governing than what we will call the little analytics. Following Henri Bergson's analysis of forms of perception which ‘cut out’ a series of figures detached from the whole, we propose that analytical algorithms are instruments of perception without which the extensity of big data would not be comprehensible. The technologies of analytics focus human attention and decision on particular persons and things of interest, whilst annulling or discarding much of the material context from which they are extracted. Following the algorithmic processes of ingestion, partitioning and memory, we illuminate how the use of analytics engines has transformed the nature of analysis and knowledge and, thus, the nature of the governing of economic, social and political life.},
  timestamp = {2017-05-19T07:25:30Z},
  number = {3},
  author = {Amoore, Louise and Piotukh, Volha},
  urldate = {2016-02-01},
  date = {2015-07-03},
  pages = {341--366}
}

@article{Jordan_2015,
  title = {Machine {{Learning}}: {{Trends}}, {{Perspectives}}, and {{Prospects}}},
  volume = {349},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org/content/349/6245/255},
  doi = {10.1126/science.aaa8415},
  shorttitle = {Machine {{Learning}}},
  abstract = {Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.},
  timestamp = {2017-05-19T07:25:30Z},
  number = {6245},
  author = {Jordan, M. I. and Mitchell, T. M.},
  urldate = {2015-09-19},
  date = {2015-07-17},
  pages = {255--260}
}

@article{Ghahramani_2015,
  title = {Probabilistic {{Machine Learning}} and {{Artificial Intelligence}}},
  volume = {521},
  issn = {0028-0836},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nature/journal/v521/n7553/full/nature14541.html},
  doi = {10.1038/nature14541},
  abstract = {How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.},
  timestamp = {2017-05-19T07:25:30Z},
  number = {7553},
  author = {Ghahramani, Zoubin},
  urldate = {2015-09-19},
  date = {2015-05-28},
  pages = {452--459},
  keywords = {Computer Science,Mathematics and computing,neuroscience}
}

@article{Schmidhuber_2015,
  title = {Deep {{Learning}} in {{Neural Networks}}: {{An Overview}}},
  volume = {61},
  issn = {0893-6080},
  url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
  doi = {10.1016/j.neunet.2014.09.003},
  shorttitle = {Deep {{Learning}} in {{Neural Networks}}},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  timestamp = {2017-05-19T07:25:30Z},
  author = {Schmidhuber, Jürgen},
  urldate = {2015-09-21},
  date = {2015-01},
  pages = {85--117},
  keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning}
}

@book{Baldi_2001,
  location = {{Cambridge, Mass}},
  edition = {2nd},
  title = {Bioinformatics: {{The Machine Learning Approach}}, {{Second Edition}}},
  isbn = {978-0-262-02506-5},
  shorttitle = {Bioinformatics},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{A Bradford Book}},
  author = {Baldi, Pierre},
  date = {2001}
}

@online{Hothorn_2014,
  title = {{{CRAN Task View}}: {{Machine Learning}} \& {{Statistical Learning}}},
  url = {http://CRAN.R-project.org/view=MachineLearning},
  shorttitle = {{{CRAN Task View}}},
  timestamp = {2017-05-19T07:25:30Z},
  author = {Hothorn, Torsten},
  urldate = {2015-09-22},
  date = {2014-12-18}
}

@book{Abramowitz_1965,
  location = {{New York}},
  title = {Handbook of {{Mathematical Functions}} : {{With Formulas}},{{Graphs}},and {{Mathematical Tables}}},
  shorttitle = {Handbook of {{Mathematical Functions}}},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Dover Books}},
  author = {Abramowitz, Milton},
  date = {1965}
}

@book{Domingos_2015,
  location = {{New York}},
  title = {The {{Master Algorithm}}: {{How}} the {{Quest}} for the {{Ultimate Learning Machine Will Remake Our World}}},
  isbn = {978-0-465-06570-7},
  shorttitle = {The {{Master Algorithm}}},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Basic Civitas Books}},
  author = {Domingos, Pedro},
  date = {2015-09-01}
}

@book{Boyd_2004,
  location = {{Cambridge ; New York}},
  title = {Convex {{Optimization}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=IUZdAAAAQBAJ&oi=fnd&pg=PR11&dq=boyd+convex&ots=HMIBdk5GAj&sig=3zx9GlXT4pYe2THUwk5i-tRJSlE},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Cambridge university press}},
  author = {Boyd, Stephen and Vandenberghe, Lieven},
  urldate = {2015-09-26},
  date = {2004}
}

@book{Aristotle_1975,
  title = {Aristotle's {{Categories}} and de {{Interpretatione}}},
  isbn = {978-0-19-872086-7},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Oxford University Press}},
  author = {{Aristotle}},
  translator = {Ackrill, J.L.},
  date = {1975}
}

@book{Franchi_2011,
  title = {The {{Search}} for a {{Theory}} of {{Cognition}}: {{Early Mechanisms}} and {{New Ideas}}},
  isbn = {978-94-012-0715-7},
  shorttitle = {The {{Search}} for a {{Theory}} of {{Cognition}}},
  abstract = {The book brings into relief the variety of approaches and disciplines that have informed the quest for a theory of cognition. The center of interest are the historical, geographical, and theoretical peripheries of classic AI's mainstream research program. The twelve chapters bring back into focus the variety of strategies and theoretical questions that researchers explored while working toward a scientific theory of cognition and pre-cognition.The volume is organized in four parts, each one including three essays. The first one deals with cybernetics, the approach that may be considered as the most important periphery of classic AI research. The second part focuses on the geographical periphery of AI research. It examines how the theories and techniques developed on AI's home ground were translated into countries with different cultures and traditions: Italy, France, and the Soviet Union. The third part focuses on AI's periphery understood in the cultural and historical meaning of the term. It contains essays that locate some of the central concepts of AI, like representation and computability, within a broader philosophical (Descartes, Aristotle, Leibniz) and technical background (programming theory and practice). The fourth and final part of the volume is focused directly on the limitation of Turing's classic computability theory and its possible alternatives, some of which were studied in the early years of AI's research (e.g. Ashby's re-entrant information model), while others have been intensely studied in recent times (quantum automata).},
  timestamp = {2017-05-19T07:25:30Z},
  publisher = {{Rodopi}},
  author = {Franchi, Stefano and Bianchini, Francesco},
  date = {2011},
  keywords = {COMPUTERS / Enterprise Applications / Business Intelligence Tools,COMPUTERS / Intelligence (AI) & Semantics,Science / Cognitive Science}
}

@incollection{Klimt_2004,
  title = {The {{Enron Corpus}}: {{A New Dataset}} for {{Email Classification Research}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-30115-8_22},
  shorttitle = {The {{Enron Corpus}}},
  timestamp = {2017-05-19T07:25:30Z},
  booktitle = {Machine {{Learning}}: {{ECML}} 2004},
  publisher = {{Springer}},
  author = {Klimt, Bryan and Yang, Yiming},
  urldate = {2015-10-01},
  date = {2004},
  pages = {217--226}
}

@article{Friedman_1997,
  title = {On {{Bias}}, {{Variance}}, 0/1—loss, and the {{Curse}}-of-{{Dimensionality}}},
  volume = {1},
  url = {http://link.springer.com/article/10.1023/A:1009778005914},
  timestamp = {2017-05-19T07:25:31Z},
  number = {1},
  author = {Friedman, Jerome H.},
  urldate = {2015-10-02},
  date = {1997},
  pages = {55--77}
}

@article{Stone_1974,
  title = {Cross-{{Validatory Choice}} and {{Assessment}} of {{Statistical Predictions}}},
  timestamp = {2017-05-19T07:25:31Z},
  author = {Stone, Mervyn},
  date = {1974},
  pages = {111--147},
  eprinttype = {jstor},
  eprint = {2984809}
}

@article{Hallinan_2014,
  title = {Recommended for {{You}}: {{The Netflix Prize}} and the {{Production}} of {{Algorithmic Culture}}},
  issn = {1461-4448, 1461-7315},
  url = {http://nms.sagepub.com/content/early/2014/06/23/1461444814538646},
  doi = {10.1177/1461444814538646},
  shorttitle = {Recommended for {{You}}},
  abstract = {How does algorithmic information processing affect the meaning of the word culture, and, by extension, cultural practice? We address this question by focusing on the Netflix Prize (2006–2009), a contest offering US\$1m to the first individual or team to boost the accuracy of the company’s existing movie recommendation system by 10\%. Although billed as a technical challenge intended for engineers, we argue that the Netflix Prize was equally an effort to reinterpret the meaning of culture in ways that overlapped with, but also diverged in important respects from, the three dominant senses of the term assayed by Raymond Williams. Thus, this essay explores the conceptual and semantic work required to render algorithmic information processing systems legible as forms of cultural decision making. It also then represents an effort to add depth and dimension to the concept of “algorithmic culture.”},
  timestamp = {2017-05-19T07:25:31Z},
  author = {Hallinan, Blake and Striphas, Ted},
  urldate = {2015-09-08},
  date = {2014-06-23},
  pages = {1--21},
  keywords = {algorithm,algorithmic culture,Culture,data,movies,Netflix,ratings,Raymond Williams,recommendation,send_me_fulltext,taste}
}

@book{_2014,
  title = {The {{Lure}} of {{Whitehead}}},
  isbn = {978-1-4529-4320-6},
  abstract = {Once largely ignored, the speculative philosophy of Alfred North Whitehead has assumed a new prominence in contemporary theory across the humanities and social sciences. Philosophers and artists, literary critics and social theorists, anthropologists and computer scientists have all embraced Whitehead's thought, extending it through inquiries into the nature of life, the problem of consciousness, and the ontology of objects, as well as into experiments in education and digital media.The Lure of Whiteheadoffers readers not only a comprehensive introduction to Whitehead's philosophy but also a demonstration of how his work advances our emerging understanding of life in the posthuman epoch.Contributors: Jeffrey A. Bell, Southeastern Louisiana U; Nathan Brown, U of California, Davis; Peter Canning; Didier Debaise, Free U of Brussels; Roland Faber, Claremont Lincoln U; Michael Halewood, U of Essex; Graham Harman, American U in Cairo; Bruno Latour, Sciences Po Paris; Erin Manning, Concordia U, Montreal; Steven Meyer, Washington U; Luciana Parisi, U of London; Keith Robinson, U of Arkansas at Little Rock; Isabelle Stengers, Free U of Brussels; James Williams, U of Dundee.},
  timestamp = {2017-05-19T07:25:31Z},
  publisher = {{University of Minnesota Press}},
  date = {2014},
  eprinttype = {jstor},
  eprint = {10.5749/j.ctt9qh3hs}
}

@article{Heis_2014,
  title = {Ernst {{Cassirer}}’s {{Substanzbegriff Und Funktionsbegriff}}},
  volume = {4},
  issn = {2152-5188},
  doi = {10.1086/676959},
  abstract = {Ernst Cassirer’s book Substanzbegriff und Funktionsbegriff is a difficult book for contemporary readers to understand. Its topic, the theory of concept formation, engages with debates and authors that are largely unknown today. And its “historical” style violates the philosophical standards of clarity first propounded by early analytic philosophers. Cassirer, for instance, never says explicitly what he means by “substance-concept” and “function-concept.” In this article, I answer three questions: Why did Cassirer choose to focus on the topic of concept formation? What did Cassirer mean in contrasting “substance-concepts” and “function-concepts”? How does Cassirer’s polemic against traditional theories of concept formation lead to the distinctive philosophy of mathematics that he defends in the book? I argue that Cassirer’s contrast between substance-concepts and function-concepts includes a series of interrelated contrasts—contrasts that touch on issues in logic, metaphysics, epistemology, and the theory of objectivity. Cassirer’s defense of mathematical structuralism flows out of a progressively unfolding and intricate argument that begins with epistemological problems in the theory of concept formation.},
  timestamp = {2017-05-19T07:25:31Z},
  number = {2},
  author = {Heis, Jeremy},
  date = {2014-09-01},
  pages = {241--270},
  eprinttype = {jstor},
  eprint = {10.1086/676959}
}

@online{Agency_2012,
  title = {{{SKYNET}}: {{Courier Detection}} via {{Machine Learning}}},
  url = {https://theintercept.com/document/2015/05/08/skynet-courier/},
  shorttitle = {{{SKYNET}}},
  timestamp = {2017-05-19T07:25:31Z},
  author = {Agency, National Security},
  urldate = {2015-10-29},
  date = {2012}
}

@book{Massumi_2013,
  location = {{Cambridge, Mass.}},
  edition = {Reprint edition},
  title = {Semblance and {{Event}}: {{Activist Philosophy}} and the {{Occurrent Arts}}},
  isbn = {978-0-262-52536-7},
  shorttitle = {Semblance and {{Event}}},
  timestamp = {2017-05-19T07:25:31Z},
  publisher = {{MIT Press}},
  author = {Massumi, Brian},
  date = {2013-09-06}
}

@article{Cheney-Lippold_2011,
  title = {A {{New Algorithmic Identity Soft Biopolitics}} and the {{Modulation}} of {{Control}}},
  volume = {28},
  url = {http://tcs.sagepub.com/content/28/6/164.short},
  timestamp = {2017-05-19T07:25:31Z},
  number = {6},
  author = {Cheney-Lippold, John},
  urldate = {2015-11-01},
  date = {2011},
  pages = {164--181}
}

@online{Fico_2015,
  title = {{{FICO}}® {{Analytic Modeler Decision Tree Professional}} | {{FICO}}™},
  url = {http://www.fico.com/en/products/fico-analytic-modeler-decision-tree-professional},
  abstract = {FICO Analytic Modeler Decision Tree Professional Decision Tree Professional supports robust decision rules that consider multiple business objectives, so users generate better insights—and make better decision},
  timestamp = {2017-05-19T07:25:31Z},
  author = {{Fico}},
  urldate = {2015-11-01},
  date = {2015}
}

@article{Appadurai_2012,
  title = {The {{Spirit}} of {{Calculation}}},
  volume = {30},
  doi = {10.3167/ca.2012.300102},
  abstract = {This paper is built on a close reading of the use of the term 'calculation' by Max Weber. On the basis of this reading, I argue for a deeper understanding of Weber's views on uncertainty in the Calvinist ethos, and for a new approach to some key issues in the moral and discursive world of nancial capital today, in which accounting, accountability and pro t-making have become dangerously delinked from one another.},
  timestamp = {2017-05-19T07:25:31Z},
  number = {1},
  author = {Appadurai, Arjun},
  date = {2012-03-01},
  pages = {3--17},
  keywords = {Calculation,Ethos,Max Weber,Nancial Capital,uncertainty}
}

@article{Striphas_2015,
  title = {Algorithmic {{Culture}}},
  volume = {18},
  issn = {1367-5494, 1460-3551},
  url = {http://ecs.sagepub.com/content/18/4-5/395},
  doi = {10.1177/1367549415577392},
  abstract = {Over the last 30 years or so, human beings have been delegating the work of culture – the sorting, classifying and hierarchizing of people, places, objects and ideas – increasingly to computational processes. Such a shift significantly alters how the category culture has long been practiced, experienced and understood, giving rise to what, following Alexander Galloway, I am calling ‘algorithmic culture’. The purpose of this essay is to trace some of the conceptual conditions out of which algorithmic culture has emerged and, in doing so, to offer a preliminary treatment on what it is. In the vein of Raymond Williams’ Keywords, I single out three terms whose bearing on the meaning of the word culture seems to have been unusually strong during the period in question: information, crowd and algorithm. My claim is that the offloading of cultural work onto computers, databases and other types of digital technologies has prompted a reshuffling of some of the words most closely associated with culture, giving rise to new senses of the term that may be experientially available but have yet to be well named, documented or recorded. This essay, though largely historical, concludes by connecting the dots critically to the present day. What is at stake in algorithmic culture is the gradual abandonment of culture’s publicness and the emergence of a strange new breed of elite culture purporting to be its opposite.},
  timestamp = {2017-05-19T07:25:31Z},
  issue = {4-5},
  author = {Striphas, Ted},
  urldate = {2015-11-18},
  date = {2015-08-01},
  pages = {395--412},
  keywords = {Algorism,algorithm,algorithmic culture,big data,crowd,Culture,Information,keywords,Raymond Williams}
}

@article{Bogost_2015,
  title = {The {{Cathedral}} of {{Computation}}},
  issn = {1072-7825},
  url = {http://www.theatlantic.com/technology/archive/2015/01/the-cathedral-of-computation/384300/},
  abstract = {We’re not living in an algorithmic culture so much as a computational theocracy.},
  timestamp = {2017-05-19T07:25:31Z},
  author = {Bogost, Ian},
  urldate = {2015-11-19},
  date = {2015-01-15}
}

@article{Worsley_2002,
  title = {A {{General Statistical Analysis}} for {{fMRI Data}}},
  volume = {15},
  issn = {1053-8119},
  url = {http://www.sciencedirect.com/science/article/pii/S1053811901909334},
  doi = {10.1006/nimg.2001.0933},
  abstract = {We propose a method for the statistical analysis of fMRI data that seeks a compromise between efficiency, generality, validity, simplicity, and execution speed. The main differences between this analysis and previous ones are: a simple bias reduction and regularization for voxel-wise autoregressive model parameters; the combination of effects and their estimated standard deviations across different runs/sessions/subjects via a hierarchical random effects analysis using the EM algorithm; overcoming the problem of a small number of runs/session/subjects using a regularized variance ratio to increase the degrees of freedom.},
  timestamp = {2017-05-19T07:25:31Z},
  number = {1},
  author = {Worsley, K. J. and Liao, C. H. and Aston, J. and Petre, V. and Duncan, G. H. and Morales, F. and Evans, A. C.},
  urldate = {2015-12-03},
  date = {2002-01},
  pages = {1--15},
  keywords = {bias reduction,EM algorithm,fMRI,hemodynamic response function,linear regression,random effects}
}

@article{Courtial_1989,
  title = {A {{Co}}-{{Word Study}} of {{Artificial}}-{{Intelligence}}},
  volume = {19},
  issn = {0306-3127},
  doi = {10.1177/030631289019002005},
  timestamp = {2017-05-19T07:25:31Z},
  number = {2},
  author = {Courtial, Jp and Law, J.},
  date = {1989-05},
  pages = {301--311}
}

@article{Hacking_2004,
  title = {Between {{Michel Foucault}} and {{Erving Goffman}}: {{Between Discourse}} in the {{Abstract}} and {{Face}}-to-{{Face Interaction}}},
  volume = {33},
  issn = {0308-5147},
  url = {http://dx.doi.org/10.1080/0308514042000225671},
  doi = {10.1080/0308514042000225671},
  shorttitle = {Between {{Michel Foucault}} and {{Erving Goffman}}},
  abstract = {Michel Foucault's ‘archaeology’ and Erving Goffman's interpersonal sociology are complementary. Both are essential for understanding how classifications of people interact with the people classified, and hence for the author's studies of ‘making up people’. The paper begins by explaining how that project is rooted in an ‘existentialist’ conception of the person. It then uses Goffman's Asylums and Foucault's Folie et déraison - both published in 1961 - to illustrate how these methodologies reinforce each other.},
  timestamp = {2017-05-19T07:25:31Z},
  number = {3},
  author = {Hacking, Ian},
  urldate = {2015-12-18},
  date = {2004-08-01},
  pages = {277--302}
}

@article{Mnih_2015,
  title = {Human-{{Level Control}} through {{Deep Reinforcement Learning}}},
  volume = {518},
  issn = {0028-0836},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nature/journal/v518/n7540/full/nature14236.html},
  doi = {10.1038/nature14236},
  abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
  timestamp = {2017-05-19T07:25:32Z},
  number = {7540},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  urldate = {2016-03-16},
  date = {2015-02-26},
  pages = {529--533},
  keywords = {Computer Science}
}

@article{Kober_2013,
  title = {Reinforcement {{Learning}} in {{Robotics}}: {{A Survey}}},
  volume = {32},
  issn = {0278-3649, 1741-3176},
  url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364913495721},
  doi = {10.1177/0278364913495721},
  shorttitle = {Reinforcement {{Learning}} in {{Robotics}}},
  timestamp = {2017-05-19T07:25:32Z},
  number = {11},
  author = {Kober, J. and Bagnell, J. A. and Peters, J.},
  urldate = {2016-05-12},
  date = {2013-09-01},
  pages = {1238--1274}
}

@article{Rosenberg_2015,
  title = {A {{Computational Perspective}} on {{Autism}}},
  volume = {112},
  issn = {0027-8424, 1091-6490},
  url = {http://www.pnas.org.ezproxy.lancs.ac.uk/content/112/30/9158},
  doi = {10.1073/pnas.1510583112},
  abstract = {Autism is a neurodevelopmental disorder that manifests as a heterogeneous set of social, cognitive, motor, and perceptual symptoms. This system-wide pervasiveness suggests that, rather than narrowly impacting individual systems such as affection or vision, autism may broadly alter neural computation. Here, we propose that alterations in nonlinear, canonical computations occurring throughout the brain may underlie the behavioral characteristics of autism. One such computation, called divisive normalization, balances a neuron’s net excitation with inhibition reflecting the overall activity of the neuronal population. Through neural network simulations, we investigate how alterations in divisive normalization may give rise to autism symptomatology. Our findings show that a reduction in the amount of inhibition that occurs through divisive normalization can account for perceptual consequences of autism, consistent with the hypothesis of an increased ratio of neural excitation to inhibition (E/I) in the disorder. These results thus establish a bridge between an E/I imbalance and behavioral data on autism that is currently absent. Interestingly, our findings implicate the context-dependent, neuronal milieu as a key factor in autism symptomatology, with autism reflecting a less “social” neuronal population. Through a broader discussion of perceptual data, we further examine how altered divisive normalization may contribute to a wide array of the disorder’s behavioral consequences. These analyses show how a computational framework can provide insights into the neural basis of autism and facilitate the generation of falsifiable hypotheses. A computational perspective on autism may help resolve debates within the field and aid in identifying physiological pathways to target in the treatment of the disorder.},
  timestamp = {2017-05-19T07:25:32Z},
  number = {30},
  author = {Rosenberg, Ari and Patterson, Jaclyn Sky and Angelaki, Dora E.},
  urldate = {2016-05-23},
  date = {2015-07-28},
  pages = {9158--9165},
  keywords = {autism,Bayesian inference,divisive normalization,E/I imbalance,neural computation}
}

@book{Kusch_2012,
  title = {Foucault’s {{Strata}} and {{Fields}}: {{An Investigation}} into {{Archaeological}} and {{Genealogical Science Studies}}},
  isbn = {978-94-011-3540-5},
  shorttitle = {Foucault’s {{Strata}} and {{Fields}}},
  abstract = {In recent years, a large number of books and articles on Foucault has been published. Almost all of the book-size studies are expository and introductory. Indeed, there seems to be no other modern philosopher with reference to whom a comparable numberofintroductionshavebeen produced in such a short period. Most ofthe articles too provide over views, rather than critical assessments or rational reconstructions, even though there existsby now a small numberoffine papers also inthe two latter genres. Moreover, more often than not, writers on Foucault approach his work as part and parcel of so-called "postmodern" philo sophy. They concentrate on topics like the "death of the subject", the relation ofFoucault's work to. Derrida or Habermas, or its significance for postmodern art and culture. Without wanting to deny the merits, either of introductory exposi tions, or ofstudies that read Foucault as a postmodern thinker, it seems to me that these received perspectives have tended to leave central areas and aspects ofFoucault's work somewhat underexposed. As I see it, the most important of these areas are such as would suggest reading Fou cault from the vantage point of recent developments in the philosophy, sociology and history of science.},
  timestamp = {2017-05-19T07:25:32Z},
  publisher = {{Springer International Publishing}},
  author = {Kusch, Maren},
  date = {2012-12-06},
  keywords = {History / General,Reference / General,Science / Philosophy & Social Aspects,Social Science / Archaeology,Social Science / General}
}

@online{Google_2015,
  title = {{{TensorFlow}} – an {{Open Source Software Library}} for {{Machine Intelligence}}},
  url = {https://www.tensorflow.org/},
  timestamp = {2017-05-19T07:25:32Z},
  author = {{Google}},
  urldate = {2016-06-07},
  date = {2015}
}

@online{_i,
  title = {Weka 3 - {{Data Mining}} with {{Open Source Machine Learning Software}} in {{Java}}},
  url = {http://www.cs.waikato.ac.nz/ml/weka/},
  abstract = {Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, Ian H. Witten (2009); The WEKA Data Mining Software: An Update; SIGKDD Explorations, Volume 11, Issue 1.},
  timestamp = {2017-05-19T07:25:32Z},
  urldate = {2016-06-07}
}

@article{Hall_2009,
  title = {The {{WEKA Data Mining Software}}: {{An Update}}},
  volume = {11},
  url = {http://dl.acm.org/citation.cfm?id=1656278},
  shorttitle = {The {{WEKA Data Mining Software}}},
  timestamp = {2017-05-19T07:25:32Z},
  number = {1},
  author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
  urldate = {2016-06-07},
  date = {2009},
  pages = {10--18}
}

@article{Abadi_2016,
  title = {Tensorflow: {{Large}}-{{Scale Machine Learning}} on {{Heterogeneous Distributed Systems}}},
  url = {http://arxiv.org/abs/1603.04467},
  shorttitle = {Tensorflow},
  timestamp = {2017-05-19T07:25:32Z},
  author = {Abadi, Martın and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S. and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and {others}},
  urldate = {2016-06-07},
  date = {2016}
}

@online{Levy_2016,
  title = {How {{Google Is Remaking Itself}} as a “{{Machine Learning First}}” {{Company}} — {{Backchannel}}},
  url = {https://backchannel.com/how-google-is-remaking-itself-as-a-machine-learning-first-company-ada63defcb70#.fj3u7o3t2},
  abstract = {If you want to build artificial intelligence into every product, you better retrain your army of coders. Check.},
  timestamp = {2017-05-19T07:25:32Z},
  author = {Levy, Steven},
  urldate = {2016-06-27},
  date = {2016-06-32}
}

@online{Karpathy_2016,
  title = {Karpathy/{{Char}}-{{Rnn}}},
  url = {https://github.com/karpathy/char-rnn},
  abstract = {char-rnn - Multi-layer Recurrent Neural Networks (LSTM, GRU, RNN) for character-level language models in Torch},
  timestamp = {2017-05-19T07:25:32Z},
  author = {Karpathy, Andrej},
  urldate = {2016-06-28},
  date = {2016}
}

@book{Bratton_2016,
  location = {{Cambridge, Massachusetts}},
  edition = {1 edition},
  title = {The {{Stack}}: {{On Software}} and {{Sovereignty}}},
  isbn = {978-0-262-02957-5},
  shorttitle = {The {{Stack}}},
  abstract = {What has planetary-scale computation done to our geopolitical realities? It takes different forms at different scales – from energy and mineral sourcing and subterranean cloud infrastructure to urban software and massive universal addressing systems; from interfaces drawn by the augmentation of the hand and eye to users identified by self – quantification and the arrival of legions of sensors, algorithms, and robots. Together, how do these distort and deform modern political geographies and produce new territories in their own image? In The Stack, Benjamin Bratton proposes that these different genres of computation – smart grids, cloud platforms, mobile apps, smart cities, the Internet of Things, automation – can be seen not as so many species evolving on their own, but as forming a coherent whole: an accidental megastructure called The Stack that is both a computational apparatus and a new governing architecture. We are inside The Stack and it is inside of us. In an account that is both theoretical and technical, drawing on political philosophy, architectural theory, and software studies, Bratton explores six layers of The Stack: Earth, Cloud, City, Address, Interface, User. Each is mapped on its own terms and understood as a component within the larger whole built from hard and soft systems intermingling – not only computational forms but also social, human, and physical forces. This model, informed by the logic of the multilayered structure of protocol "stacks," in which network technologies operate within a modular and vertical order, offers a comprehensive image of our emerging infrastructure and a platform for its ongoing reinvention. The Stack is an interdisciplinary design brief for a new geopolitics that works with and for planetary-scale computation. Interweaving the continental, urban, and perceptual scales, it shows how we can better build, dwell within, communicate with, and govern our worlds. thestack.org},
  timestamp = {2017-05-19T07:25:32Z},
  publisher = {{MIT Press}},
  author = {Bratton, Benjamin H.},
  date = {2016-01-22}
}

@book{Isin_2015,
  location = {{London}},
  title = {Being {{Digital Citizens}}},
  abstract = {From the rise of cyberbullying and hactivism to the issues surrounding digital privacy rights and freedom of speech, the Internet is changing the ways in which we govern and are governed as citizens. This book examines how citizens encounter and perform new sorts of rights, duties, opportunities and challenges through the Internet. By disrupting prevailing understandings of citizenship and cyberspace, the authors highlight the dynamic relationship between these two concepts. Rather than assuming that these are static or established “facts” of politics and society, the book shows how the challenges and opportunities presented by the Internet inevitably impact upon the action and understanding of political agency. In doing so, it investigates how we conduct ourselves in cyberspace through digital acts. This book provides a new theoretical understanding of what it means to be a citizen today for students and scholars across the social sciences.},
  timestamp = {2017-05-19T07:25:32Z},
  publisher = {{Rowman \& Littlefield International}},
  author = {Isin, Engin and Ruppert, Evelyn},
  date = {2015}
}

@book{Brynjolfsson_2014,
  location = {{New York}},
  title = {The {{Second Machine Age}} - {{Work}}, {{Progress}}, and {{Prosperity}} in a {{Time}} of {{Brilliant Technologies}}},
  isbn = {978-0-393-35064-7},
  abstract = {In recent years, Google's autonomous cars have logged thousands of miles on American highways and IBM's Watson trounced the best human Jeopardy! players. Digital technologies with hardware, software, and networks at their core will in the near future diagnose diseases more accurately than doctors can, apply enormous data sets to transform retailing, and accomplish many tasks once considered uniquely human. In The Second Machine Age MIT s Erik Brynjolfsson and Andrew McAfee two thinkers at the forefront of their field reveal the forces driving the reinvention of our lives and our economy. As the full impact of digital technologies is felt, we will realise immense bounty in the form of dazzling personal technology, advanced infrastructure, and near-boundless access to the cultural items that enrich our lives. Amid this bounty will also be wrenching change. Professions of all kinds from lawyers to truck drivers will be forever upended. Companies will be forced to transform or die. Recent economic indicators reflect this shift: fewer people are working, and wages are falling even as productivity and profits soar. Drawing on years of research and up-to-the-minute trends, Brynjolfsson and McAfee identify the best strategies for survival and offer a new path to prosperity. These include revamping education so that it prepares people for the next economy instead of the last one, designing new collaborations that pair brute processing power with human ingenuity, and embracing policies that make sense in a radically transformed landscape. A fundamentally optimistic book, The Second Machine Age alters how we think about issues of technological, societal, and economic progress."},
  timestamp = {2017-05-19T07:25:32Z},
  publisher = {{W. W. Norton \& Company}},
  author = {Brynjolfsson, Erik and Mcafee, Andrew},
  date = {2014}
}

@incollection{Bowker_2014,
  location = {{Cambridge, MA}},
  title = {Emerging {{Configurations}} of {{Knowledge Expression}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=zeK2AgAAQBAJ&oi=fnd&pg=PA167&dq=gillespie+tarleton&ots=GmjJQZ-2ue&sig=Omo2OeadgqNvz17IupCqELPagdg},
  timestamp = {2017-05-19T07:25:32Z},
  booktitle = {Media {{Technologies}}: {{Essays}} on {{Communication}}, {{Materiality}}, and {{Society}}},
  publisher = {{MIT Press}},
  author = {Bowker, Geoffrey},
  editor = {Gillespie, Tarleton and Boczkowski, Pablo and Foot, Kirsten A.},
  urldate = {2015-08-04},
  date = {2014},
  pages = {99--118}
}

@book{Montfort_2009,
  title = {Racing the {{Beam}}: {{The Atari Video Computer System}}},
  isbn = {978-0-262-26152-4},
  shorttitle = {Racing the {{Beam}}},
  abstract = {The Atari Video Computer System dominated the home video game market so completely that "Atari" became the generic term for a video game console. The Atari VCS was affordable and offered the flexibility of changeable cartridges. Nearly a thousand of these were created, the most significant of which established new techniques, mechanics, and even entire genres. This book offers a detailed and accessible study of this influential video game console from both computational and cultural perspectives. Studies of digital media have rarely investigated platforms–the systems underlying computing. This book (the first in a series of Platform Studies) does so, developing a critical approach that examines the relationship between platforms and creative expression. Nick Montfort and Ian Bogost discuss the Atari VCS itself and examine in detail six game cartridges: Combat, Adventure, Pac-Man, Yars' Revenge, Pitfall!, and Star Wars: The Empire Strikes Back. They describe the technical constraints and affordances of the system and track developments in programming, gameplay, interface, and aesthetics. Adventure, for example, was the first game to represent a virtual space larger than the screen (anticipating the boundless virtual spaces of such later games as World of Warcraft and Grand Theft Auto), by allowing the player to walk off one side into another space; and Star Wars: The Empire Strikes Back was an early instance of interaction between media properties and video games. Montfort and Bogost show that the Atari VCS–often considered merely a retro fetish object–is an essential part of the history of video games.},
  timestamp = {2017-05-19T07:25:32Z},
  publisher = {{MIT Press}},
  author = {Montfort, Nick and Bogost, Ian},
  date = {2009-01-09},
  keywords = {Computers / Programming / Games,Games / Video & Electronic}
}

@book{Larson_1996,
  location = {{Lexington, Mass}},
  edition = {3rd ed.},
  title = {Elementary {{Linear Algebra}}},
  isbn = {978-0-669-39641-6},
  timestamp = {2017-05-19T07:25:33Z},
  publisher = {{DCHeath}},
  author = {Larson, Roland E.},
  date = {1996},
  keywords = {Algebras,Linear.}
}

@book{Wiener_1961,
  location = {{Cambridge, MA}},
  edition = {2nd ed.},
  title = {Cybernetics, or, {{Control}} and {{Communication}} in the {{Animal}} and the {{Machine}}},
  isbn = {978-0-262-23007-0},
  timestamp = {2017-05-19T07:25:33Z},
  publisher = {{MITPress}},
  author = {Wiener, Norbert},
  date = {1961},
  keywords = {Cybernetics.}
}

@article{Silver_2016,
  title = {Mastering the {{Game}} of {{Go}} with {{Deep Neural Networks}} and {{Tree Search}}},
  volume = {529},
  url = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
  timestamp = {2017-05-19T07:25:33Z},
  number = {7587},
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and {others}},
  urldate = {2016-07-17},
  date = {2016},
  pages = {484--489}
}

@article{Resnick_1997,
  title = {Recommender {{Systems}}},
  volume = {40},
  issn = {0001-0782},
  url = {http://doi.acm.org/10.1145/245108.245121},
  doi = {10.1145/245108.245121},
  timestamp = {2017-05-19T07:25:33Z},
  number = {3},
  author = {Resnick, Paul and Varian, Hal R.},
  urldate = {2016-09-26},
  date = {1997-03},
  pages = {56--58}
}

@article{Schafer_2001,
  title = {E-{{Commerce Recommendation Applications}}},
  volume = {5},
  issn = {1384-5810, 1573-756X},
  url = {http://link.springer.com/article/10.1023/A%3A1009804230409},
  doi = {10.1023/A:1009804230409},
  abstract = {Recommender systems are being used by an ever-increasing number of E-commerce sites to help consumers find products to purchase. What started as a novelty has turned into a serious business tool. Recommender systems use product knowledge—either hand-coded knowledge provided by experts or “mined” knowledge learned from the behavior of consumers—to guide consumers through the often-overwhelming task of locating products they will like. In this article we present an explanation of how recommender systems are related to some traditional database analysis techniques. We examine how recommender systems help E-commerce sites increase sales and analyze the recommender systems at six market-leading sites. Based on these examples, we create a taxonomy of recommender systems, including the inputs required from the consumers, the additional knowledge required from the database, the ways the recommendations are presented to consumers, the technologies used to create the recommendations, and the level of personalization of the recommendations. We identify five commonly used E-commerce recommender application models, describe several open research problems in the field of recommender systems, and examine privacy implications of recommender systems technology.},
  timestamp = {2017-05-19T07:25:33Z},
  issue = {1-2},
  author = {Schafer, J. Ben and Konstan, Joseph A. and Riedl, John},
  urldate = {2016-09-26},
  date = {2001-01},
  pages = {115--153},
  keywords = {Artificial Intelligence (incl. Robotics),Chemistry & Geosciences,Computer Science,cross-sell,Cryptology and Information Theory,customer loyalty,database marketing,Data Mining,Data Structures,Electronic commerce,general,Information Storage and Retrieval,mass customization,personalization,Physics,privacy,recommender systems,Statistics,Statistics for Engineering,up-sell,user interface}
}

@article{Linden_2003,
  title = {Amazon. {{Com Recommendations}}: {{Item}}-to-{{Item Collaborative Filtering}}},
  volume = {7},
  url = {http://ieeexplore.ieee.org.ezproxy.lancs.ac.uk/xpls/abs_all.jsp?arnumber=1167344},
  shorttitle = {Amazon. {{Com Recommendations}}},
  timestamp = {2017-05-19T07:25:33Z},
  number = {1},
  author = {Linden, Greg and Smith, Brent and York, Jeremy},
  urldate = {2016-09-27},
  date = {2003},
  pages = {76--80}
}

@online{_j,
  title = {New {{Developments}} in {{Demographic Targeting}}–the {{Implications}} of 1991. | {{POPLINE}}.{{Org}}},
  url = {http://www.popline.org/node/370328},
  timestamp = {2017-05-19T07:25:33Z},
  urldate = {2016-09-27}
}

@inproceedings{Agrawal_1994,
  title = {Fast {{Algorithms}} for {{Mining Association Rules}}},
  volume = {1215},
  url = {https://www.it.uu.se/edu/course/homepage/infoutv/ht08/vldb94_rj.pdf},
  timestamp = {2017-05-19T07:25:33Z},
  booktitle = {Proc. 20th {{Int}}. {{Conf}}. {{Very Large Data Bases}}, {{VLDB}}},
  author = {Agrawal, Rakesh and Srikant, Ramakrishnan and {others}},
  urldate = {2016-09-28},
  date = {1994},
  pages = {487--499}
}

@online{_k,
  title = {{{DSS News}}: {{Vol}}. 3, {{No}}. 23},
  url = {http://www.dssresources.com/newsletters/66.php},
  timestamp = {2017-05-19T07:25:33Z},
  urldate = {2016-09-28}
}

@incollection{Hahsler_2006,
  title = {Implications of {{Probabilistic Data Modeling}} for {{Mining Association Rules}}},
  url = {http://link.springer.com/chapter/10.1007/3-540-31314-1_73},
  timestamp = {2017-05-19T07:25:33Z},
  booktitle = {From {{Data}} and {{Information Analysis}} to {{Knowledge Engineering}}},
  publisher = {{Springer}},
  author = {Hahsler, Michael and Hornik, Kurt and Reutterer, Thomas},
  urldate = {2016-09-28},
  date = {2006},
  pages = {598--605}
}

@article{Lo_2002,
  title = {The {{True Lift Model}}: {{A Novel Data Mining Approach}} to {{Response Modeling}} in {{Database Marketing}}},
  volume = {4},
  url = {http://dl.acm.org.ezproxy.lancs.ac.uk/citation.cfm?id=772872},
  shorttitle = {The {{True Lift Model}}},
  timestamp = {2017-05-19T07:25:33Z},
  number = {2},
  author = {Lo, Victor SY},
  urldate = {2016-10-10},
  date = {2002},
  pages = {78--86}
}

@article{Almquist_2001,
  title = {Boost {{Your Marketing ROI}} with {{Experimental Design}}},
  volume = {79},
  url = {http://offermaxima.com/pdfs/BoostYourROI.pdf},
  timestamp = {2017-05-19T07:25:33Z},
  number = {9},
  author = {Almquist, Eric and Wyner, Gordon},
  urldate = {2016-10-10},
  date = {2001},
  pages = {135--141}
}

@book{Popper_1990,
  location = {{Bristol}},
  title = {A {{World}} of {{Propensities}}},
  isbn = {978-1-85506-000-5},
  abstract = {This book contains two lectures - given in 1988 and 1989 respectively - which belong to Karl Popper's late work, most of which is still unpublished. The first introduces a new view of causality, based on Popper's interpretation of quantum theory, yet freed of difficulty. It is a new view of the universe - a view that easily merges with the commonsense view that our will is free. The second lecture gives a glimpse of human knowledge as it evolves from animal knowledge. Both lectures have been expanded by Popper for publication.},
  timestamp = {2017-05-19T07:25:33Z},
  publisher = {{Thoemmes Continuum}},
  author = {Popper, Sir Karl},
  date = {1990-03-15}
}

@article{OKeefe_1984,
  title = {Young {{Operational Research Conference}}. {{Abstracts}}. {{University}} of {{Nottingham}}, 3-5 {{April}} 1984},
  volume = {35},
  timestamp = {2017-05-19T07:25:33Z},
  number = {7},
  author = {O'Keefe, Bob},
  date = {1984},
  pages = {659--671},
  eprinttype = {jstor},
  eprint = {2582788}
}

@article{Hogan_2013,
  title = {Facebook {{Data Storage Centers}} as the {{Archive}}’s {{Underbelly}}},
  url = {http://tvn.sagepub.com.ezproxy.lancs.ac.uk/content/early/2013/11/13/1527476413509415.abstract},
  timestamp = {2017-05-19T07:25:33Z},
  author = {Hogan, Mél},
  urldate = {2016-11-21},
  date = {2013},
  pages = {1527476413509415}
}

@article{Seetharaman_2016,
  title = {Facebook {{Revenue Soars}} on {{Ad Growth}}},
  issn = {0099-9660},
  url = {http://www.wsj.com/articles/facebook-revenue-soars-on-ad-growth-1461787856},
  abstract = {Facebook posted a 52\% surge in first-quarter revenue, underscoring the strength of the social network’s newer mobile-ad products and rising popularity of its video ads.},
  timestamp = {2017-05-19T07:25:33Z},
  author = {Seetharaman, Deepa},
  urldate = {2016-11-21},
  year = {2016-04-28T04:59:00.000Z},
  keywords = {ads,advertising,Business,class c,computer hardware,Computers,computing,consumer electronics,consumer services,corporate,corporate actions,corporate funding,digital marketing,dividend,earnings,entertainment,Facebook,facebook earnings,FB,financial performance,general news,industrial news,instagram,Internet,lifestyle,living,Marketing,markets,media,new stock,nonvoting,online,plans,political,public relations,sales figures,share capital,snapchat,social media,social media marketing,social media platforms,Strategy,technology,tools}
}

@article{Calvert_2015,
  title = {From ‘{{Energy Geography}}’ to ‘{{Energy Geographies}}’ {{Perspectives}} on a {{Fertile Academic Borderland}}},
  issn = {0309-1325, 1477-0288},
  url = {http://phg.sagepub.com/content/early/2015/01/13/0309132514566343},
  doi = {10.1177/0309132514566343},
  abstract = {This paper takes stock of geographical contributions to the study of energy and energy futures. The paper is written in two parts. First, I trace the methodological and philosophical traditions that underpin geographical approaches to energy studies. I argue that while ‘energy geography’ is arguably a pragmatic shorthand with which to communicate to the broader energy studies community, geographical studies of energy have expanded in scope and theoretical plurality so that ‘energy geographies’ is a more appropriate label. Energy geographers are well positioned to contribute to scientific and policy debates surrounding energy due to their privileged position at the borderland between various philosophical and methodological traditions. Second, I identify some of the problems, opportunities and uncertainties that contemporary energy geographers are helping to identify, understand, and resolve. Past contributions and critical issues for future scholarship are highlighted in four themes: (1) using advanced socio-spatial theory to better understand the energy-society relationship; (2) geo-political and geo-economic assessments of (changing) global energy trade networks; (3) geographical perspectives on socio-technical (energy) transitions; and (4) advanced spatial decision-support for energy planning and technology implementation. While this discussion is by no means exhaustive, it aims to bring some clarity and specificity to the policy and academic relevance of geographical thought and practice as it relates to energy issues.},
  timestamp = {2017-05-19T07:25:33Z},
  author = {Calvert, Kirby},
  urldate = {2016-11-22},
  date = {2015-01-21},
  pages = {0309132514566343},
  keywords = {energy GIS,interdisciplinary,production of space,renewable energy,transition}
}

@book{Amoore_2016,
  title = {Algorithmic {{Life}}: {{Calculative Devices}} in the {{Age}} of {{Big Data}}},
  isbn = {978-1-138-85283-9},
  url = {http://ebookcentral.proquest.com/lib/lancaster/detail.action?docID=4218417},
  shorttitle = {Algorithmic {{Life}}},
  abstract = {Includes bibliographical references and index.},
  timestamp = {2017-05-19T07:25:33Z},
  author = {Amoore, Louise and Piotukh, Volha},
  urldate = {2017-01-13},
  date = {2016},
  keywords = {Big data Social aspects.,Electronic data processing Social aspects.,Information technology Social aspects.}
}

@incollection{Virilio_1997,
  location = {{London}},
  title = {The {{Perspective}} of {{Real Time}}},
  timestamp = {2017-05-19T07:24:57Z},
  booktitle = {Open {{Sky}}},
  publisher = {{Verso}},
  author = {Virilio, Paul},
  editor = {{Anonymous}},
  date = {1997},
  pages = {22--34},
  keywords = {Space and time}
}

@incollection{Kittler_1993,
  location = {{Leipzig}},
  title = {Real {{Time Analysis}}, {{Time Axis Manipulation}}},
  timestamp = {2017-05-19T07:24:58Z},
  booktitle = {Draculas {{Vermachtnis Technische Schriften}}},
  publisher = {{Reclam Verlag}},
  author = {Kittler, Friedrich},
  editor = {{Anonymous}},
  date = {1993},
  pages = {182--207}
}

@online{ApacheSoftwareFoundation_2009,
  title = {Welcome to {{Apache Hadoop}}!},
  url = {http://hadoop.apache.org/},
  timestamp = {2017-05-19T07:24:58Z},
  author = {{Apache Software Foundation}},
  urldate = {2009-10-30},
  date = {2009-07-16}
}

@article{Bucher_2012,
  title = {Want to {{Be}} on the {{Top}}? {{Algorithmic Power}} and the {{Threat}} of {{Invisibility}} on {{Facebook}}},
  volume = {14},
  issn = {1461-4448, 1461-7315},
  url = {http://nms.sagepub.com/content/early/2012/04/04/1461444812440159},
  doi = {10.1177/1461444812440159},
  shorttitle = {Want to {{Be}} on the {{Top}}?},
  abstract = {This article explores the new modalities of visibility engendered by new media, with a focus on the social networking site Facebook. Influenced by Foucault’s writings on Panopticism – that is, the architectural structuring of visibility – this article argues for understanding the construction of visibility on Facebook through an architectural framework that pays particular attention to underlying software processes and algorithmic power. Through an analysis of EdgeRank, the algorithm structuring the flow of information and communication on Facebook’s ‘News Feed’, I argue that the regime of visibility constructed imposes a perceived ‘threat of invisibility’ on the part of the participatory subject. As a result, I reverse Foucault’s notion of surveillance as a form of permanent visibility, arguing that participatory subjectivity is not constituted through the imposed threat of an all-seeing vision machine, but by the constant possibility of disappearing and becoming obsolete.},
  timestamp = {2017-05-19T07:24:58Z},
  number = {7},
  author = {Bucher, Taina},
  urldate = {2015-09-16},
  date = {2012-04-08},
  pages = {1164--1180}
}

@article{Andrejevic_2011,
  title = {The {{Work That Affective Economics Does}}},
  volume = {25},
  issn = {0950-2386},
  url = {http://dx.doi.org/10.1080/09502386.2011.600551},
  doi = {10.1080/09502386.2011.600551},
  abstract = {This article focuses upon the concept of ‘affective economics’ arguing that it should be expanded to include a consideration of emerging forms of data-mining including ‘sentiment analysis’ and ‘predictive analytics’. Sentiment analysis in particular seeks to manipulate consumer behaviour by gathering data about emotional responses and conducting controlled experiments on consumers. Any consideration of affective economics should include the ways in which marketers seek to manage consumers through the collection not just of demographic information, but of extensive real-time databases of their online behaviour and conversations.},
  timestamp = {2017-05-19T07:24:58Z},
  issue = {4-5},
  author = {Andrejevic, Mark},
  urldate = {2015-10-05},
  date = {2011-09-01},
  pages = {604--620}
}

@book{Stiegler_2017,
  edition = {1 edition},
  title = {Automatic {{Society}}: {{The Future}} of {{Work}}},
  shorttitle = {Automatic {{Society}}},
  abstract = {In July 2014 the Belgian newspaper Le Soir claimed that France, Belgium, the United Kingdom, Italy, Poland and the United States may lose between 43 and 50 per cent of their jobs within ten to fifteen years. Across the world, integrated automation, one key result of the so-called ‘data economy’, is leading to a drastic reduction in employment in all areas - from the legal profession to truck driving, from medicine to stevedoring. In this first volume of a new series, the leading cultural theorist Bernard Stiegler advocates a radical solution to the crisis posed by automation and consumer capitalism more generally. He calls for a decoupling of the concept of ‘labour’ (meaningful, intellectual participation) from ‘employment’ (dehumanizing, banal work), with the ultimate aim of eradicating ‘employment’ altogether. By doing so, new and alternative economic models will arise, where individuals are no longer simply mined for labour, but also actively produce what they consume. Building substantially on his existing theories and engaging with a wide range of figures - from Deleuze and Foucault to Bill Gates and Alan Greenspan - Automatic Society will appeal to students and scholars across the social sciences and humanities, as well as anyone concerned with the central question of the future of work.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{Polity}},
  author = {Stiegler, Bernard},
  translator = {Ross, Daniel},
  date = {2017-01-09}
}

@book{Pasquale_2015,
  title = {The {{Black Box Society}}: {{The Secret Algorithms That Control Money}} and {{Information}}},
  isbn = {978-0-674-96710-6},
  shorttitle = {The {{Black Box Society}}},
  abstract = {Every day, corporations are connecting the dots about our personal behavior—silently scrutinizing clues left behind by our work habits and Internet use. But who connects the dots about what firms are doing with all this information? Frank Pasquale exposes how powerful interests abuse secrecy for profit and explains ways to rein them in.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{Harvard University Press}},
  author = {Pasquale, Frank},
  date = {2015-01-05},
  keywords = {Law / Computer & Internet}
}

@book{Parikka_2015,
  title = {A {{Geology}} of {{Media}}},
  isbn = {978-0-8166-9552-2},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/10.5749/j.ctt13x1mnj},
  abstract = {Media history is millions, even billions, of years old. That is the premise of this pioneering and provocative book, which argues that to adequately understand contemporary media culture we must set out from material realities that precede media themselves-Earth's history, geological formations, minerals, and energy. And to do so, writes Jussi Parikka, is to confront the profound environmental and social implications of this ubiquitous, but hardly ephemeral, realm of modern-day life. Exploring the resource depletion and material resourcing required for us to use our devices to live networked lives, Parikka grounds his analysis in Siegfried Zielinski's widely discussed notion of deep time-but takes it back millennia. Not only are rare earth minerals and many other materials needed to make our digital media machines work, he observes, but used and obsolete media technologies return to the earth as residue of digital culture, contributing to growing layers of toxic waste for future archaeologists to ponder. He shows that these materials must be considered alongside the often dangerous and exploitative labor processes that refine them into the devices underlying our seemingly virtual or immaterial practices. $\backslash$emphA Geology of Media demonstrates that the environment does not just surround our media cultural world-it runs through it, enables it, and hosts it in an era of unprecedented climate change. While looking backward to Earth's distant past, it also looks forward to a more expansive media theory-and, implicitly, media activism-to come.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{University of Minnesota Press}},
  author = {Parikka, Jussi and Hayles, N. Katherine and Krapp, Peter and Raley, Rita and Weber, Samuel},
  urldate = {2017-01-31},
  date = {2015}
}

@book{Miller_2012,
  location = {{Cambridge ; Malden, MA}},
  title = {Consumption and {{Its Consequences}}},
  abstract = {A Theory of Shopping offers a highly original perspective on one of our most basic everyday activities - shopping. We commonly assume that shopping is primarily concerned with individuals and materialism. But Miller rejects this assumption and follows the surprising route of analysing shopping by means of an analogy with anthropological studies of sacrificial ritual. He argues that the act of purchasing goods is almost always linked to other social relations, and most especially those based on love and care. The ethnographic sections of the book are based on a year's study of shopping on a street in North London. This provides the basis for a sensitive description of the issues the shopper confronts when making decisions as to what to buy. Miller develops a theory to account for these observations, arguing that shopping typically consists of three major stages which reflect the three key stages of many rites of sacrifice. In both shopping and sacrifice the ultimate intention is to constitute others as desiring subjects. Finally the book examines certain historical shifts in both subjects and objects of devotion, in particular, ideals of gender and love. This treatment of shopping from the perspective of comparative anthropology represents a highly innovative approach to one of the most familiar tasks of our daily lives. Written in a clear and accessible manner, this book will be of interest to students and academics in anthropology, sociology and cultural studies, as well as anybody who wants to consider more deeply the nature of their own everyday activities.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{Polity}},
  author = {Miller, Daniel},
  date = {2012}
}

@book{Goody_1986,
  title = {The {{Logic}} of {{Writing}} and the {{Organization}} of {{Society}}},
  isbn = {978-0-521-33962-9},
  abstract = {This book assesses the impact of writing on human societies, both in the Ancient Near East and in twentieth-century Africa, and highlights some general features of social systems that have been influenced by this major change in the mode of communication. Such features are central to any attempt at the theoretical definition of human society and such constituent phenomena as religious and legal systems, and in this study Professor Goody explores the role of a specific mechanism, the introduction of writing and the development of a written tradition, in the explanation of some important social differences and similarities. Goody argues that a shift of emphasis from productive to certain communicative processes is essential to account adequately for major changes in human societies. Whilst there have been previous descussions of the effect of literacy upon social organisation, no study has hitherto presented the general synthesis developed here.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{Cambridge University Press}},
  author = {Goody, Jack},
  date = {1986-12-18},
  keywords = {Social Science / Anthropology / Cultural & Social,Social Science / Anthropology / General}
}

@book{Mainberger_2003,
  location = {{Berlin ; New York}},
  edition = {Reprint 2011},
  title = {Die {{Kunst}} Des {{Aufzählens}}: {{Elemente}} Zu Einer {{Poetik}} Des {{Enumerativen}}},
  isbn = {978-3-11-017246-1},
  shorttitle = {Die {{Kunst}} Des {{Aufzählens}}},
  abstract = {Aufzählungen finden sich in der modernen Literatur außerordentlich häufig, z.B. bei Flaubert, Joyce, Borges, Perec... Sie gehören aber auch quer durch die Geschichte und die Kulturen zur Literatur überhaupt; man denke an Homer, die Bibel, Sei Shonagon, Rabelais, Swift... Ihre konkreten Gestalten sind Inventar, Litanei, Gesetzestafel, Beschreibung, Rezept, Fragebogen, Chronik u.a. Die Arbeit versucht weder eine Geschichte noch eine Typologie des Aufzählens zu bieten, sondern stellt die Frage 'How to do things with lists?' anhand von Texten verschiedenster Art. Sie zeigt die vielfältigen Funktionen und die besondere Wandlungsfähigkeit dieses schlichten Sprachmodus. Der Schwerpunkt liegt auf der Literatur nach dem Verfall der traditionellen Katalogtopoi. Neben Fragen der Rhetorik und Poetik kommen Probleme der Wissenschaftsgeschichte und Medialität zur Sprache.},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{De Gruyter}},
  author = {Mainberger, Sabine},
  date = {2003-01-01}
}

@online{Tesco.com_2017,
  title = {Tesco {{Labs Developer Portal}}},
  url = {https://devportal.tescolabs.com/docs/services/56c73b1bf205fd0ed81dbe7a/operations/56d5b2bee2813e0a0053c47c},
  timestamp = {2017-05-19T07:24:58Z},
  author = {{Tesco.com}},
  urldate = {2017-02-09},
  date = {2017}
}

@online{Silverwood-Cope_2014,
  title = {How {{SEO Helps Tesco}} to {{Dominate}} the {{Online Grocery Market}} | {{Econsultancy}}},
  url = {https://econsultancy.com/blog/64841-how-seo-helps-tesco-to-dominate-the-online-grocery-market/},
  timestamp = {2017-05-19T07:24:58Z},
  author = {Silverwood-Cope, Sam},
  urldate = {2017-02-09},
  date = {2014-05-15}
}

@article{Scott_2012,
  title = {Reconfiguring {{Relations}} of {{Accountability}}: {{Materialization}} of {{Social Media}} in the {{Travel Sector}}},
  volume = {37},
  url = {http://www.sciencedirect.com.ezproxy.lancs.ac.uk/science/article/pii/S0361368211001139},
  shorttitle = {Reconfiguring {{Relations}} of {{Accountability}}},
  timestamp = {2017-05-19T07:24:58Z},
  number = {1},
  author = {Scott, Susan V. and Orlikowski, Wanda J.},
  urldate = {2017-02-10},
  date = {2012},
  pages = {26--40}
}

@online{Power_2002,
  title = {{{DSS News}}: {{Vol}}. 3, {{No}}. 23},
  url = {http://www.dssresources.com/newsletters/66.php},
  timestamp = {2017-05-19T07:24:58Z},
  author = {Power, Dan J.},
  urldate = {2017-02-10},
  date = {2002}
}

@book{Peters_2015,
  location = {{Chicago ; London}},
  title = {The {{Marvelous Clouds}}: {{Toward}} a {{Philosophy}} of {{Elemental Media}}},
  isbn = {978-0-226-25383-1},
  shorttitle = {The {{Marvelous Clouds}}},
  timestamp = {2017-05-19T07:24:58Z},
  publisher = {{University of Chicago Press}},
  author = {Peters, John Durham},
  date = {2015-06-30}
}

@article{deGoede_2016,
  title = {Introduction: {{The Politics}} of the {{List}}},
  volume = {34},
  issn = {0263-7758},
  url = {http://dx.doi.org/10.1177/0263775815624561},
  doi = {10.1177/0263775815624561},
  shorttitle = {Introduction},
  abstract = {This articles introduces the special issue on ‘The Politics of the List.’ We observe that lists proliferate as a technique of governance across multiple domains, including health, security, and commerce. We argue that it is important to take seriously the form and technique of the list itself and engage the knowledge practices, governance effects and ways of ordering the world that the list format enables. In other words, the special issue seeks to ‘remain in the register of the list,’ to unpack its technological arrangements and juridical power. This introduction sets out the key themes of this special issue, through discussing, in turn, the list as a technology of knowledge, the list as a technique of law and governance, the list's complex relation to space and the relation between the list and the digital. We draw on these four elements to characterise what we call the politics of the list in an era of complexity.},
  timestamp = {2017-05-19T07:24:58Z},
  number = {1},
  author = {de Goede, Marieke and Leander, Anna and Sullivan, Gavin},
  urldate = {2017-02-15},
  date = {2016-02-01},
  pages = {3--13},
  options = {useprefix=true}
}

@article{Turow_2015,
  title = {Making {{Data Mining}} a {{Natural Part}} of {{Life}}: {{Physical Retailing}}, {{Customer Surveillance}} and the 21st {{Century Social Imaginary}}},
  volume = {18},
  url = {http://journals.sagepub.com/doi/abs/10.1177/1367549415577390},
  shorttitle = {Making {{Data Mining}} a {{Natural Part}} of {{Life}}},
  timestamp = {2017-05-19T07:24:58Z},
  issue = {4-5},
  author = {Turow, Joseph and McGuigan, Lee and Maris, Elena R.},
  urldate = {2017-03-17},
  date = {2015},
  pages = {464--478}
}

@article{Turow_2014,
  title = {The {{Digital Transformation}} of {{Physical Retailing}}},
  volume = {25},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=r1ZWBQAAQBAJ&oi=fnd&pg=PA146&dq=joseph+turow&ots=fnB26ouHyM&sig=TsiAoTpRfy5uxNGurLcDCuFoTgI},
  timestamp = {2017-05-19T07:24:58Z},
  author = {Turow, Joseph},
  urldate = {2017-03-17},
  date = {2014},
  pages = {146}
}

@article{vanderVlist_2016,
  title = {Accounting for the {{Social}}: {{Investigating Commensuration}} and {{Big Data Practices}} at {{Facebook}}},
  volume = {3},
  issn = {2053-9517},
  url = {http://dx.doi.org/10.1177/2053951716631365},
  doi = {10.1177/2053951716631365},
  shorttitle = {Accounting for the {{Social}}},
  abstract = {This study explores Big Data practices at Facebook through an investigation of the role of commensuration or ‘the transformation of different qualities into a common metric’ in the structuration of analysis and interaction with a major online social media platform. It proposes a conceptual framework and demonstrates the empirical potential of a pragmatic approach based on reading published materials and available documentation. Facebook’s Data Warehousing and Analytics Infrastructure serves as an illustrative example to begin tracing out and describe data assemblages in more detail. In being attentive to the motivations, drivers and challenges engineers face when dealing with Big Data, it is argued that their solutions can enable and support but also constrain specific analytical and transactional capabilities or data flows between various devices and actors. The analysis thus moves beyond methodological critiques of the utility of Big Data that lack empirical support and specificity. It is further argued that analytics not just describe but also actively participate in the enactment of social worlds, thereby opening possibilities for new markets or market segments to arise. Online sociality accounts for a model of the social that makes it visible and measurable qua markets inviting data recontextualisation and the creation of value along multiple axes. Contra Facebook’s claim to make the web more ‘social’, an investigation of commensuration brings to the fore the question how the social is accounted for in the first place.},
  timestamp = {2017-05-19T07:24:58Z},
  number = {1},
  author = {van der Vlist, Fernando N},
  urldate = {2017-03-16},
  date = {2016-01-05},
  pages = {2053951716631365},
  options = {useprefix=true}
}

@article{Turow_2014a,
  title = {Industry {{Conceptions}} of {{Audience}} in the {{Digital Space}}: {{A Research Agenda}}},
  volume = {28},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09502386.2014.888929},
  shorttitle = {Industry {{Conceptions}} of {{Audience}} in the {{Digital Space}}},
  timestamp = {2017-05-19T07:24:59Z},
  number = {4},
  author = {Turow, Joseph and Draper, Nora},
  urldate = {2017-03-17},
  date = {2014},
  pages = {643--656}
}

@article{Couldry_2014,
  title = {Advertising, {{Big Data}} and the {{Clearance}} of the {{Public Realm}}: {{Marketers}}' {{New Approaches}} to the {{Content Subsidy}}},
  volume = {8},
  url = {http://eprints.lse.ac.uk/57944/},
  shorttitle = {Advertising, {{Big Data}} and the {{Clearance}} of the {{Public Realm}}},
  timestamp = {2017-05-19T07:24:59Z},
  author = {Couldry, Nick and Turow, Joseph},
  urldate = {2017-03-17},
  date = {2014},
  pages = {1710--1726}
}

@inproceedings{Stone_2008,
  title = {Autotagging {{Facebook}}: {{Social Network Context Improves Photo Annotation}}},
  isbn = {978-1-4244-2339-2},
  url = {http://ieeexplore.ieee.org/document/4562956/},
  doi = {10.1109/CVPRW.2008.4562956},
  shorttitle = {Autotagging {{Facebook}}},
  timestamp = {2017-05-19T07:24:59Z},
  publisher = {{IEEE}},
  author = {Stone, Zak and Zickler, Todd and Darrell, Trevor},
  urldate = {2017-03-16},
  date = {2008-06},
  pages = {1--8}
}

@inproceedings{Becker_2008,
  title = {Evaluation of {{Face Recognition Techniques}} for {{Application}} to {{Facebook}}},
  isbn = {978-1-4244-2153-4},
  url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4813471},
  doi = {10.1109/AFGR.2008.4813471},
  timestamp = {2017-05-19T07:24:59Z},
  publisher = {{IEEE}},
  author = {Becker, Brian C. and Ortiz, Enrique G.},
  urldate = {2017-03-16},
  date = {2008-09},
  pages = {1--6}
}

@article{Vis_2013,
  title = {A {{Critical Reflection}} on {{Big Data}}: {{Considering APIs}}, {{Researchers}} and {{Tools}} as {{Data Makers}}},
  volume = {18},
  issn = {13960466},
  url = {http://journals.uic.edu/ojs/index.php/fm/article/view/4878},
  doi = {10.5210/fm.v18i10.4878},
  shorttitle = {A {{Critical Reflection}} on {{Big Data}}},
  timestamp = {2017-05-19T07:24:59Z},
  number = {10},
  author = {Vis, Farida},
  urldate = {2017-03-16},
  date = {2013-10-07}
}

@online{dunnhumby_2017,
  title = {Dunnhumby},
  url = {https://www.dunnhumby.com/},
  abstract = {A suite of customer-centric \& data-enabled solutions \& data analytics services for retailers and suppliers, implemented by experienced consultants.},
  timestamp = {2017-05-19T07:24:59Z},
  author = {{dunnhumby}},
  urldate = {2017-03-17},
  date = {2017}
}

@book{Turow_2017,
  title = {The {{Aisles Have Eyes}}: {{How Retailers Track Your Shopping}}, {{Strip Your Privacy}}, and {{Define Your Power}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=YUrJDQAAQBAJ&oi=fnd&pg=PT25&dq=joseph+turow&ots=mzp4lcnuOR&sig=bSt4dLs0Hun73HoNg5_yEhsecqk},
  shorttitle = {The {{Aisles Have Eyes}}},
  timestamp = {2017-05-19T07:24:59Z},
  publisher = {{Yale University Press}},
  author = {Turow, Joseph},
  urldate = {2017-03-17},
  date = {2017}
}

@article{Plantin_2016,
  title = {Infrastructure {{Studies Meet Platform Studies}} in the {{Age}} of {{Google}} and {{Facebook}}},
  url = {http://nms.sagepub.com/content/early/2016/08/02/1461444816661553.abstract},
  timestamp = {2017-05-19T07:24:59Z},
  author = {Plantin, Jean-Christophe and Lagoze, Carl and Edwards, Paul N. and Sandvig, Christian},
  urldate = {2017-03-29},
  date = {2016},
  pages = {1461444816661553}
}

@article{Sandvig_2015,
  title = {How to {{Think}} about {{Digital Research}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=fDlkCwAAQBAJ&oi=fnd&pg=PA1&dq=sandvig+christian&ots=6Ew4Y-_r1X&sig=AadTYbFAYOemO08iYt_mmBNj-pw},
  timestamp = {2017-05-19T07:24:59Z},
  author = {Sandvig, Christian and Hargittai, Eszter},
  urldate = {2017-03-29},
  date = {2015},
  pages = {1}
}

@article{Leyshon_1999,
  title = {Lists {{Come Alive}}: {{Electronic Systems}} of {{Knowledge}} and the {{Rise}} of {{Credit}}-{{Scoring}} in {{Retail Banking}}},
  volume = {28},
  issn = {0308-5147},
  doi = {10.1080/03085149900000013},
  shorttitle = {Lists {{Come Alive}}},
  abstract = {This paper focuses upon a change in the type of market knowledge privileged by retail banks as a result of the rise of a new implementation of information technology. In traditional retail banks market knowledge was embodied in the local manager and his/her staff in branches. Over the last decade or so, such embodied knowledge has been downgraded and greater emphasis has been placed on the more systematic use of empirical information on customers derived from other sources, made possible by the rise of computers, software and databases. The most significant development in this regard has been the now routine use of credit-scoring systems, which are designed to overcome the chronic problems of information asymmetries in the industry and to distinguish 'good' from 'bad' customers 'at-a-distance'. The use of credit-scoring systems and the rise of a marketing discourse within the industry represents a major transformation in the knowledge base of the industry. The paper critically evaluates ways in which this transformation has been brought about and considers the likely shape of the new systems of knowledge which are now coming to dominate the industry.},
  timestamp = {2017-05-19T07:24:59Z},
  number = {3},
  author = {Leyshon, A. and Thrift, N.},
  date = {1999-08},
  pages = {434--466},
  keywords = {britain,credit scoring,databases,financial services,Information,knowledge,markets,services,Software,spaces}
}

@article{Helmond_2015,
  title = {The {{Platformization}} of the {{Web}}: {{Making Web Data Platform Ready}}},
  volume = {1},
  issn = {2056-3051},
  url = {http://dx.doi.org/10.1177/2056305115603080},
  doi = {10.1177/2056305115603080},
  shorttitle = {The {{Platformization}} of the {{Web}}},
  abstract = {In this article, I inquire into Facebook’s development as a platform by situating it within the transformation of social network sites into social media platforms. I explore this shift with a historical perspective on, what I refer to as, platformization, or the rise of the platform as the dominant infrastructural and economic model of the social web and its consequences. Platformization entails the extension of social media platforms into the rest of the web and their drive to make external web data “platform ready.” The specific technological architecture and ontological distinctiveness of platforms will be examined by taking their programmability into account. I position platformization as a form of platform critique that inquires into the dynamics of the decentralization of platform features and the recentralization of “platform ready” data as a way to examine the consequences of the programmability of social media platforms for the web.},
  timestamp = {2017-05-19T07:24:59Z},
  number = {2},
  author = {Helmond, Anne},
  urldate = {2017-05-04},
  date = {2015-09-22},
  pages = {2056305115603080}
}

@online{Bort_2017,
  title = {Inside {{Facebook}}'s Plan to Eat Another \$350 Billion {{IT}} Market},
  url = {http://uk.businessinsider.com/inside-facebooks-telecom-infrastructure-project-2017-5},
  abstract = {Facebook's Telecom Infrastructure Project promises to upend the telecom equipment market, just as its Open Computer Project has done to the data center.},
  timestamp = {2017-05-24T10:25:16Z},
  journaltitle = {Business Insider},
  author = {Bort, Julie},
  urldate = {2017-05-24},
  date = {2017-05-21},
  file = {Snapshot:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/PPBF9VCT/inside-facebooks-telecom-infrastructure-project-2017-5.html:text/html}
}

@inproceedings{Zagoruyko_2016,
  title = {A {{MultiPath Network}} for {{Object Detection}}},
  timestamp = {2017-05-31T12:13:44Z},
  booktitle = {{{BMVC}}},
  author = {Zagoruyko, S. and Lerer, A. and Lin, T.-Y. and Pinheiro, P. O. and Gross, S. and Chintala, S. and Dollár, P.},
  date = {2016}
}

@software{Pinheiro_2017,
  title = {Deepmask: {{Torch}} Implementation of {{DeepMask}} and {{SharpMask}}},
  rights = {BSD-3-Clause},
  url = {https://github.com/facebookresearch/deepmask},
  shorttitle = {Deepmask},
  timestamp = {2017-06-07T09:17:41Z},
  publisher = {{facebookresearch}},
  author = {Pinheiro, Pedro O.},
  urldate = {2017-06-07},
  date = {2017-06-03},
  file = {Snapshot:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/ZR22XSQG/deepmask.html:text/html},
  origdate = {2016-06-22}
}

@inproceedings{Abdullah_2014,
  title = {Frontend and {{Backend Web Technologies}} in {{Social Networking Sites}}: {{Facebook}} as an {{Example}}},
  doi = {10.1109/ACSAT.2014.22},
  shorttitle = {Frontend and {{Backend Web Technologies}} in {{Social Networking Sites}}},
  abstract = {Social Networking has been pointed out as an important evolution in the social and Internet history. The leader and the pioneer of this evolution was and still Face book despite the big and tough rivalry nowadays. Although Facebook is very well known and most of the people who surf the Internet use it and know how to use it and what the different pages are and the modules it has, a few number of technologists know the technology basis upon which this success sustains. This research paper shades a light on the web programming aspect and other supporting technologies used for the frontend and backend of social networks. Facebook is taken as an example.},
  eventtitle = {2014 3rd International Conference on Advanced Computer Science Applications and Technologies},
  timestamp = {2017-06-16T11:29:14Z},
  booktitle = {2014 3rd {{International Conference}} on {{Advanced Computer Science Applications}} and {{Technologies}}},
  author = {Abdullah, H. M. and Zeki, A. M.},
  date = {2014-12},
  pages = {85--89},
  keywords = {backend Web technology,Computer architecture,Facebook,frontend Web technology,Internet,Internet history,Linux,Servers,social networking (online),social networking sites,Social Networks,Software,Web pages,Web Programming,Web programming aspect},
  file = {IEEE Xplore Full Text PDF:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/B6ANKR2T/Abdullah and Zeki - 2014 - Frontend and Backend Web Technologies in Social Ne.pdf:application/pdf;IEEE Xplore Abstract Record:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/4668VQZF/7076874.html:text/html}
}

@online{_v,
  title = {Introducing {{FBLearner Flow}}: {{Facebook}}'s {{AI}} Backbone},
  url = {https://code.facebook.com/posts/1072626246134461/introducing-fblearner-flow-facebook-s-ai-backbone/},
  shorttitle = {Introducing {{FBLearner Flow}}},
  abstract = {The FBLearner Flow platform puts state-of-the-art algorithms in AI and machine learning at the fingertips of every Facebook engineer.},
  timestamp = {2017-06-27T08:29:09Z},
  journaltitle = {Facebook Code},
  author = {Dunn, Jeffrey},
  urldate = {2017-06-27},
  date = {2016-05-10},
  file = {Snapshot:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/E2QFW9IW/introducing-fblearner-flow-facebook-s-ai-backbone.html:text/html}
}

@online{Higginbotham_2016,
  title = {Inside {{Facebook}}’s {{Biggest Artificial Intelligence Project Ever}}},
  url = {http://fortune.com/facebook-machine-learning/},
  abstract = {How do you serve up content to 1.5 billion users each month? By teaching machines to learn.},
  timestamp = {2017-06-27T08:39:27Z},
  journaltitle = {Fortune},
  author = {Higginbotham, Stacey},
  urldate = {2017-06-27},
  date = {2016-04-13},
  file = {Snapshot:/home/mackenza/.zotero/zotero/zl26h2qh.default/zotero/storage/3P84ZNKW/facebook-machine-learning.html:text/html}
}

@article{Marris_2015,
  title = {Taking {{Roles}} in {{Interdisciplinary Collaborations}}: {{Reflections}} on {{Working}} in {{Post}}-{{ELSI Spaces}} in the {{UK Synthetic Biology Community}}},
  volume = {28},
  url = {http://openaccess.city.ac.uk/id/eprint/14196},
  shorttitle = {Taking {{Roles}} in {{Interdisciplinary Collaborations}}},
  timestamp = {2017-05-19T07:26:22Z},
  number = {3},
  author = {Marris, C. and Balmert, A. and Calvert, J. and Molyneux-Hodgson, Susan and Frow, Emma and Kearnes, Matthew and Bulpin, Kate and Schyfter, Pablo and Mackenzie, Adrian and Martin, Paul},
  urldate = {2017-01-30},
  date = {2015}
}

@article{Balmer_2016,
  title = {Five {{Rules}} of {{Thumb}} for {{Post}}-{{ELSI Interdisciplinary Collaborations}}},
  volume = {3},
  url = {http://www.tandfonline.com/doi/abs/10.1080/23299460.2016.1177867},
  timestamp = {2017-05-19T07:26:22Z},
  number = {1},
  author = {Balmer, Andrew S. and Calvert, Jane and Marris, Claire and Molyneux-Hodgson, Susan and Frow, Emma and Kearnes, Matthew and Bulpin, Kate and Schyfter, Pablo and Mackenzie, Adrian and Martin, Paul},
  urldate = {2017-01-30},
  date = {2016},
  pages = {73--80}
}

@article{Mackenzie_2013,
  title = {Programming {{Subjects}} in the {{Regime}} of {{Anticipation}}: {{Software Studies}} and {{Subjectivity}}},
  volume = {6},
  url = {http://link.springer.com/article/10.1057/sub.2013.12},
  shorttitle = {Programming {{Subjects}} in the {{Regime}} of {{Anticipation}}},
  timestamp = {2017-05-19T07:26:22Z},
  number = {4},
  author = {Mackenzie, Adrian},
  urldate = {2017-01-30},
  date = {2013},
  pages = {391--405}
}

@article{Ruppert_2015,
  title = {Socialising {{Big Data}}: {{From Concept}} to {{Practice}}},
  url = {http://research.gold.ac.uk/id/eprint/11614},
  shorttitle = {Socialising {{Big Data}}},
  timestamp = {2017-05-19T07:26:22Z},
  number = {138},
  author = {Ruppert, Evelyn and Harvey, Penny and Lury, Cellia and Mackenzie, Adrian and McNally, Ruth and Baker, Stephanie Alice and Kallianos, Yannis and Lewis, Camilla and {others}},
  urldate = {2017-01-30},
  date = {2015}
}

@article{Mackenzie_2013a,
  title = {Living {{Multiples}}: {{How Large}}-{{Scale Scientific Data}}-{{Mining Pursues Identity}} and {{Differences}}},
  volume = {30},
  url = {http://journals.sagepub.com/doi/abs/10.1177/0263276413476558},
  shorttitle = {Living {{Multiples}}},
  timestamp = {2017-05-19T07:26:22Z},
  number = {4},
  author = {Mackenzie, Adrian and McNally, Ruth},
  urldate = {2017-01-30},
  date = {2013},
  pages = {72--91}
}

@incollection{Mackenzie_2016,
  title = {Code {{Traffic}}: {{Repositories}}, {{Crowds}} and {{Urban Life}}},
  url = {https://books.google.co.uk/books?hl=en&lr=&id=bioFDAAAQBAJ&oi=fnd&pg=PP1&dq=code+in+the+city+sung&ots=cVVNuXPiOV&sig=VL-1C7Bq43nC32DHB5jCWztpvjw},
  timestamp = {2017-05-19T07:26:22Z},
  booktitle = {Code and the {{City}}},
  publisher = {{Routledge}},
  author = {Mackenzie, Adrian},
  editor = {Kitchin, Rob and Perng, Sung-Yueh},
  urldate = {2017-01-30},
  date = {2016},
  pages = {72--88}
}

@incollection{Mackenzie_2016a,
  location = {{Manchester}},
  title = {Distributive {{Numbers}}: {{A Post}}-{{Demographic Perspective}} on {{Probability}}},
  timestamp = {2017-05-19T07:26:22Z},
  booktitle = {Modes of {{Knowing}}},
  publisher = {{Mattering Press}},
  author = {Mackenzie, Adrian},
  editor = {Law, John and Ruppert, Evelyn},
  date = {2016},
  pages = {115--135}
}

@incollection{McNeil_2016,
  title = {Conceptualizing {{Imaginaries}} of {{Science}}, {{Technology}}, and {{Society}}},
  isbn = {978-0-262-33811-0},
  abstract = {Science and Technology Studies (STS) is a flourishing interdisciplinary field that examines the transformative power of science and technology to arrange and rearrange contemporary societies. The Handbook of Science and Technology Studies provides a comprehensive and authoritative overview of the field, reviewing current research and major theoretical and methodological approaches in a way that is accessible to both new and established scholars from a range of disciplines. This new edition, sponsored by the Society for Social Studies of Science, is the fourth in a series of volumes that have defined the field of STS. It features 36 chapters, each written for the fourth edition, that capture the state of the art in a rich and rapidly growing field. One especially notable development is the increasing integration of feminist, gender, and postcolonial studies into the body of STS knowledge. The book covers methods and participatory practices in STS research; mechanisms by which knowledge, people, and societies are coproduced; the design, construction, and use of material devices and infrastructures; the organization and governance of science; and STS and societal challenges including aging, agriculture, security, disasters, environmental justice, and climate change.},
  timestamp = {2017-05-19T07:26:22Z},
  booktitle = {The {{Handbook}} of {{Science}} and {{Technology Studies}}},
  publisher = {{MIT Press}},
  author = {McNeil, Maureen and Arribas-Ayllon, Michael and Haran, Joan and Mackenzie, Adrian and Tutton, Richard},
  editor = {Felt, Ulrike and Fouché, Rayvon and Miller, Clark A. and Smith-Doerr, Laurel},
  date = {2016},
  pages = {435--464},
  keywords = {Science / History,Technology & Engineering / History}
}

@book{Nafus_2016,
  title = {Quantified: {{Biosensing Technologies}} in {{Everyday Life}}},
  isbn = {978-0-262-33455-6},
  shorttitle = {Quantified},
  abstract = {Today anyone can purchase technology that can track, quantify, and measure the body and its environment. Wearable or portable sensors detect heart rates, glucose levels, steps taken, water quality, genomes, and microbiomes, and turn them into electronic data. Is this phenomenon empowering, or a new form of social control? Who volunteers to enumerate bodily experiences, and who is forced to do so? Who interprets the resulting data? How does all this affect the relationship between medical practice and self care, between scientific and lay knowledge? Quantified examines these and other issues that arise when biosensing technologies become part of everyday life. The book offers a range of perspectives, with views from the social sciences, cultural studies, journalism, industry, and the nonprofit world. The contributors consider data, personhood, and the urge to self-quantify; legal, commercial, and medical issues, including privacy, the outsourcing of medical advice, and self-tracking as a "paraclinical" practice; and technical concerns, including interoperability, sociotechnical calibration, alternative views of data, and new space for design.ContributorsMarc Böhlen, Geoffrey C. Bowker, Sophie Day, Anna de Paula Hanika, Deborah Estrin, Brittany Fiore-Gartland, Dana Greenfield, Judith Gregory, Mette Kragh-Furbo, Celia Lury, Adrian Mackenzie, Rajiv Mehta, Maggie Mort, Dawn Nafus, Gina Neff, Helen Nissenbaum, Heather Patterson, Celia Roberts, Jamie Sherman, Alex Taylor, Gary Wolf},
  timestamp = {2017-05-19T07:26:22Z},
  publisher = {{MIT Press}},
  author = {Nafus, Dawn},
  date = {2016},
  keywords = {Computers / Social Aspects / Human-Computer Interaction,Technology & Engineering / Telecommunications}
}

@incollection{Mackenzie_2018,
  location = {{London \& New York}},
  title = {Affiliating with {{Analytics}}: {{Altered States}} in {{Ethnographies}} of {{Code}}},
  timestamp = {2017-05-19T07:26:22Z},
  booktitle = {Ethnography in a {{Data Saturated World}}},
  publisher = {{Routledge}},
  author = {Mackenzie, Adrian},
  editor = {Nafus, Dawn and Knox, Hannah},
  date = {2018},
  pages = {TBA}
}

@incollection{Fuller_2016,
  location = {{Amsterdam, Netherlands}},
  title = {Big {{Diff}}: {{Granularity}}, {{Incoherence}} and {{Production}} in the {{Github Software Repository}}},
  timestamp = {2017-05-19T07:26:22Z},
  booktitle = {Memory in {{Motion}}. {{Archive}}, {{Technology}} and the {{Social}}},
  publisher = {{Amsterdam University Press}},
  author = {Fuller, Mattew and Goffey, Andrew and Mackenzie, Adrian},
  editor = {Blom, Ina and Lundemo, Trond and Rosaak, Evind},
  date = {2016},
  pages = {87--102}
}

@book{Takhteyev_2010,
  title = {Investigating the {{Geography}} of {{Open Source Software}} through {{GitHub}}},
  url = {http://takhteyev.org/papers/Takhteyev-Hilts-2010.pdf},
  timestamp = {2017-05-19T07:25:53Z},
  author = {Takhteyev, Yuri and Hilts, Andrew},
  urldate = {2014-05-23},
  date = {2010}
}

@inproceedings{Dabbish_2012,
  title = {Social {{Coding}} in {{GitHub}}: {{Transparency}} and {{Collaboration}} in an {{Open Software Repository}}},
  url = {http://dl.acm.org/citation.cfm?id=2145396},
  shorttitle = {Social {{Coding}} in {{GitHub}}},
  timestamp = {2017-05-19T07:25:53Z},
  booktitle = {Proceedings of the {{ACM}} 2012 {{Conference}} on {{Computer Supported Cooperative Work}}},
  publisher = {{ACM}},
  author = {Dabbish, Laura and Stuart, Colleen and Tsay, Jason and Herbsleb, Jim},
  urldate = {2014-05-23},
  date = {2012},
  pages = {1277--1286}
}

@article{Palsson_2014,
  title = {Personal {{Names Embodiment}}, {{Differentiation}}, {{Exclusion}}, and {{Belonging}}},
  volume = {39},
  issn = {0162-2439, 1552-8251},
  url = {http://sth.sagepub.com.ezproxy.lancs.ac.uk/content/39/4/618},
  doi = {10.1177/0162243913516808},
  abstract = {Because they are right under our nose, taken-for-granted, and essential to every person everywhere, personal names have often eluded the theoretical and analytical scrutiny they deserve. To what extent do naming practices exemplify or parallel the biopolitics of bodily inscriptions and markings such as tattoos, birthmarks, and presumed racial signatures? To what extent do names represent “technologies of the self” (Foucault 1988) in the broadest sense, as both means of domination and empowerment, facilitating collective surveillance and subjugation, and the individual fashioning of identity and subjectivity? Partly drawing upon indigenous contexts in the North American Arctic (Inuit and Yup’ik), this commentary discusses personal names and genealogies in relation to other technologies of belonging. Practices of naming, it is argued, are not only key elements of identification and personhood, embodied in the biosocial habitus much like other biomarkers, also they situate people in genealogies, social networks, and states. Clashes, I suggest, between different traditions and practices of naming, especially in the context of slavery and empires, illuminate with striking clarity the relevance of names as technologies of exclusion, subjugation, and belonging.},
  timestamp = {2017-05-19T07:25:53Z},
  number = {4},
  author = {Palsson, Gisli},
  urldate = {2014-05-27},
  date = {2014-07-01},
  pages = {618--630},
  keywords = {cultures and ethnicities,genders,governance,inequality,justice,politics,power,protest}
}

@book{Riles_2001,
  title = {The {{Network}} inside {{Out}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=iOu_LP1w2LEC&oi=fnd&pg=PR9&dq=annelise+riles+networks+2004&ots=SKkvqn85hP&sig=cCS3Jakbv4tK24ttTEzy2wlq7iE},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{University of Michigan Press}},
  author = {Riles, Annelise},
  urldate = {2014-06-09},
  date = {2001}
}

@book{deTarde_1895,
  location = {{Paris,}},
  title = {La {{Logique Sociale}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{F. Alcan}},
  author = {de Tarde, Gabriel},
  date = {1895},
  keywords = {Sociology.},
  options = {useprefix=true}
}

@article{Thrift_2002,
  title = {The {{Automatic Production}} of {{Space}}},
  volume = {27},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/1475-5661.00057/abstract},
  timestamp = {2017-05-19T07:25:53Z},
  number = {3},
  author = {Thrift, Nigel and French, Shaun},
  urldate = {2014-06-16},
  date = {2002},
  pages = {309--335}
}

@article{Horvath_1974,
  title = {Machine {{Space}}},
  volume = {64},
  issn = {0016-7428},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/213809},
  doi = {10.2307/213809},
  abstract = {The concept of machine space translates the hitherto aspatial phenomenon of technology into an explicitly spatial one in order to encourage recognition of the territorial demands involved in the growth of technology. Machine space is found where machines have priority over people in the use of territory. The exponential growth of technology on a finite earth has created a series of conflicts between people and machines. These conflicts arise when human purposes contradict human consequences of technological growth. Three aspects of this contradictory relationship revealed by an examination of machine space are use rights, the nature of control, and the deadly quality of such space both in human and in ecological terms. Nontechnological spatial antidotes, including the containment or reversal of machine space, are discussed in a framework of advocacy geography. Empirical analysis focuses on the automobile in urban locations in the United States.},
  timestamp = {2017-05-19T07:25:53Z},
  number = {2},
  author = {Horvath, Ronald J.},
  urldate = {2014-06-16},
  date = {1974-04-01},
  pages = {167--188}
}

@book{Borch_2012,
  title = {The {{Politics}} of {{Crowds}}: {{An Alternative History}} of {{Sociology}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Cambridge University Press}},
  author = {Borch, Christian},
  date = {2012}
}

@book{Latour_1987,
  location = {{Cambridge, Mass.}},
  title = {Science in {{Action}} : {{How}} to {{Follow Scientists}} and {{Engineers}} through {{Society}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Harvard University Press}},
  author = {Latour, Bruno},
  date = {1987},
  keywords = {Science History.,Science Philosophy.,Science Social aspects.,Technology Social aspects.}
}

@book{Latour_2008,
  title = {L'{{Economie}}},
  timestamp = {2017-05-19T07:25:53Z},
  author = {Latour, Bruno and Lepinay, Vincent},
  date = {2008}
}

@book{deTarde_1903,
  location = {{New York,}},
  title = {The {{Laws}} of {{Imitation}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{H. Holt and Company}},
  author = {de Tarde, Gabriel and Parsons, Elsie Worthington Clews},
  date = {1903},
  keywords = {Imitation.,Sociology.},
  options = {useprefix=true}
}

@book{deTarde_1999,
  location = {{Le Plessis-Robinson}},
  title = {Monadologie et {{Sociologie}}},
  isbn = {2-84324-065-4},
  timestamp = {2017-05-19T07:25:53Z},
  series = {Collection Les empãecheurs de penser en rond},
  publisher = {{Institut Synthâelabo}},
  author = {de Tarde, Gabriel},
  editor = {Alliez, Eric},
  date = {1999},
  keywords = {Monadology.,Sociology Philosophy.},
  options = {useprefix=true}
}

@article{Gill_2008,
  title = {In the {{Social Factory}}?: {{Immaterial Labour}}, {{Precariousness}} and {{Cultural Work}}},
  volume = {25},
  issn = {0263-2764},
  url = {http://tcs.sagepub.com/cgi/doi/10.1177/0263276408097794},
  doi = {10.1177/0263276408097794},
  shorttitle = {In the {{Social Factory}}?},
  timestamp = {2017-05-19T07:25:53Z},
  issue = {7-8},
  author = {Gill, Ros and Pratt, Andy},
  urldate = {2014-09-05},
  date = {2008-12-01},
  pages = {1--30}
}

@article{Callon_2005,
  title = {Peripheral {{Vision}}: {{Economic Markets}} as {{Calculative Collective Devices}}},
  volume = {26},
  url = {http://oss.sagepub.com/cgi/content/abstract/26/8/1229},
  doi = {10.1177/0170840605056393},
  abstract = {How to address empirically the calculative character of markets without dissolving it? In our paper, we propose a theoretical framework that helps to deal with markets without suspending their calculative properties. In the first section, we construct a broad definition of calculation, grounded on the anthropology of science and techniques. In the next sections, we apply this definition to three constitutive elements of markets: economic goods, economic agents and economic exchanges. First, we examine the question of the calculability of goods: in order to be calculated, goods must be calculable. In the following section, we introduce the notion of calculative distributed agencies to understand how these calculable goods are actually calculated. Thirdly, we consider the rules and material devices that organize the encounter between (and aggregation of) individual supplies and demands, i.e. the specific organizations that allow for a calculated exchange and a market output. Those three elements define concrete markets as collective organized devices that calculate compromises on the values of goods. In each, we encounter different versions of our broad definition of calculation, which we illustrate with examples, mainly taken from the fields of financial markets and mass retail.},
  timestamp = {2017-05-19T07:25:53Z},
  number = {8},
  author = {Callon, Michel and Muniesa, Fabian},
  date = {2005},
  pages = {1229--1250}
}

@article{Barry_2005,
  title = {Pharmaceutical {{Matters}}: {{The Invention}} of {{Informed Materials}}},
  volume = {22},
  timestamp = {2017-05-19T07:25:53Z},
  number = {1},
  author = {Barry, Andrew},
  date = {2005},
  pages = {51--69}
}

@article{Dourish_2007,
  title = {The {{Infrastructure}} of {{Experience}} and the {{Experience}} of {{Infrastructure}}: {{Meaning}} and {{Structure}} in {{Everyday Encounters}} with {{Space}}},
  volume = {34},
  timestamp = {2017-05-19T07:25:53Z},
  author = {Dourish, Paul and Bell, Genevieve},
  date = {2007},
  pages = {414--430}
}

@book{Ong_2005,
  location = {{Malden, MA}},
  title = {Global {{Assemblages}} : {{Technology}}, {{Politics}}, and {{Ethics}} as {{Anthropological Problems}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Blackwell Publishing}},
  author = {Ong, Aihwa and Collier, Stephen J},
  date = {2005},
  keywords = {Discoveries in science Social aspects.,Globalization Social aspects.,Social change.,Technological innovations Social aspects.}
}

@book{Lazzarato_2002,
  location = {{Paris}},
  title = {Puissances de l'invention : {{La Psychologie Âeconomique}} de {{Gabriel Tarde Contre}} l'âEconomie {{Politique}}},
  isbn = {2-84671-033-3},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Empãecheurs de penser en rond}},
  author = {Lazzarato, M.},
  date = {2002},
  keywords = {Economic Psychology - Philosophy - 19th Century.}
}

@book{Bourdieu_2000,
  location = {{Stanford, Calif.}},
  title = {Pascalian {{Meditations}}},
  isbn = {0804733317 (cloth acid-free paper) 0804733325 (paper acid-free paper)},
  url = {http://www.loc.gov/catdir/description/cam0210/99071220.html},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Stanford University Press}},
  author = {Bourdieu, Pierre},
  date = {2000},
  keywords = {Sociology Philosophy.}
}

@book{Tarde_1895,
  edition = {2nd},
  title = {Les {{Lois}} de l'imitation: {{Étude Sociologique}}},
  isbn = {1-4212-5278-3},
  url = {http://openlibrary.org/b/OL23311522M/lois_de_l%27imitation},
  shorttitle = {Les {{Lois}} de l'imitation},
  timestamp = {2017-05-19T07:25:53Z},
  author = {Tarde, Gabriel},
  date = {1895}
}

@book{Graham_2001,
  location = {{London}},
  title = {Splintering {{Urbanism}} : {{Networked Infrastructures}}, {{Technological Mobilities}} and the {{Urban Condition}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Routledge}},
  author = {Graham, Stephen and Marvin, Simon},
  date = {2001},
  keywords = {Urbanization}
}

@online{News_2015,
  title = {The {{NSA Files}}},
  url = {http://www.theguardian.com/us-news/the-nsa-files},
  abstract = {Latest The NSA files news, comment and analysis from the Guardian, the world's leading liberal voice},
  timestamp = {2017-05-19T07:25:53Z},
  author = {News, Guardian},
  urldate = {2015-11-10},
  date = {2015}
}

@book{Kelty_2008,
  title = {Two {{Bits}}: {{The Cultural Significance}} of {{Free Software}}},
  isbn = {0-8223-4264-2},
  shorttitle = {Two {{Bits}}},
  timestamp = {2017-05-19T07:25:53Z},
  publisher = {{Duke University Press}},
  author = {Kelty, Christopher},
  date = {2008-06-30}
}

@book{Lessig_2004,
  location = {{New York}},
  title = {Free {{Culture}} : {{How Big Media Uses Technology}} and the {{Law}} to {{Lock Down}}},
  timestamp = {2017-05-19T07:25:54Z},
  publisher = {{Penguin Press}},
  author = {Lessig, Lawrence},
  date = {2004},
  keywords = {Art - United States,Intellectual property - United States,Mass media - United States,Technological innovations - United States}
}

@book{Verran_2001,
  location = {{Chicago, London}},
  title = {Science and {{An African Logic}}},
  timestamp = {2017-05-19T07:25:54Z},
  publisher = {{The University of Chicago Press}},
  author = {Verran, Helen},
  date = {2001}
}

@article{Osborne_1999,
  title = {Do the {{Social Sciences Create Phenomena}}?: {{The Example}} of {{Public Opinion Research}}},
  volume = {50},
  timestamp = {2017-05-19T07:25:54Z},
  number = {3},
  author = {Osborne, Thomas and Rose, Nikolas},
  date = {1999},
  pages = {367--396}
}

@article{Law_2004,
  title = {Enacting the {{Social}}},
  volume = {33},
  url = {http://www.tandfonline.com/doi/abs/10.1080/0308514042000225716},
  timestamp = {2017-05-19T07:25:54Z},
  number = {3},
  author = {Law, John and Urry, John},
  urldate = {2014-10-31},
  date = {2004},
  pages = {390--410}
}

@article{Law_2009,
  title = {Seeing like a {{Survey}}},
  volume = {3},
  url = {http://cus.sagepub.com/content/3/2/239.short},
  timestamp = {2017-05-19T07:25:54Z},
  number = {2},
  author = {Law, John},
  urldate = {2014-11-10},
  date = {2009},
  pages = {239--256}
}

@book{Stengers_1997a,
  location = {{Minneapolis ; London}},
  title = {Power and {{Invention}} : {{Situating Science}}},
  timestamp = {2017-05-19T07:25:54Z},
  series = {Theory out of bounds ; v.10},
  publisher = {{University of Minnesota Press}},
  author = {Stengers, Isabelle},
  date = {1997},
  keywords = {Inventions - Philosophy,Science - Philosophy,Science - Social aspects}
}

@online{_m,
  title = {Metacommunities/{{Metacommunities}}},
  url = {https://github.com/metacommunities/metacommunities},
  abstract = {Contribute to metacommunities development by creating an account on GitHub.},
  timestamp = {2017-05-19T07:25:54Z},
  urldate = {2014-12-18}
}

@inproceedings{Hanrahan_2012,
  location = {{New York, NY, USA}},
  title = {Modeling {{Problem Difficulty}} and {{Expertise}} in {{Stackoverflow}}},
  isbn = {978-1-4503-1051-2},
  url = {http://doi.acm.org.ezproxy.lancs.ac.uk/10.1145/2141512.2141550},
  doi = {10.1145/2141512.2141550},
  abstract = {Supporting expert communities is becoming a 'must-have' capability whenever users are helping each other solve problems. Examples of these expert communities abound in the form of enthusiast communities, both inside and outside of organizations. In order to achieve success, these systems have to connect several different actors. In this paper we aim to inform the design of these Hybrid Intelligence Systems through the investigation of StackOverflow. Our focus in this paper is to develop indicators for hard problems and experts. The long-term goal of our study is to examine how complex problems are handled and dispatched across multiple experts. We outline implications for modeling these attributes and how they might inform better design in the future.},
  timestamp = {2017-05-19T07:25:54Z},
  booktitle = {Proceedings of the {{ACM}} 2012 {{Conference}} on {{Computer Supported Cooperative Work Companion}}},
  series = {CSCW '12},
  publisher = {{ACM}},
  author = {Hanrahan, Benjamin V. and Convertino, Gregorio and Nelson, Les},
  urldate = {2012-09-11},
  date = {2012},
  pages = {91--94},
  keywords = {collective intelligence,community of experts,crowdsourcing,cscw}
}

@article{Furlong_2014,
  title = {{{STS}} beyond the “{{Modern Infrastructure Ideal}}”: {{Extending Theory}} by {{Engaging}} with {{Infrastructure Challenges}} in the {{South}}},
  volume = {38},
  issn = {0160-791X},
  url = {http://www.sciencedirect.com/science/article/pii/S0160791X14000244},
  doi = {10.1016/j.techsoc.2014.04.001},
  shorttitle = {{{STS}} beyond the “{{Modern Infrastructure Ideal}}”},
  abstract = {With few exceptions, STS theories of infrastructure stability and change have not been applied to circumstances in the South. Developed in post-War Europe, these theories are often applied in ways that lack transferability to situations where infrastructure conditions are precarious and hybrid. This article seeks to broaden these theories by relating them to infrastructure challenges common to the South, drawing in particular on prevalent issues in water supply. Such engagement helps to identify shortcomings in these theories, to push their paradigms further, and to raise new questions related to infrastructure configuration, stability, and transition. As such, the study of sociotechnical systems across a range of contexts can be enriched. In particular, this article extends theory by placing coexistence among sociotechnical systems, as opposed to the universality of a single dominant infrastructure network, at the center of enquiry. Recognizing coexistence is important because it enables one to decouple key concepts in STS from the presumption of universalized and uniform networks, enabling them to become relevant for the South. Examples discussed in this essay include stability or “momentum” and transitions.},
  timestamp = {2017-05-19T07:25:54Z},
  author = {Furlong, Kathryn},
  urldate = {2015-01-09},
  date = {2014-08},
  pages = {139--147},
  keywords = {Coexistence,Disrepair,Global South,STS,Water supply}
}

@incollection{Bowker_2010a,
  title = {Toward {{Information Infrastructure Studies}}: {{Ways}} of {{Knowing}} in a {{Networked Environment}}},
  url = {http://link.springer.com/chapter/10.1007/978-1-4020-9789-8_5},
  shorttitle = {Toward {{Information Infrastructure Studies}}},
  timestamp = {2017-05-19T07:25:54Z},
  booktitle = {International {{Handbook}} of {{Internet Research}}},
  publisher = {{Springer}},
  author = {Bowker, Geoffrey C. and Baker, Karen and Millerand, Florence and Ribes, David},
  urldate = {2015-01-09},
  date = {2010},
  pages = {97--117}
}

@article{Mnih_2013,
  title = {Playing {{Atari}} with {{Deep Reinforcement Learning}}},
  url = {http://arxiv.org/abs/1312.5602},
  abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
  timestamp = {2017-05-19T07:25:54Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1312.5602},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  urldate = {2015-01-27},
  date = {2013-12-19},
  keywords = {Computer Science - Learning}
}

@online{Levy_2015,
  title = {The {{Deep Mind}} of {{Demis Hassabis}} — {{Backchannel}}},
  url = {https://medium.com/backchannel/the-deep-mind-of-demis-hassabis-156112890d8a},
  abstract = {Google’s prize AI prodigy tells all},
  timestamp = {2017-05-19T07:25:54Z},
  author = {Levy, Steven},
  urldate = {2015-01-27},
  date = {2015-01-16}
}

@article{Tippmann_2014,
  title = {My {{Digital Toolbox}}: {{Nuclear Engineer Katy Huff}} on {{Version}}-{{Control Systems}}},
  issn = {1476-4687},
  url = {http://www.nature.com/doifinder/10.1038/nature.2014.16014},
  doi = {10.1038/nature.2014.16014},
  shorttitle = {My {{Digital Toolbox}}},
  timestamp = {2017-05-19T07:25:54Z},
  author = {Tippmann, Sylvia},
  urldate = {2015-02-19},
  date = {2014-09-29}
}

@article{Kelty_2005,
  title = {Geeks, {{Social Imaginaries}}, and {{Recursive Publics}}},
  volume = {20},
  issn = {0886-7356},
  doi = {10.1525/can.2005.20.2.185},
  abstract = {This article investigates the social, technical, and legal affiliations among “geeks” (hackers, lawyers, activists, and IT entrepreneurs) on the Internet. The mode of association specific to this group is that of a “recursive public sphere” constituted by a shared imaginary of the technical and legal conditions of possibility for their own association. On the basis of fieldwork conducted in the United States, Europe, and India, I argue that geeks imagine their social existence and relations as much through technical practices (hacking, networking, and code writing) as through discursive argument (rights, identities, and relations). In addition, they consider a “right to tinker” a form of free speech that takes the form of creating, implementing, modifying, or using specific kinds of software (especially Free Software) rather than verbal discourse.},
  timestamp = {2017-05-19T07:25:54Z},
  number = {2},
  author = {Kelty, C},
  date = {2005-05},
  pages = {185--214}
}

@incollection{Desrosieres_2011,
  title = {Words and {{Numbers}}: {{For}} a {{Sociology}} of the {{Statistical Argument}}},
  isbn = {978-0-203-84661-2},
  shorttitle = {Words and {{Numbers}}},
  timestamp = {2017-05-19T07:25:55Z},
  booktitle = {The {{Mutual Construction}} of {{Statistics}} and {{Society}}},
  author = {Desrosières, A.},
  date = {2011},
  pages = {41--63},
  doi = {10.4324/9780203846612}
}

@article{Verran_2011,
  title = {Imagining {{Nature Politics}} in the {{Era}} of {{Australia}}'s {{Emerging Market}} in {{Environmental Services Interventions}}},
  volume = {59},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-954X.2011.02017.x/full},
  timestamp = {2017-05-19T07:25:55Z},
  number = {3},
  author = {Verran, Helen},
  urldate = {2015-03-04},
  date = {2011},
  pages = {411--431}
}

@article{Newman_2014,
  title = {The {{Results}} of {{GitHub}}'s {{Harassment Investigation Are}} ... {{Vague}}},
  issn = {1091-2339},
  url = {http://www.slate.com/blogs/future_tense/2014/04/21/github_ceo_tom_preston_werner_is_cleared_but_still_resigns_over_harassment.html},
  timestamp = {2017-05-19T07:25:55Z},
  author = {Newman, Lily Hay},
  urldate = {2015-05-14},
  date = {2014-04-21}
}

@online{Netcraft_2015,
  title = {January 2015 {{Web Server Survey}} | {{Netcraft}}},
  url = {http://news.netcraft.com/archives/2015/01/15/january-2015-web-server-survey.html},
  timestamp = {2017-05-19T07:25:55Z},
  author = {{Netcraft}},
  urldate = {2015-07-13},
  date = {2015}
}

@online{W3Techs_2012,
  title = {{{jQuery Now Runs}} on {{Every Second Website}}},
  url = {http://w3techs.com/blog/entry/jquery_now_runs_on_every_second_website},
  timestamp = {2017-05-19T07:25:55Z},
  author = {{W3Techs}},
  urldate = {2015-07-14},
  date = {2012}
}

@online{CJFE_2015,
  title = {Snowden {{Digital Surveillance Archive}}},
  url = {https://snowdenarchive.cjfe.org/greenstone/cgi-bin/library.cgi},
  timestamp = {2017-05-19T07:25:55Z},
  author = {{CJFE}},
  urldate = {2015-07-20},
  date = {2015}
}

@article{Gad_2014,
  title = {The {{Conceptual}} and the {{Empirical}} in {{Science}} and {{Technology Studies}}},
  volume = {39},
  issn = {0162-2439, 1552-8251},
  url = {http://sth.sagepub.com/content/39/2/183},
  doi = {10.1177/0162243914522304},
  abstract = {It is the purpose of this special issue to acknowledge the shifting definitions and uses of the conceptual and empirical in the field of Science and Technology Studies (STS), and to explore the constructive potential of this condition. In this introductory essay we point to four formulations in STS for the relation between the conceptual and the empirical which do not figure them as binaries or opposites: (1) the empirical as a path to the conceptual, (2) the conceptual as practical and empirical, (3) the empirical as an instantiation of the conceptual (and the dangers of that view), and (4) a conceptual minimalism. We then point to some inspirations in contemporary thought for engaging creatively with the conceptual and empirical, and conclude by summarizing the contributions to this issue.},
  timestamp = {2017-05-19T07:25:55Z},
  number = {2},
  author = {Gad, Christopher and Ribes, David},
  urldate = {2015-07-20},
  date = {2014-03-01},
  pages = {183--191},
  keywords = {conceptual,empirical,method,STS,theory}
}

@incollection{Herraiz_2009,
  location = {{Los Alamitos}},
  title = {{{FLOSSMetrics}}: {{Free Libre Open Source Software Metrics}}},
  isbn = {978-0-7695-3589-0},
  shorttitle = {{{FLOSSMetrics}}},
  abstract = {This paper presents FLOSSMetrics, a European Commission 6th Framework. Progranune-funded research project. The main objective of FLOSSMETRICS is to construct, publish and analyse a large scale database with information and metrics about libre software development coming from several thousands of software projects, using existing methodologies, and tools already developed. The project also provides a public platform for validation and industrial exploitation of results. The project is in its final stage, and some results and databases are already available, as is shown in this paper},
  timestamp = {2017-05-19T07:25:55Z},
  booktitle = {13th {{European Conference}} on {{Software Maintenance}} and {{Reengineering}}: {{Csmr}} 2009, {{Proceedings}}},
  publisher = {{Ieee Computer Soc}},
  author = {Herraiz, Israel and Izquierdo-Cortazar, Daniel and Rivas-Hernandez, Francisco and Gonzalez-Barahona, Jesus and Robles, Gregorio and Duenas-Dominguez, Santiago and Garcia-Campos, Carlos and Francisco Gato, Juan and Tovar, Liliana},
  editor = {Winter, A. and Knodel, J.},
  date = {2009},
  pages = {281--284}
}

@online{Google_2015a,
  title = {Bidding {{Farewell}} to {{Google Code}}},
  url = {http://google-opensource.blogspot.com/2015/03/farewell-to-google-code.html},
  timestamp = {2017-05-19T07:25:55Z},
  author = {{Google}},
  urldate = {2015-07-20},
  date = {2015}
}

@article{Robles_2009,
  title = {Tools for the {{Study}} of the {{Usual Data Sources Found}} in {{Libre Software Projects}}},
  volume = {1},
  issn = {1942-3926, 1942-3934},
  url = {http://www.igi-global.com/article/tools-study-usual-data-sources/2769},
  doi = {10.4018/jossp.2009010102},
  timestamp = {2017-05-19T07:25:55Z},
  number = {1},
  author = {Robles, Gregorio and González-Barahona, Jesús M. and Izquierdo-Cortazar, Daniel and Herraiz, Israel},
  urldate = {2013-05-13},
  date = {2009-31},
  pages = {24--45},
  keywords = {unavailable}
}

@article{Capiluppi_2011,
  title = {Software {{Reuse}} in {{Open Source}}},
  volume = {3},
  issn = {1942-3926, 1942-3934},
  url = {http://www.igi-global.com/article/software-reuse-open-source/68148},
  doi = {10.4018/jossp.2011070102},
  timestamp = {2017-05-19T07:25:55Z},
  number = {3},
  author = {Capiluppi, Andrea and Stol, Klaas-Jan and Boldyreff, Cornelia},
  urldate = {2013-05-14},
  date = {2011-33},
  pages = {10--35}
}

@book{Iqbal_2012,
  location = {{New York}},
  title = {Integrating {{Developer}}-{{Related Information}} across {{Open Source Repositories}}},
  isbn = {978-1-4673-2284-3},
  abstract = {Software developers use various software repositories in order to interact with each other or to solve software related problems. They are required to adopt an identity for each of the software repositories they wanted to use. Quite often developers are also found on different code forges developing open source projects. It is worth mentioning that the information relevant to the developers are distributed on the Web among different data sources each requires an ID and an authentication mechanism. In this paper, we propose to interlink the identities of a developer across different data sources on the Web. Further, we show the benefit of integrating developer-related information from different data sources using some real-world scenarios.},
  timestamp = {2017-05-19T07:25:55Z},
  publisher = {{Ieee}},
  author = {Iqbal, Aftab and Hausenblas, Michael},
  editor = {Zhang, C. and Joshi, J. and Bertino, E. and Thuraisingham, B.},
  date = {2012}
}

@incollection{Keivanloo_2012,
  location = {{New York}},
  title = {Semantic {{Web}} - {{The Missing Link}} in {{Global Source Code Analysis}}?},
  isbn = {978-0-7695-4736-7},
  abstract = {There has been an ongoing trend towards open and shared source code that is published on the Internet in large software repositories to support collaborative development processes. While traditional source code analysis techniques perform well in single project contexts, new types of global source code analysis techniques are slowly introduced to address the analysis of global distributed and often incomplete source code. In this article, we discuss how the Semantic Web, an enabling technology for these emerging source code analysis domains, can support a standardized, formal, and semantic rich representation to model these corpora. We also illustrate how inference services can be used to provide support for emerging source code analysis approaches on this data, such as search, call graph construction, and clone detection.},
  timestamp = {2017-05-19T07:25:55Z},
  booktitle = {2012 {{Ieee}} 36th {{Annual Computer Software}} and {{Applications Conference}} ({{Compsac}})},
  publisher = {{Ieee}},
  author = {Keivanloo, Iman and Rilling, Juergen and Charland, Philippe},
  editor = {Bai, X. and Belli, F. and Bertino, E. and Chang, C. K. and Elci, A. and Seceleanu, C. and Xie, H. and Zulkernine, M.},
  date = {2012},
  pages = {541--550},
  keywords = {irrelevant,Linked Data,semantic web,source code analysis}
}

@incollection{Keivanloo_2012a,
  location = {{New York}},
  title = {Online {{Sharing}} and {{Integration}} of {{Results}} from {{Mining Software Repositories}}},
  isbn = {978-1-4673-1067-3},
  abstract = {The mining of software repository involves the extraction of both basic and value-added information from existing software repositories. Depending on stakeholders (e. g., researchers, management), these repositories are mined several times for different application purposes. To avoid unnecessary pre-processing steps and improve productivity, sharing, and integration of extracted facts and results are needed. The motivation of this research is to introduce a novel collaborative sharing platform for software datasets that supports on-the-fly inter-datasets integration. We want to facilitate and promote a paradigm shift in the source code analysis domain, similar to the one by Wikipedia in the knowledge-sharing domain. In this paper, we present the SeCold project, which is the first online, publicly available software ecosystem Linked Data dataset. As part of this research, not only theoretical background on how to publish such datasets is provided, but also the actual dataset. SeCold contains about two billion facts, such as source code statements, software licenses, and code clones from over 18.000 software projects. SeCold is also an official member of the Linked Data cloud and one of the eight largest online Linked Data datasets available on the cloud.},
  timestamp = {2017-05-19T07:25:55Z},
  booktitle = {2012 34th {{International Conference}} on {{Software Engineering}} ({{Icse}})},
  publisher = {{Ieee}},
  author = {Keivanloo, Iman},
  editor = {Glinz, M. and Murphy, G. and Pezze, M.},
  date = {2012},
  pages = {1644--1646},
  keywords = {Linked Data,model,sharing,software mining}
}

@incollection{Schwarz_2012,
  location = {{New York}},
  title = {On {{How Often Code Is Cloned}} across {{Repositories}}},
  isbn = {978-1-4673-1067-3},
  abstract = {Detecting code duplication in large code bases, or even across project boundaries, is problematic due to the massive amount of data involved. Large-scale clone detection also opens new challenges beyond asking for the provenance of a single clone fragment, such as assessing the prevalence of code clones on the entire code base, and their evolution. We propose a set of lightweight techniques that may scale up to very large amounts of source code in the presence of multiple versions. The common idea behind these techniques is to use bad hashing to get a quick answer. We report on a case study, the Squeaksource ecosystem, which features thousands of software projects, with more than 40 million versions of methods, across more than seven years of evolution. We provide estimates for the prevalence of type-1, type-2, and type-3 clones in Squeaksource.},
  timestamp = {2017-05-19T07:25:55Z},
  booktitle = {2012 34th {{International Conference}} on {{Software Engineering}} ({{Icse}})},
  publisher = {{Ieee}},
  author = {Schwarz, Niko and Lungu, Mircea and Robbes, Romain},
  editor = {Glinz, M. and Murphy, G. and Pezze, M.},
  date = {2012},
  pages = {1289--1292},
  keywords = {ccfinder,Clone detection,Software ecosystems}
}

@article{Gonzalez-Barahona_2012,
  title = {On the {{Reproducibility}} of {{Empirical Software Engineering Studies Based}} on {{Data Retrieved}} from {{Development Repositories}}},
  volume = {17},
  issn = {1382-3256},
  doi = {10.1007/s10664-011-9181-9},
  abstract = {Among empirical software engineering studies, those based on data retrieved from development repositories (such as those of source code management, issue tracking or communication systems) are specially suitable for reproduction. However their reproducibility status can vary a lot, from easy to almost impossible to reproduce. This paper explores which elements can be considered to characterize the reproducibility of a study in this area, and how they can be analyzed to better understand the type of reproduction studies they enable or obstruct. One of the main results of this exploration is the need of a systematic approach to asses the reproducibility of a study, due to the complexity of the processes usually involved, and the many details to be taken into account. To address this need, a methodology for assessing the reproducibility of studies is also presented and discussed, as a tool to help to raise awareness about research reproducibility in this field. The application of the methodology in practice has shown how, even for papers aimed to be reproducible, a systematic analysis raises important aspects that render reproduction difficult or impossible. We also show how, by identifying elements and attributes related to reproducibility, it can be better understood which kind of reproduction can be done for a specific study, given the description of datasets, methodologies and parameters it uses.},
  timestamp = {2017-05-19T07:25:55Z},
  issue = {1-2},
  author = {Gonzalez-Barahona, Jesus M. and Robles, Gregorio},
  date = {2012-02},
  pages = {75--89},
  keywords = {knowledge,mining software repositories,Repeatable results,Reproducibility}
}

@article{Yu_2012,
  title = {An {{Evolutionary Programming Based Asymmetric Weighted Least Squares Support Vector Machine Ensemble Learning Methodology}} for {{Software Repository Mining}}},
  volume = {191},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2011.09.034},
  abstract = {In this paper, a novel evolutionary programming (EP) based asymmetric weighted least squares support vector machine (LSSVM) ensemble learning methodology is proposed for software repository mining. In this methodology, an asymmetric weighted LSSVM model is first proposed. Then the process of building the EP-based asymmetric weighted LSSVM ensemble learning methodology is described in detail. Two publicly available software defect datasets are finally used for illustration and verification of the effectiveness of the proposed EP-based asymmetric weighted LSSVM ensemble learning methodology. Experimental results reveal that the proposed EP-based asymmetric weighted LSSVM ensemble learning methodology can produce promising classification accuracy in software repository mining, relative to other classification methods listed in this study. (C) 2011 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:25:55Z},
  author = {Yu, Lean},
  date = {2012-05-15},
  pages = {31--46},
  keywords = {Asymmetric weighted least squares support vector machine,classifiers,defect prediction,Ensemble learning algorithm,Evolutionary programming,field,framework,management,Models,neural-network ensembles,Software repository mining,source code}
}

@article{Shao_2012,
  title = {Mapping {{Collaboration}} in {{Open Source Geospatial Ecosystem}}},
  volume = {16},
  issn = {1361-1682},
  doi = {10.1111/j.1467-9671.2012.01305.x},
  abstract = {Over the last decade, there has been a tremendous growth and exploitation of open source geospatial software and technologies. A combination of factors is driving this momentum, including the contributions made by hundreds of developers and the leading role played by the Open Source Geospatial Foundation (OSGeo), aiming primarily to support and promote the collaborative development of open source geospatial technologies and data. This article seeks to map out the social history of collaborative activities within the OSGeo ecosystem. We used the archival logs of developers' contributions, specifically looking for boundary spanning activities where contributions crossed multiple projects. The analysis and visualization of these activities allow us to have a better understanding of the role of boundary spanning in the resourcing of each project, the incubation mechanism advocated by OSGeo, and the significance of the social interrelatedness among projects. The data consisted of the subversion (SVN) commit history made by individual developers in the programming code repository. We applied several network analytical and visualization techniques to explore the data. Our findings indicate that more than one in seven developers spanned multiple projects which potentially had the effects of shaping the projects' directions, and increased knowledge flow and innovation. In addition, the OSGeo's incubation mechanism provided an important encouragement for boundary spanning and increased knowledge sharing. By studying the social history of contributions, further tools can be developed in future to assist tracking of the social history, and make developers mindful of the significance of the interdependence among projects and hence continuously contribute to the health of the OSGeo ecosystem.},
  timestamp = {2017-05-19T07:25:55Z},
  number = {4},
  author = {Shao, Jianhua and Anand, Suchith and Jackson, Mike J. and Kuk, George and Morley, Jeremy G. and Mitchell, Tyler},
  date = {2012-08},
  pages = {581--597}
}

@article{Gerlec_2012,
  title = {A {{Programming Language Independent Framework}} for {{Metrics}}-{{Based Software Evolution}} and {{Analysis}}},
  volume = {9},
  issn = {1820-0214},
  doi = {10.2298/CSIS120104026G},
  abstract = {Knowledge about different aspects of software quality during software evolution can be valuable information for developers and project managers. It helps to reduce the number of defects and improves the internal structure of software. However, determining software's quality and structure in heterogeneous systems is a difficult task. In this paper, a programming language independent framework for evaluating software metrics and analyzing software structure during software development and its evolution will be presented. The framework consists of the SMIILE tool for calculation of software metrics, extended with an analysis of software structure. The data are stored in a central repository via enriched Concrete Syntax Tree (eCST) for universal source code representation. The framework is demonstrated in a case study. The development of such a framework is a step forward to consistent support for software evolution by providing a change analysis and quality control. The significance of this consistency is growing today, when software projects are more complex, consisting of components developed in diverse programming languages.},
  timestamp = {2017-05-19T07:25:55Z},
  number = {3},
  author = {Gerlec, Crt and Rakic, Gordana and Budimac, Zoran and Hericko, Marjan},
  date = {2012-09},
  pages = {1155--1186},
  keywords = {History,software development,Software evolution,software metrics,software quality,software structure,syntax tree}
}

@article{Phannachitta_2012,
  title = {An {{Algorithm}} for {{Gradual Patch Acceptance Detection}} in {{Open Source Software Repository Mining}}},
  volume = {E95A},
  issn = {0916-8508},
  doi = {10.1587/transfun.E95.A.1478},
  abstract = {Nowadays, software development societies have given more precedence to Open Source Software (OSS). There is much research aimed at understanding the OSS society to sustain the OSS product. To lead an OSS project to a successful conclusion, researchers study how developers change source codes called patches in project repositories. In existing studies, we found an argument in the conventional patch acceptance detection procedure. It was so simplified that it omitted important cases from the analysis, and would lead researchers to wrong conclusions. In this research, we propose an algorithm to overcome the problem. To prove out our algorithm, we constructed a framework and conducted two case studies. As a result, we came to a new and interesting understanding of patch activities.},
  timestamp = {2017-05-19T07:25:55Z},
  number = {9},
  author = {Phannachitta, Passakorn and Ihara, Akinori and Jirapiwong, Pijak and Ohira, Masao and Matsumoto, Ken-ichi},
  date = {2012-09},
  pages = {1478--1489},
  keywords = {Open source software,OSS evolution pattern,OSS repository mining,patch acceptance,patch submission}
}

@article{Alam_2012,
  title = {Preserving {{Knowledge}} in {{Software Projects}}},
  volume = {85},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2012.03.028},
  abstract = {Up-to-date preservation of project knowledge like developer communication and design documents is essential for the successful evolution of software systems. Ideally, all knowledge should be preserved, but since projects only have limited resources, and software systems continuously grow in scope and complexity, one needs to prioritize the subsystems and development periods for which knowledge preservation is more urgent. For example, core subsystems on which the majority of other subsystems build are obviously prime candidates for preservation, yet if these subsystems change continuously, picking a development period to start knowledge preservation and to maintain knowledge for over time become very hard. This paper exploits the time dependence between code changes to automatically determine for which subsystems and development periods of a software project knowledge preservation would be most valuable. A case study on two large open source projects (PostgreSQL and FreeBSD) shows that the most valuable subsystems to preserve knowledge for are large core subsystems. However, the majority of these subsystems (1) are continuously foundational, i.e., ideally for each development period knowledge should be preserved, and (2) experience substantial changes, i.e., preserving knowledge requires substantial effort. (C) 2012 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:25:55Z},
  number = {10},
  author = {Alam, Omar and Adams, Bram and Hassan, Ahmed E.},
  date = {2012-10},
  pages = {2318--2330},
  keywords = {Documentation,Empirical analysis,Evolution,History,Knowledge preservation,mining software repositories,Software maintenance,systems}
}

@article{Shang_2012,
  title = {Using {{Pig}} as a {{Data Preparation Language}} for {{Large}}-{{Scale Mining Software Repositories Studies}}: {{An Experience Report}}},
  volume = {85},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2011.07.034},
  shorttitle = {Using {{Pig}} as a {{Data Preparation Language}} for {{Large}}-{{Scale Mining Software Repositories Studies}}},
  abstract = {The Mining Software Repositories (MSR) field analyzes software repository data to uncover knowledge and assist development of ever growing, complex systems. However, existing approaches and platforms for MSR analysis face many challenges when performing large-scale MSR studies. Such approaches and platforms rarely scale easily out of the box. Instead, they often require custom scaling tricks and designs that are costly to maintain and that are not reusable for other types of analysis. We believe that the web community has faced many of these software engineering scaling challenges before, as web analyses have to cope with the enormous growth of web data. In this paper, we report on our experience in using a web-scale platform (i.e., Pig) as a data preparation language to aid large-scale MSR studies. Through three case studies, we carefully validate the use of this web platform to prepare (i.e., Extract, Transform, and Load, ETL) data for further analysis. Despite several limitations, we still encourage MSR researchers to leverage Pig in their large-scale studies because of Pig's scalability and flexibility. Our experience report will help other researchers who want to scale their analyses. (C) 2011 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {10},
  author = {Shang, Weiyi and Adams, Bram and Hassan, Ahmed E.},
  date = {2012-10},
  pages = {2195--2204},
  keywords = {code,Evolution,MapReduce,mining software repositories,Pig,Software engineering}
}

@article{Sihai_2013,
  title = {Statistical Properties of File Modification in Open-Source Software Repositories:Case Studies},
  volume = {49},
  issn = {1002-8331},
  shorttitle = {Statistical Properties of File Modification in Open-Source Software Repositories},
  abstract = {Open and collaborative development of open-source software may change the traditional mode for software development. Mining the evolutionary rules of source code files in a SVN(Subversion) repository is conducive to detecting potential bugs and then to improving the quality of software. This paper conducts empirical experiments on two object-oriented open-source software systems, and finds that the number of changes for class files follows roughly a power-law distribution, the modification difference between a pair of adjacent versions of frequently-changed classes also follows approximately a power-law distribution, and there are significantly positive correlations between the number of changes and both source lines of code and the number of imported classes, implying that the function and structure of these classes tend to become more complex. The findings of these 2 case studies provide new insights into the research on evolution, refactoring, and task allocation of maintenance for open-source software.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {2},
  author = {Sihai, Lin and Yutao, Ma and Jianxun, Chen},
  date = {2013},
  pages = {80--85},
  keywords = {open source,power law,reversion,svn}
}

@article{Capiluppi_2013,
  title = {Effort {{Estimation}} of {{FLOSS Projects}}: {{A Study}} of the {{Linux Kernel}}},
  volume = {18},
  issn = {1382-3256},
  doi = {10.1007/s10664-011-9191-7},
  shorttitle = {Effort {{Estimation}} of {{FLOSS Projects}}},
  abstract = {Empirical research on Free/Libre/Open Source Software (FLOSS) has shown that developers tend to cluster around two main roles: "core" contributors differ from "peripheral" developers in terms of a larger number of responsibilities and a higher productivity pattern. A further, cross-cutting characterization of developers could be achieved by associating developers with "time slots", and different patterns of activity and effort could be associated to such slots. Such analysis, if replicated, could be used not only to compare different FLOSS communities, and to evaluate their stability and maturity, but also to determine within projects, how the effort is distributed in a given period, and to estimate future needs with respect to key points in the software life-cycle (e.g., major releases). This study analyses the activity patterns within the Linux kernel project, at first focusing on the overall distribution of effort and activity within weeks and days; then, dividing each day into three 8-hour time slots, and focusing on effort and activity around major releases. Such analyses have the objective of evaluating effort, productivity and types of activity globally and around major releases. They enable a comparison of these releases and patterns of effort and activities with traditional software products and processes, and in turn, the identification of company-driven projects (i.e., working mainly during office hours) among FLOSS endeavors. The results of this research show that, overall, the effort within the Linux kernel community is constant (albeit at different levels) throughout the week, signalling the need of updated estimation models, different from those used in traditional 9am-5pm, Monday to Friday commercial companies. It also becomes evident that the activity before a release is vastly different from after a release, and that the changes show an increase in code complexity in specific time slots (notably in the late night hours), which will later require additional maintenance efforts.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {1},
  author = {Capiluppi, Andrea and {Daniel Izquierdo-Cortazar}},
  date = {2013-02},
  pages = {60--88},
  keywords = {complexity,cost estimation,Effort estimation,Effort models,effort prediction,Evolution,maintenance,method,metrics,mining software repositories,Models,Open source software,validation}
}

@article{diBella_2013,
  title = {A {{Multivariate Classification}} of {{Open Source Developers}}},
  volume = {221},
  doi = {10.1016/j.ins.2012.09.031},
  abstract = {Open source software development is becoming always more relevant. Understanding the behavior of developers in open source software projects and identifying the kinds of their contributions is an essential step to improve the efficiency of the development process and to organize the development teams more effectively. Moreover, understanding the level of participation of the different developers helps to understand which members of the development team are more important than others and who are the actual key developers. This paper investigates the behavior of open source developers and the structure of the development of open source projects through the analysis of a very large dataset: 10 well-known and widely used open source software projects for a total of more than 4 MLOC (millions of lines of code) modified distributed in more than 200 K versions. This study builds on the top of other studies in this area applying a set of rigorous statistical techniques, analyzing how developers contribute to the projects. Its novelty is in the fine gain analysis of the developers that have commit rights on the repository of the project they work on, in the automated identification of key contributors of the project, in the size of the analyzed datasets, and in the statistical techniques used to classify the behavior of the developers in an automated way. To collect such large volume of data and to ensure their integrity, a tool to automatically mine open source version control systems has been used. The main result of this study is the identification of a recurrent pattern of four kinds of contributors with the same characteristics in all the projects analyzed even if the projects are very different in domain, size, language, etc. (C) 2012 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:25:56Z},
  author = {di Bella, Enrico and Sillitti, Alberto and Succi, Giancarlo},
  date = {2013-02-01},
  pages = {72--83},
  keywords = {clustering,developers},
  options = {useprefix=true}
}

@article{Bettenburg_2013,
  title = {Studying the {{Impact}} of {{Social Interactions}} on {{Software Quality}}},
  volume = {18},
  issn = {1382-3256},
  doi = {10.1007/s10664-012-9205-0},
  abstract = {Correcting software defects accounts for a significant amount of resources in a software project. To make best use of testing efforts, researchers have studied statistical models to predict in which parts of a software system future defects are likely to occur. By studying the mathematical relations between predictor variables used in these models, researchers can form an increased understanding of the important connections between development activities and software quality. Predictor variables used in past top-performing models are largely based on source code-oriented metrics, such as lines of code or number of changes. However, source code is the end product of numerous interlaced and collaborative activities carried out by developers. Traces of such activities can be found in the various repositories used to manage development efforts. In this paper, we develop statistical models to study the impact of social interactions in a software project on software quality. These models use predictor variables based on social information mined from the issue tracking and version control repositories of two large open-source software projects. The results of our case studies demonstrate the impact of metrics from four different dimensions of social interaction on post-release defects. Our findings show that statistical models based on social information have a similar degree of explanatory power as traditional models. Furthermore, our results demonstrate that social information does not substitute, but rather augments traditional source code-based metrics used in defect prediction models.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {2},
  author = {Bettenburg, Nicolas and Hassan, Ahmed E.},
  date = {2013-04},
  pages = {375--431},
  keywords = {code churn,Human factors,metrics,Metrics/measurement,Software evolution,Software quality assurance}
}

@article{Soares_2013,
  title = {Comparing {{Approaches}} to {{Analyze Refactoring Activity}} on {{Software Repositories}}},
  volume = {86},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2012.10.040},
  abstract = {Some approaches have been used to investigate evidence on how developers refactor their code, whether refactorings activities may decrease the number of bugs, or improve developers' productivity. However, there are some contradicting evidence in previous studies. For instance, some investigations found evidence that if the number of refactoring changes increases in the preceding time period the number of defects decreases, different from other studies. They have used different approaches to evaluate refactoring activities. Some of them identify committed behavior-preserving transformations in software repositories by using manual analysis, commit messages, or dynamic analysis. Others focus on identifying which refactorings are applied between two programs by using manual inspection or static analysis. In this work, we compare three different approaches based on manual analysis, commit message (Ratzinger's approach) and dynamic analysis (SAFEREFACTOR'S approach) to detect whether a pair of versions determines a refactoring, in terms of behavioral preservation. Additionally, we compare two approaches (manual analysis and REF-FINDER) to identify which refactorings are performed in each pair of versions. We perform both comparisons by evaluating their accuracy, precision, and recall in a randomly selected sample of 40 pairs of versions of JHotDraw, and 20 pairs of versions of Apache Common Collections. While the manual analysis presents the best results in both comparisons, it is not as scalable as the automated approaches. Ratzinger's approach is simple and fast, but presents a low recall; differently, SAFEREFACTOR is able to detect most applied refactorings, although limitations in its test generation backend results for some kinds of subjects in low precision values. REF-FINDER presented a low precision and recall in our evaluation. (c) 2012 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {4},
  author = {Soares, Gustavo and Gheyi, Rohit and Murphy-Hill, Emerson and Johnson, Brittany},
  date = {2013-04},
  pages = {1006--1022},
  keywords = {Automated analysis,java programs,Manual analysis,Refactoring,Repository}
}

@online{Gomez_2014,
  title = {{{CoderStats Blog}}},
  url = {http://blog.coderstats.net/},
  timestamp = {2017-05-19T07:25:56Z},
  author = {Gomez, Ramiro},
  urldate = {2015-07-22},
  date = {2014}
}

@article{Niederer_2010,
  title = {Wisdom of the {{Crowd}} or {{Technicity}} of {{Content}}? {{Wikipedia}} as a {{Socio}}-{{Technical System}}},
  volume = {12},
  url = {http://dare.uva.nl/cgi/arno/show.cgi?fid=337567},
  shorttitle = {Full {{Title}}},
  abstract = {Sabine Niederer \& José van Dijck (2010). "Wisdom of the Crowd or Technicity of Content? Wikipedia as a Socio-Technical System." New Media \& Society 12 (8): 1368-1387.},
  timestamp = {2017-05-19T07:25:56Z},
  author = {Niederer, Sabine and van Dijck, José},
  urldate = {2015-07-30},
  date = {2010},
  options = {useprefix=true}
}

@article{Marres_2015,
  title = {Interface {{Methods}}: {{Renegotiating Relations}} between {{Digital Social Research}}, {{STS}} and {{Sociology}}},
  url = {http://research.gold.ac.uk/11343/},
  shorttitle = {Interface {{Methods}}},
  timestamp = {2017-05-19T07:25:56Z},
  author = {Marres, Noortje and Gerlitz, Carolin and {others}},
  urldate = {2015-07-30},
  date = {2015}
}

@article{Sismondo_2010,
  title = {Inclusion by {{Numbers}}: {{New Biomedical Subjects}} and {{Biopolitical Citizens}}},
  volume = {40},
  doi = {10.1177/0306312710363512},
  shorttitle = {Inclusion by {{Numbers}}},
  timestamp = {2017-05-19T07:25:56Z},
  number = {4},
  author = {Sismondo, Sergio},
  date = {2010-08},
  pages = {633--640}
}

@article{Lampland_2010,
  title = {False {{Numbers}} as {{Formalizing Practices}}},
  volume = {40},
  doi = {10.1177/0306312709359963},
  abstract = {It will be argued that false numbers in working documents, formulae, and business plans are used as temporary or conditional devices to enable rationalization. The social processes of creating formalized practices depend upon activities that are themselves conditional and ephemeral. That is, rather than subvert the ostensible purpose of fixed representation, false numbers make stability and fixity in representation possible. Examples used include business forecasting, property tax assessments, and the introduction of accounting into cooperative agriculture in Stalinist Hungary.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {3},
  author = {Lampland, Martha},
  date = {2010-06},
  pages = {377--404}
}

@article{Miller_2009,
  title = {What {{Does It Mean That PRIMES Is}} in {{P}}? {{Popularization}} and {{Distortion Revisited}}},
  volume = {39},
  doi = {10.1177/0306312708101131},
  shorttitle = {What {{Does It Mean That PRIMES Is}} in {{P}}?},
  abstract = {In August 2002 three Indian computer scientists published a paper entitled 'PRIMES is in P' online. It presents a 'deterministic algorithm' which determines in 'polynomial time' if a given number is a prime number. The story was quickly picked up by the general press, and by this means spread through the scientific community of complexity theorists, where it was hailed as a major theoretical breakthrough. This is despite scientists regarding the media reports as vulgar popularizations. When the paper was published in a peer-reviewed journal only l years later, the three scientists had already received wide recognition for their accomplishment. Current sociological theory challenges the ability to clearly distinguish on independent epistemic grounds between distorted and non-distorted scientific knowledge. It views the demarcation lines between such forms of presentation as contextual and unstable. In my paper, I challenge this view. By systematically surveying the popular press coverage of the 'PRIMES is in P' affair, I argue-against the prevailing new orthodoxy-that distorted simplifications of scientific knowledge are distinguishable from non-distorted simplifications on independent epistemic grounds. I argue that in the 'PRIMES is in P' affair, the three scientists could ride on the wave of the general press-distorted coverage of their algorithm, while counting on their colleagues' ability to distinguish genuine accounts from distorted ones. Thus, their scientific reputation was unharmed. This suggests that the possibility of the existence of independent epistemic standards must be incorporated into the new SSK model of popularization.},
  timestamp = {2017-05-19T07:25:56Z},
  number = {2},
  author = {Miller, Boaz},
  date = {2009-04},
  pages = {257--288}
}

@article{Godin_2007,
  title = {From {{Eugenics}} to {{Scientometrics}}: {{Galton}}, {{Catell}}, and {{Men}} of {{Science}}},
  volume = {37},
  doi = {10.1177/0306312706075338},
  shorttitle = {From {{Eugenics}} to {{Scientometrics}}},
  abstract = {In 1906, James McKeen Cattell, editor of Science, published a directory of men of science. American Men of Science was a collection of biographical sketches of thousands of men of science in the USA and was published periodically. It launched, and was used in, the very first systematic quantitative studies on science. Cattell used two concepts for his statistics: productivity, defined as the number of men of science a nation produces, and performance or merit, defined as scientific contributions to research as judged by peers. These are the two dimensions that still define measurement of scientific productivity today: quantity and quality. This paper analyzes the emergence of statistics on science and the very first uses to which they were put. It argues that the measurement of science emerged out of interest in great men, heredity and eugenics, and the contribution of eminent men to civilization. Among these eminent men were men of science, the population of whom was thought to be in decline and insufficiently appreciated and supported. Statistics on men of science thus came to be collected to document the case, and to contribute to the advancement of science and the scientific profession.},
  timestamp = {2017-05-19T07:25:57Z},
  number = {5},
  author = {Godin, Benoit},
  date = {2007-10},
  pages = {691--728}
}

@article{Bloomfield_1991,
  title = {The {{Role}} of {{Information}}-{{Systems}} in the {{Uk}}-{{National}}-{{Health}}-{{Service}} - {{Action}} at a {{Distance}} and the {{Fetish}} of {{Calculation}}},
  volume = {21},
  doi = {10.1177/030631291021004004},
  abstract = {This paper examines some fundamental issues pertaining to the use of, as well as to the distinctive characteristics of, information technology in relation to the development of information systems within the UK National Health Service (NHS). The paper refers to the current Resource Management Initiative in the NHS, which involves the fabrication of information systems to connect medical activity to resource usage, and thus to costs. Examining the features of some of the rival inscriptions undergoing development to make this connection visible, the paper highlights the properties of information technology in enhancing their mobilization. It also addresses the immutability and combinability of these inscriptions, and discusses some of the implications, in terms of medical practice and knowledge, which may follow from their use.},
  timestamp = {2017-05-19T07:25:57Z},
  number = {4},
  author = {Bloomfield, Bp},
  date = {1991-11},
  pages = {701--734}
}

@article{Watson_1990,
  title = {Investigating the {{Social Foundations}} of {{Mathematics}} - {{Natural Number}} in {{Culturally Diverse Forms}} of {{Life}}},
  volume = {20},
  doi = {10.1177/030631290020002004},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Watson, H.},
  date = {1990-05},
  pages = {283--312}
}

@article{Day_2014,
  title = {Number {{Ecologies}}: {{Numbers}} and {{Numbering Practices}}},
  volume = {15},
  issn = {1600-910X},
  url = {http://dx.doi.org/10.1080/1600910X.2014.923011},
  doi = {10.1080/1600910X.2014.923011},
  shorttitle = {Number {{Ecologies}}},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Day, Sophie and Lury, Celia and Wakeford, Nina},
  urldate = {2016-01-25},
  date = {2014-05-04},
  pages = {123--154}
}

@article{Gerlitz_2014,
  title = {Social {{Media}} and {{Self}}-{{Evaluating Assemblages}}: {{On Numbers}}, {{Orderings}} and {{Values}}},
  volume = {15},
  issn = {1600-910X},
  url = {http://dx.doi.org/10.1080/1600910X.2014.920267},
  doi = {10.1080/1600910X.2014.920267},
  shorttitle = {Social {{Media}} and {{Self}}-{{Evaluating Assemblages}}},
  abstract = {This paper takes tools of self-valuation in social media as an empirical focus. By way of a case-study of Klout, an influential measure of influence, we suggest that the forms of reactivity and self-fulfilling prophecy that have been identified as a problem with some forms of measurement are actually an intentional effect of such tools: that is, the measurements that such tools produce are not designed to capture a separate reality, but are deliberately employed to modify the activity that they themselves invite. In other words, they expect and exploit reactivity. We suggest that such media are indicative of the rise in what might be called participative metrics of value. We further suggest that the capacity to evaluate and modify the self that Klout affords is intricately tied up with the agency and (self-)valuation of Klout as a tool itself. An intermediate layer of the argument is that this tying up is achieved through the production of numbers as specific kinds of ‘enumerated entities’. We use this term to draw attention to the ways in which numbers are never simply abstractions, but always have specific material-semiotic properties. In this case, we show that these properties are tied to the use of media-specific operations, and that these properties, including those of inclusion and belonging, inform how Klout participates in particular kinds of ordering and valuation. We thus explore the interlinked movement of numbers, media, and value in social media as a kind of dynamic assemblage.},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Gerlitz, Carolin and Lury, Celia},
  urldate = {2016-01-25},
  date = {2014-05-04},
  pages = {174--188}
}

@article{Nafus_2014,
  title = {Stuck {{Data}}, {{Dead Data}}, and {{Disloyal Data}}: {{The Stops}} and {{Starts}} in {{Making Numbers}} into {{Social Practices}}},
  volume = {15},
  issn = {1600-910X},
  url = {http://dx.doi.org/10.1080/1600910X.2014.920266},
  doi = {10.1080/1600910X.2014.920266},
  shorttitle = {Stuck {{Data}}, {{Dead Data}}, and {{Disloyal Data}}},
  abstract = {Indicators with long social histories, such as the Consumer Price Index, often serve as nodes of calculative infrastructures. They create a field of social action, making some relations between people, institutions, and materials possible, and other relations less possible. By reflecting on two experiments in do-it-yourself sensor data, this article explores the tensions that occur when indicators have not yet become stable entities. When the conditions of possibility for the indicator's continued existence are less assured, the labor it takes to build numbers into something socially meaningful becomes surprisingly visible. This labor proceeds in stops and starts, as the various material and epistemological and social resistances reveal themselves. Sensors shape these starts and stops. Sensors give their users an indication of a possible whole entity whose contents they cannot fully imagine, and either must create or abandon. Far from producing certainty, sensor data often provokes a sense of vagueness that is worked on until it becomes either clarity or action, failure or indifference. Through this view of numbers in the making, we can see just how remarkable it is that indicators become part of calculative infrastructures at all.},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Nafus, Dawn},
  urldate = {2016-01-25},
  date = {2014-05-04},
  pages = {208--222}
}

@article{Guyer_2014,
  title = {Percentages and {{Perchance}}: {{Archaic Forms}} in the {{Twenty}}-{{First Century}}},
  volume = {15},
  issn = {1600-910X},
  url = {http://dx.doi.org/10.1080/1600910X.2014.920268},
  doi = {10.1080/1600910X.2014.920268},
  shorttitle = {Percentages and {{Perchance}}},
  abstract = {As sequel to an earlier paper on ordinal ranking, this paper focuses on another old, but increasingly widespread, numerical expression, in both technical and public domains: namely, the percentage. It argues that the long and expanding genealogy of use, from descriptive to governmental to probabilistic, gives it persuasive as well as instrumental power, as people come to grips with novel terms of life by drawing on old concepts. The ‘one hundred’ offers a sense of understanding, while in public expressions, there appears to be an increasing vagueness of the specific nature of the one hundred as denominator and a new potential for one hundred to gesture towards an aspirational future rather than any simple description of the present. The second section engages with Helen Verran's approach to number, where she shows how numerical expressions can move from one mode to another through the possibility of expressing both one/many and part/whole relationships. The next section illustrates the applications of percentage in different domains of social life, particularly as proportion in governance (the tax regime) and political philosophy (Rawls on ‘fairness’), both of which orient instrumentally towards a future. The final section describes a current representation of the city of Baltimore in ordinals and percentages, oriented in more clearly expressive, aspirational terms, towards a future whose nature has become indeterminate. The conclusion reaffirms the importance of an ethnographic approach to widely used numerical forms, such as percentage, in all contexts, as they mediate public understanding and aspiration.},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Guyer, Jane I.},
  urldate = {2016-01-25},
  date = {2014-05-04},
  pages = {155--173}
}

@article{Dumit_2014,
  title = {Writing the {{Implosion}}: {{Teaching}} the {{World One Thing}} at a {{Time}}},
  volume = {29},
  issn = {15481360},
  url = {http://culanth.org/articles/741-writing-the-implosion-teaching-the-world-one},
  doi = {10.14506/ca29.2.09},
  shorttitle = {Writing the {{Implosion}}},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Dumit, Joseph},
  urldate = {2016-01-27},
  date = {2014-05-19},
  pages = {344--362}
}

@inproceedings{Guzman_2014,
  location = {{New York, NY, USA}},
  title = {Sentiment {{Analysis}} of {{Commit Comments}} in {{GitHub}}: {{An Empirical Study}}},
  isbn = {978-1-4503-2863-0},
  url = {http://doi.acm.org/10.1145/2597073.2597118},
  doi = {10.1145/2597073.2597118},
  shorttitle = {Sentiment {{Analysis}} of {{Commit Comments}} in {{GitHub}}},
  abstract = {Emotions have a high impact in productivity, task quality, creativity, group rapport and job satisfaction. In this work we use lexical sentiment analysis to study emotions expressed in commit comments of different open source projects and analyze their relationship with different factors such as used programming language, time and day of the week in which the commit was made, team distribution and project approval. Our results show that projects developed in Java tend to have more negative commit comments, and that projects that have more distributed teams tend to have a higher positive polarity in their emotional content. Additionally, we found that commit comments written on Mondays tend to a more negative emotion. While our results need to be confirmed by a more representative sample they are an initial step into the study of emotions and related factors in open source projects.},
  timestamp = {2017-05-19T07:25:57Z},
  booktitle = {Proceedings of the 11th {{Working Conference}} on {{Mining Software Repositories}}},
  series = {MSR 2014},
  publisher = {{ACM}},
  author = {Guzman, Emitza and Azócar, David and Li, Yang},
  urldate = {2016-02-25},
  date = {2014},
  pages = {352--355},
  keywords = {Human Factors in Software Engineering,Sentiment Analysis}
}

@book{Manning_2013,
  title = {Big {{Data}} in {{History}}},
  timestamp = {2017-05-19T07:25:57Z},
  publisher = {{Palgrave Macmillan}},
  author = {Manning, Patrick},
  date = {2013}
}

@article{Espeland_2008,
  title = {A {{Sociology}} of {{Quantification}}},
  volume = {49},
  issn = {1474-0583},
  url = {http://journals.cambridge.org/article_S0003975609000150},
  doi = {10.1017/S0003975609000150},
  abstract = {One of the most notable political developments of the last thirty years has been increasing public and governmental demand for the quantification of social phenomena, yet sociologists generally have paid little attention to the spread of quantification or the significance of new regimes of measurement. Our article addresses this oversight by analyzing quantification – the production and communication of numbers – as a general sociological phenomenon. Drawing on scholarship across the social sciences in Europe and North America as well as humanistic inquiry, we articulate five sociological dimensions of quantification and call for an ethics of numbers.},
  timestamp = {2017-05-19T07:25:57Z},
  issue = {03},
  author = {Espeland, Wendy Nelson and Stevens, Mitchell L.},
  urldate = {2016-02-25},
  date = {2008-12},
  pages = {401--436}
}

@online{Gage_2015,
  title = {{{GitHub Raises}} \$250 {{Million}} at \$2 {{Billion Valuation}}},
  url = {http://www.wsj.com/articles/github-raises-250-million-at-2-billion-valuation-1438206722},
  abstract = {GitHub this week raised \$250 million from prominent Silicon Valley venture firms, the company said. The infusion raised its valuation to about \$2 billion, according to sources familiar with the matter.},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Gage, Deborah},
  urldate = {2016-02-26},
  date = {2015-07-29}
}

@online{Google_2016,
  title = {Github {{Timeline Data}} on {{Google BigQuery}}},
  url = {https://bigquery.cloud.google.com/table/githubarchive:github.timeline},
  timestamp = {2017-05-19T07:25:57Z},
  author = {{Google}},
  urldate = {2016-02-29},
  date = {2016}
}

@online{EclipseFoundation_2016,
  title = {Eclipse - {{The Eclipse Foundation Open Source Community Website}}.},
  url = {https://www.eclipse.org/},
  abstract = {Eclipse is probably best known as a Java IDE, but it is more: it is an IDE framework, a tools framework, an open source project, a community, an eco-system, and a foundation.},
  timestamp = {2017-05-19T07:25:57Z},
  author = {{Eclipse Foundation}},
  urldate = {2016-03-03},
  date = {2016}
}

@book{Ensmenger_2010,
  title = {The {{Computer Boys Take Over}}: {{Computers}}, {{Programmers}}, and the {{Politics}} of {{Technical Expertise}}},
  isbn = {978-0-262-51796-6},
  url = {http://www.jstor.org.ezproxy.lancs.ac.uk/stable/j.ctt5hhjdh},
  shorttitle = {The {{Computer Boys Take Over}}},
  abstract = {This is a book about the computer revolution of the mid-twentieth century and the people who made it possible. Unlike most histories of computing, it is not a book about machines, inventors, or entrepreneurs. Instead, it tells the story of the vast but largely anonymous legions of computer specialists–programmers, systems analysts, and other software developers–who transformed the electronic computer from a scientific curiosity into the defining technology of the modern era. As the systems that they built became increasingly powerful and ubiquitous, these specialists became the focus of a series of critiques of the social and organizational impact of electronic computing. To many of their contemporaries, it seemed the "computer boys" were taking over, not just in the corporate setting, but also in government, politics, and society in general. In The Computer Boys Take Over, Nathan Ensmenger traces the rise to power of the computer expert in modern American society. His rich and nuanced portrayal of the men and women (a surprising number of the "computer boys" were, in fact, female) who built their careers around the novel technology of electronic computing explores issues of power, identity, and expertise that have only become more significant in our increasingly computerized society.In his recasting of the drama of the computer revolution through the eyes of its principle revolutionaries, Ensmenger reminds us that the computerization of modern society was not an inevitable process driven by impersonal technological or economic imperatives, but was rather a creative, contentious, and above all, fundamentally human development.},
  timestamp = {2017-05-19T07:25:57Z},
  publisher = {{MIT Press}},
  author = {Ensmenger, Nathan},
  urldate = {2016-03-06},
  date = {2010}
}

@article{Leydesdorff_2013,
  title = {Global {{Maps}} of {{Science Based}} on the {{New Web}}-of-{{Science Categories}}},
  volume = {94},
  url = {http://link.springer.com/article/10.1007/s11192-012-0784-8},
  timestamp = {2017-05-19T07:25:57Z},
  number = {2},
  author = {Leydesdorff, Loet and Carley, Stephen and Rafols, Ismael},
  urldate = {2016-03-08},
  date = {2013},
  pages = {589--593}
}

@online{Foreman-Mackay_2014,
  title = {The {{Open Source Report Card}}},
  url = {https://web.archive.org/web/20140214105201/http://osrc.dfm.io/},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Foreman-Mackay, Dan},
  urldate = {2016-03-11},
  date = {2014-02-14}
}

@online{Roussell_2015,
  title = {Octoboard},
  url = {https://web.archive.org/web/20150801193208/http://octoboard.com/},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Roussell, Dennis},
  urldate = {2016-03-11},
  date = {2015-08-01}
}

@online{Bynens_2016,
  title = {Mathiasbynens/{{Dotfiles}}},
  url = {https://github.com/mathiasbynens/dotfiles},
  abstract = {dotfiles - :wrench: .files, including $\backslash$textasciitilde/.osx — sensible hacker defaults for OS X},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Bynens, Mathias},
  urldate = {2016-03-15},
  date = {2016}
}

@article{Rogers_2004,
  title = {Information {{Politics}} on the {{Web}}},
  url = {http://mitpress.mit.edu/catalog/item/default.asp?ttype=2&tid=10329},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Rogers, Richard},
  urldate = {2012-07-17},
  date = {2004-12-01}
}

@online{Finley_2012,
  title = {5 {{Ways}} to {{Tell Which Programming Languages Are Most Popular}}},
  url = {http://www.readwriteweb.com/hack/2012/06/5-ways-to-tell-which-programming-lanugages-are-most-popular.php},
  abstract = {Are older programming languages like Java and Perl giving way to newer languages like Python and Ruby? Is HTML5/CSS3/JavaScript overtaking Flash and/or native mobile application development? Do Microsoft’s languages still have a large developer following, even as Microsoft promotes other languages as first-class citizens on platforms such as Windows 8 and Azure? Finding the answer to these questions can be harder than you think.},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Finley, Klint},
  urldate = {2012-09-17},
  date = {2012}
}

@online{_n,
  title = {The {{Metacommunity Concept}}: {{A Framework}} for {{Multi}}-{{Scale Community Ecology}} - {{Leibold}} - 2004 - {{Ecology Letters}} - {{Wiley Online Library}}},
  url = {http://onlinelibrary.wiley.com.ezproxy.lancs.ac.uk/doi/10.1111/j.1461-0248.2004.00608.x/full},
  timestamp = {2017-05-19T07:25:57Z},
  urldate = {2012-09-17}
}

@online{Software_2012,
  title = {{{TIOBE Software}}: {{Tiobe Index}}},
  url = {http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html},
  timestamp = {2017-05-19T07:25:57Z},
  author = {Software, TIOBE},
  urldate = {2012-09-17},
  date = {2012}
}

@article{Godfrey_2012,
  title = {Introduction to the {{Special Issue}} on {{Software Repository Mining}} in 2009},
  volume = {17},
  issn = {1382-3256},
  doi = {10.1007/s10664-011-9188-2},
  timestamp = {2017-05-19T07:25:57Z},
  issue = {4-5},
  author = {Godfrey, Michael and Whitehead, Jim},
  date = {2012-08},
  pages = {345--347}
}

@article{Whitehead_2012,
  title = {Introduction to the {{Special Issue}} on {{Mining Software Repositories}} in 2010},
  volume = {17},
  issn = {1382-3256},
  doi = {10.1007/s10664-012-9206-z},
  timestamp = {2017-05-19T07:25:58Z},
  issue = {4-5},
  author = {Whitehead, Jim and Zimmermann, Thomas},
  date = {2012-08},
  pages = {500--502}
}

@book{Thomas_2011,
  location = {{New York}},
  title = {Mining {{Software Repositories Using Topic Models}}},
  isbn = {978-1-4503-0445-0},
  abstract = {Software repositories, such as source code, email archives, and bug databases, contain unstructured and unlabeled text that is difficult to analyze with traditional techniques. We propose the use of statistical topic models to automatically discover structure in these textual repositories. This discovered structure has the potential to be used in software engineering tasks, such as bug prediction and traceability link recovery. Our research goal is to address the challenges of applying topic models to software repositories.},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Ieee}},
  author = {Thomas, Stephen W.},
  date = {2011},
  keywords = {lda,mining software repositories,Topic models}
}

@article{Marres_2012,
  title = {On {{Some Uses}} and {{Abuses}} of {{Topology}} in the {{Social Analysis}} of {{Technology}} ({{Or}} the {{Problem}} with {{Smart Meters}})},
  url = {http://eprints.gold.ac.uk/7173/},
  timestamp = {2017-05-19T07:25:58Z},
  author = {Marres, N. and {others}},
  urldate = {2012-09-19},
  date = {2012},
  pages = {na--na}
}

@article{Feuz_2011,
  title = {Personal {{Web Searching}} in the {{Age}} of {{Semantic Capitalism}}: {{Diagnosing}} the {{Mechanisms}} of {{Personalisation}}},
  volume = {16},
  url = {http://www.firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/3344},
  timestamp = {2017-05-19T07:25:58Z},
  number = {2},
  author = {Feuz, Martin and Fuller, Mathew and Stalder, Felix},
  urldate = {2012-09-19},
  date = {2011}
}

@article{Coleman_2009,
  title = {Code {{Is Speech}}: {{Legal Tinkering}}, {{Expertise}}, and {{Protest}} among {{Free}} and {{Open Source Software Developers}}},
  volume = {24},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1548-1360.2009.01036.x/full},
  shorttitle = {Code {{Is Speech}}},
  timestamp = {2017-05-19T07:25:58Z},
  number = {3},
  author = {Coleman, Gabrielle},
  urldate = {2012-09-19},
  date = {2009},
  pages = {420--454}
}

@article{Coleman_2005,
  title = {The {{Social Production}} of {{Ethics}} in {{Debian}} and {{Free Software Communities}}: {{Anthropological Lessons}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=6DOhvnKwMQAC&oi=fnd&pg=PA273&dq=gabriella+coleman&ots=iiqM58O0fo&sig=Q-_-Y7VrbQ_pAFbMql4A_3_zlCk},
  shorttitle = {The {{Social Production}} of {{Ethics}} in {{Debian}} and {{Free Software Communities}}},
  timestamp = {2017-05-19T07:25:58Z},
  author = {Coleman, Gabrielle},
  urldate = {2012-09-19},
  date = {2005},
  pages = {273}
}

@book{Wickham_2009,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  isbn = {978-0-387-98140-6},
  url = {http://had.co.nz/ggplot2/book},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Springer New York}},
  author = {Wickham, Hadley},
  date = {2009}
}

@book{Lave_1991,
  title = {Situated {{Learning}}: {{Legitimate Peripheral Participation}}},
  isbn = {978-0-521-42374-8},
  shorttitle = {Situated {{Learning}}},
  abstract = {In this important theoretical treatise, Jean Lave, anthropologist, and Etienne Wenger, computer scientist, push forward the notion of situated learning–that learning is fundamentally a social process and not solely in the learner's head. The authors maintain that learning viewed as situated activity has as its central defining characteristic a process they call legitimate peripheral participation. Learners participate in communities of practitioners, moving toward full participation in the sociocultural practices of a community. Legitimate peripheral participation provides a way to speak about crucial relations between newcomers and oldtimers and about their activities, identities, artifacts, knowledge and practice. The communities discussed in the book are midwives, tailors, quartermasters, butchers, and recovering alcoholics, however, the process by which participants in those communities learn can be generalized to other social groups.},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Cambridge University Press}},
  author = {Lave, Jean and Wenger, Etienne},
  date = {1991},
  keywords = {Psychology / Developmental / General,Psychology / General}
}

@article{Gabadinho_2011,
  title = {Analyzing and {{Visualizing State Sequences}} in {{R}} with {{TraMineR}}},
  volume = {40},
  url = {http://www.jstatsoft.org/v40/i04/},
  timestamp = {2017-05-19T07:25:58Z},
  number = {4},
  author = {Gabadinho, Alexis and Ritschard, Gilbert and Müller, Nicolas S. and Studer, Matthias},
  date = {2011},
  pages = {1--37}
}

@book{Benkler_2006,
  title = {The {{Wealth}} of {{Networks}}: {{How Social Production Transforms Markets}} and {{Freedom}}},
  isbn = {978-0-300-11056-2},
  shorttitle = {The {{Wealth}} of {{Networks}}},
  abstract = {With the radical changes in information production that the Internet has introduced, we stand at an important moment of transition, says Yochai Benkler in this thought-provoking book. The phenomenon he describes as social production is reshaping markets, while at the same time offering new opportunities to enhance individual freedom, cultural diversity, political discourse, and justice. But these results are by no means inevitable: a systematic campaign to protect the entrenched industrial information economy of the last century threatens the promise of today’s emerging networked information environment.In this comprehensive social theory of the Internet and the networked information economy, Benkler describes how patterns of information, knowledge, and cultural production are changing—and shows that the way information and knowledge are made available can either limit or enlarge the ways people can create and express themselves. He describes the range of legal and policy choices that confront us and maintains that there is much to be gained—or lost—by the decisions we make today.},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Yale University Press}},
  author = {Benkler, Yochai},
  date = {2006-05-16},
  keywords = {Law / Computer & Internet,Law / General}
}

@book{Dodge_2011,
  location = {{Cambridge MA}},
  title = {Code/{{Space}}: {{Software}} and {{Everyday Life}}},
  shorttitle = {Code/{{Space}}},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{MIT Press}},
  author = {Dodge, Rob Kitchin and {Martin}},
  date = {2011}
}

@article{Olden_2008,
  title = {Machine {{Learning Methods Without Tears}}: {{A Primer}} for {{Ecologists}}},
  volume = {83},
  issn = {0033-5770},
  shorttitle = {Machine {{Learning Methods Without Tears}}},
  abstract = {ABSTRACT Machine learning methods, a family of statistical techniques with origins in the field of artificial intelligence, are recognized as holding great promise for the advancement of understanding and prediction about ecological phenomena. These modeling techniques are flexible enough to handle complex problems with multiple interacting elements and typically outcompete traditional approaches (e.g., generalized linear models), making them ideal for modeling ecological systems. Despite their inherent advantages, a review of the literature reveals only a modest use of these approaches in ecology as compared to other disciplines. One potential explanation for this lack of interest is that machine learning techniques do not fall neatly into the class of statistical modeling approaches with which most ecologists are familiar. In this paper, we provide an introduction to three machine learning approaches that can be broadly used by ecologists: classification and regression trees, artificial neural networks, and evolutionary computation. For each approach, we provide a brief background to the methodology, give examples of its application in ecology, describe model development and implementation, discuss strengths and weaknesses, explore the availability of statistical software, and provide an illustrative example. Although the ecological application of machine learning approaches has increased, there remains considerable skepticism with respect to the role of these techniques in ecology. Our review encourages a greater understanding of machine learning approaches and promotes their future application and utilization, while also providing a basis from which ecologists can make informed decisions about whether to select or avoid these approaches in their future modeling endeavors.},
  timestamp = {2017-05-19T07:25:58Z},
  number = {2},
  author = {Olden, Julian D. and {Lawler} and Poff, N. LeRoy},
  date = {2008-06-01},
  pages = {171--193},
  eprinttype = {jstor},
  eprint = {10.1086/587826}
}

@article{Dietz_2003,
  title = {The {{Struggle}} to {{Govern}} the {{Commons}}},
  volume = {302},
  url = {http://www.sciencemag.org/content/302/5652/1907.short},
  timestamp = {2017-05-19T07:25:58Z},
  number = {5652},
  author = {Dietz, T. and Ostrom, E. and Stern, P. C.},
  urldate = {2012-10-01},
  date = {2003},
  pages = {1907--1912}
}

@book{Ostrom_1990,
  title = {Governing the {{Commons}}: {{The Evolution}} of {{Institutions}} for {{Collective Action}}},
  shorttitle = {Governing the {{Commons}}},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Cambridge University Press}},
  author = {Ostrom, Elinor},
  date = {1990}
}

@article{Ostrom_1999,
  title = {Revisiting the {{Commons}}: {{Local Lessons}}, {{Global Challenges}}},
  volume = {284},
  url = {http://www.sciencemag.org/content/284/5412/278.short},
  shorttitle = {Revisiting the {{Commons}}},
  timestamp = {2017-05-19T07:25:58Z},
  number = {5412},
  author = {Ostrom, E. and Burger, J. and Field, C. B. and Norgaard, R. B. and Policansky, D.},
  urldate = {2012-10-01},
  date = {1999},
  pages = {278--282}
}

@article{Bamman_2012,
  title = {Gender in {{Twitter}}: {{Styles}}, {{Stances}}, and {{Social Networks}}},
  url = {http://arxiv.org/abs/1210.4567},
  shorttitle = {Gender in {{Twitter}}},
  abstract = {We present a study of the relationship between gender, linguistic style, and social networks, using a novel corpus of 14,000 users of Twitter. Prior quantitative work on gender often treats this social variable as a binary; we argue for a more nuanced approach. By clustering Twitter feeds, we find a range of styles and interests that reflects the multifaceted interaction between gender and language. Some styles mirror the aggregated language-gender statistics, while others contradict them. Next, we investigate individuals whose language better matches the other gender. We find that such individuals have social networks that include significantly more individuals from the other gender, and that in general, social network homophily is correlated with the use of same-gender language markers. Pairing computational methods and social theory thus offers a new perspective on how gender emerges as individuals position themselves relative to audiences, topics, and mainstream gender norms.},
  timestamp = {2017-05-19T07:25:58Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1210.4567},
  author = {Bamman, David and Eisenstein, Jacob and Schnoebelen, Tyler},
  urldate = {2013-01-22},
  date = {2012-10-16},
  keywords = {Computer Science - Computation and Language}
}

@book{Peirce_1955,
  title = {Philosophical {{Writings}} of {{Peirce}}},
  timestamp = {2017-05-19T07:25:58Z},
  publisher = {{Dover}},
  author = {Peirce, Charles Sanders},
  date = {1955}
}

@online{Mackenzie_2013b,
  title = {Metacommunities},
  url = {https://github.com/Milllss/metacommunities},
  abstract = {Contribute to metacommunities development by creating an account on GitHub.},
  timestamp = {2017-05-19T07:25:58Z},
  author = {Mackenzie, Adrian},
  urldate = {2013-05-27},
  date = {2013}
}

@article{Callon_1991,
  title = {Co-{{Word Analysis}} as a {{Tool}} for {{Describing}} the {{Network}} of {{Interactions}} between {{Basic}} and {{Technological Research}}: {{The Case}} of {{Polymer Chemsitry}}},
  volume = {22},
  issn = {0138-9130, 1588-2861},
  url = {http://link.springer.com.ezproxy.lancs.ac.uk/article/10.1007/BF02019280},
  doi = {10.1007/BF02019280},
  shorttitle = {Co-{{Word Analysis}} as a {{Tool}} for {{Describing}} the {{Network}} of {{Interactions}} between {{Basic}} and {{Technological Research}}},
  abstract = {The goal of this paper is to show how co-word analysis techniques can be used to study interactions between academic and technological research. It is based upon a systematic content analysis of publications in the polymer science field over a period of 15 years. The results concern a.) the evolution of research in different subject areas and the patterns of their interaction; b.) a description of subject area “life cycles”; c.) an analysis of ”research trajectories” given factors of stability and change in a research network; d.) the need to use both science push and technology pull theories to explain the interaction dynamics of a research field. The co-word techniques developed in this paper should help to build a bridge between research in scientometrics and work underway to better understand the economics of innovation.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {1},
  author = {Callon, M. and Courtial, J. P. and Laville, F.},
  urldate = {2013-09-03},
  date = {1991-09-01},
  pages = {155--205},
  keywords = {Information Storage and Retrieval,Interdisciplinary Studies,Library Science}
}

@article{Arvidsson_2009,
  title = {The {{Ethical Economy}}: {{Towards}} a {{Post}}-{{Capitalist Theory}} of {{Value}}},
  volume = {33},
  issn = {0309-8168, 2041-0980},
  url = {http://cnc.sagepub.com/content/33/1/13},
  doi = {10.1177/030981680909700102},
  shorttitle = {The {{Ethical Economy}}},
  abstract = {Social production has risen on the agenda of the social sciences. Ye t most observers have been reluctant to confront the question of the value of these practices. Instead they have mostly been characterised as ‘free’, ‘common’ or beyond value. This article argues that far from being free, social production abides to a particular value logic, an ‘ethical economy’ where value is related not to the input of labour time, but to the ability to give productive organisation to a diffuse connectivity or, which is the same thing, to transform weak ties into affectively significant strong ones. The article concludes that progressive politics should work with this new emerging value logic.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {1},
  author = {Arvidsson, Adam},
  urldate = {2013-11-11},
  date = {2009-01-03},
  pages = {13--29}
}

@book{Arms_2006,
  location = {{New York}},
  title = {Building a {{Research Library}} for the {{History}} of the {{Web}}},
  isbn = {1-59593-354-9},
  abstract = {This paper describes the building of a research library for studying the Web, especially research on how the structure and content of the Web change over time. The library is particularly aimed at supporting social scientists for whom the Web is both a fascinating social phenomenon and a mirror on society. The library is built on the collections of the Internet Archive, which has been preserving a crawl of the Web every two months since 1996. The technical challenges in organizing this data for research fall into two categories: high-performance computing to transfer and manage the very large amounts of data, and human-computer interfaces that empower research by non-computer specialists.},
  timestamp = {2017-05-19T07:25:59Z},
  publisher = {{Assoc Computing Machinery}},
  author = {Arms, William Y. and Aya, Selcuk and Dmitriev, Pavel and Kot, Blazej J. and Mitchell, Ruth and Walle, Lucia},
  date = {2006},
  keywords = {computational social science,digital libraries,history of the Web,Internet Archive}
}

@article{Cioffi-Revilla_2010,
  title = {A {{Methodology}} for {{Complex Social Simulations}}},
  volume = {13},
  issn = {1460-7425},
  abstract = {Social simulation-an emerging field of computational social science-has progressed from simple toy models to increasingly realistic models of complex social systems, such as agent-based models where heterogeneous agents interact with changing natural or artificial environments. These larger, multidisciplinary projects require a scientific research methodology distinct from, say, simpler social simulations with more limited scope, intentionally minimal complexity, and typically under a single investigator. This paper proposes a methodology for complex social simulations-particularly inter-and multidisciplinary socio-natural systems with multi-level architecture-based on a succession of models akin to but distinct from the late Imre Lakatos' notion of a 'research programme'. The proposed methodology is illustrated through examples from the Mason-Smithsonian project on agent-based models of the rise and fall of polities in Inner Asia. While the proposed methodology requires further development, so far it has proven valuable for advancing the scientific objectives of the project and avoiding some pitfalls.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {1},
  author = {Cioffi-Revilla, Claudio},
  date = {2010-01},
  keywords = {Agent-Based Modeling Methodology,computational social science,Inner Asia,m2m,Models,Social Complexity,Social Simulation}
}

@article{Schoen_2013,
  title = {The {{Power}} of {{Prediction}} with {{Social Media}}},
  volume = {23},
  issn = {1066-2243},
  doi = {10.1108/IntR-06-2013-0115},
  abstract = {Purpose - Social media provide an impressive amount of data about users and their interactions, thereby offering computer and social scientists, economists, and statisticians - among others - new opportunities for research. Arguably, one of the most interesting lines of work is that of predicting future events and developments from social media data. However, current work is fragmented and lacks of widely accepted evaluation approaches. Moreover, since the first techniques emerged rather recently, little is known about their overall potential, limitations and general applicability to different domains. Therefore, better understanding the predictive power and limitations of social media is of utmost importance. Design/methodology/approach - Different types of forecasting models and their adaptation to the special circumstances of social media are analyzed and the most representative research conducted up to date is surveyed. Presentations of current research on techniques, methods, and empirical studies aimed at the prediction of future or current events from social media data are provided. Findings - A taxonomy of prediction models is introduced, along with their relative advantages and the particular scenarios where they have been applied to. The main areas of prediction that have attracted research so far are described, and the main contributions made by the papers in this special issue are summarized. Finally, it is argued that statistical models seem to be the most fruitful approach to apply to make predictions from social media data. Originality/value - This special issue raises important questions to be addressed in the field of social media-based prediction and forecasting, fills some gaps in current research, and outlines future lines of work.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {5},
  author = {Schoen, Harald and Gayo-Avello, Daniel and Metaxas, Panagiotis Takis and Mustafaraj, Eni and Strohmaier, Markus and Gloor, Peter},
  date = {2013},
  pages = {528--543},
  keywords = {computational social science,forecast,Forecasting,Internet,model,noise,political stock-market,polls,Predicting,presidential-election,search,social media,vote}
}

@article{Procter_2013,
  title = {Reading the {{Riots}} on {{Twitter}}: {{Methodological Innovation}} for the {{Analysis}} of {{Big Data}}},
  volume = {16},
  issn = {1364-5579},
  doi = {10.1080/13645579.2013.774172},
  shorttitle = {Reading the {{Riots}} on {{Twitter}}},
  abstract = {For social scientists, the widespread adoption of social media presents both an opportunity and a challenge. Data that can shed light on people's habits, opinions and behaviour is available now on a scale never seen before, but this also means that it is impossible to analyse using conventional methodologies and tools. This article represents an experiment in applying a computationally assisted methodology to the analysis of a large corpus of tweets sent during the August 2011 riots in England.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {3},
  author = {Procter, Rob and Vis, Farida and Voss, Alex},
  date = {2013-05-01},
  pages = {197--214},
  keywords = {big data,computational social science,crisis communication,riot,rumour,social media,Twitter}
}

@article{Weng_2013,
  title = {Virality {{Prediction}} and {{Community Structure}} in {{Social Networks}}},
  volume = {3},
  issn = {2045-2322},
  doi = {10.1038/srep02522},
  abstract = {How does network structure affect diffusion? Recent studies suggest that the answer depends on the type of contagion. Complex contagions, unlike infectious diseases (simple contagions), are affected by social reinforcement and homophily. Hence, the spread within highly clustered communities is enhanced, while diffusion across communities is hampered. A common hypothesis is that memes and behaviors are complex contagions. We show that, while most memes indeed spread like complex contagions, a few viral memes spread across many communities, like diseases. We demonstrate that the future popularity of a meme can be predicted by quantifying its early spreading pattern in terms of community concentration. The more communities a meme permeates, the more viral it is. We present a practical method to translate data about community structure into predictive knowledge about what information will spread widely. This connection contributes to our understanding in computational social science, social media analytics, and marketing applications.},
  timestamp = {2017-05-19T07:25:59Z},
  author = {Weng, Lilian and Menczer, Filippo and Ahn, Yong-Yeol},
  date = {2013-08-28},
  keywords = {behavior,complex networks,contagion,spread}
}

@article{Lupton_2012,
  title = {Digital {{Sociology}}: {{An Introduction}}},
  url = {http://prijipati.library.usyd.edu.au/handle/2123/8621},
  shorttitle = {Digital {{Sociology}}},
  timestamp = {2017-05-19T07:25:59Z},
  author = {Lupton, Deborah},
  urldate = {2013-11-14},
  date = {2012}
}

@article{Wang_2012,
  title = {On {{Social Computing Research Collaboration Patterns}}: {{A Social Network Perspective}}},
  volume = {6},
  issn = {2095-2228},
  doi = {10.1007/s11704-011-1173-9},
  shorttitle = {On {{Social Computing Research Collaboration Patterns}}},
  abstract = {The field of social computing emerged more than ten years ago. During the last decade, researchers from a variety of disciplines have been closely collaborating to boost the growth of social computing research. This paper aims at identifying key researchers and institutions, and examining the collaboration patterns in the field. We employ co-authorship network analysis at different levels to study the bibliographic information of 6 543 publications in social computing from 1998 to 2011. This paper gives a snapshot of the current research in social computing and can provide an initial guidance to new researchers in social computing.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {1},
  author = {Wang, Tao and Zhang, Qingpeng and Liu, Zhong and Liu, Wenli and Wen, Ding},
  date = {2012-02},
  pages = {122--130},
  keywords = {bibliographic analysis,cocitation,community,computational social science,emergence,expansion,Information,intelligence,knowledge,scientific literature,search,social computing,social network analysis,systems}
}

@article{Helbing_2011,
  title = {From {{Social Data Mining}} to {{Forecasting Socio}}-{{Economic Crises}}},
  volume = {195},
  issn = {1951-6355},
  doi = {10.1140/epjst/e2011-01401-8},
  abstract = {The purpose of this White Paper of the EU Support Action "Visioneer"(see www.visioneer.ethz.ch) is to address the following goals: 1. Develop strategies to quickly increase the objective knowledge about social and economic systems. 2. Describe requirements for efficient large-scale scientific data mining of anonymized social and economic data. 3. Formulate strategies how to collect stylized facts extracted from large data set. 4. Sketch ways how to successfully build up centers for computational social science. 5. Propose plans how to create centers for risk analysis and crisis forecasting. 6. Elaborate ethical standards regarding the storage, processing, evaluation, and publication of social and economic data.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {1},
  author = {Helbing, D. and Balietti, S.},
  date = {2011-05},
  pages = {3--68},
  keywords = {behavior,big data,Design,framework,future,networks,Science,spread,systems,tacit collusion}
}

@article{Mestyan_2013,
  title = {Early {{Prediction}} of {{Movie Box Office Success Based}} on {{Wikipedia Activity Big Data}}},
  volume = {8},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0071226},
  abstract = {Use of socially generated "big data" to access information about collective states of the minds in human societies has become a new paradigm in the emerging field of computational social science. A natural application of this would be the prediction of the society's reaction to a new product in the sense of popularity and adoption rate. However, bridging the gap between "real time monitoring" and "early predicting" remains a big challenge. Here we report on an endeavor to build a minimalistic predictive model for the financial success of movies based on collective activity data of online users. We show that the popularity of a movie can be predicted much before its release by measuring and analyzing the activity level of editors and viewers of the corresponding entry to the movie in Wikipedia, the well-known online encyclopedia.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {8},
  author = {Mestyan, Marton and Yasseri, Taha and Kertesz, Janos},
  date = {2013-08-21},
  keywords = {blockbusters,coverage,impact,Life,motion-pictures}
}

@article{Rusch_2013,
  title = {Model {{Trees}} with {{Topic Model Preprocessing}}: {{An Approach}} for {{Data Journalism Illustrated}} with the {{Wikileaks Afghanistan War Logs}}},
  volume = {7},
  issn = {1932-6157},
  doi = {10.1214/12-AOAS618},
  shorttitle = {Model {{Trees}} with {{Topic Model Preprocessing}}},
  abstract = {The WikiLeaks Afghanistan war logs contain nearly 77,000 reports of incidents in the US-led Afghanistan war, covering the period from January 2004 to December 2009. The recent growth of data on complex social systems and the potential to derive stories from them has shifted the focus of journalistic and scientific attention increasingly toward data-driven journalism and computational social science. In this paper we advocate the usage of modern statistical methods for problems of data journalism and beyond, which may help journalistic and scientific work and lead to additional insight. Using the WikiLeaks Afghanistan war logs for illustration, we present an approach that builds intelligible statistical models for interpretable segments in the data, in this case to explore the fatality rates associated with different circumstances in the Afghanistan war. Our approach combines preprocessing by Latent Dirichlet Allocation (LDA) with model trees. LDA is used to process the natural language information contained in each report summary by estimating latent topics and assigning each report to one of them. Together with other variables these topic assignments serve as splitting variables for finding segments in the data to which local statistical models for the reported number of fatalities are fitted. Segmentation and fitting is carried out with recursive partitioning of negative binomial distributions. We identify segments with different fatality rates that correspond to a small number of topics and other variables as well as their interactions. Furthermore, we carve out the similarities between segments and connect them to stories that have been covered in the media. This gives an unprecedented description of the war in Afghanistan and serves as an example of how data journalism, computational social science and other areas with interest in database data can benefit from modern statistical techniques.},
  timestamp = {2017-05-19T07:25:59Z},
  number = {2},
  author = {Rusch, Thomas and Hofmarcher, Paul and Hatzinger, Reinhold and Hornik, Kurt},
  date = {2013-06},
  pages = {613--639},
  keywords = {Afghanistan,casualties,classification trees,computational social science,conflict,count data,database data,iraq,latent Dirichlet allocation,model-based recursive partitioning,Mortality,rates,regression trees,Science,Selection,text mining,tree stability,tree validation,WikiLeaks}
}

@incollection{Santos_2013,
  location = {{Bellingham}},
  title = {Modeling {{Emergent Border}}-{{Crossing Behaviors}} during {{Pandemics}}},
  volume = {8711},
  isbn = {978-0-8194-9502-0},
  abstract = {Modeling real-world scenarios is a challenge for traditional social science researchers, as it is often hard to capture the intricacies and dynamisms of real-world situations without making simplistic assumptions. This imposes severe limitations on the capabilities of such models and frameworks. Complex population dynamics during natural disasters such as pandemics is an area where computational social science can provide useful insights and explanations. In this paper, we employ a novel intent-driven modeling paradigm for such real-world scenarios by causally mapping beliefs, goals, and actions of individuals and groups to overall behavior using a probabilistic representation called Bayesian Knowledge Bases (BKBs). To validate our framework we examine emergent behavior occurring near a national border during pandemics, specifically the 2009 H1N1 pandemic in Mexico. The novelty of the work in this paper lies in representing the dynamism at multiple scales by including both coarse-grained (events at the national level) and fine-grained (events at two separate border locations) information. This is especially useful for analysts in disaster management and first responder organizations who need to be able to understand both macro-level behavior and changes in the immediate vicinity, to help with planning, prevention, and mitigation. We demonstrate the capabilities of our framework in uncovering previously hidden connections and explanations by comparing independent models of the border locations with their fused model to identify emergent behaviors not found in either independent location models nor in a simple linear combination of those models.},
  timestamp = {2017-05-19T07:25:59Z},
  booktitle = {Sensors, and {{Command}}, {{Control}}, {{Communications}}, and {{Intelligence}} ({{C3i}}) {{Technologies}} for {{Homeland Security}} and {{Homeland Defense Xii}}},
  publisher = {{Spie-Int Soc Optical Engineering}},
  author = {Santos, Eunice E. and Santos, Eugene and Korah, John and Thompson, Jeremy E. and Gu, Qi and Kim, Keum Joo and Li, Deqing and Russell, Jacob and Subramanian, Suresh and Zhang, Yuxi and Zhao, Yan},
  editor = {Carapezza, E. M.},
  date = {2013},
  keywords = {Bayesian Knowledge Bases,complexity,disaster management,emergent behaviors,framework,h1n1,intent-driven modeling,pandemics,population dynamics,Prediction,social science}
}

@incollection{Whitney_2010,
  location = {{Berlin}},
  title = {Calibrating {{Bayesian Network Representations}} of {{Social}}-{{Behavioral Models}}},
  volume = {6007},
  isbn = {978-3-642-12078-7},
  abstract = {While human behavior has long been studied, recent and ongoing advances in computational modeling present opportunities for recasting research outcomes in human behavior. In this paper we describe how Bayesian networks can represent outcomes of human behavior research. We demonstrate a Bayesian network that represents political radicalization research - and show a corresponding visual representation of aspects of this research outcome. Since Bayesian networks can be quantitatively compared with external observations, the representation can also be used for empirical assessments of the research which the network summarizes. For a political radicalization model based on published research, we show this empirical comparison with data taken from the Minorities at Risk Organizational Behaviors database.},
  timestamp = {2017-05-19T07:26:00Z},
  booktitle = {Advances in {{Social Computing}}, {{Proceedings}}},
  publisher = {{Springer-Verlag Berlin}},
  author = {Whitney, Paul and Walsh, Stephen},
  editor = {Chai, S. K. and Salerno, J. J. and Mabry, P. L.},
  date = {2010},
  pages = {338--345},
  keywords = {calibration,computational social science}
}

@article{Jungherr_2012,
  title = {Why the {{Pirate Party Won}} the {{German Election}} of 2009 or {{The Trouble With Predictions}}: {{A Response}} to {{Tumasjan}}, {{A}}., {{Sprenger}}, {{T}}. {{O}}., {{Sander}}, {{P}}. {{G}}., \& {{Welpe}}, {{I}}. {{M}}. "{{Predicting Elections With Twitter}}: {{What}} 140 {{Characters Reveal About Political Sentiment}}"},
  volume = {30},
  issn = {0894-4393},
  doi = {10.1177/0894439311404119},
  shorttitle = {Why the {{Pirate Party Won}} the {{German Election}} of 2009 or {{The Trouble With Predictions}}},
  abstract = {In their article "Predicting Elections with Twitter: What 140 Characters Reveal About Political Sentiment," the authors Andranik Tumasjan, Timm O. Sprenger, Philipp G. Sandner, and Isabell M. Welpe (TSSW) the authors claim that it would be possible to predict election outcomes in Germany by examining the relative frequency of the mentions of political parties in Twitter messages posted during the election campaign. In this response we show that the results of TSSW are contingent on arbitrary choices of the authors. We demonstrate that as of yet the relative frequency of mentions of German political parties in Twitter message allows no prediction of election results.},
  timestamp = {2017-05-19T07:26:00Z},
  number = {2},
  author = {Jungherr, Andreas and Juergens, Pascal and Schoen, Harald},
  date = {2012-05},
  pages = {229--234},
  keywords = {computational social science,elections,predictions,social media,Twitter}
}

@article{Marres_2013,
  title = {{{SCRAPING THE SOCIAL}}? {{Issues}} in {{Live Social Research}}},
  url = {http://www.tandfonline.com/doi/abs/10.1080/17530350.2013.772070},
  shorttitle = {{{SCRAPING THE SOCIAL}}?},
  timestamp = {2017-05-19T07:26:00Z},
  issue = {ahead-of-print},
  author = {Marres, Noortje and Weltevrede, Esther},
  urldate = {2013-11-14},
  date = {2013},
  pages = {1--23}
}

@article{Housley_2013,
  title = {Computational {{Social Science}}: {{Research Strategies}}, {{Design}} and {{Methods Introduction}}},
  volume = {16},
  issn = {1364-5579},
  doi = {10.1080/13645579.2013.774164},
  shorttitle = {Computational {{Social Science}}},
  timestamp = {2017-05-19T07:26:00Z},
  number = {3},
  author = {Housley, William and Williams, Matthew and Williams, Malcolm and Edwards, Adam},
  date = {2013-05-01},
  pages = {173--175}
}

@article{Wang_2012a,
  title = {Guest {{Editorial}}: {{Special Issue}} on {{Data Mining Technologies}} for {{Computational Social Science}}},
  volume = {25},
  issn = {1384-5810},
  doi = {10.1007/s10618-012-0271-0},
  shorttitle = {Guest {{Editorial}}},
  timestamp = {2017-05-19T07:26:00Z},
  number = {3},
  author = {Wang, Fei and Tong, Hanghang and Yu, Phillip and Aggarwal, Charu},
  date = {2012-11},
  pages = {415--419},
  keywords = {Internet,networks}
}

@article{Bankes_2002,
  title = {Making {{Computational Social Science Effective}} - {{Epistemology}}, {{Methodology}}, and {{Technology}}},
  volume = {20},
  issn = {0894-4393},
  doi = {10.1177/089443902237317},
  abstract = {There has been significant recent interest in Agent Based Modeling in many social sciences including economics, sociology, anthropology, political science, and game theory. This article describes three problems that need to be addressed in order for such models to become effective tools for formulating new social theory and informing policy debates and suggests approaches to meeting them. These issues are computational epistemology, research methodology, and software technology. These innovations augment Agent Based Modeling to create an effective new tool base to help better understand complex social systems.},
  timestamp = {2017-05-19T07:26:00Z},
  number = {4},
  author = {Bankes, S. and Lempert, R. and Popper, S.},
  year = {WIN 2002},
  pages = {377--388},
  keywords = {Agent Based Modeling,computational epistemology,computational science,Computer Assisted Reasoning System (CARs),exploratory modeling}
}

@article{Conte_2012,
  title = {Manifesto of {{Computational Social Science}}},
  volume = {214},
  issn = {1951-6355},
  doi = {10.1140/epjst/e2012-01697-8},
  abstract = {The increasing integration of technology into our lives has created unprecedented volumes of data on society's everyday behaviour. Such data opens up exciting new opportunities to work towards a quantitative understanding of our complex social systems, within the realms of a new discipline known as Computational Social Science. Against a background of financial crises, riots and international epidemics, the urgent need for a greater comprehension of the complexity of our interconnected global society and an ability to apply such insights in policy decisions is clear. This manifesto outlines the objectives of this new scientific direction, considering the challenges involved in it, and the extensive impact on science, technology and society that the success of this endeavour is likely to bring about.},
  timestamp = {2017-05-19T07:26:00Z},
  number = {1},
  author = {Conte, R. and Gilbert, N. and Bonelli, G. and Cioffi-Revilla, C. and Deffuant, G. and Kertesz, J. and Loreto, V. and Moat, S. and Nadal, J.-P. and Sanchez, A. and Nowak, A. and Flache, A. and San Miguel, M. and Helbing, D.},
  date = {2012-11},
  pages = {325--346},
  keywords = {coevolution,collapse,dynamics,emergence,Evolution,local convergence,model,networks,reputation,systems}
}

@article{Dutton_2011,
  title = {The {{Politics}} of next {{Generation Research}}: {{Democratizing Research}}-{{Centred Computational Networks}}},
  volume = {26},
  issn = {0268-3962},
  doi = {10.1057/jit.2011.2},
  shorttitle = {The {{Politics}} of next {{Generation Research}}},
  abstract = {Research on information technology has been focused primarily on the worlds of IT and management systems for business and government to the relative neglect of research on the digital and institutional infrastructures that underpin the research enterprise itself. When digital research is studied, the emphasis has been on the diffusion of technological innovations, rather than the social and political dynamics shaping the design and role of technologies in research. However, what researchers know, and with whom they collaborate, could be transformed through the strategic use of advances designed to support research, defined here as 'research-centred computational networks'. This article presents a framework for conceptualizing the social and technological choices shaping the next generation of research in ways that could open democratize key aspects of the research process that move well beyond academic publication. The framework highlights the limited scope of innovation to date, and identifies a variety of factors that maintain and enhance institutional control over the research process, at the risk of losing the creative and productive bottom-up participation by networked researchers and citizen researchers among the public at large. Conceptualizing, prioritizing and advancing study of next generation research is one of the most significant but difficult challenges facing scholars of information technology. Journal of Information Technology (2011) 26, 1 09 1 19. doi:10.1057/jit.2011.2 Published online 12 April 2011},
  timestamp = {2017-05-19T07:26:00Z},
  number = {2},
  author = {Dutton, William H.},
  date = {2011-06},
  pages = {109--119},
  keywords = {computational social science,digital scholarship,e-Research,e-Science,e-Social Science,research technology}
}

@article{Cioffi-Revilla_2009,
  title = {Simplicity and {{Reality}} in {{Computational Modeling}} of {{Politics}}},
  volume = {15},
  issn = {1381-298X},
  doi = {10.1007/s10588-008-9042-2},
  abstract = {Modeling a polity based on viable scientific concepts and theoretical understanding has been a challenge in computational social science and social simulation in general and political science in particular. This paper presents a computational model of a polity (political system) in progressive versions from simple to more realistic. The model, called SimPol to highlight the fundamental structures and processes of politics in a generic society, is developed using the combined methodologies of object-based modeling (OOM), the Unified Modeling Language (UML), and the methodology of Lakatos' research programs. SimPol demonstrates that computational models of entire political systems are methodologically feasible and scientifically viable; they can also build on and progress beyond previous theory and research to advance our understanding of how polities operate across a variety of domains (simple vs. complex) and levels of analysis (local, national, international). Both simple and realistic models are necessary, for theoretical and empirical purposes, respectively.},
  timestamp = {2017-05-19T07:26:00Z},
  number = {1},
  author = {Cioffi-Revilla, Claudio},
  date = {2009-03},
  pages = {26--46},
  keywords = {Agent-based modeling,Comparative political systems,Lakatos,policy,Policy process,Political science,Systems of governance,UML unified modeling language}
}

@article{Hanquinet_2013,
  title = {The {{Eyes}} of the {{Beholder}}: {{Aesthetic Preferences}} and the {{Remaking}} of {{Cultural Capital}}},
  issn = {0038-0385, 1469-8684},
  url = {http://soc.sagepub.com/content/early/2013/07/17/0038038513477935},
  doi = {10.1177/0038038513477935},
  shorttitle = {The {{Eyes}} of the {{Beholder}}},
  abstract = {Bourdieu’s Distinction (1984) has been highly influential in sociological debates regarding cultural inequality, but it has rarely been considered a theory of aesthetics. In this article we explore empirically how the modernist framing of Bourdieu’s aesthetics needs to be rethought in the context of contemporary aesthetic change. Drawing on a survey of museum visitors in Ghent, Belgium (n = 1195), we use Multiple Correspondence Analysis to analyse what aesthetic dimensions are important when people contemplate works of art. We find that the familiar Bourdieusian opposition between popular (based on beauty and harmony) and highbrow aesthetics is still important. However, the content of highbrow aesthetics has changed, now privileging ‘postmodernist’ dimensions over modernist ones. We can also detect another dimension that favours a socially reflexive art compared to a detachment of art from social preoccupations, which is not recognized in Bourdieu’s account.},
  timestamp = {2017-05-19T07:26:00Z},
  author = {Hanquinet, Laurie and Roose, Henk and Savage, Mike},
  urldate = {2013-11-20},
  date = {2013-07-18},
  pages = {0038038513477935},
  keywords = {aesthetics,Bourdieu,dispositions,multiple correspondence analysis,museum audience}
}

@article{Ruppert_2013,
  title = {Reassembling {{Social Science Methods}}: {{The Challenge}} of {{Digital Devices}}},
  issn = {0263-2764, 1460-3616},
  url = {http://tcs.sagepub.com/content/early/2013/05/13/0263276413484941},
  doi = {10.1177/0263276413484941},
  shorttitle = {Reassembling {{Social Science Methods}}},
  abstract = {The aim of the article is to intervene in debates about the digital and, in particular, framings that imagine the digital in terms of epochal shifts or as redefining life. Instead, drawing on recent developments in digital methods, we explore the lively, productive and performative qualities of the digital by attending to the specificities of digital devices and how they interact, and sometimes compete, with older devices and their capacity to mobilize and materialize social and other relations. In doing so, our aim is to explore the implications of digital devices and data for reassembling social science methods or what we call the social science apparatuses that assemble digital devices and data to ‘know’ the social and other relations. Building on recent work at CRESC on the social life of methods, we recommend a genealogical approach that is alive to the ways in which digital devices are simultaneously shaped by social worlds, and can in turn become agents that shape those worlds. This calls for attending to the specificities of digital devices themselves, how they are varied and composed of diverse socio-technical arrangements, and are enrolled in the creation of new knowledge spaces, institutions and actors. Rather than exploring what large-scale changes can be revealed and understood through the digital, we argue for explorations of how digital devices themselves are materially implicated in the production and performance of contemporary sociality. To that end we offer the following nine propositions about the implications of digital data and devices and argue that these demand rethinking the theoretical assumptions of social science methods: transactional actors; heterogeneity; visualization; continuous time; whole populations; granularity; expertise; mobile and mobilizing; and non-coherence.},
  timestamp = {2017-05-19T07:26:00Z},
  author = {Ruppert, Evelyn and Law, John and Savage, Mike},
  urldate = {2013-11-20},
  date = {2013-05-14},
  pages = {0263276413484941},
  keywords = {actor network theory,big data,digital devices,genealogy,methodology,performativity,transactional data}
}

@inproceedings{Wynn_2009,
  title = {Digital {{Sociology}}: {{Emergent Technologies}} in the {{Field}} and the {{Classroom}}},
  volume = {24},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1573-7861.2009.01109.x/full},
  shorttitle = {Digital {{Sociology}}},
  timestamp = {2017-05-19T07:26:00Z},
  booktitle = {Sociological {{Forum}}},
  author = {Wynn, Jonathan R.},
  urldate = {2013-11-20},
  date = {2009},
  pages = {448--456}
}

@article{Murthy_2013,
  title = {Ethnographic {{Research}} 2.0: {{The Potentialities}} of {{Emergent Digital Technologies}} for {{Qualitative Organizational Research}}},
  volume = {2},
  url = {http://www.emeraldinsight.com/journals.htm?articleid=17090341&show=abstract},
  shorttitle = {Ethnographic {{Research}} 2.0},
  timestamp = {2017-05-19T07:26:01Z},
  number = {1},
  author = {Murthy, Dhiraj},
  urldate = {2013-11-20},
  date = {2013},
  pages = {23--36}
}

@article{Arvidsson_2011,
  title = {General {{Sentiment}}: {{How Value}} and {{Affect Converge}} in the {{Information Economy}}},
  volume = {59},
  issn = {1467-954X},
  url = {http://onlinelibrary.wiley.com.ezproxy.lancs.ac.uk/doi/10.1111/j.1467-954X.2012.02052.x/abstract},
  doi = {10.1111/j.1467-954X.2012.02052.x},
  shorttitle = {General {{Sentiment}}},
  abstract = {The Fordist economy was marked by what David Stark calls a Parsonian Compromise in which economic value and other values were clearly separated, in theory as well as in practice. Today this is changing. Trends such as Ethical Consumerism and Corporate Social Responsibility are on the rise. More fundamentally, the economic importance of intangible assets like brands has increased. Together these developments testify to a new role for a wider range of values in determining price formation. In this paper I will argue that this trend has two principal causes. First, the socialization of production has increased the importance of affective investments in things like brands, reputation, corporate culture and efficient teamwork as sources of value. Second, a common criterion for the measurement of affective investments is forming, based on the new abstract or General Sentiment that is emerging as a new ‘general equivalent’ as a consequence of the present remediation of communicative relations, primarily throughout the diffusion of social media. Together these two dimensions make up the foundations for a new value logic, an ‘ethical economy’ that is emerging within contemporary wealth creation. After briefly summarizing the first argument, this paper will concentrate on the second, describing the emergence and features of General Sentiment as a criterion of value. The conclusion will suggest possible consequences of this development in both practical and theoretical terms.},
  timestamp = {2017-05-19T07:26:01Z},
  author = {Arvidsson, Adam},
  urldate = {2013-11-22},
  date = {2011},
  pages = {39--59},
  keywords = {affect,general intellect,General Sentiment,information economy,value}
}

@article{Muchnik_2013,
  title = {Origins of {{Power}}-{{Law Degree Distribution}} in the {{Heterogeneity}} of {{Human Activity}} in {{Social Networks}}},
  volume = {3},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/srep/2013/130507/srep01783/full/srep01783.html},
  doi = {10.1038/srep01783},
  abstract = {The probability distribution of number of ties of an individual in a social network follows a scale-free power-law. However, how this distribution arises has not been conclusively demonstrated in direct analyses of people's actions in social networks. Here, we perform a causal inference analysis and find an underlying cause for this phenomenon. Our analysis indicates that heavy-tailed degree distribution is causally determined by similarly skewed distribution of human activity. Specifically, the degree of an individual is entirely random - following a “maximum entropy attachment” model - except for its mean value which depends deterministically on the volume of the users' activity. This relation cannot be explained by interactive models, like preferential attachment, since the observed actions are not likely to be caused by interactions with other people.},
  timestamp = {2017-05-19T07:26:01Z},
  author = {Muchnik, Lev and Pei, Sen and Parra, Lucas C. and Reis, Saulo D. S. and Andrade Jr, José S. and Havlin, Shlomo and Makse, Hernán A.},
  urldate = {2014-03-01},
  date = {2013-05-07},
  keywords = {Applied physics,complex networks}
}

@article{Jenkins_2004,
  title = {The {{Cultural Logic}} of {{Media Convergence}}},
  volume = {7},
  url = {http://ics.sagepub.com/content/7/1/33.short},
  timestamp = {2017-05-19T07:26:01Z},
  number = {1},
  author = {Jenkins, Henry},
  urldate = {2013-12-09},
  date = {2004},
  pages = {33--43}
}

@article{Aronczyk_2012,
  title = {Introduction: {{Cultures}} of {{Circulation}}},
  volume = {40},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X12000101},
  doi = {10.1016/j.poetic.2012.02.001},
  shorttitle = {Introduction},
  abstract = {What are cultures of circulation, and how can they be understood in ways that inform critical scholarship and relationships between academic work and public engagement in globalized settings? This introductory article discusses the initial formulation of the phrase in 2002 and describes how the seven articles in this special issue extend its implications 10 years later. We begin by charting some of the key contexts in which the concept has flourished, noting some of the problems and limitations of its use in different disciplines. We then provide an overview of how each article in this issue takes up the dialectics of circulation and the programmatic of culture as practice. We conclude by proposing avenues for further research as well as opportunities for self-reflexive uses of the concept within academic debates and via wider public engagement.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {Aronczyk, Melissa and Craig, Ailsa},
  urldate = {2013-12-16},
  date = {2012-04},
  pages = {93--100}
}

@article{McClain_2012,
  title = {Free to {{Those Who Can Afford It}}: {{The Everyday Affordance}} of {{Privilege}}},
  volume = {40},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X12000125},
  doi = {10.1016/j.poetic.2012.02.003},
  shorttitle = {Free to {{Those Who Can Afford It}}},
  abstract = {Zero-priced goods (which we call ‘free stuff’) are an overlooked foundation of privilege. From corporate perks to meal accoutrements and easy access to bathrooms, free stuff does work of a number of important types, from easing everyday personal routine to solidifying economic ties. We trace the flow of free stuff using an ‘affordance’ perspective on privilege, a useful way to examine the micro-situational foundations of inequality. This perspective focuses attention on exactly how resources, from cash to cultural capital, are made useful in day-to-day life. We examine the transaction of freebies in three ideal-typical networks: that of the professional, the culture industry broker, and the poor urban dweller. Through comparison of each of these cases, we argue that freebies and perks are affordances of class position, whether in their abundance, as in the case of the professional's ease with perks, or in their absence in the case of poor people's subsistence. Free stuff can be an important medium of exchange in a number of worlds, and often serves to seamlessly provide recipients with important situational resources. The poor, however, are often left out of valuable networks of exchange, thus facing considerable retrieval costs for free stuff others take for granted.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {McClain, Noah and Mears, Ashley},
  urldate = {2013-12-16},
  date = {2012-04},
  pages = {133--149}
}

@article{Guggenheim_2012,
  title = {How {{Facts Travel}}: {{The Model Systems}} of {{Sociology}}},
  volume = {40},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X12000162},
  doi = {10.1016/j.poetic.2012.02.007},
  shorttitle = {How {{Facts Travel}}},
  abstract = {The discussion in the sociology of science about the role of model systems in biology provides an invitation to reflect on whether and how similar devices operate in sociology. This paper shows that sociology relies on objects of study that receive a disproportionate amount of attention and implicitly come to stand in for a specific class of objects. But, unlike other disciplines, sociology has no agreed language or theory to classify the discipline-specific objects that it studies, which hinders explicit reflection on the use of model systems across sociological subfields. In contrast to other disciplines, which use model systems, physical copies of sociological model systems usually do not travel. Because of this, the relationship between specimen and epistemic object is less standardised in sociology than in other disciplines, which creates problems for the accumulation of knowledge. Sociology also encounters unique problems of access to model systems.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {Guggenheim, Michael and Krause, Monika},
  urldate = {2013-12-16},
  date = {2012-04},
  pages = {101--117}
}

@article{Davies_2012,
  title = {Ways of {{Owning}}: {{Towards}} an {{Economic Sociology}} of {{Privatisation}}},
  volume = {40},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X12000174},
  doi = {10.1016/j.poetic.2012.02.008},
  shorttitle = {Ways of {{Owning}}},
  abstract = {Economic sociology has been preoccupied with the institution of markets, to the relative neglect of ownership. It has inherited certain technical and governmental problematics regarding that which can or cannot be internalised within the market price system, leading to the assumption that the ‘social’ or the ‘public’ is a type of empirical externality. But by shifting attention towards institutions of ownership, the public and the private come to appear as primarily normative appeals, used to challenge and justify the drawing of boundaries in economic life. Boundaries are judged for their justice, as well as for their empirical efficacy. Adopting a pragmatist approach, this paper outlines three possible ‘orders of appropriation’ which can be appealed to when justifying and criticising privatisation in economic situations: the socialist, the neoliberal and the liberal. Beyond any scientific or technical account of property, each of these offers an ‘ultimate’ basis on which to view ownership, according to different and incompatible philosophical anthropologies.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {Davies, William},
  urldate = {2013-12-16},
  date = {2012-04},
  pages = {167--184}
}

@inproceedings{Baltrusaitis_2013,
  location = {{Shanghai}},
  title = {Dimensional {{Affect Recognition Using Continuous Conditional Random Fields}}},
  timestamp = {2017-05-19T07:26:01Z},
  author = {Baltrušaitis, Tadas and Banda, Ntombikayise and Peter Robinson, Peter},
  date = {2013-04}
}

@article{DiMaggio_2013,
  title = {Exploiting {{Affinities}} between {{Topic Modeling}} and the {{Sociological Perspective}} on {{Culture}}: {{Application}} to {{Newspaper Coverage}} of {{U}}.{{S}}. {{Government Arts Funding}}},
  volume = {41},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X13000661},
  doi = {10.1016/j.poetic.2013.08.004},
  shorttitle = {Exploiting {{Affinities}} between {{Topic Modeling}} and the {{Sociological Perspective}} on {{Culture}}},
  abstract = {Topic modeling provides a valuable method for identifying the linguistic contexts that surround social institutions or policy domains. This article uses Latent Dirichlet Allocation (LDA) to analyze how one such policy domain, government assistance to artists and arts organizations, was framed in almost 8000 articles. These comprised all articles that referred to government support for the arts in the U.S. published in five U.S. newspapers between 1986 and 1997—a period during which such assistance, once noncontroversial, became a focus of contention. We illustrate the strengths of topic modeling as a means of analyzing large text corpora, discuss the proper choice of models and interpretation of model results, describe means of validating topic-model solutions, and demonstrate the use of topic models in combination with other statistical tools to estimate differences between newspapers in the prevalence of different frames. Throughout, we emphasize affinities between the topic-modeling approach and such central concepts in the study of culture as framing, polysemy, heteroglossia, and the relationality of meaning.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {6},
  author = {DiMaggio, Paul and Nag, Manish and Blei, David},
  urldate = {2013-12-16},
  date = {2013-12},
  pages = {570--606},
  keywords = {Content analysis,Heteroglossia,Meaning,National Endowment for the Arts,Polysemy,Topic models}
}

@article{McFarland_2013,
  title = {Differentiating {{Language Usage}} through {{Topic Models}}},
  volume = {41},
  issn = {0304-422X},
  url = {http://www.sciencedirect.com/science/article/pii/S0304422X13000442},
  doi = {10.1016/j.poetic.2013.06.004},
  abstract = {Sociologists wishing to employ topic models in their research need a helpful guide that describes the variety of topic modeling procedures, their issues, and various means of resolving them so as to convincingly answer sociological questions. We present this overview by recounting a series of our prior collaborative projects that have employed and developed various forms of topic models to understand language differentiation in academe. With each project, we encountered a variety of model-specific issues concerning the validity of topics and their suitability to our data and research questions. We developed a variety of novel visualization techniques to make sense of topic-solutions and used a variety of techniques to validate our results. In addition, we created a variety of new topic modeling techniques and procedures suitable to different kinds of data and research questions.},
  timestamp = {2017-05-19T07:26:01Z},
  number = {6},
  author = {McFarland, Daniel A. and Ramage, Daniel and Chuang, Jason and Heer, Jeffrey and Manning, Christopher D. and Jurafsky, Daniel},
  urldate = {2013-12-16},
  date = {2013-12},
  pages = {607--625},
  keywords = {Culture,Domains,Language differentiation,Sociology,Text,Topic models}
}

@article{Ruppert_2013a,
  title = {Rethinking {{Empirical Social Sciences}}},
  volume = {3},
  url = {http://dhg.sagepub.com/content/3/3/268.short},
  timestamp = {2017-05-19T07:26:01Z},
  number = {3},
  author = {Ruppert, Evelyn},
  urldate = {2014-01-10},
  date = {2013},
  pages = {268--273}
}

@article{Myers_2006,
  title = {Animating {{Mechanism}}: {{Animations}} and the {{Propagation}} of {{Affect}} in the {{Lively Arts}} of {{Protein Modelling}}.},
  volume = {19},
  url = {http://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=07863012&AN=23965230&h=RnS6nfjUMaayxD8kLVrRvZ3P1%2BW31%2FWYZT4hPDu0F%2BtCqVymVhi2abbRHSwh1UaqT8GnpY%2BMIavbEXW5cet2QA%3D%3D&crl=c},
  shorttitle = {Animating {{Mechanism}}},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {Myers, Natasha},
  urldate = {2014-02-12},
  date = {2006}
}

@article{Myers_2008,
  title = {Molecular {{Embodiments}} and the {{Body}}-{{Work}} of {{Modeling}} in {{Protein Crystallography}}},
  volume = {38},
  url = {http://sss.sagepub.com/content/38/2/163.short},
  timestamp = {2017-05-19T07:26:01Z},
  number = {2},
  author = {Myers, Natasha},
  urldate = {2014-02-12},
  date = {2008},
  pages = {163--199}
}

@online{Times_2012,
  title = {2012: {{The Year}} in {{Graphics}}},
  url = {http://www.nytimes.com/interactive/2012/12/30/multimedia/2012-the-year-in-graphics.html},
  shorttitle = {2012},
  abstract = {A selection of graphics and interactives from 2012 with information on how they were produced.},
  timestamp = {2017-05-19T07:26:01Z},
  author = {Times, New York},
  urldate = {2014-01-30},
  date = {2012}
}

@online{News_2009,
  title = {Data {{Journalism}} and {{Data Visualization}} from the {{Datablog}} | {{News}} | {{The Guardian}}},
  url = {http://www.theguardian.com/news/datablog},
  abstract = {Data journalism and data visualization from the Guardian},
  timestamp = {2017-05-19T07:26:02Z},
  author = {News, Guardian},
  urldate = {2014-01-30},
  date = {2009},
  keywords = {News}
}

@online{Inc_2009,
  title = {Back to {{Basics}}: {{Direct}}, {{Referral}} or {{Organic}} - {{Definitions Straight}} from the {{Source}} - {{Analytics Blog}}},
  url = {http://analytics.blogspot.co.uk/2009/08/back-to-basics-direct-referral-or.html},
  shorttitle = {Back to {{Basics}}},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Inc, Google},
  urldate = {2014-02-07},
  date = {2009}
}

@incollection{Suchman_2012,
  title = {Configuration},
  timestamp = {2017-05-19T07:26:02Z},
  booktitle = {Devices and the {{Happening}} of the {{Social}}},
  publisher = {{Routledge}},
  author = {Suchman, Lucy},
  editor = {Lury, Celia and Wakeford, Nina},
  date = {2012},
  pages = {48--60}
}

@online{Picture_2012,
  title = {Music {{Timeline}}},
  url = {http://research.google.com/bigpicture/music/#},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Picture, Big},
  urldate = {2014-02-12},
  date = {2012}
}

@book{Pariser_2011,
  title = {The {{Filter Bubble}}: {{What}} the {{Internet Is Hiding}} from {{You}}},
  url = {http://books.google.co.uk/books?hl=en&lr=&id=-FWO0puw3nYC&oi=fnd&pg=PT3&dq=eli+pariser&ots=g2PoCtpQV-&sig=3_CftKt2BPOwLVpT_OFzizJr_-c},
  shorttitle = {The {{Filter Bubble}}},
  timestamp = {2017-05-19T07:26:02Z},
  publisher = {{Penguin UK}},
  author = {Pariser, Eli},
  urldate = {2014-02-13},
  date = {2011}
}

@online{Meyer_2013,
  title = {Github, {{Object}} of {{Nerd Love}}, {{Makes Play}} for {{Non}}-{{Programmers}}},
  url = {http://www.theatlantic.com/technology/archive/2013/08/github-object-of-nerd-love-makes-play-for-non-programmers/278971/},
  abstract = {The popular service could become the web's de facto home for open data.},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Meyer, Robinson},
  urldate = {2014-02-13},
  date = {2013-08-44}
}

@online{Git_2014,
  title = {Git},
  url = {http://git-scm.com/},
  timestamp = {2017-05-19T07:26:02Z},
  author = {{Git}},
  urldate = {2014-02-25},
  date = {2014}
}

@online{Torvalds_2013,
  title = {Git(1) {{Manual Page}}},
  url = {https://www.kernel.org/pub/software/scm/git/docs/},
  timestamp = {2017-05-19T07:26:02Z},
  author = {{Torvalds}},
  urldate = {2014-02-25},
  date = {2013}
}

@online{Briandoll_2012,
  title = {Data at {{Github}}},
  url = {https://github.com/blog/1112-data-at-github},
  abstract = {There are over 1.5 million people working on over 2.5 million repositories on GitHub these days. Here are a few more fun stats I grabbed recently: Exploring GitHub Data The GitHub API provides access to the many public activities that happen on GitHub.com. Before today, if you were looking to analyze this data, you would need to archive it on your own and store it somewhere capable of querying such a large dataset. Ilya Grigorik recently released a project called GitHub Archive. GitHub Archive is a project to record the public GitHub timeline, archive it, and make it easily accessible for further analysis. Analyze GitHub Data with Google BigQuery We are happy to announce that the GitHub public timeline is now a featured public dataset available on Google BigQuery, which launched to the public today. Running queries against the GitHub dataset is free. After logging into BigQuery, add the project name "githubarchive". Bonus Dataset: Programming Language Correlations This dataset, available in the language\_correlation table on BigQuery, explores the relationships between programming languages as seen by GitHub. Example: How likely is it that a programmer who writes in Objective-C also programs in Java? (31\%). Read on to learn more about how this data was gathered. Generals in the Editor War may note that Emacs users are 35.2\% likely to also hack on Vim, while Vim users are only 17.3\% likely to hack on Emacs, so there's that.},
  timestamp = {2017-05-19T07:26:02Z},
  author = {{Briandoll}},
  urldate = {2014-03-03},
  date = {2012-05-01}
}

@article{John_2013,
  title = {Sharing and {{Web}} 2.0: {{The Emergence}} of a {{Keyword}}},
  volume = {15},
  issn = {1461-4448, 1461-7315},
  url = {http://nms.sagepub.com/content/15/2/167},
  doi = {10.1177/1461444812450684},
  shorttitle = {Sharing and {{Web}} 2.0},
  abstract = {Sharing is the constitutive activity of Web 2.0. But when did ‘sharing’ become the term used to describe the activities that constitute participation in Web 2.0? What does sharing mean in this context? What is its rhetorical force? This paper argues that a new meaning of sharing has emerged in the context of Web 2.0 with three main features: fuzzy objects of sharing; the use of the word ‘share’ with no object at all; and presenting in terms of sharing functions of social network sites that used not to be so described. Following a critique of the use of the notion of sharing by social network sites, the article concludes by suggesting affinities between sharing in Web 2.0 and in other social spheres.},
  timestamp = {2017-05-19T07:26:02Z},
  number = {2},
  author = {John, Nicholas A.},
  urldate = {2014-03-27},
  date = {2013-03-01},
  pages = {167--182},
  keywords = {Facebook,Internet,sharing,social network sites,Wayback Machine,Web 2.0}
}

@online{Hardy_2012,
  title = {Dreams of '{{Open}}' {{Everything}}},
  url = {http://bits.blogs.nytimes.com/2012/12/28/github-has-big-dreams-for-open-source-software-and-more/},
  abstract = {GitHub, a successful young company for open-source software projects, has \$100 million in funding and a long-term dream of taking its approach outside engineering and into all business, even government. Other Silicon Valley companies share the attitude.},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Hardy, Quentin},
  urldate = {2014-03-27},
  date = {2012-12-28},
  keywords = {GitHub Inc,Open-Source Software,Preston-Werner Tom}
}

@online{Grigorik_2012,
  title = {{{GitHub Archive}}},
  url = {http://www.githubarchive.org/},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Grigorik, Ilya},
  urldate = {2014-03-31},
  date = {2012}
}

@article{Burrows_2012,
  title = {Living with the {{H}}-{{Index}}? {{Metric Assemblages}} in the {{Contemporary Academy}}},
  volume = {60},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-954X.2012.02077.x/full},
  shorttitle = {Living with the {{H}}-{{Index}}?},
  timestamp = {2017-05-19T07:26:02Z},
  number = {2},
  author = {Burrows, Roger},
  urldate = {2016-02-17},
  date = {2012},
  pages = {355--372}
}

@article{Begel_2013,
  title = {Social {{Networking Meets Software Development}}: {{Perspectives}} from {{GitHub}}, {{MSDN}}, {{Stack Exchange}}, and {{TopCoder}}},
  volume = {30},
  shorttitle = {Social {{Networking Meets Software Development}}},
  timestamp = {2017-05-19T07:26:02Z},
  number = {1},
  author = {Begel, Andrew and Bosch, Jan and Storey, Margaret-Anne and Doll, Brian and Laundry, Doug and Fullerton, David and Hughes, Robert},
  year = {JAN-FEB 2013},
  pages = {52--66}
}

@article{Vasilescu_2013,
  title = {{{StackOverflow}} and {{GitHub}}: {{Associations Between Software Development}} and {{Crowdsourced Knowledge}}},
  doi = {10.1109/SocialCom.2013.35},
  shorttitle = {{{StackOverflow}} and {{GitHub}}},
  abstract = {StackOverflow is a popular on-line programming question and answer community providing its participants with rapid access to knowledge and expertise of their peers, especially benefitting coders. Despite the popularity of StackOverflow, its role in the work cycle of open-source developers is yet to be understood: on the one hand, participation in it has the potential to increase the knowledge of individual developers thus improving and speeding up the development process. On the other hand, participation in StackOverflow may interrupt the regular working rhythm of the developer, hence also possibly slow down the development process. In this paper we investigate the interplay between StackOverflow activities and the development process, reflected by code changes committed to the largest social coding repository, GitHub. Our study shows that active GitHub committers ask fewer questions and provide more answers than others. Moreover, we observe that active StackOverflow askers distribute their work in a less uniform way than developers that do not ask questions. Finally, we show that despite the interruptions incurred, the StackOverflow activity rate correlates with the code changing activity in GitHub.},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Vasilescu, Bogdan and Filkov, Vladimir and Serebrenik, Alexander},
  date = {2013},
  pages = {188--195}
}

@article{Bouquin_2015,
  title = {{{GitHub}}},
  volume = {103},
  doi = {10.3163/1536-5050.103.3.019},
  timestamp = {2017-05-19T07:26:02Z},
  number = {3},
  author = {Bouquin, Daina R.},
  date = {2015-07},
  pages = {166--167}
}

@article{Jurado_2015,
  title = {Sentiment {{Analysis}} in {{Monitoring Software Development Processes}}: {{An Exploratory Case Study}} on {{GitHub}}'s {{Project Issues}}},
  volume = {104},
  doi = {10.1016/j.jss.2015.02.055},
  shorttitle = {Sentiment {{Analysis}} in {{Monitoring Software Development Processes}}},
  abstract = {Software process models, which allow us to develop software products, can be improved by using the corresponding quality model. However, current tendencies in the application of Global Software Engineering and Global Software Development, which forces geographically dispersed teams to collaborate, make the usual monitoring techniques obsolete. This situation has led to looking for new methods that can help in the decision making process, such as the case of the Social Network Analysis field. In this article we propose the introduction of Sentiment Analysis techniques in order to identify and monitor the underlying sentiments in the text written by developers in issues and tickets. Therefore, in order to check its viability we conducted an exploratory case study analysing polarity and emotional clues in development issues from nine well-known projects that are freely available. Results show that although both polarity and emotional analysis are applicable, the emotional analysis looks to be more suitable to this kind of corpus. The developers leave underlying sentiments in the text, and that information could be monitored as any other feature in the development process. (C) 2015 Elsevier Inc. All rights reserved.},
  timestamp = {2017-05-19T07:26:02Z},
  author = {Jurado, Francisco and Rodriguez, Pilar},
  date = {2015-06},
  pages = {82--89}
}

@article{Grier_2015,
  title = {The {{GitHub Effect}}},
  volume = {48},
  abstract = {Although GitHub has become a great tool for studying the software development process, it poses a fundamental problem to those who study work.},
  timestamp = {2017-05-19T07:26:02Z},
  number = {5},
  author = {Grier, David Alan},
  date = {2015-05},
  pages = {106--106}
}

@article{McDonald_2014,
  title = {Modeling {{Distributed Collaboration}} on {{Github}}},
  volume = {17},
  doi = {10.1142/S0219525914500246},
  abstract = {In this paper, we apply concepts from Distributed Leadership, a theory suggesting that leadership is shared among members of an organization, to frame models of contribution that we uncover in five relatively successful open source software (OSS) projects hosted on GitHub. In this qualitative, comparative case study, we show how these projects make use of GitHub features such as pull requests (PRs). We find that projects in which member PRs are more frequently merged with the codebase experience more sustained participation. We also find that projects with higher success rates among contributors and higher contributor retention tend to have more distributed (non-centralized) practices for reviewing and processing PRs. The relationships between organizational form and GitHub practices are enabled and made visible as a result of GitHub's novel interface. Our results demonstrate specific dimensions along which these projects differ and explicate a framework that warrants testing in future studies of OSS, particularly GitHub.},
  timestamp = {2017-05-19T07:26:02Z},
  issue = {7-8},
  author = {McDonald, Nora and Blincoe, Kelly and Petakovic, Eva and Goggins, Sean},
  date = {2014-12},
  pages = {1450024}
}

@article{Robertson_2014,
  title = {Mining the {{Social Web}}: {{Data Mining Facebook}}, {{Twitter}}, {{LinkedIn}}, {{Google}} plus , {{GitHub}}, and {{More}}, 2 {{Edition}}},
  volume = {61},
  shorttitle = {Mining the {{Social Web}}},
  timestamp = {2017-05-19T07:26:02Z},
  number = {3},
  author = {Robertson, Angela},
  date = {2014-08},
  pages = {209--209}
}

@incollection{Jarczyk_2014,
  title = {{{GitHub Projects}}. {{Quality Analysis}} of {{Open}}-{{Source Software}}},
  volume = {8851},
  abstract = {Nowadays Open-Source Software is developed mostly by decentralized teams of developers cooperating on-line. GitHub portal is an online social network that supports development of software by virtual teams of programmers. Since there is no central mechanism that governs the process of team formation, it is interesting to investigate if there are any significant correlations between project quality and the characteristics of the team members. However, for such analysis to be possible, we need good metrics of a project quality. This paper develops two such metrics, first one reflecting project's popularity, and the second one - the quality of support offered by team members to users. The first metric is based on the number of 'stars' a project is given by other GitHub members, the second is obtained using survival analysis techniques applied to issues reported on the project by its users. After developing the metrics we have gathered characteristics of several GitHub projects and analyzed their influence on the project quality using statistical regression techniques.},
  timestamp = {2017-05-19T07:26:02Z},
  booktitle = {Social {{Informatics}}, {{Socinfo}} 2014},
  author = {Jarczyk, Oskar and Gruszka, Blazej and Jaroszewicz, Szymon and Bukowski, Leszek and Wierzbicki, Adam},
  editor = {Aiello, L. M. and McFarland, D.},
  date = {2014},
  pages = {80--94}
}

@incollection{Yu_2014,
  title = {An {{Empirical Study}} of the {{Dynamics}} of {{GitHub Repository}} and {{Its Impact}} on {{Distributed Software Development}}},
  volume = {8842},
  abstract = {GitHub is a distributed code repository and project hosting web site. It is becoming one of the most popular web-based services to host both open-source projects and closed-source projects. In this paper, we review different kinds of version control systems and study the dynamics of GitHub, i.e., the ability and scalability of GitHub to process different requests and provide different services to different GitHub projects and GitHub users. Our study shows that GitHub could handle hundreds of thousands of requests a day for all the projects and thousands of requests for one project. This capability of GitHub makes it suitable for supporting distributed software development.},
  timestamp = {2017-05-19T07:26:02Z},
  booktitle = {On the {{Move}} to {{Meaningful Internet Systems}}: {{Otm}} 2014 {{Workshops}}},
  author = {Yu, Liguo and Mishra, Alok and Mishra, Deepti},
  editor = {Meersman, R. and Panetto, H. and Mishra, A. and ValenciaGarcia, R. and Soares, A. L. and Ciuciu, I. and Ferri, F. and Weichhart, G. and Moser, T. and Bezzi, M. and Chan, H.},
  date = {2014},
  pages = {457--466}
}

@incollection{Bissyande_2013,
  title = {Got {{Issues}}? {{Who Cares About It}}? {{A Large Scale Investigation}} of {{Issue Trackers}} from {{GitHub}}},
  shorttitle = {Got {{Issues}}?},
  abstract = {Feedback from software users constitutes a vital part in the evolution of software projects. By filing issue reports, users help identify and fix bugs, document software code, and enhance the software via feature requests. Many studies have explored issue reports, proposed approaches to enable the submission of higher-quality reports, and presented techniques to sort, categorize and leverage issues for software engineering needs. Who, however, cares about filing issues? What kind of issues are reported in issue trackers? What kind of correlation exist between issue reporting and the success of software projects? In this study, we address the need for answering such questions by performing an empirical study on a hundred thousands of open source projects. After filtering relevant trackers, the study used about 20,000 projects. We investigate and answer various research questions on the popularity and impact of issue trackers.},
  timestamp = {2017-05-19T07:26:03Z},
  booktitle = {2013 {{Ieee}} 24th {{International Symposium}} on {{Software Reliability Engineering}} ({{Issre}})},
  author = {Bissyande, Tegawende F. and Lo, David and Jiang, Lingxiao and Reveillere, Laurent and Klein, Jacques and Le Traon, Yves},
  date = {2013},
  pages = {188--197}
}

@incollection{Onoue_2013,
  title = {A {{Study}} of the {{Characteristics}} of {{Developers}}' {{Activities}} in {{GitHub}}},
  abstract = {What types of developers do active software projects have? This paper presents a study of the characteristics of developers' activities in open source software development. GitHub, a widely-used hosting service for software development projects, provides APIs for collecting various kinds of GitHub data. To clarify the characteristics of developers' activities, we used these APIs to investigate GitHub events generated by each developer. Using this information, we categorized developers based on measures such as whether they prefer communication by coding or comments, or whether they are specialists or generalists. Our study indicates that active software projects have various kinds of developers characterized by different types of development activities.},
  timestamp = {2017-05-19T07:26:03Z},
  booktitle = {2013 20th {{Asia}}-{{Pacific Software Engineering Conference}} ({{Apsec}} 2013), {{Vol}} 2},
  author = {Onoue, Saya and Hata, Hideaki and Matsumoto, Ken-ichi},
  editor = {Muenchaisri, P. and Rothermel, G.},
  date = {2013},
  pages = {7--12}
}

@incollection{Weicheng_2013,
  title = {Mining {{GitHub}}: {{Why Commit Stops}}},
  shorttitle = {Mining {{GitHub}}},
  abstract = {Using the freeware in GitHub, we are often confused by a phenomenon: the new version of GitHub freeware usually was released in an indefinite frequency; and developers often committed nothing for a long time. This evolution phenomenon interferes with our own development plan and architecture design. Why do these updates happen at that time? Can we predict GitHub software version evolution by developers' activities? This paper aims to explore the developer commit patterns in GitHub, and try to mine the relationship between these patterns (if exists) and code evolution. First, we define four metrics to measure commit activity and code evolution: the changes in each commit; the time between two commits; the author of each changes; and the source code dependency. Then, we adopt visualization techniques to explore developers' commit activity and code evolution. Visual techniques are used to describe the progress of the given project and the authors' contributions. To analyze the commit logs in GitHub software repository automatically, Commits Analysis Tool (CAT) is designed and implemented. Finally, eight open source projects in GitHub are analyzed using CAT, and we find that: 1) the file changes in the previous versions may affect the file depend on it in the next version; 2) the average days around "huge commit" is 3 times of that around normal commit. Using these two patterns and developer's commit model, we can predict when his next commit comes and which file may be changed in that commit. Such information is valuable for project planning of both GitHub projects and other projects which use GitHub freeware to develop software.},
  timestamp = {2017-05-19T07:26:03Z},
  booktitle = {2013 20th {{Asia}}-{{Pacific Software Engineering Conference}} ({{Apsec}} 2013), {{Vol}} 2},
  author = {Weicheng, Yang and Beijun, Shen and Ben, Xu},
  editor = {Muenchaisri, P. and Rothermel, G.},
  date = {2013},
  pages = {165--169}
}

@online{_o,
  title = {Concealed {{Dual Control Shower}} with {{Diverter}} | {{Fired Earth}}},
  url = {http://www.firedearth.com/concealed-dual-control-shower-with-diverter},
  timestamp = {2017-05-19T07:26:03Z},
  urldate = {2015-11-23}
}

@article{Cronin_2014,
  title = {Visualisation of {{GitHub}}’s {{Public Data}}},
  doi = {10.13140/2.1.3782.1763},
  timestamp = {2017-05-19T07:26:03Z},
  author = {Cronin, Cathal and Nikolov, Nikola S.},
  date = {2014}
}

@inproceedings{Melnik_2010,
  title = {Dremel: {{Interactive Analysis}} of {{Web}}-{{Scale Datasets}}},
  url = {http://www.vldb2010.org/accept.htm},
  timestamp = {2017-05-19T07:26:03Z},
  booktitle = {Proc. of the 36th {{Int}}'l {{Conf}} on {{Very Large Data Bases}}},
  author = {Melnik, Sergey and Gubarev, Andrey and Long, Jing Jing and Romer, Geoffrey and Shivakumar, Shiva and Tolton, Matt and Vassilakis, Theo},
  date = {2010},
  pages = {330--339}
}

@online{Github_2013,
  title = {Data {{Challenge II Results}}},
  url = {https://github.com/blog/1544-data-challenge-ii-results},
  abstract = {In April we announced the second annual GitHub data challenge. Since last year, GitHub's public timeline data on Google BigQuery has grown by over 80 million events, including 3.8 million new repos...},
  timestamp = {2017-05-19T07:26:03Z},
  author = {{Github}},
  urldate = {2016-03-15},
  date = {2013-06-26}
}

@online{Inc_2016,
  title = {{{GithubArchive Timeline}}},
  url = {https://bigquery.cloud.google.com/table/githubarchive:github.timeline},
  timestamp = {2017-05-19T07:26:03Z},
  author = {Inc, Google},
  urldate = {2016-03-15},
  date = {2016}
}

@online{Github_2016,
  title = {Github {{Events Application Programmer Interface}}},
  url = {https://api.github.com/events},
  timestamp = {2017-05-19T07:26:03Z},
  author = {{Github}},
  urldate = {2016-03-15},
  date = {2016}
}

@online{Fischer_2013,
  title = {Open {{Source Contributions}} by {{Location}}},
  url = {http://davidfischer.github.io/gdc2/#languages/All},
  timestamp = {2017-05-19T07:26:03Z},
  author = {Fischer, David},
  urldate = {2016-03-15},
  date = {2013-05-04}
}

@online{Github_2012,
  title = {{{GitHub}} · {{Social Coding}}},
  url = {http://wayback.archive.org/web/20121127113950/https://github.com/},
  timestamp = {2017-05-19T07:26:03Z},
  author = {{Github}},
  urldate = {2016-03-15},
  date = {2012}
}

@online{Fischer_2013a,
  title = {{{GitHub Data Challenge II}}},
  url = {https://www.davidfischer.name/2013/05/github-data-challenge-ii/},
  abstract = {GitHub’s public timeline contains a wealth of knowledge about contributions to open source software from all over the world. It’s pretty typical to see over ten thousand contributions o…},
  timestamp = {2017-05-19T07:26:03Z},
  author = {Fischer, David},
  urldate = {2016-03-15},
  year = {2013-05-05T02:47:58+00:00}
}

@article{Kenney_2015,
  title = {Counting, {{Accounting}}, and {{Accountability}}: {{Helen Verran}}'s {{Relational Empiricism}}},
  volume = {45},
  issn = {0306-3127},
  doi = {10.1177/0306312715607413},
  shorttitle = {Counting, {{Accounting}}, and {{Accountability}}},
  abstract = {Helen Verran uses the term relational empiricism' to describe situated empirical inquiry that is attentive to the relations that constitute its objects of study, including the investigator's own practices. Relational empiricism draws on and reconfigures Science and Technology Studies' traditional concerns with reflexivity and relationality, casting empirical inquiry as an important and non-innocent world-making practice. Through a reading of Verran's postcolonial projects in Nigeria and Australia, this article develops a concept of empirical and political accountability' to complement her relational empiricism. In Science and an African Logic, Verran provides accounts of the relations that materialize her empirical objects. These accounts work to decompose her original objects, generating new objects that are more promising for the specific postcolonial contexts of her work. The process of decomposition is part of remaining accountable for her research methods and accountable to the worlds she is working in and writing about. This is a practice of narrating relations and learning to tell better technoscientific stories. What counts as better, however, is not given, but is always contextual and at stake. In this way, Verran acts not as participant-observer, but as participant-storyteller, telling stories to facilitate epistemic flourishing within and as part of a historically located community of practice. The understanding of accountability that emerges from this discussion is designed as a contribution, both practical and evocative, to the theoretical toolkit of Science and Technology Studies scholars who are interested in thinking concretely about how we can be more accountable to the worlds we study.},
  timestamp = {2017-05-19T07:26:03Z},
  number = {5},
  author = {Kenney, Martha},
  date = {2015-10},
  pages = {749--771},
  keywords = {accountability,Feminist theory,Helen Verran,politics of method,postcolonial STS,scientists}
}

@article{Bucher_2013,
  title = {Objects of {{Intense Feeling}}: {{The Case}} of the {{Twitter API}} : {{Computational Culture}}},
  url = {http://computationalculture.net/article/objects-of-intense-feeling-the-case-of-the-twitter-api},
  shorttitle = {Objects of {{Intense Feeling}}},
  timestamp = {2017-05-19T07:26:03Z},
  number = {3},
  author = {Bucher, Taina},
  urldate = {2016-03-16},
  date = {2013}
}

@online{Github_2014,
  title = {Results of the {{GitHub Investigation}}},
  url = {https://github.com/blog/1823-results-of-the-github-investigation},
  abstract = {Last month, a number of allegations were made against GitHub and some of its employees, including one of its co-founders, Tom Preston-Werner. We took these claims seriously and launched a full, ind...},
  timestamp = {2017-05-19T07:26:03Z},
  author = {{Github}},
  urldate = {2016-03-16},
  date = {2014-04-21}
}

@online{_p,
  title = {About · {{GitHub}}},
  url = {http://web.archive.org/web/20140605120710/https://github.com/about},
  timestamp = {2017-05-19T07:26:03Z},
  urldate = {2016-03-16}
}

@online{Marczak_2015,
  title = {China's {{Great Cannon}}},
  url = {https://citizenlab.org/2015/04/chinas-great-cannon/},
  abstract = {This post describes our analysis of an attack tool that we identify as separate from, but co-located with, the Great Firewall of China.},
  timestamp = {2017-05-19T07:26:03Z},
  author = {Marczak, Bill and Weaver, Nicholas},
  urldate = {2016-03-16},
  year = {2015-04-10T05:55:18+00:00}
}

@article{Diggle_2015,
  title = {Statistics: {{A Data Science}} for the 21st {{Century}}},
  volume = {178},
  issn = {1467-985X},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/rssa.12132/abstract},
  doi = {10.1111/rssa.12132},
  shorttitle = {Statistics},
  abstract = {The rise of data science could be seen as a potental threat to the long-term status of the statistics discipline. I first argue that, although there is a threat, there is also a much greater opportunity to re-emphasize the universal relevance of statistical method to the interpretation of data, and I give a short historical outline of the increasingly important links between statistics and information technology. The core of the paper is a summary of several recent research projects, through which I hope to demonstrate that statistics makes an essential, but incomplete, contribution to the emerging field of ‘electronic health’ research. Finally, I offer personal thoughts on how statistics might best be organized in a research-led university, on what we should teach our students and on some issues broadly related to data science where the Royal Statistical Society can take a lead.},
  timestamp = {2017-05-19T07:26:03Z},
  number = {4},
  author = {Diggle, Peter J.},
  urldate = {2015-12-02},
  date = {2015-10-01},
  pages = {793--813},
  keywords = {data science,Electronic health research,Health surveillance,Informatics,National Health Service prescribing patterns,Reproducible research,Statistical education}
}

@article{Park_2013,
  title = {Decomposing {{Social}} and {{Semantic Networks}} in {{Emerging}} "{{Big Data}}" {{Research}}},
  volume = {7},
  doi = {10.1016/j.joi.2013.05.004},
  abstract = {This paper examines the structural patterns of networks of internationally co-authored SCI papers in the domain of research driven by big data and provides an empirical analysis of semantic patterns of paper titles. The results based on data collected from the DVD version of the 2011 SCI database identify the U.S. as the most central country, followed by the U.K., Germany, France, Italy, Australia, the Netherlands, Canada, and Spain, in that order. However, some countries (e.g., Portugal) with low degree centrality occupied relatively central positions in terms of betweenness centrality. The results of the semantic network analysis suggest that internationally co-authored papers tend to focus on primary technologies, particularly in terms of programming and related database issues. The results show that a combination of words and locations can provide a richer representation of an emerging field of science than the sum of the two separate representations. (C) 2013 Elsevier Ltd. All rights reserved.},
  timestamp = {2017-05-19T07:26:03Z},
  number = {3},
  author = {Park, Han Woo and Leydesdorff, Loet},
  date = {2013},
  pages = {756--765},
  keywords = {get,methods}
}

@book{Stark_2011,
  title = {The {{Sense}} of {{Dissonance}}: {{Accounts}} of {{Worth}} in {{Economic Life}}},
  isbn = {978-1-4008-3100-5},
  shorttitle = {The {{Sense}} of {{Dissonance}}},
  abstract = {What counts? In work, as in other areas of life, it is not always clear what standards we are being judged by or how our worth is being determined. This can be disorienting and disconcerting. Because of this, many organizations devote considerable resources to limiting and clarifying the logics used for evaluating worth. But as David Stark argues, firms would often be better off, especially in managing change, if they allowed multiple logics of worth and did not necessarily discourage uncertainty. In fact, in many cases multiple orders of worth are unavoidable, so organizations and firms should learn to harness the benefits of such "heterarchy" rather than seeking to purge it. Stark makes this argument with ethnographic case studies of three companies attempting to cope with rapid change: a machine-tool company in late and postcommunist Hungary, a new-media startup in New York during and after the collapse of the Internet bubble, and a Wall Street investment bank whose trading room was destroyed on 9/11. In each case, the friction of competing criteria of worth promoted an organizational reflexivity that made it easier for the company to change and deal with market uncertainty. Drawing on John Dewey's notion that "perplexing situations" provide opportunities for innovative inquiry, Stark argues that the dissonance of diverse principles can lead to discovery.},
  timestamp = {2017-05-19T07:26:03Z},
  publisher = {{Princeton University Press}},
  author = {Stark, David},
  date = {2011-08-01},
  keywords = {Business & Economics / Economics / General,Business & Economics / Finance,Business & Economics / Finance / General,Business & Economics / Labor,Social Science / Sociology / General}
}

@article{Allamanis_2016,
  title = {A {{Convolutional Attention Network}} for {{Extreme Summarization}} of {{Source Code}}},
  url = {http://arxiv.org/abs/1602.03001},
  abstract = {Attention mechanisms in neural networks have proved useful for problems in which the input and output do not have fixed dimension. Often there exist features that are locally translation invariant and would be valuable for directing the model's attention, but previous attentional architectures are not constructed to learn such features specifically. We introduce an attentional neural network that employs convolution on the input tokens to detect local time-invariant and long-range topical attention features in a context-dependent way. We apply this architecture to the problem of extreme summarization of source code snippets into short, descriptive function name-like summaries. Using those features, the model sequentially generates a summary by marginalizing over two attention mechanisms: one that predicts the next summary token based on the attention weights of the input tokens and another that is able to copy a code token as-is directly into the summary. We demonstrate our convolutional attention neural network's performance on 10 popular Java projects showing that it achieves better performance compared to previous attentional mechanisms.},
  timestamp = {2017-05-19T07:26:03Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.03001},
  author = {Allamanis, Miltiadis and Peng, Hao and Sutton, Charles},
  urldate = {2016-06-13},
  date = {2016-02-09},
  keywords = {Computer Science - Computation and Language,Computer Science - Learning,Computer Science - Software Engineering}
}

@inproceedings{Weber_2014,
  title = {What {{Makes}} an {{Open Source Code Popular}} on {{Git Hub}}?},
  doi = {10.1109/ICDMW.2014.55},
  abstract = {The rise of social networks for software development has attached a notion of popularity to open source projects. This work attempts to extract knowledge from the differences between popular and unpopular Python projects on GitHub. A large set of projects was mined for a rich variety of features that measure language utilization, documentation, and code volume. These features were used to train a classifier which predicted current popularity well (F-score = ×8). Notably, these features outperformed measures of author popularity (F-score = ×7). However, these features did not strongly predict future growth in popularity. An in-depth analysis of the perform ant features revealed that they could be useful as a measure of not only popularity, but of code quality.},
  timestamp = {2017-05-19T07:26:04Z},
  booktitle = {2014 {{IEEE International Conference}} on {{Data Mining Workshop}}},
  author = {Weber, S. and Luo, J.},
  date = {2014-12},
  pages = {851--855},
  keywords = {code quality,code volume,Communities,Conferences,Current measurement,Data Mining,Documentation,Feature extraction,GitHub,Git Hub,in-depth analysis,knowledge acquisition,knowledge extraction,language utilization,open source code,open source project,Open source software,popularity prediction,public domain software,Python,Python project,social network,social networking (online),Software,software development,Software engineering,source code (software),system documentation}
}

@article{Borges_2015,
  title = {On the {{Popularity}} of {{GitHub Applications}}: {{A Preliminary Note}}},
  url = {http://arxiv.org/abs/1507.00604},
  shorttitle = {On the {{Popularity}} of {{GitHub Applications}}},
  abstract = {GitHub is the world's largest collection of open source software. Therefore, it is important both to software developers and users to compare and track the popularity of GitHub repositories. In this paper, we propose a framework to assess the popularity of GitHub software, using their number of stars. We also propose a set of popularity growth patterns, which describe the evolution of the number of stars of a system over time. We show that stars tend to correlate with other measures, like forks, and with the effective usage of GitHub software by third-party programs. Throughout the paper we illustrate the application of our framework using real data extracted from GitHub.},
  timestamp = {2017-05-19T07:26:04Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1507.00604},
  author = {Borges, Hudson and Valente, Marco Tulio and Hora, Andre and Coelho, Jailton},
  urldate = {2016-07-26},
  date = {2015-07-02},
  keywords = {Computer Science - Software Engineering}
}

@book{Anderson_2009,
  location = {{London}},
  title = {The {{Longer Long Tail}}: {{How Endless Choice Is Creating Unlimited Demand}}},
  isbn = {978-1-84794-036-0},
  shorttitle = {The {{Longer Long Tail}}},
  abstract = {What happens when there is almost unlimited choice? When everything becomes available to everyone? And when the combined value of the millions of items that only sell in small quantities equals or even exceeds the value of a handful of best-sellers?In this ground-breaking book, Chris Anderson shows that the future of business does not lie in hits - the high-volume end of a traditional demand curve - but in what used to be regarded as misses - the endlessly long tail of that same curve. As our world is transformed by the Internet and the near infinite choice it offers consumers, so traditional business models are being overturned and new truths revealed about what consumers want and how they want to get it. Chris Anderson first explored the Long Tail in an article in Wired magazine that has become one of the most influential business essays of our time. Now, in this eagerly anticipated book, he takes a closer look at the new economics of the Internet age, showing where business is going and exploring the huge opportunities that exist: for new producers, new e-tailers, and new tastemakers. He demonstrates how long tail economics apply to industries ranging from the toy business to advertising to kitchen appliances. He sets down the rules for operating in a long tail economy. And he provides a glimpse of a future that's already here.},
  timestamp = {2017-05-19T07:26:04Z},
  publisher = {{Random House Business}},
  author = {Anderson, Chris},
  date = {2009-07-02}
}

@online{Github_2016a,
  title = {Event {{Types}} \& {{Payloads}} | {{GitHub Developer Guide}}},
  url = {https://developer.github.com/v3/activity/events/types/},
  timestamp = {2017-05-19T07:26:04Z},
  author = {{Github}},
  urldate = {2016-09-13},
  date = {2016}
}

@online{Inc_2016a,
  title = {Github {{Repositories}} on {{Google BigQuery}}},
  url = {https://bigquery.cloud.google.com/dataset/bigquery-public-data:github_repos},
  timestamp = {2017-05-19T07:26:04Z},
  author = {Inc, Google},
  urldate = {2016-09-16},
  date = {2016}
}

@article{Marshall_2016,
  title = {Facebook {{Wants}} to {{Help Sell Every Ad}} on the {{Web}}},
  issn = {0099-9660},
  url = {http://www.wsj.com/articles/facebook-wants-to-help-sell-every-ad-on-the-web-1464321603},
  abstract = {Facebook will help marketers show ads to non-Facebook users who visit websites and applications in its Audience Network ad network.},
  timestamp = {2017-05-19T07:26:04Z},
  author = {Marshall, Jack},
  urldate = {2016-12-06},
  year = {2016-05-27T04:00:00.000Z},
  keywords = {advertising,advertising networks,Alphabet Cl C,Business,consumer services,corporate,digital marketing,entertainment,Facebook,FB,general news,GOOG,GOOGL,industrial news,Internet,lifestyle,living,Marketing,markets,media,online,political,public relations,social media,social media marketing,social media platforms,technology,tools}
}

@article{Newcomer_2016,
  title = {{{GitHub Is Building}} a {{Coder}}’s {{Paradise}}. {{It}}’s {{Not Coming Cheap}}},
  url = {https://www.bloomberg.com/news/articles/2016-12-15/github-is-building-a-coder-s-paradise-it-s-not-coming-cheap},
  abstract = {The VC-backed unicorn startup lost \$66 million in nine months of 2016, financial documents show.},
  timestamp = {2017-05-19T07:26:04Z},
  author = {Newcomer, Eric},
  urldate = {2016-12-19},
  date = {2016-12-45}
}

@online{GHTorrent_2017,
  title = {The {{GHTorrent Project}}},
  url = {http://ghtorrent.org/},
  timestamp = {2017-05-19T07:26:04Z},
  author = {{GHTorrent}},
  urldate = {2017-01-23},
  date = {2017}
}

@book{Wittgenstein_2003,
  location = {{London \& New York}},
  edition = {2 edition},
  title = {Tractatus {{Logico}}-{{Philosophicus}}: {{Volume}} 123},
  shorttitle = {Tractatus {{Logico}}-{{Philosophicus}}},
  abstract = {Perhaps the most important work of philosophy written in the twentieth century, Tractatus Logico-Philosophicus was the only philosophical work that Ludwig Wittgenstein published during his lifetime. Written in short, carefully numbered paragraphs of extreme brilliance, it captured the imagination of a generation of philosophers. For Wittgenstein, logic was something we use to conquer a reality which is in itself both elusive and unobtainable. He famously summarized the book in the following words: 'What can be said at all can be said clearly; and what we cannot talk about we must pass over in silence.' David Pears and Brian McGuinness received the highest praise for their meticulous translation. The work is prefaced by Bertrand Russell's original introduction to the first English edition.},
  timestamp = {2017-05-19T07:26:04Z},
  publisher = {{Routledge}},
  author = {Wittgenstein, Ludwig},
  date = {2003}
}

@article{Straube_2016,
  title = {Stacked {{Spaces}}: {{Mapping Digital Infrastructures}}},
  volume = {3},
  issn = {2053-9517},
  url = {http://bds.sagepub.com/lookup/doi/10.1177/2053951716642456},
  doi = {10.1177/2053951716642456},
  shorttitle = {Stacked {{Spaces}}},
  timestamp = {2017-05-19T07:26:04Z},
  number = {2},
  author = {Straube, Theodore},
  urldate = {2017-02-02},
  date = {2016-09-19}
}

@online{Gomez_2012,
  title = {Exploring {{Expressions}} of {{Emotions}} in {{GitHub Commit Messages}}},
  url = {http://geeksta.net/geeklog/exploring-expressions-emotions-github-commit-messages/},
  abstract = {An exploration of expressions of emotions, issues and swearing in GitHub commit messages based on data from the GitHub Archive accessed via Google BigQuery.},
  timestamp = {2017-05-19T07:26:04Z},
  author = {Gómez, Ramiro},
  urldate = {2017-04-25},
  date = {2012}
}

@article{Star_1996,
  title = {Steps {{Toward}} an {{Ecology}} of {{Infrastructure}}: {{Design}} and {{Access}} for {{Large Information Spaces}}},
  volume = {7},
  timestamp = {2017-05-19T07:26:31Z},
  number = {1},
  author = {Star, Susan Leigh and Ruhleder, Karen},
  date = {1996},
  pages = {111--134}
}

@book{Rose_2006,
  location = {{Princeton, NJ}},
  title = {The {{Politics}} of {{Life Itself}} : {{Biomedicine}}, {{Power}}, and {{Subjectivity}} in the {{Twenty}}-{{First Century}}},
  isbn = {9780691121901 (alk. paper) 0691121907 (alk. paper)},
  timestamp = {2017-05-19T07:26:32Z},
  publisher = {{Princeton University Press}},
  author = {Rose, Nikolas},
  date = {2006}
}

@article{Leonelli_2013,
  title = {Global {{Data}} for {{Local Science}}},
  volume = {8},
  issn = {1745-8552},
  url = {http://dx.doi.org/10.1057/biosoc.2013.23},
  timestamp = {2017-05-19T07:26:32Z},
  number = {4},
  author = {Leonelli, Sabine},
  date = {2013-12},
  pages = {449--465}
}

@incollection{Hood_1992,
  location = {{Cambridge MA}},
  title = {Biology and {{Medicine}} in the {{Twenty}}-{{First Century}}},
  url = {http://www.vjf.cnrs.fr/histrecmed/publications-electroniques/Leroy%20Hood.pdf},
  timestamp = {2017-05-19T07:26:32Z},
  booktitle = {The {{Code}} of {{Code}}},
  publisher = {{Harvard University Press}},
  editor = {Hood, Leroy and Kevles, Daniel J.},
  urldate = {2012-12-18},
  date = {1992},
  pages = {136--63}
}

@article{Zhu_2013,
  title = {{{SRAdb}}: {{Query}} and {{Use Public}} next-{{Generation Sequencing Data}} from within {{R}}},
  volume = {14},
  url = {http://www.biomedcentral.com/1471-2105/14/19?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+bioinformatics_today+(Bioinformatics)},
  shorttitle = {{{SRAdb}}},
  timestamp = {2017-05-19T07:26:32Z},
  number = {1},
  author = {Zhu, Yuelin and Stephens, Robert M. and Meltzer, Paul S. and Davis, Sean R.},
  urldate = {2014-08-28},
  date = {2013},
  pages = {19}
}

@article{Mogoutov_2008,
  title = {Biomedical {{Innovation}} at the {{Laboratory}}, {{Clinical}} and {{Commercial Interface}}: {{A New Method}} for {{Mapping Research Projects}}, {{Publications}} and {{Patents}} in the {{Field}} of {{Microarrays}}},
  volume = {2},
  shorttitle = {Biomedical {{Innovation}} at the {{Laboratory}}, {{Clinical}} and {{Commercial Interface}}},
  timestamp = {2017-05-19T07:26:32Z},
  number = {4},
  author = {Mogoutov, A. and Cambrosio, A. and Keating, P. and Mustar, P.},
  date = {2008},
  pages = {341--353}
}

@article{Hilgartner_1995,
  title = {Biomolecular {{Databases New Communication Regimes}} for {{Biology}}?},
  volume = {17},
  issn = {1075-5470, 1552-8545},
  url = {http://scx.sagepub.com/content/17/2/240},
  doi = {10.1177/1075547095017002009},
  abstract = {During the past two decades, computerized biomolecular databases have rapidly expanded and have been prominently integrated into laboratory work in biological sciences. This article offers an exploratory look at the potential significance of these databases as novel tools for scientific communication. The article develops the concept of a science communication regime—a sociotechnical system that constitutes a particular means of scientific communication, such as the scientific journal. This concept is then used to examine biomolecular databases and their potential implications for scientific institutions and practices. The field of genome research provides empirical examples, and the discussion explores the potential significance of these new forms of electronic communication.},
  timestamp = {2017-05-19T07:26:32Z},
  number = {2},
  author = {Hilgartner, Stephen},
  urldate = {2014-09-15},
  date = {1995-01-12},
  pages = {240--263}
}

@book{SunderRajan_2006,
  location = {{Durham}},
  title = {Biocapital : {{The Constitution}} of {{Postgenomic Life}}},
  timestamp = {2017-05-19T07:26:32Z},
  publisher = {{Duke University Press}},
  author = {Sunder Rajan, Kaushik},
  date = {2006},
  keywords = {20th Century.,21st Century.,Biotechnology history.,Biotechnology industries.,Drug Industry history.,Genomics Economic aspects.,Genomics economics.,Genomics history.,History,Pharmaceutical industry.}
}

@book{Kay_2000,
  location = {{Stanford, CA}},
  title = {Who {{Wrote}} the {{Book}} of {{Life}}? : {{A History}} of the {{Genetic Code}}},
  timestamp = {2017-05-19T07:26:32Z},
  series = {Writing science},
  publisher = {{Stanford University Press}},
  author = {Kay, Lily E},
  date = {2000},
  keywords = {Genetic code - Research - History}
}

@article{Hoffman_2012,
  title = {Unsupervised {{Pattern Discovery}} in {{Human Chromatin Structure}} through {{Genomic Segmentation}}},
  volume = {9},
  url = {http://www.nature.com/nmeth/journal/v9/n5/abs/nmeth.1937.html},
  timestamp = {2017-05-19T07:26:32Z},
  number = {5},
  author = {Hoffman, M. M. and Buske, O. J. and Wang, J. and Weng, Z. and Bilmes, J. A. and Noble, W. S.},
  urldate = {2012-12-19},
  date = {2012},
  pages = {473--476}
}

@article{Busch_2007,
  title = {Performing the {{Economy}}, {{Performing Science}}: {{From Neoclassical}} to {{Supply Chain Models}} in the {{Agrifood Sector}}},
  volume = {36},
  issn = {0308-5147},
  url = {http://www.informaworld.com/10.1080/03085140701428399},
  doi = {10.1080/03085140701428399},
  shorttitle = {Performing the {{Economy}}, {{Performing Science}}},
  timestamp = {2017-05-19T07:26:32Z},
  number = {3},
  author = {Busch, Lawrence},
  urldate = {2010-08-17},
  date = {2007},
  pages = {437--466}
}

@article{Li_2010,
  title = {Building the {{Sequence Map}} of the {{Human Pan}}-{{Genome}}},
  volume = {28},
  issn = {1087-0156},
  url = {http://dx.doi.org.ezproxy.lancs.ac.uk/10.1038/nbt.1596},
  doi = {10.1038/nbt.1596},
  timestamp = {2017-05-19T07:26:32Z},
  number = {1},
  author = {Li, Ruiqiang and Li, Yingrui and Zheng, Hancheng and Luo, Ruibang and Zhu, Hongmei and Li, Qibin and Qian, Wubin and Ren, Yuanyuan and Tian, Geng and Li, Jinxiang and Zhou, Guangyu and Zhu, Xuan and Wu, Honglong and Qin, Junjie and Jin, Xin and Li, Dongfang and Cao, Hongzhi and Hu, Xueda and Blanche, Helene and Cann, Howard and Zhang, Xiuqing and Li, Songgang and Bolund, Lars and Kristiansen, Karsten and Yang, Huanming and Wang, Jun and Wang, Jian},
  urldate = {2011-03-28},
  date = {2010-01},
  pages = {57--63}
}

@article{Qin_2010,
  title = {A {{Human Gut Microbial Gene Catalogue Established}} by {{Metagenomic Sequencing}}},
  volume = {464},
  issn = {0028-0836},
  url = {http://dx.doi.org/10.1038/nature08821},
  doi = {10.1038/nature08821},
  timestamp = {2017-05-19T07:26:32Z},
  number = {7285},
  author = {Qin, Junjie and Li, Ruiqiang and Raes, Jeroen and Arumugam, Manimozhiyan and Burgdorf, Kristoffer Solvsten and Manichanh, Chaysavanh and Nielsen, Trine and Pons, Nicolas and Levenez, Florence and Yamada, Takuji and Mende, Daniel R. and Li, Junhua and Xu, Junming and Li, Shaochuan and Li, Dongfang and Cao, Jianjun and Wang, Bo and Liang, Huiqing and Zheng, Huisong and Xie, Yinlong and Tap, Julien and Lepage, Patricia and Bertalan, Marcelo and Batto, Jean-Michel and Hansen, Torben and Le Paslier, Denis and Linneberg, Allan and Nielsen, H. Bjorn and Pelletier, Eric and Renault, Pierre and Sicheritz-Ponten, Thomas and Turner, Keith and Zhu, Hongmei and Yu, Chang and Li, Shengting and Jian, Min and Zhou, Yan and Li, Yingrui and Zhang, Xiuqing and Li, Songgang and Qin, Nan and Yang, Huanming and Wang, Jian and Brunak, Soren and Dore, Joel and Guarner, Francisco and Kristiansen, Karsten and Pedersen, Oluf and Parkhill, Julian and Weissenbach, Jean and Bork, Peer and Ehrlich, S. Dusko and Wang, Jun},
  urldate = {2011-03-28},
  date = {2010-03-04},
  pages = {59--65}
}

@book{Canguilhem_2000,
  location = {{New York}},
  title = {A {{Vital Rationalist}} : {{Selected Writings}} from {{Georges Canguilhem}}},
  timestamp = {2017-05-19T07:26:32Z},
  publisher = {{Zone Books}},
  author = {Canguilhem, Georges},
  editor = {Delaporte, Franðcois},
  date = {2000},
  keywords = {Science History.,Science Philosophy.}
}

@online{HapMap_2006,
  title = {{{HapMap}}: {{About}} the {{Project}}},
  url = {http://hapmap.ncbi.nlm.nih.gov/abouthapmap.html},
  timestamp = {2017-05-19T07:26:32Z},
  author = {{HapMap}},
  urldate = {2011-03-28},
  date = {2006}
}

@book{Bowker_1997,
  location = {{Mahwah, N.J. ; London}},
  title = {Social {{Science}}, {{Technical Systems}}, and {{Cooperative Work}} : {{Beyond}} the {{Great Divide}}},
  timestamp = {2017-05-19T07:26:32Z},
  publisher = {{Lawrence Erlbaum}},
  author = {Bowker, Geoffrey C},
  date = {1997},
  keywords = {Social sciences,Teams in the workplace - Data processing}
}

@online{Institute_2011,
  title = {The {{ENCODE Project}}: {{ENCyclopedia Of DNA Eements}}},
  url = {http://www.genome.gov/10005107},
  timestamp = {2017-05-19T07:26:32Z},
  author = {Institute, National Human Genome Reseearch},
  urldate = {2011-03-28},
  date = {2011}
}

@book{Helmreich_2009,
  location = {{Berkeley}},
  title = {Alien {{Ocean}} : {{Anthropological Voyages}} in {{Microbial Seas}}},
  isbn = {9780520250611 (cloth alk. paper) 0520250613 (cloth alk. paper) 9780520250628 (pbk. alk. paper) 0520250621 (pbk. alk. paper)},
  timestamp = {2017-05-19T07:26:32Z},
  publisher = {{University of California Press}},
  author = {Helmreich, Stefan},
  date = {2009},
  keywords = {Human ecology.,Marine biologists.,Marine microbiology Research.}
}

@article{Kitzman_2011,
  title = {Haplotype-{{Resolved Genome Sequencing}} of a {{Gujarati Indian Individual}}},
  volume = {29},
  issn = {1087-0156},
  url = {http://dx.doi.org/10.1038/nbt.1740},
  doi = {10.1038/nbt.1740},
  timestamp = {2017-05-19T07:26:32Z},
  number = {1},
  author = {Kitzman, Jacob O and MacKenzie, Alexandra P and Adey, Andrew and Hiatt, Joseph B and Patwardhan, Rupali P and Sudmant, Peter H and Ng, Sarah B and Alkan, Can and Qiu, Ruolan and Eichler, Evan E and Shendure, Jay},
  urldate = {2011-02-10},
  date = {2011-01},
  pages = {59--63}
}

@article{Stamatoyannopoulos_2012,
  title = {What {{Does Our Genome Encode}}?},
  volume = {22},
  url = {http://genome.cshlp.org/content/22/9/1602.short},
  timestamp = {2017-05-19T07:26:32Z},
  number = {9},
  author = {Stamatoyannopoulos, J. A.},
  urldate = {2012-12-19},
  date = {2012},
  pages = {1602--1611}
}

@article{Helmreich_2008,
  title = {Species of {{Biocapital}}},
  volume = {17},
  timestamp = {2017-05-19T07:26:32Z},
  number = {4},
  author = {Helmreich, Stefan},
  date = {2008},
  pages = {463--478}
}

@article{Fan_2011,
  title = {Whole-{{Genome Molecular Haplotyping}} of {{Single Cells}}},
  volume = {29},
  issn = {1087-0156},
  url = {http://dx.doi.org/10.1038/nbt.1739},
  doi = {10.1038/nbt.1739},
  timestamp = {2017-05-19T07:26:32Z},
  number = {1},
  author = {Fan, H Christina and Wang, Jianbin and Potanina, Anastasia and Quake, Stephen R},
  urldate = {2011-02-10},
  date = {2011-01},
  pages = {51--57}
}

@article{Lury_2009,
  title = {Brand as {{Assemblage}}},
  volume = {2},
  timestamp = {2017-05-19T07:26:32Z},
  issue = {1-2},
  author = {Lury, C.},
  date = {2009},
  pages = {67--82}
}

@article{Buettner_2015,
  title = {Computational {{Analysis}} of {{Cell}}-to-{{Cell Heterogeneity}} in {{Single}}-{{Cell RNA}}-{{Sequencing Data Reveals Hidden Subpopulations}} of {{Cells}}},
  issn = {1087-0156},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nbt/journal/vaop/ncurrent/full/nbt.3102.html},
  doi = {10.1038/nbt.3102},
  abstract = {Recent technical developments have enabled the transcriptomes of hundreds of cells to be assayed in an unbiased manner, opening up the possibility that new subpopulations of cells can be found. However, the effects of potential confounding factors, such as the cell cycle, on the heterogeneity of gene expression and therefore on the ability to robustly identify subpopulations remain unclear. We present and validate a computational approach that uses latent variable models to account for such hidden factors. We show that our single-cell latent variable model (scLVM) allows the identification of otherwise undetectable subpopulations of cells that correspond to different stages during the differentiation of naive T cells into T helper 2 cells. Our approach can be used not only to identify cellular subpopulations but also to tease apart different sources of gene expression heterogeneity in single-cell transcriptomes.},
  timestamp = {2017-05-19T07:26:32Z},
  author = {Buettner, Florian and Natarajan, Kedar N. and Casale, F. Paolo and Proserpio, Valentina and Scialdone, Antonio and Theis, Fabian J. and Teichmann, Sarah A. and Marioni, John C. and Stegle, Oliver},
  urldate = {2015-01-20},
  date = {2015}
}

@article{Tishkoff_2009,
  title = {The {{Genetic Structure}} and {{History}} of {{Africans}} and {{African Americans}}},
  volume = {324},
  url = {http://www.sciencemag.org/content/324/5930/1035.abstract},
  doi = {10.1126/science.1172257},
  abstract = {Africa is the source of all modern humans, but characterization of genetic variation and of relationships among populations across the continent has been enigmatic. We studied 121 African populations, four African American populations, and 60 non-African populations for patterns of variation at 1327 nuclear microsatellite and insertion/deletion markers. We identified 14 ancestral population clusters in Africa that correlate with self-described ethnicity and shared cultural and/or linguistic properties. We observed high levels of mixed ancestry in most populations, reflecting historical migration events across the continent. Our data also provide evidence for shared ancestry among geographically diverse hunter-gatherer populations (Khoesan speakers and Pygmies). The ancestry of African Americans is predominantly from Niger-Kordofanian ($\backslash$textasciitilde71\%), European ($\backslash$textasciitilde13\%), and other African ($\backslash$textasciitilde8\%) populations, although admixture levels varied considerably among individuals. This study helps tease apart the complex evolutionary history of Africans and African Americans, aiding both anthropological and genetic epidemiologic studies.},
  timestamp = {2017-05-19T07:26:32Z},
  number = {5930},
  author = {Tishkoff, Sarah A. and Reed, Floyd A. and Friedlaender, Françoise R. and Ehret, Christopher and Ranciaro, Alessia and Froment, Alain and Hirbo, Jibril B. and Awomoyi, Agnes A. and Bodo, Jean-Marie and Doumbo, Ogobara and Ibrahim, Muntaser and Juma, Abdalla T. and Kotze, Maritha J. and Lema, Godfrey and Moore, Jason H. and Mortensen, Holly and Nyambo, Thomas B. and Omar, Sabah A. and Powell, Kweli and Pretorius, Gideon S. and Smith, Michael W. and Thera, Mahamadou A. and Wambebe, Charles and Weber, James L. and Williams, Scott M.},
  urldate = {2011-03-29},
  date = {2009-05-22},
  pages = {1035 --1044}
}

@article{Metzker_2009,
  title = {Sequencing {{Technologies}} — the next {{Generation}}},
  volume = {11},
  issn = {1471-0056},
  url = {http://www.nature.com/doifinder/10.1038/nrg2626},
  doi = {10.1038/nrg2626},
  timestamp = {2017-05-19T07:26:33Z},
  number = {1},
  author = {Metzker, Michael L.},
  urldate = {2011-03-02},
  date = {2009-12},
  pages = {31--46}
}

@article{Gilbert_2010,
  title = {Evaluating {{Genome}}-{{Scale Approaches}} to {{Eukaryotic DNA Replication}}},
  volume = {11},
  issn = {1471-0056},
  url = {http://www.nature.com/doifinder/10.1038/nrg2830},
  doi = {10.1038/nrg2830},
  timestamp = {2017-05-19T07:26:33Z},
  number = {10},
  author = {Gilbert, David M.},
  urldate = {2011-03-02},
  date = {2010-09},
  pages = {673--684}
}

@article{Licatalosi_2010,
  title = {{{APPLICATIONS OF NEXT}}-{{GENERATION SEQUENCING RNA Processing}} and {{Its Regulation}}: {{Global Insights}} into {{Biological Networks}}},
  volume = {11},
  issn = {1471-0056},
  url = {http://apps.isiknowledge.com/full_record.do?product=WOS&search_mode=Refine&qid=8&SID=U2Mcc7pCchPC6M2LmjG&page=1&doc=9},
  doi = {10.1038/nrg2673},
  shorttitle = {{{APPLICATIONS OF NEXT}}-{{GENERATION SEQUENCING RNA Processing}} and {{Its Regulation}}},
  abstract = {In recent years views of eukaryotic gene expression have been transformed by the finding that enormous diversity can be generated at the RNA level. Advances in technologies for characterizing RNA populations are revealing increasingly complete descriptions of RNA regulation and complexity; for example, through alternative splicing, alternative polyadenylation and RNA editing. New biochemical strategies to map protein-RNA interactions in vivo are yielding transcriptome-wide insights into mechanisms of RNA processing. These advances, combined with bioinformatics and genetic validation, are leading to the generation of functional RNA maps that reveal the rules underlying RNA regulation and networks of biologically coherent transcripts. Together these are providing new insights into molecular cell biology and disease.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {1},
  author = {Licatalosi, DD and Darnell, RB},
  urldate = {2011-03-02},
  date = {2010-01},
  pages = {75--87}
}

@article{Park_2009,
  title = {{{ChIP}}-{{Seq}}: {{Advantages}} and {{Challenges}} of a {{Maturing Technology}}},
  volume = {10},
  issn = {1471-0056},
  url = {http://apps.isiknowledge.com/full_record.do?product=WOS&search_mode=Refine&qid=8&SID=U2Mcc7pCchPC6M2LmjG&page=1&doc=10},
  doi = {10.1038/nrg2641},
  shorttitle = {{{ChIP}}-{{Seq}}},
  abstract = {Chromatin immunoprecipitation followed by sequencing (ChIP-seq) is a technique for genome-wide profiling of DNA-binding proteins, histone modifications or nucleosomes. Owing to the tremendous progress in next-generation sequencing technology, ChIP-seq offers higher resolution, less noise and greater coverage than its array-based predecessor ChIP-chip. With the decreasing cost of sequencing, ChIP-seq has become an indispensable tool for studying gene regulation and epigenetic mechanisms. In this Review, I describe the benefits and challenges in harnessing this technique with an emphasis on issues related to experimental design and data analysis. ChIP-seq experiments generate large quantities of data, and effective computational analysis will be crucial for uncovering biological mechanisms.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {10},
  author = {Park, PJ},
  urldate = {2011-03-02},
  date = {2009-10},
  pages = {669--680}
}

@article{Snyder_2009,
  title = {Next-{{Generation Sequencing}}-the {{Promise}} and {{Perils}} of {{Charting}} the {{Great Microbial Unknown}}},
  volume = {57},
  issn = {0095-3628},
  doi = {10.1007/s00248-008-9465-9},
  timestamp = {2017-05-19T07:26:33Z},
  number = {1},
  author = {Snyder, Lori A. S and Loman, Nick and Pallen, Mark J and Penn, Charles W},
  date = {2009-01},
  pages = {1--3}
}

@article{Mardis_2008,
  title = {Next-{{Generation DNA Sequencing Methods}}},
  volume = {9},
  issn = {1527-8204},
  doi = {10.1146/annurev.genom.9.081307.164359},
  abstract = {Recent scientific discoveries that resulted from the application of next-generation DNA sequencing technologies highlight the striking impact of these massively parallel platforms on genetics. These new methods have expanded previously focused readouts from a variety of DNA preparation protocols to a genome-wide scale and have fine-coned their resolution to single base precision. The sequencing of RNA also has transitioned and now includes full-length cDNA analyses, serial analysis of gene expression (SAGE)-based methods, and noncoding RNA discovery. Next-generation sequencing has also enabled novel applications such as the sequencing of ancient DNA samples, and has substantially widened the scope of metagenomic analysis of environmentally derived samples. Taken together, an astounding potential exists for these technologies to bring enormous change in genetic and biological research anti to enhance our fundamental biological knowledge.},
  timestamp = {2017-05-19T07:26:33Z},
  author = {Mardis, Elaine R},
  date = {2008},
  pages = {387--402},
  keywords = {massively,parallel,resequencing,sequencing,sequencing-by-synthesis}
}

@article{Hawkins_2010,
  title = {Next-{{Generation Genomics}}: {{An Integrative Approach}}},
  issn = {1471-0056},
  url = {http://www.nature.com/doifinder/10.1038/nrg2795},
  doi = {10.1038/nrg2795},
  shorttitle = {Next-{{Generation Genomics}}},
  timestamp = {2017-05-19T07:26:33Z},
  author = {Hawkins, R. David and Hon, Gary C. and Ren, Bing},
  urldate = {2011-03-02},
  date = {2010-12}
}

@article{Meyerson_2010,
  title = {Advances in {{Understanding Cancer Genomes}} through {{Second}}-{{Generation Sequencing}}},
  volume = {11},
  issn = {1471-0056},
  url = {http://www.nature.com/doifinder/10.1038/nrg2841},
  doi = {10.1038/nrg2841},
  timestamp = {2017-05-19T07:26:33Z},
  number = {10},
  author = {Meyerson, Matthew and Gabriel, Stacey and Getz, Gad},
  urldate = {2011-03-02},
  date = {2010-10},
  pages = {685--696}
}

@article{Kahn_2011,
  title = {On the {{Future}} of {{Genomic Data}}},
  volume = {331},
  url = {http://www.sciencemag.org/content/331/6018/728.abstract},
  doi = {10.1126/science.1197891},
  abstract = {Many of the challenges in genomics derive from the informatics needed to store and analyze the raw sequencing data that is available from highly multiplexed sequencing technologies. Because single week-long sequencing runs today can produce as much data as did entire genome centers a few years ago, the need to process terabytes of information has become de rigueur for many labs engaged in genomic research. The availability of deep (and large) genomic data sets raises concerns over information access, data security, and subject/patient privacy that must be addressed for the field to continue its rapid advances.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {6018},
  author = {Kahn, Scott D.},
  urldate = {2011-09-19},
  date = {2011-02-11},
  pages = {728 --729}
}

@article{Leonelli_2011,
  title = {Re-{{Thinking Organisms}}: {{The Impact}} of {{Databases}} on {{Model Organism Biology}}},
  volume = {43},
  issn = {1369-8486},
  url = {http://www.sciencedirect.com/science/article/pii/S1369848611000793},
  doi = {10.1016/j.shpsc.2011.10.003},
  shorttitle = {Re-{{Thinking Organisms}}},
  abstract = {Community databases have become crucial to the collection, ordering and retrieval of data gathered on model organisms, as well as to the ways in which these data are interpreted and used across a range of research contexts. This paper analyses the impact of community databases on research practices in model organism biology by focusing on the history and current use of four community databases: FlyBase, Mouse Genome Informatics, WormBase and The Arabidopsis Information Resource. We discuss the standards used by the curators of these databases for what counts as reliable evidence, acceptable terminology, appropriate experimental set-ups and adequate materials (e.g., specimens). On the one hand, these choices are informed by the collaborative research ethos characterising most model organism communities. On the other hand, the deployment of these standards in databases reinforces this ethos and gives it concrete and precise instantiations by shaping the skills, practices, values and background knowledge required of the database users. We conclude that the increasing reliance on community databases as vehicles to circulate data is having a major impact on how researchers conduct and communicate their research, which affects how they understand the biology of model organisms and its relation to the biology of other species.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {1},
  author = {Leonelli, Sabina and Ankeny, Rachel A.},
  urldate = {2011-11-02},
  date = {2011},
  pages = {29--36},
  keywords = {Curator,data,Database,Data-intensive science,Model organism}
}

@article{Penrose_1932,
  title = {On the {{Interaction}} of {{Heredity}} and {{Environment}} in the {{Study}} of {{Human Genetics}} (with {{Special Reference}} to {{Mongolian Imbecility}})},
  volume = {25},
  issn = {0022-1333},
  url = {http://www.springerlink.com/content/mu5r13q377011705/},
  doi = {10.1007/BF02984599},
  timestamp = {2017-05-19T07:26:33Z},
  author = {Penrose, L. S.},
  urldate = {2011-11-09},
  date = {1932-04},
  pages = {407--422}
}

@article{Stevens_2011,
  title = {Coding {{Sequences}}: {{A History}} of {{Sequence Comparison Algorithms}} as a {{Scientific Instrument}}},
  volume = {19},
  issn = {1063-6145},
  url = {http://dx.doi.org/10.1162/POSC_a_00042},
  doi = {i: 10.1162/POSC_a_00042</p>},
  shorttitle = {Coding {{Sequences}}},
  abstract = {Sequence comparison algorithms are sophisticated pieces of software that compare and match identical or similar regions of DNA, RNA, or protein sequence. This paper examines the origins and development of these algorithms from the 1960s to the 1990s. By treating this software as a kind of scientific instrument used to examine sets of biological objects, the paper shows how algorithms have been used as different sorts of tools and appropriated for different sorts of uses according to the disciplinary context in which they were deployed. These particular uses have made sequences themselves into different kinds of objects.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {3},
  author = {Stevens, Hallam},
  date = {2011},
  pages = {263--299}
}

@article{Galperin_2010,
  title = {The 2011 {{Nucleic Acids Research Database Issue}} and the {{Online Molecular Biology Database Collection}}},
  volume = {39},
  issn = {0305-1048, 1362-4962},
  url = {http://nar.oxfordjournals.org/content/39/suppl_1/D1.short},
  doi = {10.1093/nar/gkq1243},
  timestamp = {2017-05-19T07:26:33Z},
  author = {Galperin, M. Y. and Cochrane, G. R.},
  urldate = {2011-11-25},
  date = {2010-12-22},
  pages = {D1--D6}
}

@article{MacLean_2012,
  title = {Big {{Data}} in {{Small Places}}},
  volume = {30},
  issn = {1087-0156, 1546-1696},
  url = {http://www.nature.com/doifinder/10.1038/nbt.2079},
  doi = {10.1038/nbt.2079},
  timestamp = {2017-05-19T07:26:33Z},
  number = {1},
  author = {MacLean, Daniel and Kamoun, Sophien},
  urldate = {2012-01-24},
  date = {2012-01-09},
  pages = {33--34}
}

@article{Ernst_2011,
  title = {Mapping and {{Analysis}} of {{Chromatin State Dynamics}} in {{Nine Human Cell Types}}},
  volume = {473},
  url = {http://www.nature.com/nature/journal/vaop/ncurrent/full/nature09906.html},
  timestamp = {2017-05-19T07:26:33Z},
  number = {7345},
  author = {Ernst, J. and Kheradpour, P. and Mikkelsen, T. S. and Shoresh, N. and Ward, L. D. and Epstein, C. B. and Zhang, X. and Wang, L. and Issner, R. and Coyne, M.},
  urldate = {2012-12-19},
  date = {2011},
  pages = {43--49}
}

@article{Iverson_2012,
  title = {Untangling {{Genomes}} from {{Metagenomes}}: {{Revealing}} an {{Uncultured Class}} of {{Marine Euryarchaeota}}},
  volume = {335},
  url = {http://www.sciencemag.org/content/335/6068/587.abstract},
  doi = {10.1126/science.1212665},
  shorttitle = {Untangling {{Genomes}} from {{Metagenomes}}},
  abstract = {Ecosystems are shaped by complex communities of mostly unculturable microbes. Metagenomes provide a fragmented view of such communities, but the ecosystem functions of major groups of organisms remain mysterious. To better characterize members of these communities, we developed methods to reconstruct genomes directly from mate-paired short-read metagenomes. We closed a genome representing the as-yet uncultured marine group II Euryarchaeota, assembled de novo from 1.7\% of a metagenome sequenced from surface seawater. The genome describes a motile, photo-heterotrophic cell focused on degradation of protein and lipids and clarifies the origin of proteorhodopsin. It also demonstrates that high-coverage mate-paired sequence can overcome assembly difficulties caused by interstrain variation in complex microbial communities, enabling inference of ecosystem functions for uncultured members.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {6068},
  author = {Iverson, Vaughn and Morris, Robert M. and Frazar, Christian D. and Berthiaume, Chris T. and Morales, Rhonda L. and Armbrust, E. Virginia},
  urldate = {2012-02-07},
  date = {2012-02-03},
  pages = {587 --590}
}

@article{Patterson_2010,
  title = {Genetic {{Structure}} of a {{Unique Admixed Population}}: {{Implications}} for {{Medical Research}}},
  volume = {19},
  issn = {0964-6906, 1460-2083},
  url = {http://hmg.oxfordjournals.org/content/19/3/411},
  doi = {10.1093/hmg/ddp505},
  shorttitle = {Genetic {{Structure}} of a {{Unique Admixed Population}}},
  abstract = {Statement: In naming population groups, we think a chief aim is to use terms that the group members use themselves, or find familiar and comfortable. The terms used in this manuscript to describe populations are as historically correct as possible and are chosen so as not to offend any population group. Two of the authors (DCP and REvdR) belong to the Coloured population, with one of the authors (REvdR) having contributed extensively to current literature on the history of the Coloured people of South Africa and served as Vice-President of the South African Institute of Race Relations. According to the 2001 South African census (http://www.statssa.gov.za/census01/HTML/CInBrief/CIB2001.pdf), ‘Statistics South Africa continues to classify people by population group, in order to monitor progress in moving away from the apartheid-based discrimination of the past. However, membership of a population group is now based on self-perception and self-classification, not on a legal definition. Five options were provided on the questionnaire, Black African, Coloured, Indian or Asian, White and Other. Responses in the category “Other” were very few and were therefore imputed’. We have elected to use the term Bushmen rather than San to refer to the hunter-gatherer people of Southern Africa. Although they have no collective name for themselves, this decision was based on the term Bushmen (or Bossiesman) being the more familiar to the communities themselves, while the term San is the more accepted academic classification. Understanding human genetic structure has fundamental implications for understanding the evolution and impact of human diseases. In this study, we describe the complex genetic substructure of a unique and recently admixed population arising ∼350 years ago as a direct result of European settlement in South Africa. Analysis was performed using over 900 000 genome-wide single nucleotide polymorphisms in 20 unrelated ancestry-informative marker selected Coloured individuals and made comparisons with historically predicted founder populations. We show that there is substantial genetic contribution from at least four distinct population groups: Europeans, South Asians, Indonesians and a population genetically close to the isiXhosa sub-Saharan Bantu. This is in good accord with the historical record. We briefly examine the implications of determining the genetic diversity of this population, not only for furthering understanding of human evolution out of Africa, but also for genome-wide association studies using admixture mapping. In conclusion, we define the genetic structure of a uniquely admixed population that holds great potential to advance genetic-based medical research.},
  timestamp = {2017-05-19T07:26:33Z},
  number = {3},
  author = {Patterson, Nick and Petersen, Desiree C. and van der Ross, Richard E. and Sudoyo, Herawati and Glashoff, Richard H. and Marzuki, Sangkot and Reich, David and Hayes, Vanessa M.},
  urldate = {2012-08-13},
  date = {2010-01-02},
  pages = {411--419},
  options = {useprefix=true}
}

@article{Day_2007,
  title = {Unsupervised {{Segmentation}} of {{Continuous Genomic Data}}},
  volume = {23},
  issn = {1367-4803, 1460-2059},
  url = {http://bioinformatics.oxfordjournals.org/content/23/11/1424},
  doi = {10.1093/bioinformatics/btm096},
  abstract = {Summary: The advent of high-density, high-volume genomic data has created the need for tools to summarize large datasets at multiple scales. HMMSeg is a command-line utility for the scale-specific segmentation of continuous genomic data using hidden Markov models (HMMs). Scale specificity is achieved by an optional wavelet-based smoothing operation. HMMSeg is capable of handling multiple datasets simultaneously, rendering it ideal for integrative analysis of expression, phylogenetic and functional genomic data. Availability: http://noble.gs.washington.edu/proj/hmmseg Contact: rthurman@u.washington.edu},
  timestamp = {2017-05-19T07:26:34Z},
  number = {11},
  author = {Day, Nathan and Hemmaplardh, Andrew and Thurman, Robert E. and Stamatoyannopoulos, John A. and Noble, William S.},
  urldate = {2012-09-12},
  date = {2007},
  pages = {1424--1426}
}

@article{Rose_2009,
  title = {Normality and {{Pathology}} in a {{Biomedical Age}}},
  volume = {57},
  issn = {0038-0261},
  url = {://000275532000004},
  timestamp = {2017-05-19T07:26:34Z},
  author = {Rose, N.},
  date = {2009},
  pages = {66--83},
  keywords = {BURDEN,DISEASE,DISORDERS,EUROPE,GENOME-WIDE ASSOCIATION,SEQUENCE,SIZE}
}

@online{WellcomeTrustSangerInstitute_2011,
  title = {{{UK10K}} - {{UK10K Goals}}},
  url = {http://www.uk10k.org/goals.html},
  timestamp = {2017-05-19T07:26:34Z},
  author = {{Wellcome Trust Sanger Institute}},
  urldate = {2011-04-04},
  date = {2011}
}

@article{Durbin_2010,
  title = {A {{Map}} of {{Human Genome Variation}} from {{Population}}-{{Scale Sequencing}}},
  volume = {467},
  issn = {0028-0836},
  timestamp = {2017-05-19T07:26:34Z},
  number = {7319},
  author = {Durbin, R. M and Altshuler, D. L and Abecasis, G. R and Bentley, D. R and Chakravarti, A. and Clark, A. G and Collins, F. S and De La Vega, F. M and Donnelly, P. and Egholm, M. and {others}},
  date = {2010},
  pages = {1061--1073}
}

@article{Moore_2011,
  title = {Global {{Analysis}} of {{Disease}}-{{Related DNA Sequence Variation}} in 10 {{Healthy Individuals}}: {{Implications}} for {{Whole Genome}}-{{Based Clinical Diagnostics}}},
  volume = {13},
  issn = {1098-3600},
  url = {http://journals.lww.com/geneticsinmedicine/Fulltext/2011/03000/Global_analysis_of_disease_related_DNA_sequence.12.aspx?WT.mc_id=HPxADx20100319xMP},
  doi = {10.1097/GIM.0b013e31820ed321},
  shorttitle = {Global {{Analysis}} of {{Disease}}-{{Related DNA Sequence Variation}} in 10 {{Healthy Individuals}}},
  timestamp = {2017-05-19T07:26:34Z},
  number = {3},
  author = {Moore, Barry and Hu, Hao and Singleton, Marc and Reese, Martin G. and De La Vega, Francisco M. and Yandell, Mark},
  urldate = {2011-04-05},
  date = {2011-03},
  pages = {210--217}
}

@article{Lam_2012,
  title = {Performance {{Comparison}} of {{Whole}}-{{Genome Sequencing Platforms}}},
  volume = {30},
  issn = {1087-0156},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nbt/journal/v30/n1/full/nbt.2065.html},
  doi = {10.1038/nbt.2065},
  abstract = {Whole-genome sequencing is becoming commonplace, but the accuracy and completeness of variant calling by the most widely used platforms from Illumina and Complete Genomics have not been reported. Here we sequenced the genome of an individual with both technologies to a high average coverage of $\backslash$textasciitilde76×, and compared their performance with respect to sequence coverage and calling of single-nucleotide variants (SNVs), insertions and deletions (indels). Although 88.1\% of the $\backslash$textasciitilde3.7 million unique SNVs were concordant between platforms, there were tens of thousands of platform-specific calls located in genes and other genomic regions. In contrast, 26.5\% of indels were concordant between platforms. Target enrichment validated 92.7\% of the concordant SNVs, whereas validation by genotyping array revealed a sensitivity of 99.3\%. The validation experiments also suggested that \$$>$\$60\% of the platform-specific variants were indeed present in the genome. Our results have important implications for understanding the accuracy and completeness of the genome sequencing platforms.},
  timestamp = {2017-05-19T07:26:34Z},
  number = {1},
  author = {Lam, Hugo Y K and Clark, Michael J and Chen, Rui and Chen, Rong and Natsoulis, Georges and O'Huallachain, Maeve and Dewey, Frederick E and Habegger, Lukas and Ashley, Euan A and Gerstein, Mark B and Butte, Atul J and Ji, Hanlee P and Snyder, Michael},
  urldate = {2012-06-08},
  date = {2012},
  pages = {78--82}
}

@article{Cock_2010,
  title = {The {{Sanger FASTQ File Format}} for {{Sequences}} with {{Quality Scores}}, and the {{Solexa}}/{{Illumina FASTQ Variants}}},
  volume = {38},
  issn = {0305-1048},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2847217/},
  doi = {10.1093/nar/gkp1137},
  abstract = {FASTQ has emerged as a common file format for sharing sequencing read data combining both the sequence and an associated per base quality score, despite lacking any formal definition to date, and existing in at least three incompatible variants. This article defines the FASTQ format, covering the original Sanger standard, the Solexa/Illumina variants and conversion between them, based on publicly available information such as the MAQ documentation and conventions recently agreed by the Open Bioinformatics Foundation projects Biopython, BioPerl, BioRuby, BioJava and EMBOSS. Being an open access publication, it is hoped that this description, with the example files provided as Supplementary Data, will serve in future as a reference for this important file format.},
  timestamp = {2017-05-19T07:26:34Z},
  number = {6},
  author = {Cock, Peter J. A. and Fields, Christopher J. and Goto, Naohisa and Heuer, Michael L. and Rice, Peter M.},
  urldate = {2013-02-14},
  date = {2010-04},
  pages = {1767--1771},
  pmcid = {PMC2847217}
}

@article{Barrett_2009,
  title = {{{NCBI GEO}}: {{Archive}} for {{High}}-{{Throughput Functional Genomic Data}}},
  volume = {37},
  issn = {0305-1048, 1362-4962},
  url = {http://nar.oxfordjournals.org/content/37/suppl_1/D885.full},
  doi = {10.1093/nar/gkn764},
  shorttitle = {{{NCBI GEO}}},
  timestamp = {2017-05-19T07:26:34Z},
  issue = {Database},
  author = {Barrett, T. and Troup, D. B. and Wilhite, S. E. and Ledoux, P. and Rudnev, D. and Evangelista, C. and Kim, I. F. and Soboleva, A. and Tomashevsky, M. and Marshall, K. A. and Phillippy, K. H. and Sherman, P. M. and Muertter, R. N. and Edgar, R.},
  urldate = {2012-07-06},
  date = {2009-01-01},
  pages = {D885--D890}
}

@article{Reich_2010,
  title = {Genetic {{History}} of an {{Archaic Hominin Group}} from {{Denisova Cave}} in {{Siberia}}},
  volume = {468},
  issn = {0028-0836},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nature/journal/v468/n7327/full/nature09710.html#/supplementary-information},
  doi = {10.1038/nature09710},
  abstract = {Using DNA extracted from a finger bone found in Denisova Cave in southern Siberia, we have sequenced the genome of an archaic hominin to about 1.9-fold coverage. This individual is from a group that shares a common origin with Neanderthals. This population was not involved in the putative gene flow from Neanderthals into Eurasians; however, the data suggest that it contributed 4–6\% of its genetic material to the genomes of present-day Melanesians. We designate this hominin population ‘Denisovans’ and suggest that it may have been widespread in Asia during the Late Pleistocene epoch. A tooth found in Denisova Cave carries a mitochondrial genome highly similar to that of the finger bone. This tooth shares no derived morphological features with Neanderthals or modern humans, further indicating that Denisovans have an evolutionary history distinct from Neanderthals and modern humans.},
  timestamp = {2017-05-19T07:26:34Z},
  number = {7327},
  author = {Reich, David and Green, Richard E. and Kircher, Martin and Krause, Johannes and Patterson, Nick and Durand, Eric Y. and Viola, Bence and Briggs, Adrian W. and Stenzel, Udo and Johnson, Philip L. F. and Maricic, Tomislav and Good, Jeffrey M. and Marques-Bonet, Tomas and Alkan, Can and Fu, Qiaomei and Mallick, Swapan and Li, Heng and Meyer, Matthias and Eichler, Evan E. and Stoneking, Mark and Richards, Michael and Talamo, Sahra and Shunkov, Michael V. and Derevianko, Anatoli P. and Hublin, Jean-Jacques and Kelso, Janet and Slatkin, Montgomery and Pääbo, Svante},
  urldate = {2012-08-13},
  date = {2010-12-23},
  pages = {1053--1060},
  keywords = {Evolution,Genetics and genomics,Palaeontology}
}

@article{Shi_2010,
  title = {The {{MicroArray Quality Control}} ({{MAQC}})-{{II Study}} of {{Common Practices}} for the {{Development}} and {{Validation}} of {{Microarray}}-{{Based Predictive Models}}},
  volume = {28},
  issn = {1087-0156, 1546-1696},
  url = {http://ukpmc.ac.uk/abstract/MED/20676074},
  doi = {10.1038/nbt.1665},
  timestamp = {2017-05-19T07:26:35Z},
  number = {8},
  author = {Shi, Leming and Campbell, Gregory and Jones, Wendell D and Campagne, Fabien and Wen, Zhining and Walker, Stephen J and Su, Zhenqiang and Chu, Tzu-Ming and Goodsaid, Federico M and Pusztai, Lajos and Shaughnessy, John D and Oberthuer, André and Thomas, Russell S and Paules, Richard S and Fielden, Mark and Barlogie, Bart and Chen, Weijie and Du, Pan and Fischer, Matthias and Furlanello, Cesare and Gallas, Brandon D and Ge, Xijin and Megherbi, Dalila B and Symmans, W Fraser and Wang, May D and Zhang, John and Bitter, Hans and Brors, Benedikt and Bushel, Pierre R and Bylesjo, Max and Chen, Minjun and Cheng, Jie and Cheng, Jing and Chou, Jeff and Davison, Timothy S and Delorenzi, Mauro and Deng, Youping and Devanarayan, Viswanath and Dix, David J and Dopazo, Joaquin and Dorff, Kevin C and Elloumi, Fathi and Fan, Jianqing and Fan, Shicai and Fan, Xiaohui and Fang, Hong and Gonzaludo, Nina and Hess, Kenneth R and Hong, Huixiao and Huan, Jun and Irizarry, Rafael A and Judson, Richard and Juraeva, Dilafruz and Lababidi, Samir and Lambert, Christophe G and Li, Li and Li, Yanen and Li, Zhen and Lin, Simon M and Liu, Guozhen and Lobenhofer, Edward K and Luo, Jun and Luo, Wen and McCall, Matthew N and Nikolsky, Yuri and Pennello, Gene A and Perkins, Roger G and Philip, Reena and Popovici, Vlad and Price, Nathan D and Qian, Feng and Scherer, Andreas and Shi, Tieliu and Shi, Weiwei and Sung, Jaeyun and Thierry-Mieg, Danielle and Thierry-Mieg, Jean and Thodima, Venkata and Trygg, Johan and Vishnuvajjala, Lakshmi and Wang, Sue Jane and Wu, Jianping and Wu, Yichao and Xie, Qian and Yousef, Waleed A and Zhang, Liang and Zhang, Xuegong and Zhong, Sheng and Zhou, Yiming and Zhu, Sheng and Arasappan, Dhivya and Bao, Wenjun and Lucas, Anne Bergstrom and Berthold, Frank and Brennan, Richard J and Buness, Andreas and Catalano, Jennifer G and Chang, Chang and Chen, Rong and Cheng, Yiyu and Cui, Jian and Czika, Wendy and Demichelis, Francesca and Deng, Xutao and Dosymbekov, Damir and Eils, Roland and Feng, Yang and Fostel, Jennifer and Fulmer-Smentek, Stephanie and Fuscoe, James C and Gatto, Laurent and Ge, Weigong and Goldstein, Darlene R and Guo, Li and Halbert, Donald N and Han, Jing and Harris, Stephen C and Hatzis, Christos and Herman, Damir and Huang, Jianping and Jensen, Roderick V and Jiang, Rui and Johnson, Charles D and Jurman, Giuseppe and Kahlert, Yvonne and Khuder, Sadik A and Kohl, Matthias and Li, Jianying and Li, Li and Li, Menglong and Li, Quan-Zhen and Li, Shao and Li, Zhiguang and Liu, Jie and Liu, Ying and Liu, Zhichao and Meng, Lu and Madera, Manuel and Martinez-Murillo, Francisco and Medina, Ignacio and Meehan, Joseph and Miclaus, Kelci and Moffitt, Richard A and Montaner, David and Mukherjee, Piali and Mulligan, George J and Neville, Padraic and Nikolskaya, Tatiana and Ning, Baitang and Page, Grier P and Parker, Joel and Parry, R Mitchell and Peng, Xuejun and Peterson, Ron L and Phan, John H and Quanz, Brian and Ren, Yi and Riccadonna, Samantha and Roter, Alan H and Samuelson, Frank W and Schumacher, Martin M and Shambaugh, Joseph D and Shi, Qiang and Shippy, Richard and Si, Shengzhu and Smalter, Aaron and Sotiriou, Christos and Soukup, Mat and Staedtler, Frank and Steiner, Guido and Stokes, Todd H and Sun, Qinglan and Tan, Pei-Yi and Tang, Rong and Tezak, Zivana and Thorn, Brett and Tsyganova, Marina and Turpaz, Yaron and Vega, Silvia C and Visintainer, Roberto and von Frese, Juergen and Wang, Charles and Wang, Eric and Wang, Junwei and Wang, Wei and Westermann, Frank and Willey, James C and Woods, Matthew and Wu, Shujian and Xiao, Nianqing and Xu, Joshua and Xu, Lei and Yang, Lun and Zeng, Xiao and Zhang, Jialu and Zhang, Li and Zhang, Min and Zhao, Chen and Puri, Raj K and Scherf, Uwe and Tong, Weida and Wolfinger, Russell D},
  urldate = {2012-08-13},
  date = {2010-07-30},
  pages = {827--838},
  options = {useprefix=true}
}

@article{Konopka_2009,
  title = {What {{Is Microbial Community Ecology}}?},
  volume = {3},
  issn = {1751-7370},
  doi = {10.1038/ismej.2009.88},
  abstract = {The activities of complex communities of microbes affect biogeochemical transformations in natural, managed and engineered ecosystems. Meaningfully defining what constitutes a community of interacting microbial populations is not trivial, but is important for rigorous progress in the field. Important elements of research in microbial community ecology include the analysis of functional pathways for nutrient resource and energy flows, mechanistic understanding of interactions between microbial populations and their environment, and the emergent properties of the complex community. Some emergent properties mirror those analyzed by community ecologists who study plants and animals: biological diversity, functional redundancy and system stability. However, because microbes possess mechanisms for the horizontal transfer of genetic information, the metagenome may also be considered as a community property.},
  timestamp = {2017-05-19T07:26:35Z},
  number = {11},
  author = {Konopka, Allan},
  date = {2009-11},
  pages = {1223--1230},
  keywords = {Ecology,Ecosystem,Environmental Microbiology,Genetics,Microbial,Plants}
}

@article{Kapranov_2005,
  title = {Examples of the {{Complex Architecture}} of the {{Human Transcriptome Revealed}} by {{RACE}} and {{High}}-{{Density Tiling Arrays}}},
  volume = {15},
  url = {http://genome.cshlp.org/content/15/7/987.short},
  timestamp = {2017-05-19T07:26:35Z},
  number = {7},
  author = {Kapranov, P. and Drenkow, J. and Cheng, J. and Long, J. and Helt, G. and Dike, S. and Gingeras, T. R.},
  urldate = {2012-08-20},
  date = {2005},
  pages = {987--997}
}

@article{Rozowsky_2007,
  title = {The {{DART Classification}} of {{Unannotated Transcription}} within the {{ENCODE Regions}}: {{Associating Transcription}} with {{Known}} and {{Novel Loci}}},
  volume = {17},
  issn = {1088-9051, 1549-5469},
  url = {http://genome.cshlp.org/content/17/6/732},
  doi = {10.1101/gr.5696007},
  shorttitle = {The {{DART Classification}} of {{Unannotated Transcription}} within the {{ENCODE Regions}}},
  abstract = {An international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms},
  timestamp = {2017-05-19T07:26:35Z},
  number = {6},
  author = {Rozowsky, Joel S. and Newburger, Daniel and Sayward, Fred and Wu, Jiaqian and Jordan, Greg and Korbel, Jan O. and Nagalakshmi, Ugrappa and Yang, Jin and Zheng, Deyou and Guigó, Roderic and Gingeras, Thomas R. and Weissman, Sherman and Miller, Perry and Snyder, Michael and Gerstein, Mark B.},
  urldate = {2012-08-20},
  date = {2007-01-06},
  pages = {732--745}
}

@article{Burton_2007,
  title = {Genome-{{Wide Association Study}} of 14,000 {{Cases}} of {{Seven Common Diseases}} and 3,000 {{Shared Controls}}},
  volume = {447},
  issn = {0028-0836},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nature/journal/v447/n7145/full/nature05911.html},
  doi = {10.1038/nature05911},
  abstract = {There is increasing evidence that genome-wide association (GWA) studies represent a powerful approach to the identification of genes involved in common human diseases. We describe a joint GWA study (using the Affymetrix GeneChip 500K Mapping Array Set) undertaken in the British population, which has examined 2,000 individuals for each of 7 major diseases and a shared set of 3,000 controls. Case-control comparisons identified 24 independent association signals at P \$$<$\$ 5 10-7: 1 in bipolar disorder, 1 in coronary artery disease, 9 in Crohn's disease, 3 in rheumatoid arthritis, 7 in type 1 diabetes and 3 in type 2 diabetes. On the basis of prior findings and replication studies thus-far completed, almost all of these signals reflect genuine susceptibility effects. We observed association at many previously identified loci, and found compelling evidence that some loci confer risk for more than one of the diseases studied. Across all diseases, we identified a large number of further signals (including 58 loci with single-point P values between 10-5 and 5 10-7) likely to yield additional susceptibility loci. The importance of appropriately large samples was confirmed by the modest effect sizes observed at most loci identified. This study thus represents a thorough validation of the GWA approach. It has also demonstrated that careful use of a shared control group represents a safe and effective approach to GWA analyses of multiple disease phenotypes; has generated a genome-wide genotype database for future studies of common diseases in the British population; and shown that, provided individuals with non-European ancestry are excluded, the extent of population stratification in the British population is generally modest. Our findings offer new avenues for exploring the pathophysiology of these important disorders. We anticipate that our data, results and software, which will be widely available to other investigators, will provide a powerful resource for human genetics research.},
  timestamp = {2017-05-19T07:26:35Z},
  number = {7145},
  author = {Burton, Paul R. and Clayton, David G. and Cardon, Lon R. and Craddock, Nick and Deloukas, Panos and Duncanson, Audrey and Kwiatkowski, Dominic P. and McCarthy, Mark I. and Ouwehand, Willem H. and Samani, Nilesh J. and Todd, John A. and Donnelly, Peter and Barrett, Jeffrey C. and Burton, Paul R. and Davison, Dan and Donnelly, Peter and Easton, Doug and Evans, David and Leung, Hin-Tak and Marchini, Jonathan L. and Morris, Andrew P. and Spencer, Chris C. A. and Tobin, Martin D. and Cardon, Lon R. and Clayton, David G. and Attwood, Antony P. and Boorman, James P. and Cant, Barbara and Everson, Ursula and Hussey, Judith M. and Jolley, Jennifer D. and Knight, Alexandra S. and Koch, Kerstin and Meech, Elizabeth and Nutland, Sarah and Prowse, Christopher V. and Stevens, Helen E. and Taylor, Niall C. and Walters, Graham R. and Walker, Neil M. and Watkins, Nicholas A. and Winzer, Thilo and Todd, John A. and Ouwehand, Willem H. and Jones, Richard W. and McArdle, Wendy L. and Ring, Susan M. and Strachan, David P. and Pembrey, Marcus and Breen, Gerome and Clair, David St and Caesar, Sian and Gordon-Smith, Katherine and Jones, Lisa and Fraser, Christine and Green, Elaine K. and Grozeva, Detelina and Hamshere, Marian L. and Holmans, Peter A. and Jones, Ian R. and Kirov, George and Moskvina, Valentina and Nikolov, Ivan and O'Donovan, Michael C. and Owen, Michael J. and Craddock, Nick and Collier, David A. and Elkin, Amanda and Farmer, Anne and Williamson, Richard and McGuffin, Peter and Young, Allan H. and Ferrier, I. Nicol and Ball, Stephen G. and Balmforth, Anthony J. and Barrett, Jennifer H. and Bishop, D. Timothy and Iles, Mark M. and Maqbool, Azhar and Yuldasheva, Nadira and Hall, Alistair S. and Braund, Peter S. and Burton, Paul R. and Dixon, Richard J. and Mangino, Massimo and Stevens, Suzanne and Tobin, Martin D. and Thompson, John R. and Samani, Nilesh J. and Bredin, Francesca and Tremelling, Mark and Parkes, Miles and Drummond, Hazel and Lees, Charles W. and Nimmo, Elaine R. and Satsangi, Jack and Fisher, Sheila A. and Forbes, Alastair and Lewis, Cathryn M. and Onnie, Clive M. and Prescott, Natalie J. and Sanderson, Jeremy and Mathew, Christopher G. and Barbour, Jamie and Mohiuddin, M. Khalid and Todhunter, Catherine E. and Mansfield, John C. and Ahmad, Tariq and Cummings, Fraser R. and Jewell, Derek P. and Webster, John and Brown, Morris J. and Clayton, David G. and Lathrop, G. Mark and Connell, John and Dominiczak, Anna and Samani, Nilesh J. and Marcano, Carolina A. Braga and Burke, Beverley and Dobson, Richard and Gungadoo, Johannie and Lee, Kate L. and Munroe, Patricia B. and Newhouse, Stephen J. and Onipinla, Abiodun and Wallace, Chris and Xue, Mingzhan and Caulfield, Mark and Farrall, Martin and Barton, Anne and (braggs), The Biologics in RA Genetics and {Genomics} and Bruce, Ian N. and Donovan, Hannah and Eyre, Steve and Gilbert, Paul D. and Hider, Samantha L. and Hinks, Anne M. and John, Sally L. and Potter, Catherine and Silman, Alan J. and Symmons, Deborah P. M. and Thomson, Wendy and Worthington, Jane and Clayton, David G. and Dunger, David B. and Nutland, Sarah and Stevens, Helen E. and Walker, Neil M. and Widmer, Barry and Todd, John A. and Frayling, Timothy M. and Freathy, Rachel M. and Lango, Hana and Perry, John R. B. and Shields, Beverley M. and Weedon, Michael N. and Hattersley, Andrew T. and Hitman, Graham A. and Walker, Mark and Elliott, Kate S. and Groves, Christopher J. and Lindgren, Cecilia M. and Rayner, Nigel W. and Timpson, Nicholas J. and Zeggini, Eleftheria and McCarthy, Mark I. and Newport, Melanie and Sirugo, Giorgio and Lyons, Emily and Vannberg, Fredrik and Hill, Adrian V. S. and Bradbury, Linda A. and Farrar, Claire and Pointon, Jennifer J. and Wordsworth, Paul and Brown, Matthew A. and Franklyn, Jayne A. and Heward, Joanne M. and Simmonds, Matthew J. and Gough, Stephen C. L. and Seal, Sheila and (uk), Breast Cancer Susceptibility Collaboration and Stratton, Michael R. and Rahman, Nazneen and Ban, Maria and Goris, An and Sawcer, Stephen J. and Compston, Alastair and Conway, David and Jallow, Muminatou and Newport, Melanie and Sirugo, Giorgio and Rockett, Kirk A. and Kwiatkowski, Dominic P. and Bumpstead, Suzannah J. and Chaney, Amy and Downes, Kate and Ghori, Mohammed J. R. and Gwilliam, Rhian and Hunt, Sarah E. and Inouye, Michael and Keniry, Andrew and King, Emma and McGinnis, Ralph and Potter, Simon and Ravindrarajah, Rathi and Whittaker, Pamela and Widden, Claire and Withers, David and Deloukas, Panos and Leung, Hin-Tak and Nutland, Sarah and Stevens, Helen E. and Walker, Neil M. and Todd, John A. and Easton, Doug and Clayton, David G. and Burton, Paul R. and Tobin, Martin D. and Barrett, Jeffrey C. and Evans, David and Morris, Andrew P. and Cardon, Lon R. and Cardin, Niall J. and Davison, Dan and Ferreira, Teresa and Pereira-Gale, Joanne and Hallgrimsdóttir, Ingileif B. and Howie, Bryan N. and Marchini, Jonathan L. and Spencer, Chris C. A. and Su, Zhan and Teo, Yik Ying and Vukcevic, Damjan and Donnelly, Peter and Bentley, David and Brown, Matthew A. and Cardon, Lon R. and Caulfield, Mark and Clayton, David G. and Compston, Alistair and Craddock, Nick and Deloukas, Panos and Donnelly, Peter and Farrall, Martin and Gough, Stephen C. L. and Hall, Alistair S. and Hattersley, Andrew T. and Hill, Adrian V. S. and Kwiatkowski, Dominic P. and Mathew, Christopher G. and McCarthy, Mark I. and Ouwehand, Willem H. and Parkes, Miles and Pembrey, Marcus and Rahman, Nazneen and Samani, Nilesh J. and Stratton, Michael R. and Todd, John A. and Worthington, Jane},
  urldate = {2012-08-29},
  date = {2007-07-06},
  pages = {661--678},
  keywords = {astronomy,astrophysics,biochemistry,bioinformatics,Biology,Biotechnology,Cancer,cell cycle,cell signalling.,climate change,development,developmental biology,DNA,drug discovery,earth science,Ecology,Environmental science,Evolution,evolutionary biology,functional genomics,geophysics,immunology,interdisciplinary science,Life,marine biology,materials science,Medical research,Medicine,metabolomics,molecular interactions,nanotechnology,Nature,neurobiology,neuroscience,palaeobiology,pharmacology,Physics,Proteomics,quantum physics,RNA,Science,science news,science policy,Signal Transduction,structural biology,Systems Biology,transcriptomics}
}

@article{Cantor_2010,
  title = {Prioritizing {{GWAS Results}}: {{A Review}} of {{Statistical Methods}} and {{Recommendations}} for {{Their Application}}},
  volume = {86},
  issn = {0002-9297},
  url = {http://www.sciencedirect.com/science/article/pii/S0002929709005321},
  doi = {10.1016/j.ajhg.2009.11.017},
  shorttitle = {Prioritizing {{GWAS Results}}},
  abstract = {Genome-wide association studies (GWAS) have rapidly become a standard method for disease gene discovery. A substantial number of recent GWAS indicate that for most disorders, only a few common variants are implicated and the associated SNPs explain only a small fraction of the genetic risk. This review is written from the viewpoint that findings from the GWAS provide preliminary genetic information that is available for additional analysis by statistical procedures that accumulate evidence, and that these secondary analyses are very likely to provide valuable information that will help prioritize the strongest constellations of results. We review and discuss three analytic methods to combine preliminary GWAS statistics to identify genes, alleles, and pathways for deeper investigations. Meta-analysis seeks to pool information from multiple GWAS to increase the chances of finding true positives among the false positives and provides a way to combine associations across GWAS, even when the original data are unavailable. Testing for epistasis within a single GWAS study can identify the stronger results that are revealed when genes interact. Pathway analysis of GWAS results is used to prioritize genes and pathways within a biological context. Following a GWAS, association results can be assigned to pathways and tested in aggregate with computational tools and pathway databases. Reviews of published methods with recommendations for their application are provided within the framework for each approach.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {1},
  author = {Cantor, Rita M. and Lange, Kenneth and Sinsheimer, Janet S.},
  urldate = {2012-08-29},
  date = {2010-01-08},
  pages = {6--22}
}

@article{Wu_2009,
  title = {Genome-{{Wide Association Analysis}} by {{Lasso Penalized Logistic Regression}}},
  volume = {25},
  url = {http://bioinformatics.oxfordjournals.org/content/25/6/714.short},
  timestamp = {2017-05-19T07:26:36Z},
  number = {6},
  author = {Wu, T. T. and Chen, Y. F. and Hastie, T. and Sobel, E. and Lange, K.},
  urldate = {2012-08-30},
  date = {2009},
  pages = {714--721}
}

@article{Keating_2012,
  title = {Too {{Many Numbers}}: {{Microarrays}} in {{Clinical Cancer Research}}},
  volume = {43},
  issn = {1369-8486},
  url = {http://www.sciencedirect.com/science/article/pii/S136984861100080X},
  doi = {10.1016/j.shpsc.2011.10.004},
  shorttitle = {Too {{Many Numbers}}},
  timestamp = {2017-05-19T07:26:36Z},
  number = {1},
  author = {Keating, Peter and Cambrosio, Alberto},
  urldate = {2012-09-03},
  date = {2012-03},
  pages = {37--51}
}

@article{Nekrutenko_2012,
  title = {Next-{{Generation Sequencing Data Interpretation}}: {{Enhancing Reproducibility}} and {{Accessibility}}},
  volume = {13},
  issn = {1471-0056},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nrg/journal/v13/n9/abs/nrg3305.html},
  doi = {10.1038/nrg3305},
  shorttitle = {Next-{{Generation Sequencing Data Interpretation}}},
  abstract = {Areas of life sciences research that were previously distant from each other in ideology, analysis practices and toolkits, such as microbial ecology and personalized medicine, have all embraced techniques that rely on next-generation sequencing instruments. Yet the capacity to generate the data greatly outpaces our ability to analyse it. Existing sequencing technologies are more mature and accessible than the methodologies that are available for individual researchers to move, store, analyse and present data in a fashion that is transparent and reproducible. Here we discuss currently pressing issues with analysis, interpretation, reproducibility and accessibility of these data, and we present promising solutions and venture into potential future developments.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {9},
  author = {Nekrutenko, Anton and Taylor, James},
  urldate = {2012-09-04},
  date = {2012},
  pages = {667--672}
}

@article{Parry_2010,
  title = {K-{{Nearest Neighbor Models}} for {{Microarray Gene Expression Analysis}} and {{Clinical Outcome Prediction}}},
  volume = {10},
  url = {http://www.nature.com/tpj/journal/v10/n4/abs/tpj201056a.html},
  timestamp = {2017-05-19T07:26:36Z},
  number = {4},
  author = {Parry, R. M. and Jones, W. and Stokes, T. H. and Phan, J. H. and Moffitt, R. A. and Fang, H. and Shi, L. and Oberthuer, A. and Fischer, M. and Tong, W. and {others}},
  urldate = {2012-09-11},
  date = {2010},
  pages = {292--309}
}

@article{Consortium_2012,
  title = {An {{Integrated Encyclopedia}} of {{DNA Elements}} in the {{Human Genome}}},
  volume = {489},
  issn = {0028-0836},
  url = {http://www.nature.com/nature/journal/v489/n7414/full/nature11247.html},
  doi = {10.1038/nature11247},
  abstract = {The human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. These data enabled us to assign biochemical functions for 80\% of the genome, in particular outside of the well-studied protein-coding regions. Many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. The newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. Overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {7414},
  author = {Consortium, Encode},
  urldate = {2012-09-10},
  date = {2012-09-06},
  pages = {57--74},
  keywords = {Genetics,Genomics,Molecular biology}
}

@article{_2004,
  title = {The {{ENCODE}} ({{ENCyclopedia Of DNA Elements}}) {{Project}}},
  volume = {306},
  issn = {1095-9203},
  doi = {10.1126/science.1105136},
  abstract = {The ENCyclopedia Of DNA Elements (ENCODE) Project aims to identify all functional elements in the human genome sequence. The pilot phase of the Project is focused on a specified 30 megabases (approximately 1\%) of the human genome sequence and is organized as an international consortium of computational and laboratory-based scientists working to develop and apply high-throughput approaches for detecting all sequence elements that confer biological function. The results of this pilot phase will guide future efforts to analyze the entire human genome.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {5696},
  date = {2004-10-22},
  pages = {636--640},
  keywords = {Access to Information,Animals,Computational Biology,Conserved Sequence,databases,DNA,Evolution,genome,Genomics,human,Humans,Information Dissemination,Internet,Molecular,National Institutes of Health (U.S.),Nucleic Acid,Pilot Projects,Proteins,Publishing,Regulatory Sequences,Sequence Analysis,United States}
}

@article{Gerstein_2012,
  title = {Architecture of the {{Human Regulatory Network Derived}} from {{ENCODE Data}}},
  volume = {489},
  issn = {0028-0836},
  url = {http://www.nature.com/nature/journal/v489/n7414/full/nature11245.html},
  doi = {10.1038/nature11245},
  abstract = {Transcription factors bind in a combinatorial fashion to specify the on-and-off states of genes; the ensemble of these binding events forms a regulatory network, constituting the wiring diagram for a cell. To examine the principles of the human transcriptional regulatory network, we determined the genomic binding information of 119 transcription-related factors in over 450 distinct experiments. We found the combinatorial, co-association of transcription factors to be highly context specific: distinct combinations of factors bind at specific genomic locations. In particular, there are significant differences in the binding proximal and distal to genes. We organized all the transcription factor binding into a hierarchy and integrated it with other genomic information (for example, microRNA regulation), forming a dense meta-network. Factors at different levels have different properties; for instance, top-level transcription factors more strongly influence expression and middle-level ones co-regulate targets to mitigate information-flow bottlenecks. Moreover, these co-regulations give rise to many enriched network motifs (for example, noise-buffering feed-forward loops). Finally, more connected network components are under stronger selection and exhibit a greater degree of allele-specific activity (that is, differential binding to the two parental alleles). The regulatory information obtained in this study will be crucial for interpreting personal genome sequences and understanding basic principles of human biology and disease.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {7414},
  author = {Gerstein, Mark B. and Kundaje, Anshul and Hariharan, Manoj and Landt, Stephen G. and Yan, Koon-Kiu and Cheng, Chao and Mu, Xinmeng Jasmine and Khurana, Ekta and Rozowsky, Joel and Alexander, Roger and Min, Renqiang and Alves, Pedro and Abyzov, Alexej and Addleman, Nick and Bhardwaj, Nitin and Boyle, Alan P. and Cayting, Philip and Charos, Alexandra and Chen, David Z. and Cheng, Yong and Clarke, Declan and Eastman, Catharine and Euskirchen, Ghia and Frietze, Seth and Fu, Yao and Gertz, Jason and Grubert, Fabian and Harmanci, Arif and Jain, Preti and Kasowski, Maya and Lacroute, Phil and Leng, Jing and Lian, Jin and Monahan, Hannah and O’Geen, Henriette and Ouyang, Zhengqing and Partridge, E. Christopher and Patacsil, Dorrelyn and Pauli, Florencia and Raha, Debasish and Ramirez, Lucia and Reddy, Timothy E. and Reed, Brian and Shi, Minyi and Slifer, Teri and Wang, Jing and Wu, Linfeng and Yang, Xinqiong and Yip, Kevin Y. and Zilberman-Schapira, Gili and Batzoglou, Serafim and Sidow, Arend and Farnham, Peggy J. and Myers, Richard M. and Weissman, Sherman M. and Snyder, Michael},
  urldate = {2012-09-10},
  date = {2012-09-06},
  pages = {91--100},
  keywords = {Genetics,Genomics}
}

@article{Arvey_2012,
  title = {Sequence and {{Chromatin Determinants}} of {{Cell}}-{{Type}}–specific {{Transcription Factor Binding}}},
  volume = {22},
  issn = {1088-9051, 1549-5469},
  url = {http://genome.cshlp.org/content/22/9/1723},
  doi = {10.1101/gr.127712.111},
  abstract = {An international, peer-reviewed genome sciences journal featuring outstanding original research that offers novel insights into the biology of all organisms},
  timestamp = {2017-05-19T07:26:36Z},
  number = {9},
  author = {Arvey, Aaron and Agius, Phaedra and Noble, William Stafford and Leslie, Christina},
  urldate = {2012-09-10},
  date = {2012-01-09},
  pages = {1723--1734}
}

@article{_2011,
  title = {A {{User}}'s {{Guide}} to the {{Encyclopedia}} of {{DNA Elements}} ({{ENCODE}})},
  volume = {9},
  issn = {1544-9173},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3079585/},
  doi = {10.1371/journal.pbio.1001046},
  abstract = {The mission of the Encyclopedia of DNA Elements (ENCODE) Project is to enable the scientific and medical communities to interpret the human genome sequence and apply it to understand human biology and improve health. The ENCODE Consortium is integrating multiple technologies and approaches in a collective effort to discover and define the functional elements encoded in the human genome, including genes, transcripts, and transcriptional regulatory regions, together with their attendant chromatin states and DNA methylation patterns. In the process, standards to ensure high-quality data have been implemented, and novel algorithms have been developed to facilitate analysis. Data and derived results are made available through a freely accessible database. Here we provide an overview of the project and the resources it is generating and illustrate the application of ENCODE data to interpret the human genome., The Encyclopedia of DNA Elements (ENCODE) Project was created to enable the scientific and medical communities to interpret the human genome sequence and to use it to understand human biology and improve health. The ENCODE Consortium, a large group of scientists from around the world, uses a variety of experimental methods to identify and describe the regions of the 3 billion base-pair human genome that are important for function. Using experimental, computational, and statistical analyses, we aimed to discover and describe genes, transcripts, and transcriptional regulatory regions, as well as DNA binding proteins that interact with regulatory regions in the genome, including transcription factors, different versions of histones and other markers, and DNA methylation patterns that define states of the genome in various cell types. The ENCODE Project has developed standards for each experiment type to ensure high-quality, reproducible data and novel algorithms to facilitate analysis. All data and derived results are made available through a freely accessible database. This article provides an overview of the complete project and the resources it is generating, as well as examples to illustrate the application of ENCODE data as a user's guide to facilitate the interpretation of the human genome.},
  timestamp = {2017-05-19T07:26:36Z},
  number = {4},
  urldate = {2012-09-10},
  date = {2011-04},
  pmcid = {PMC3079585}
}

@online{Anthony_2012,
  title = {Google {{Compute Engine}}: {{For}} \$2 {{Million}}/{{Day}}, {{Your Company Can Run}} the {{Third Fastest Supercomputer}} in the {{World}} | {{ExtremeTech}}},
  url = {http://www.extremetech.com/extreme/131962-google-compute-engine-for-2-millionday-your-company-can-run-the-third-fastest-supercomputer-in-the-world},
  shorttitle = {Google {{Compute Engine}}},
  abstract = {At the Google I/O conference in San Francisco, Google has announced the immediate availability of Compute Engine, an infrastructure-as-a-service (IAAS) product that directly competes with Amazon EC2 and Microsoft Azure.},
  timestamp = {2017-05-19T07:26:36Z},
  author = {Anthony, Sebastian},
  urldate = {2012-10-03},
  date = {2012}
}

@article{Huttenhower_2010,
  title = {A {{Quick Guide}} to {{Large}}-{{Scale Genomic Data Mining}}},
  volume = {6},
  url = {http://dx.plos.org/10.1371/journal.pcbi.1000779},
  timestamp = {2017-05-19T07:26:36Z},
  number = {5},
  author = {Huttenhower, C. and Hofmann, O.},
  urldate = {2012-10-04},
  date = {2010},
  pages = {e1000779}
}

@online{Team_2012,
  title = {The {{Galaxy Project}}: {{Online Bioinformatics Analysis}} for {{Everyone}}},
  url = {http://galaxy.psu.edu/},
  timestamp = {2017-05-19T07:26:36Z},
  author = {Team, Galaxy},
  urldate = {2012-10-05},
  date = {2012}
}

@article{Strasser_2012,
  title = {Data-{{Driven Sciences}}: {{From Wonder Cabinets}} to {{Electronic Databases}}},
  volume = {43},
  issn = {1879-2499},
  doi = {10.1016/j.shpsc.2011.10.009},
  shorttitle = {Data-{{Driven Sciences}}},
  timestamp = {2017-05-19T07:26:36Z},
  number = {1},
  author = {Strasser, Bruno J},
  date = {2012-03},
  pages = {85--87},
  keywords = {19th Century,21st Century,Computational Biology,databases,Factual,History,Natural History,Research Design,Science}
}

@article{Slikker_2010,
  title = {Of {{Genomics}} and {{Bioinformatics}}},
  volume = {10},
  issn = {1473-1150},
  doi = {10.1038/tpj.2010.59},
  timestamp = {2017-05-19T07:26:36Z},
  number = {4},
  author = {Slikker, Jr, W},
  date = {2010-08},
  pages = {245--246},
  keywords = {Computational Biology,Oligonucleotide Array Sequence Analysis,Pharmacogenetics,Quality Control,United States,United States Food and Drug Administration}
}

@book{Szallasi_2006,
  title = {System {{Modeling}} in {{Cellular Biology}}: {{From Concepts}} to {{Nuts}} and {{Bolts}}},
  isbn = {0-262-19548-8},
  shorttitle = {System {{Modeling}} in {{Cellular Biology}}},
  timestamp = {2017-05-19T07:26:36Z},
  publisher = {{MIT Press}},
  author = {Szallasi, Zoltan and Stelling, Jorg and Periwal, Vipul},
  date = {2006}
}

@book{Keller_2010,
  title = {The {{Mirage}} of a {{Space Between Nature}} and {{Nurture}}},
  isbn = {0-8223-4731-8},
  timestamp = {2017-05-19T07:26:36Z},
  publisher = {{Duke University Press}},
  author = {Keller, Evelyn Fox},
  date = {2010}
}

@article{Beaulieu_2012,
  title = {Rethinking {{Research Ethics}} for {{Mediated Settings}}},
  volume = {15},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1369118X.2010.535838},
  timestamp = {2017-05-19T07:26:36Z},
  number = {1},
  author = {Beaulieu, A. and Estalella, A.},
  urldate = {2012-10-08},
  date = {2012},
  pages = {23--42}
}

@article{Coles_2010,
  title = {Ethnographic {{Reform}}: {{A Technical Turn}}},
  url = {http://lch.sagepub.com/content/early/2010/11/12/1743872110379180.abstract},
  shorttitle = {Ethnographic {{Reform}}},
  timestamp = {2017-05-19T07:26:37Z},
  author = {Coles, K.},
  urldate = {2012-10-08},
  date = {2010}
}

@article{Beaulieu_2010,
  title = {Research {{Note}}: {{From Co}}-{{Location}} to {{Co}}-{{Presence}}: {{Shifts}} in the {{Use}} of {{Ethnography}} for the {{Study}} of {{Knowledge}}},
  volume = {40},
  url = {http://sss.sagepub.com/content/40/3/453.short},
  shorttitle = {Research {{Note}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {3},
  author = {Beaulieu, A.},
  urldate = {2012-10-08},
  date = {2010},
  pages = {453--470}
}

@article{Waterton_2010,
  title = {Experimenting with the {{Archive}}: {{STS}}-{{Ers}} as {{Analysts}} and {{Co}}-{{Constructors}} of {{Databases}} and {{Other Archival Forms}}},
  volume = {35},
  url = {http://sth.sagepub.com/content/35/5/645.short},
  shorttitle = {Experimenting with the {{Archive}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {5},
  author = {Waterton, C.},
  urldate = {2012-10-08},
  date = {2010},
  pages = {645--676}
}

@article{Ruff_1979,
  title = {Citation {{Analysis}} of a {{Scientific Career}}: {{A Case Study}}},
  volume = {9},
  url = {http://sss.sagepub.com/content/9/1/81.short},
  shorttitle = {Citation {{Analysis}} of a {{Scientific Career}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {1},
  author = {Ruff, I.},
  urldate = {2012-10-08},
  date = {1979},
  pages = {81--90}
}

@article{Neuhaus_2012,
  title = {Agile {{Ethics}} for {{Massified Research}} and {{Visualization}}},
  volume = {15},
  url = {http://www.tandfonline.com/doi/abs/10.1080/1369118X.2011.616519},
  timestamp = {2017-05-19T07:26:37Z},
  number = {1},
  author = {Neuhaus, F. and Webmoor, T.},
  urldate = {2012-10-08},
  date = {2012},
  pages = {43--65}
}

@article{Ribes_2010,
  title = {Sociotechnical {{Studies}} of {{Cyberinfrastructure}} and {{E}}-{{Research}}: {{Current Themes}} and {{Future Trajectories}}},
  volume = {19},
  url = {http://www.springerlink.com/index/0758541448001G53.pdf},
  shorttitle = {Sociotechnical {{Studies}} of {{Cyberinfrastructure}} and {{E}}-{{Research}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {3},
  author = {Ribes, D. and Lee, C. P.},
  urldate = {2012-10-08},
  date = {2010},
  pages = {231--244}
}

@article{Gilbert_1974,
  title = {Essay {{Review}}: {{The Quantitative Study}} of {{Science}}: {{An Examination}} of the {{Literature}}},
  volume = {4},
  issn = {0306-3127},
  url = {http://sss.sagepub.com/content/4/3/279.full.pdf+html},
  doi = {10.1177/030631277400400305},
  shorttitle = {Essay {{Review}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {3},
  author = {Gilbert, G. N. and Woolgar, S.},
  urldate = {2012-10-11},
  date = {1974-07-01},
  pages = {279--294}
}

@article{Small_1977,
  title = {A {{Co}}-{{Citation Model}} of a {{Scientific Specialty}}: {{A Longitudinal Study}} of {{Collagen Research}}},
  volume = {7},
  issn = {0306-3127},
  url = {http://sss.sagepub.com/content/7/2/139.full.pdf+html},
  doi = {10.1177/030631277700700202},
  shorttitle = {A {{Co}}-{{Citation Model}} of a {{Scientific Specialty}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {2},
  author = {Small, H. G.},
  urldate = {2012-10-11},
  date = {1977-05-01},
  pages = {139--166}
}

@article{Sullivan_1977,
  title = {Co-{{Citation Analyses}} of {{Science}}: {{An Evaluation}}},
  volume = {7},
  issn = {0306-3127},
  url = {http://sss.sagepub.com/content/7/2/223.full.pdf+html},
  doi = {10.1177/030631277700700205},
  shorttitle = {Co-{{Citation Analyses}} of {{Science}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {2},
  author = {Sullivan, D. and White, D. H. and Barboni, E. J.},
  urldate = {2012-10-11},
  date = {1977-05-01},
  pages = {223--240}
}

@article{Porter_1977,
  title = {Citation {{Analysis}}: {{Queries}} and {{Caveats}}},
  volume = {7},
  issn = {0306-3127},
  url = {http://sss.sagepub.com/content/7/2/257.full.pdf+html},
  doi = {10.1177/030631277700700207},
  shorttitle = {Citation {{Analysis}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {2},
  author = {Porter, A. L.},
  urldate = {2012-10-11},
  date = {1977-05-01},
  pages = {257--267}
}

@article{Rogers_2000,
  title = {Landscaping {{Climate Change}}: {{A Mapping Technique}} for {{Understanding Science}} and {{Technology Debates}} on the {{World Wide Web}}},
  volume = {9},
  timestamp = {2017-05-19T07:26:37Z},
  number = {2},
  author = {Rogers, R. and Marres, N.},
  date = {2000},
  pages = {141--163}
}

@article{Rogers_2002,
  title = {Operating {{Issue Networks}} on the {{Web}}},
  volume = {11},
  timestamp = {2017-05-19T07:26:37Z},
  number = {2},
  author = {Rogers, R.},
  date = {2002},
  pages = {191--213}
}

@article{Marres_2005,
  title = {Recipe for {{Tracing}} the {{Fate}} of {{Issues}} and {{Their Publics}} on the {{Web}}},
  timestamp = {2017-05-19T07:26:37Z},
  author = {Marres, N. and Rogers, R. and {others}},
  date = {2005}
}

@article{Cochrane_2009,
  title = {Petabyte-{{Scale Innovations}} at the {{European Nucleotide Archive}}},
  volume = {37},
  url = {http://nar.oxfordjournals.org/content/37/suppl_1/D19.short},
  timestamp = {2017-05-19T07:26:37Z},
  issue = {suppl 1},
  author = {Cochrane, G. and Akhtar, R. and Bonfield, J. and Bower, L. and Demiralp, F. and Faruque, N. and Gibson, R. and Hoad, G. and Hubbard, T. and Hunter, C.},
  urldate = {2012-11-08},
  date = {2009},
  pages = {D19--D25}
}

@article{Mardis_2011,
  title = {A {{Decade}}/'s {{Perspective}} on {{DNA Sequencing Technology}}},
  volume = {470},
  url = {http://www.nature.com/nature/journal/v470/n7333/abs/nature09796.html},
  timestamp = {2017-05-19T07:26:37Z},
  number = {7333},
  author = {Mardis, E. R.},
  urldate = {2012-11-08},
  date = {2011},
  pages = {198--203}
}

@article{Cupples_2004,
  title = {Estimating {{Risk Curves}} for {{First}}-{{Degree Relatives}} of {{Patients}} with {{Alzheimer}}'s {{Disease}}: {{The REVEAL Study}}},
  volume = {6},
  issn = {1098-3600},
  doi = {10.109701.GIM.0000132679.92238.58},
  shorttitle = {Estimating {{Risk Curves}} for {{First}}-{{Degree Relatives}} of {{Patients}} with {{Alzheimer}}'s {{Disease}}},
  abstract = {PURPOSE The REVEAL study is a randomized, controlled study of the psychological and behavioral impact of APOE disclosure in a risk assessment protocol provided to first degree relatives of patients with Alzheimer's disease. The protocol presents risk information as cumulative incidence curves. This article describes how these curves were estimated. METHODS Curves were calculated using Bayes' rule to compute the posterior survival curves incorporating APOE information. RESULTS A combination of survival data from the MIRAGE study and gender- and age-specific APOE odds ratios were used to create risk curves for males and females within each of the 6 APOE genotypes. CONCLUSION Utilizing comparative genotype relative risk information and survival data from family studies, estimates of gender-, age-, and genotype-specific risk can be generated for use in a risk assessment research study that features genotype disclosure.},
  timestamp = {2017-05-19T07:26:37Z},
  number = {4},
  author = {Cupples, L Adrienne and Farrer, Lindsay A and Sadovnick, A Dessa and Relkin, Norman and Whitehouse, Peter and Green, Robert C},
  year = {2004 Jul-Aug},
  pages = {192--196},
  keywords = {80 and over,Adult,Aged,Alzheimer Disease,Apolipoprotein E3,Apolipoprotein E4,Apolipoproteins E,Case-Control Studies,Family Health,Genetic Counseling,Genotype,Humans,Male,Middle Aged,Randomized Controlled Trials as Topic,Risk}
}

@article{Foster_2007,
  title = {The {{Work}} of the {{New Economy}}: {{Consumers}}, {{Brands}}, and {{Value Creation}}},
  volume = {22},
  url = {http://onlinelibrary.wiley.com/doi/10.1525/can.2007.22.4.707/abstract},
  shorttitle = {The {{Work}} of the {{New Economy}}},
  timestamp = {2017-05-19T07:26:37Z},
  number = {4},
  author = {Foster, R. J.},
  urldate = {2012-12-05},
  date = {2007},
  pages = {707--731}
}

@article{ProjectConsortium_2012,
  title = {Structure, {{Function}} and {{Diversity}} of the {{Healthy Human Microbiome}}},
  volume = {486},
  url = {http://www.nature.com/nature/journal/v486/n7402/full/nature11234.html},
  doi = {10.1038/nature11234},
  abstract = {Studies of the human microbiome have revealed that even healthy individuals differ remarkably in the microbes that occupy habitats such as the gut, skin and vagina. Much of this diversity remains unexplained, although diet, environment, host genetics and early microbial exposure have all been implicated. Accordingly, to characterize the ecology of human-associated microbial communities, the Human Microbiome Project has analysed the largest cohort and set of distinct, clinically relevant body habitats so far. We found the diversity and abundance of each habitat’s signature microbes to vary widely even among healthy subjects, with strong niche specialization both within and among individuals. The project encountered an estimated 81–99\% of the genera, enzyme families and community configurations occupied by the healthy Western microbiome. Metagenomic carriage of metabolic pathways was stable among individuals despite variation in community structure, and ethnic/racial background proved to be one of the strongest associations of both pathways and microbes with clinical metadata. These results thus delineate the range of structural and functional configurations normal in the microbial communities of a healthy population, enabling future characterization of the epidemiology, ecology and translational applications of the human microbiome.},
  timestamp = {2017-05-19T07:26:37Z},
  number = {7402},
  author = {ProjectConsortium, Human Microbiome},
  urldate = {2012-12-03},
  date = {2012-06-14},
  pages = {207},
  keywords = {Ecology,Genetics,Genomics,Health and medicine,Microbiology}
}

@article{Chen_2012,
  title = {Random {{Forests}} for {{Genomic Data Analysis}}},
  volume = {99},
  issn = {0888-7543},
  url = {http://www.sciencedirect.com/science/article/pii/S0888754312000626},
  doi = {10.1016/j.ygeno.2012.04.003},
  abstract = {Random forests (RF) is a popular tree-based ensemble machine learning tool that is highly data adaptive, applies to “large p, small n” problems, and is able to account for correlation as well as interactions among features. This makes RF particularly appealing for high-dimensional genomic data analysis. In this article, we systematically review the applications and recent progresses of RF for genomic data, including prediction and classification, variable selection, pathway analysis, genetic association and epistasis detection, and unsupervised learning.},
  timestamp = {2017-05-19T07:26:37Z},
  number = {6},
  author = {Chen, Xi and Ishwaran, Hemant},
  urldate = {2012-12-13},
  date = {2012-06},
  pages = {323--329},
  keywords = {Classification,Genomic data analysis,Prediction,Random forests,Random survival forests,Variable selection}
}

@article{Tuv_2009,
  title = {Feature {{Selection}} with {{Ensembles}}, {{Artificial Variables}}, and {{Redundancy Elimination}}},
  volume = {10},
  url = {http://dl.acm.org/citation.cfm?id=1577069.1755828},
  timestamp = {2017-05-19T07:26:38Z},
  author = {Tuv, E. and Borisov, A. and Runger, G. and Torkkola, K.},
  urldate = {2012-12-13},
  date = {2009},
  pages = {1341--1366}
}

@article{Shendure_2012,
  title = {The {{Expanding Scope}} of {{DNA Sequencing}}},
  volume = {30},
  issn = {1087-0156},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nbt/journal/v30/n11/full/nbt.2421.html},
  doi = {10.1038/nbt.2421},
  abstract = {In just seven years, next-generation technologies have reduced the cost and increased the speed of DNA sequencing by four orders of magnitude, and experiments requiring many millions of sequencing reads are now routine. In research, sequencing is being applied not only to assemble genomes and to investigate the genetic basis of human disease, but also to explore myriad phenomena in organismic and cellular biology. In the clinic, the utility of sequence data is being intensively evaluated in diverse contexts, including reproductive medicine, oncology and infectious disease. A recurrent theme in the development of new sequencing applications is the creative 'recombination' of existing experimental building blocks. However, there remain many potentially high-impact applications of next-generation DNA sequencing that are not yet fully realized.},
  timestamp = {2017-05-19T07:26:38Z},
  number = {11},
  author = {Shendure, Jay and Aiden, Erez Lieberman},
  urldate = {2013-01-23},
  date = {2012},
  pages = {1084--1094}
}

@article{Rohde_2011,
  title = {Open-{{Source Genomic Analysis}} of {{Shiga}}-{{Toxin}}–{{Producing E}}. {{Coli O104}}:{{H4}}},
  volume = {365},
  issn = {0028-4793},
  url = {http://www.nejm.org/doi/full/10.1056/NEJMoa1107643},
  doi = {10.1056/NEJMoa1107643},
  shorttitle = {Open-{{Source Genomic Analysis}} of {{Shiga}}-{{Toxin}}–{{Producing E}}. {{Coli O104}}},
  abstract = {Escherichia coli is a widespread commensal of the mammalian gut and a versatile pathogen.1,2 Enterovirulent strains of E. coli are classified into a number of overlapping pathotypes, which include Shiga-toxin–producing, enterohemorrhagic, and enteroaggregative varieties.2 Enteroaggregative E. coli strains have been associated with sporadic and epidemic diarrhea and, in the laboratory, show a distinctive pattern of adherence to Hep-2 cells (termed aggregative, or “stacked brick”).3 In Shiga-toxin–producing E. coli, the toxin is encoded on a prophage and inhibits protein synthesis within susceptible eukaryotic cells. Strains of enterohemorrhagic E. coli produce Shiga toxin and a specific protein secretion system (called a . . .},
  timestamp = {2017-05-19T07:26:38Z},
  number = {8},
  author = {Rohde, Holger and Qin, Junjie and Cui, Yujun and Li, Dongfang and Loman, Nicholas J. and Hentschke, Moritz and Chen, Wentong and Pu, Fei and Peng, Yangqing and Li, Junhua and Xi, Feng and Li, Shenghui and Li, Yin and Zhang, Zhaoxi and Yang, Xianwei and Zhao, Meiru and Wang, Peng and Guan, Yuanlin and Cen, Zhong and Zhao, Xiangna and Christner, Martin and Kobbe, Robin and Loos, Sebastian and Oh, Jun and Yang, Liang and Danchin, Antoine and Gao, George F. and Song, Yajun and Li, Yingrui and Yang, Huanming and Wang, Jian and Xu, Jianguo and Pallen, Mark J. and Wang, Jun and Aepfelbacher, Martin and Yang, Ruifu},
  urldate = {2013-01-23},
  date = {2011},
  pages = {718--724}
}

@article{Siva_2008,
  title = {1000 {{Genomes Project}}},
  volume = {26},
  issn = {1087-0156},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nbt/journal/v26/n3/full/nbt0308-256b.html},
  doi = {10.1038/nbt0308-256b},
  abstract = {Nature Biotechnology journal featuring biotechnology articles and science research papers of commercial interest in pharmaceutical, medical, and environmental sciences.},
  timestamp = {2017-05-19T07:26:38Z},
  number = {3},
  author = {Siva, Nayanah},
  urldate = {2013-01-23},
  date = {2008},
  pages = {256--256}
}

@article{Leinonen_2010,
  title = {Improvements to {{Services}} at the {{European Nucleotide Archive}}},
  volume = {38},
  issn = {0305-1048},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2808951/},
  doi = {10.1093/nar/gkp998},
  abstract = {The European Nucleotide Archive (ENA; http://www.ebi.ac.uk/ena) is Europe’s primary nucleotide sequence archival resource, safeguarding open nucleotide data access, engaging in worldwide collaborative data exchange and integrating with the scientific publication process. ENA has made significant contributions to the collaborative nucleotide archival arena as an active proponent of extending the traditional collaboration to cover capillary and next-generation sequencing information. We have continued to co-develop data and metadata representation formats with our collaborators for both data exchange and public data dissemination. In addition to the DDBJ/EMBL/GenBank feature table format, we share metadata formats for capillary and next-generation sequencing traces and are using and contributing to the NCBI SRA Toolkit for the long-term storage of the next-generation sequence traces. During the course of 2009, ENA has significantly improved sequence submission, search and access functionalities provided at EMBL–EBI. In this article, we briefly describe the content and scope of our archive and introduce major improvements to our services.},
  timestamp = {2017-05-19T07:26:38Z},
  issue = {Database issue},
  author = {Leinonen, Rasko and Akhtar, Ruth and Birney, Ewan and Bonfield, James and Bower, Lawrence and Corbett, Matt and Cheng, Ying and Demiralp, Fehmi and Faruque, Nadeem and Goodgame, Neil and Gibson, Richard and Hoad, Gemma and Hunter, Christopher and Jang, Mikyung and Leonard, Steven and Lin, Quan and Lopez, Rodrigo and Maguire, Michael and McWilliam, Hamish and Plaister, Sheila and Radhakrishnan, Rajesh and Sobhany, Siamak and Slater, Guy and Ten Hoopen, Petra and Valentin, Franck and Vaughan, Robert and Zalunin, Vadim and Zerbino, Daniel and Cochrane, Guy},
  urldate = {2013-01-24},
  date = {2010-01},
  pages = {D39--D45},
  pmcid = {PMC2808951}
}

@article{Loman_2012,
  title = {Performance {{Comparison}} of {{Benchtop High}}-{{Throughput Sequencing Platforms}}},
  volume = {30},
  issn = {1087-0156},
  url = {http://www.nature.com/nbt/journal/v30/n5/full/nbt.2198.html},
  doi = {10.1038/nbt.2198},
  abstract = {Three benchtop high-throughput sequencing instruments are now available. The 454 GS Junior (Roche), MiSeq (Illumina) and Ion Torrent PGM (Life Technologies) are laser-printer sized and offer modest set-up and running costs. Each instrument can generate data required for a draft bacterial genome sequence in days, making them attractive for identifying and characterizing pathogens in the clinical setting. We compared the performance of these instruments by sequencing an isolate of Escherichia coli O104:H4, which caused an outbreak of food poisoning in Germany in 2011. The MiSeq had the highest throughput per run (1.6 Gb/run, 60 Mb/h) and lowest error rates. The 454 GS Junior generated the longest reads (up to 600 bases) and most contiguous assemblies but had the lowest throughput (70 Mb/run, 9 Mb/h). Run in 100-bp mode, the Ion Torrent PGM had the highest throughput (80–100 Mb/h). Unlike the MiSeq, the Ion Torrent PGM and 454 GS Junior both produced homopolymer-associated indel errors (1.5 and 0.38 errors per 100 bases, respectively).},
  timestamp = {2017-05-19T07:26:38Z},
  number = {5},
  author = {Loman, Nicholas J. and Misra, Raju V. and Dallman, Timothy J. and Constantinidou, Chrystala and Gharbia, Saheer E. and Wain, John and Pallen, Mark J.},
  urldate = {2013-01-24},
  date = {2012},
  pages = {434--439}
}

@article{Cochrane_2013,
  title = {Facing {{Growth}} in the {{European Nucleotide Archive}}},
  volume = {41},
  url = {http://nar.oxfordjournals.org/content/41/D1/D30.short},
  timestamp = {2017-05-19T07:26:38Z},
  issue = {D1},
  author = {Cochrane, G. and Alako, B. and Amid, C. and Bower, L. and Cerdeño-Tárraga, A. and Cleland, I. and Gibson, R. and Goodgame, N. and Jang, M. and Kay, S.},
  urldate = {2013-01-24},
  date = {2013},
  pages = {D30--D35}
}

@article{Cochrane_2012,
  title = {The {{Future}} of {{DNA Sequence Archiving}}},
  volume = {1},
  url = {http://www.biomedcentral.com/content/pdf/2047-217X-1-2.pdf},
  timestamp = {2017-05-19T07:26:38Z},
  number = {1},
  author = {Cochrane, G. and Cook, C. E. and Birney, E.},
  urldate = {2013-01-24},
  date = {2012},
  pages = {2}
}

@article{Cochrane_2011,
  title = {The {{International Nucleotide Sequence Database Collaboration}}},
  volume = {39},
  issn = {0305-1048},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013722/},
  doi = {10.1093/nar/gkq1150},
  abstract = {Under the International Nucleotide Sequence Database Collaboration (INSDC; http://www.insdc.org), globally comprehensive public domain nucleotide sequence is captured, preserved and presented. The partners of this long-standing collaboration work closely together to provide data formats and conventions that enable consistent data submission to their databases and support regular data exchange around the globe. Clearly defined policy and governance in relation to free access to data and relationships with journal publishers have positioned INSDC databases as a key provider of the scientific record and a core foundation for the global bioinformatics data infrastructure. While growth in sequence data volumes comes no longer as a surprise to INSDC partners, the uptake of next-generation sequencing technology by mainstream science that we have witnessed in recent years brings a step-change to growth, necessarily making a clear mark on INSDC strategy. In this article, we introduce the INSDC, outline data growth patterns and comment on the challenges of increased growth.},
  timestamp = {2017-05-19T07:26:38Z},
  issue = {Database issue},
  author = {Cochrane, Guy and Karsch-Mizrachi, Ilene and Nakamura, Yasukazu},
  urldate = {2013-01-24},
  date = {2011-01},
  pages = {D15--D18},
  pmcid = {PMC3013722}
}

@online{DDBJ_2013,
  title = {Introduction of {{DDBJ}} | {{DDBJ}}},
  url = {http://www.ddbj.nig.ac.jp/intro-e.html},
  timestamp = {2017-05-19T07:26:38Z},
  author = {{DDBJ}},
  urldate = {2013-01-25},
  date = {2013}
}

@online{Callaway_2011,
  title = {Unpopular {{Genomic Database Faces Budget Axe}} : {{Nature News Blog}}},
  url = {http://blogs.nature.com/news/2011/02/database_cuts.html},
  timestamp = {2017-05-19T07:26:38Z},
  author = {Callaway, Ewen},
  urldate = {2013-01-29},
  date = {2011}
}

@online{SEQanswers_2011,
  title = {Short {{Read Archive Canned}} - {{SEQanswers}}},
  url = {http://seqanswers.com/forums/showthread.php?t=9431},
  timestamp = {2017-05-19T07:26:38Z},
  author = {{SEQanswers}},
  urldate = {2013-01-29},
  date = {2011}
}

@online{NCBI_2011,
  title = {Status of the {{NCBI Sequence Read Archive}} ({{SRA}})},
  url = {http://www.ncbi.nlm.nih.gov/About/news/13Oct2011.html},
  timestamp = {2017-05-19T07:26:38Z},
  author = {{NCBI}},
  urldate = {2013-01-29},
  date = {2011}
}

@article{Goldman_2013,
  title = {Towards {{Practical}}, {{High}}-{{Capacity}}, {{Low}}-{{Maintenance Information Storage}} in {{Synthesized DNA}}},
  issn = {0028-0836},
  url = {http://www.nature.com.ezproxy.lancs.ac.uk/nature/journal/vaop/ncurrent/full/nature11875.html},
  doi = {10.1038/nature11875},
  abstract = {Digital production, transmission and storage have revolutionized how we access and use information but have also made archiving an increasingly complex task that requires active, continuing maintenance of digital media. This challenge has focused some interest on DNA as an attractive target for information storage because of its capacity for high-density information encoding, longevity under easily achieved conditions and proven track record as an information bearer. Previous DNA-based information storage approaches have encoded only trivial amounts of information or were not amenable to scaling-up, and used no robust error-correction and lacked examination of their cost-efficiency for large-scale information archival. Here we describe a scalable method that can reliably store more information than has been handled before. We encoded computer files totalling 739 kilobytes of hard-disk storage and with an estimated Shannon information of 5.2 × 106 bits into a DNA code, synthesized this DNA, sequenced it and reconstructed the original files with 100\% accuracy. Theoretical analysis indicates that our DNA-based storage scheme could be scaled far beyond current global information volumes and offers a realistic technology for large-scale, long-term and infrequently accessed digital archiving. In fact, current trends in technological advances are reducing DNA synthesis costs at a pace that should make our scheme cost-effective for sub-50-year archiving within a decade.},
  timestamp = {2017-05-19T07:26:38Z},
  author = {Goldman, Nick and Bertone, Paul and Chen, Siyuan and Dessimoz, Christophe and LeProust, Emily M. and Sipos, Botond and Birney, Ewan},
  urldate = {2013-01-29},
  date = {2013},
  keywords = {DNA and RNA,DNA nanotechnology,Information technology,Synthetic Biology}
}

@article{Stevens_2012,
  title = {Dr. {{Sanger}}, {{Meet Mr}}. {{Moore}}},
  volume = {34},
  issn = {1521-1878},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/bies.201100146/abstract},
  doi = {10.1002/bies.201100146},
  timestamp = {2017-05-19T07:26:38Z},
  number = {2},
  author = {Stevens, Hallam},
  urldate = {2013-02-04},
  date = {2012},
  pages = {103--105}
}

@article{Zerbino_2012,
  title = {Integrating {{Genomes}}},
  volume = {336},
  issn = {0036-8075, 1095-9203},
  url = {http://www.sciencemag.org.ezproxy.lancs.ac.uk/content/336/6078/179},
  doi = {10.1126/science.1216830},
  abstract = {As genomic sequencing projects attempt ever more ambitious integration of genetic, molecular, and phenotypic information, a specialization of genomics has emerged, embodied in the subdiscipline of computational genomics. Models inherited from population genetics, phylogenetics, and human disease genetics merge with those from graph theory, statistics, signal processing, and computer science to provide a rich quantitative foundation for genomics that can only be realized with the aid of a computer. Unleashed on a rapidly increasing sample of the planet’s 1030 organisms, these analyses will have an impact on diverse fields of science while providing an extraordinary new window into the story of life.},
  timestamp = {2017-05-19T07:26:38Z},
  number = {6078},
  author = {Zerbino, D. R. and Paten, B. and Haussler, D.},
  urldate = {2013-02-11},
  date = {2012-04-13},
  pages = {179--182}
}

@article{Li_2009,
  title = {The {{Sequence Alignment}}/{{Map Format}} and {{SAMtools}}},
  volume = {25},
  issn = {1367-4803, 1460-2059},
  url = {http://bioinformatics.oxfordjournals.org/content/25/16/2078},
  doi = {10.1093/bioinformatics/btp352},
  abstract = {Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments. Availability: http://samtools.sourceforge.net Contact: rd@sanger.ac.uk},
  timestamp = {2017-05-19T07:26:38Z},
  number = {16},
  author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard},
  urldate = {2013-02-14},
  date = {2009-08-15},
  pages = {2078--2079}
}

@online{_l,
  title = {Genomic {{Data}} // {{CIRCOS Circular Genome Data Visualization}}},
  url = {http://circos.ca/intro/genomic_data/},
  timestamp = {2017-05-19T07:26:38Z},
  urldate = {2013-03-13}
}

@article{Stevens_2011a,
  title = {On the {{Means}} of {{Bio}}-{{Production}}: {{Bioinformatics}} and {{How}} to {{Make Knowledge}} in a {{High}}-{{Throughput Genomics Laboratory}}},
  volume = {6},
  issn = {1745-8552},
  url = {http://www.palgrave-journals.com/biosoc/journal/v6/n2/abs/biosoc201038a.html},
  doi = {10.1057/biosoc.2010.38},
  shorttitle = {On the {{Means}} of {{Bio}}-{{Production}}},
  abstract = {Accounts of ‘biocapital’ abound in studies of the contemporary biosciences. However, these have tended to pay attention to the use and consumption of biological knowledge rather than the means and conditions of the production of data. This article draws on an ethnographic account of a high-throughput genomics laboratory (the Eli and Edythe L. Broad Institute, Cambridge, MA) to show how the means through which biological data is produced exerts a determinative effect on the kind of knowledge that is generated by the laboratory. High-speed, high-volume, high-efficiency production of data requires the high-throughput consumption of data by statistical and computational techniques. These techniques, in turn, generate general, broad-scale accounts of biological systems, rather than particular knowledge about individual genes or biological components. This cycle of production and consumption is described as ‘bioinformatics’ in order to indicate the centrality of computers and computing to the knowledge production process in contemporary biology.},
  timestamp = {2017-05-19T07:26:38Z},
  number = {2},
  author = {Stevens, Hallam},
  urldate = {2013-10-25},
  date = {2011-06},
  pages = {217--242},
  keywords = {biocapital,bioinformatics,Broad Institute,consumption,Genomics,production}
}

@book{Stevens_2013,
  location = {{Chicago, London}},
  title = {Life out of {{Sequence}}: {{A Data}}-{{Driven History}} of {{Bioinformatics}}},
  isbn = {978-0-226-08017-8 0-226-08017-X 978-0-226-08020-8 0-226-08020-X},
  shorttitle = {Life out of {{Sequence}}},
  timestamp = {2017-05-19T07:26:38Z},
  publisher = {{University Of Chicago Press}},
  author = {Stevens, Hallam},
  date = {2013}
}

@article{Buchanan_2013,
  title = {Issues {{Surrounding}} the {{Health Economic Evaluation}} of {{Genomic Technologies}}},
  volume = {14},
  issn = {1462-2416, 1744-8042},
  url = {http://www.futuremedicine.com/doi/pdf/10.2217/pgs.13.183},
  doi = {10.2217/pgs.13.183},
  timestamp = {2017-05-19T07:26:39Z},
  number = {15},
  author = {Buchanan, James and Wordsworth, Sarah and Schuh, Anna},
  urldate = {2013-11-26},
  date = {2013-11},
  pages = {1833--1847}
}

@article{Tsing_2009,
  title = {Supply {{Chains}} and the {{Human Condition}}},
  volume = {21},
  url = {http://www.tandfonline.com/doi/abs/10.1080/08935690902743088},
  timestamp = {2017-05-19T07:26:39Z},
  number = {2},
  author = {Tsing, Anna},
  urldate = {2013-11-29},
  date = {2009},
  pages = {148--176}
}

